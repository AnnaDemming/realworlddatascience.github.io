[
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact us",
    "section": "",
    "text": "Email: b.tarran@rss.org.uk\nGitHub: @realworlddatascience\nTwitter: @rwdatasci\nMastodon: @rwdatasci\nLinkedin: RSS Real World Data Science"
  },
  {
    "objectID": "contact.html#advertising-and-commercial",
    "href": "contact.html#advertising-and-commercial",
    "title": "Contact us",
    "section": "Advertising and commercial",
    "text": "Advertising and commercial\nEmail: advertising@rss.org.uk"
  },
  {
    "objectID": "contact.html#the-royal-statistical-society",
    "href": "contact.html#the-royal-statistical-society",
    "title": "Contact us",
    "section": "The Royal Statistical Society",
    "text": "The Royal Statistical Society\nReal World Data Science is a project of the Royal Statistical Society (RSS). The Society was founded in 1834 and is one of the world’s leading organisations advocating for the importance of statistics and data.\nRSS has more than 10,000 members in the UK and across the world. As a charity, it advocates for the key role of statistics and data in society, and works to ensure that policy formulation and decision making are informed by evidence for the public good.\nTo support the work of the RSS, including Real World Data Science and other projects, become a member today.\nEmail: info@rss.org.uk"
  },
  {
    "objectID": "contributor-docs/exercises.html",
    "href": "contributor-docs/exercises.html",
    "title": "Exercises",
    "section": "",
    "text": "Exercises on Real World Data Science will provide users with the opportunity to put knowledge, skills and new learnings into practice, helping them to challenge and refine problem-solving approaches while strengthening the analytical mindset.\nWe will achieve this by supporting contributors to design tasks that replicate real-world data scientific processes."
  },
  {
    "objectID": "contributor-docs/exercises.html#structure",
    "href": "contributor-docs/exercises.html#structure",
    "title": "Exercises",
    "section": "Structure",
    "text": "Structure\nThe structure of each published exercise will vary based on the nature of the task(s) being set by contributors and the outcomes they have in mind. But, in general, exercises must do more than simply ask users to, e.g., download dataset – analyse – report.\n\n\nSet the scene\n\nProvide a believable, realistic scenario for the exercise. Establish the “client challenge” within that context, the resources available to the data scientist, and the outputs expected.\n\n\n\nGive users space to map the problem themselves\n\nHave users translate the “client challenge” into a data analytic question that can be answered using the resources available.\n\n\n\nMake data exploration, cleaning and tidying part of the process\n\nData exploration and preparation are an important part of most – if not all – data science projects, so let users loose on messy datasets so they can figure out for themselves (a) what they’re working with and (b) what analytical approach makes sense given the features of the data and the problem at hand.\n\n\n\nIntegrate ethics\n\nPrompt users to think about and work through ethical questions and issues that are relevant to the exercise: the challenge they’ve been set, the data they’ve been given, their proposed approach to analysis and modelling, etc.\n\n\n\nEncourage users to document their work and their thinking\n\nThrough computational notebooks (e.g., Jupyter notebooks), users can record not only what they’ve done and how they’ve done it, but why.\n\n\n\nMake data presentation part of the expected project outputs\n\nAsk users to think about presenting to specific audiences: not just fellow data scientists, but to decision-makers, policy experts, the public – whatever makes most sense given the exercise scenario."
  },
  {
    "objectID": "contributor-docs/exercises.html#advice-and-recommendations",
    "href": "contributor-docs/exercises.html#advice-and-recommendations",
    "title": "Exercises",
    "section": "Advice and recommendations",
    "text": "Advice and recommendations\nInvite users to share their work. If users have followed the advice to document their work and thinking, encourage them to share their computational notebooks (including their results and outputs) on their own websites, in a GitHub repository, through social media, etc. This could be a great way for others to discover your exercise, and we could also link to a selection of these notebooks through the exercise page itself.\nThink about building in hints and tips. Some users – depending on their prior level of experience – might appreciate some additional guidance here and there.\n\n\n\n\n\n\nSpoiler warning\n\n\n\n\n\nCollapsible callouts like this make hints and tips visible only to those who want to see them.\n\n\n\nBring different resources together. Exercises provide an ideal opportunity to draw together different strands of the Real World Data Science platform: case studies could provide inspiration or pointers for how to tackle a particular challenge; explainers might contain useful information about the tools and techniques to apply to specific types of data; and if you’re looking for a suitable set of data, it may already be listed in our datasets section."
  },
  {
    "objectID": "contributor-docs/style-guide.html",
    "href": "contributor-docs/style-guide.html",
    "title": "Style guide",
    "section": "",
    "text": "Content must be presented in a conversational yet professional and respectful tone. Contributors should imagine themselves delivering a lively, engaging conference presentation, rather than preparing a dry, formal report or journal publication. Contributors to Real World Data Science are creating content for their colleagues and peers and should “speak” to them as such."
  },
  {
    "objectID": "contributor-docs/style-guide.html#structure",
    "href": "contributor-docs/style-guide.html#structure",
    "title": "Style guide",
    "section": "Structure",
    "text": "Structure\nEach contribution must, in effect, tell “a story”, and so contributors need to be clear (a) what their story is, (b) why people should be interested, and (c) what its main message or key takeaways are. To help figure this out, we recommend contributors apply the XY Story Formula."
  },
  {
    "objectID": "contributor-docs/style-guide.html#technical-content-and-jargon",
    "href": "contributor-docs/style-guide.html#technical-content-and-jargon",
    "title": "Style guide",
    "section": "Technical content and jargon",
    "text": "Technical content and jargon\nTechnical content is a necessary feature of a site like ours. Without it, an article or other piece of content may be of little practical use to a technical audience. But if there’s too much of it, even experts may struggle to stay engaged. Contributors are also faced with a dilemma when it comes to explaining technical content: explain nothing, and you risk alienating some of your audience; explain everything, and you’ll struggle to establish a clear, strong narrative thread. So, careful consideration is required:\n\nWho is my audience for this article?\nWhat is this audience likely to know already, and what needs to be explained?\nIf something needs to be explained, can I do so briefly and then link to other resources? Or is a full explanation required?\nIn telling my “story”, what are the absolute-need-to-knows, and what are the simply-nice-to-knows?\n\nThinking through these questions will help contributors to find the right mix of valuable, technical content paired with accessible, readable narrative.\nKeep in mind that the same general advice applies to the use of industry jargon. Jargon can be a valuable shorthand when communicating with people working in the same organisation or sector, but those working in different fields may struggle to make sense of it. So, contributors need to think carefully about how much jargon to use, and what needs to be explained."
  },
  {
    "objectID": "contributor-docs/style-guide.html#figuresgraphics",
    "href": "contributor-docs/style-guide.html#figuresgraphics",
    "title": "Style guide",
    "section": "Figures/graphics",
    "text": "Figures/graphics\nAll data visualisations and other graphical outputs directly related to the content of submissions must be presented neatly and cleanly (avoid chart junk). They should also be labelled correctly and legibly, with colours chosen carefully to ensure they can be easily distinguished by all readers. Accompanying captions must be written to support the reader’s understanding of the visual presentation (e.g., “Figure 1: a bar chart” is an insufficient description).\nIf contributors wish to use charts or graphs that are not their own work, they must ensure that such items are correctly sourced and referenced, and that permission to republish has been obtained. A letter or email confirming this permission is required."
  },
  {
    "objectID": "contributor-docs/style-guide.html#data-sources",
    "href": "contributor-docs/style-guide.html#data-sources",
    "title": "Style guide",
    "section": "Data sources",
    "text": "Data sources\nContributors must include within their submissions any links and/or references to the sources of data, code and/or software and software packages on which their analyses are based. We understand that some data sources may not be publicly available, whether for legal, ethical or commercial reasons. However, readers must still be told where the data come from, even if they are not able to access the data themselves."
  },
  {
    "objectID": "contributor-docs/style-guide.html#references",
    "href": "contributor-docs/style-guide.html#references",
    "title": "Style guide",
    "section": "References",
    "text": "References\nCitations are to be formatted in The Chicago Manual of Style author-date format."
  },
  {
    "objectID": "contributor-docs/style-guide.html#use-of-images",
    "href": "contributor-docs/style-guide.html#use-of-images",
    "title": "Style guide",
    "section": "Use of images",
    "text": "Use of images\nImages for general illustration purposes will be sourced and – where necessary and within reason – paid for by Real World Data Science.\n\n\n\n\n\n\n\nNote\n\n\n\nFor all other style-related matters, we follow The Guardian and Observer Style Guide."
  },
  {
    "objectID": "contributor-docs/case-studies.html",
    "href": "contributor-docs/case-studies.html",
    "title": "Case studies",
    "section": "",
    "text": "Case studies are a core feature of the Real World Data Science platform. Our case studies are designed to show how data science is used to solve real-world problems in business, public policy and beyond.\nA good case study will be a source of information, insight and inspiration for each of our target audiences:"
  },
  {
    "objectID": "contributor-docs/case-studies.html#structure",
    "href": "contributor-docs/case-studies.html#structure",
    "title": "Case studies",
    "section": "Structure",
    "text": "Structure\nCase studies should follow the structure below. It is not necessary to use the section headings we have provided – creativity and variety are encouraged. However, the areas outlined under each section heading should be covered in all submissions.\n\n\nThe problem/challenge\n\nSummarise the project and its relevance to your organisation’s needs, aims and ambitions.\n\n\n\nGoals\n\nSpecify what exactly you sought to achieve with this project.\n\n\n\nBackground\n\nAn opportunity to explain more about your organisation, your team’s work leading up to this project, and to introduce audiences more generally to the type of problem/challenge you faced, particularly if it is a problem/challenge that may be experienced by organisations working in different sectors and industries.\n\n\n\nApproach\n\nDescribe how you turned the organisational problem/challenge into a task that could be addressed by data science. Explain how you proposed to tackle the problem, including an introduction, explanation and (possibly) a demonstration of the method, model or algorithm used. (NB: If you have a particular interest and expertise in the method, model or algorithm employed, including the history and development of the approach, please consider writing an Explainer article for us.) Discuss the pros and cons, strengths and limitations of the approach.\n\n\n\nImplementation\n\nWalk audiences through the implementation process. Discuss any challenges you faced, the ethical questions you needed to ask and answer, and how you tested the approach to ensure that outcomes would be robust, unbiased, good quality, and aligned with the goals you set out to achieve.\n\n\n\nImpact\n\nHow successful was the project? Did you achieve your goals? How has the project benefited your organisation? How has the project benefited your team? Does it inform or pave the way for future projects?\n\n\n\nLearnings\n\nWhat are your key takeaways from the project? Are there lessons that you can apply to future projects, or are there learnings for other data scientists working on similar problems/challenges?"
  },
  {
    "objectID": "contributor-docs/case-studies.html#advice-and-recommendations",
    "href": "contributor-docs/case-studies.html#advice-and-recommendations",
    "title": "Case studies",
    "section": "Advice and recommendations",
    "text": "Advice and recommendations\nYou do not need to divulge the detailed inner workings of your organisation. Audiences are mostly interested in understanding the general use case and the problem-solving process you went through, to see how they might apply the same approach within their own organisations.\nGoals can be defined quite broadly. There’s no expectation that you set out your organisation’s short- or long-term targets. Instead, audiences need to know enough about what you want to do so they can understand what motivates your choice of approach.\nUse toy examples and synthetic data to good effect. We understand that – whether for commercial, legal or ethical reasons – it can be difficult or impossible to share real data in your case studies, or to describe the actual outputs of your work. However, there are many ways to share learnings and insights without divulging sensitive information. This blog post from Lyft uses hypotheticals, mathematical notation and synthetic data to explain the company’s approach to causal forecasting without revealing actual KPIs or data.\nPeople like to experiment, so encourage them to do so. Our platform allows you to embed code and to link that code to interactive coding environments like Google Colab. So if, for example, you want to explain a technique like bootstrapping, why not provide a code block so that audiences can run a bootstrapping simulation themselves.\nLeverage links. You can’t be expected to explain or cover every detail in one case study, so feel free to point audiences to other sources of information that can enrich their understanding: blogs, videos, journal articles, conference papers, etc."
  },
  {
    "objectID": "contributor-docs/call-for-contributions.html",
    "href": "contributor-docs/call-for-contributions.html",
    "title": "Call for contributions",
    "section": "",
    "text": "Real World Data Science aims to inform, inspire and strengthen the data science community by showcasing real-world examples of data science practice and bringing together data scientists to share knowledge.\nWe cannot succeed in these aims without the support and contributions of the data science community, so thank you for taking the time to review this open call for contributions."
  },
  {
    "objectID": "contributor-docs/call-for-contributions.html#what-are-we-looking-for",
    "href": "contributor-docs/call-for-contributions.html#what-are-we-looking-for",
    "title": "Call for contributions",
    "section": "What are we looking for?",
    "text": "What are we looking for?\nBelow is a list of our core content areas. We welcome submissions in any of these areas. Each content area is linked to its own set of notes for contributors.\n\nCase studies\nExplainers\nExercises\nDatasets\nTraining guides\nRecommenders\n\nSubmissions can focus on any and all topics and application areas. We want our content to reflect the breadth and depth of real-world data science."
  },
  {
    "objectID": "contributor-docs/call-for-contributions.html#our-target-audience",
    "href": "contributor-docs/call-for-contributions.html#our-target-audience",
    "title": "Call for contributions",
    "section": "Our target audience",
    "text": "Our target audience\nReal World Data Science is for all who work in data science - whether they are students, teachers, practitioners or leaders. Submissions do not have to appeal to all data scientists, however. Contributors should think carefully about who they are trying to reach, and craft their submissions accordingly."
  },
  {
    "objectID": "contributor-docs/call-for-contributions.html#what-can-submissions-include",
    "href": "contributor-docs/call-for-contributions.html#what-can-submissions-include",
    "title": "Call for contributions",
    "section": "What can submissions include?",
    "text": "What can submissions include?\nWe encourage contributors to experiment with and include different media formats in their submissions - text, images, audio and video. And as our site is built on Quarto - the new open-source publishing system developed by RStudio - submissions to Real World Data Science can also include code cells, equations, figures, interactive data displays, and other elements to enrich the user experience. If you haven’t used Quarto before, check out this fantastic tutorial from the developers."
  },
  {
    "objectID": "contributor-docs/call-for-contributions.html#how-to-submit",
    "href": "contributor-docs/call-for-contributions.html#how-to-submit",
    "title": "Call for contributions",
    "section": "How to submit",
    "text": "How to submit\nOnce you’ve reviewed our notes for contributors and settled on a content area, theme and audience, please review our contributor guidelines for details on the submission process."
  },
  {
    "objectID": "contributor-docs/recommender.html",
    "href": "contributor-docs/recommender.html",
    "title": "Recommenders",
    "section": "",
    "text": "Too much content, not enough time. That about sums up the problem facing the data science community. So, our Recommenders are here to help. Contributors are invited to submit lists (or Feeds) of high-quality sources on all manner of topics – from foundational ideas in data science and cutting-edge techniques, to opinion and thought-leadership on the future of the profession. Reviews of new books and other material are also welcome."
  },
  {
    "objectID": "contributor-docs/recommender.html#article-types-and-structures",
    "href": "contributor-docs/recommender.html#article-types-and-structures",
    "title": "Recommenders",
    "section": "Article types and structures",
    "text": "Article types and structures\n\nFeeds\nFeeds can be constructed around different topics and audiences. For example, you might want to recommend to all data scientists the “10 best blogs on machine learning” or “5 data visualisation experts to follow on Twitter”. Or you might have a list of sources specifically targeted at data science educators (e.g., “the best books on teaching coding”) or data science leaders (“5 insightful case studies on building data science teams”).\nWhatever you choose to focus on, the following outline provides a basic guide for structuring your feed:\n\n\nOverview\n\nA brief introduction to your list, its main focus, who you are writing it for, and why. You should also say something about yourself and your background, too. This will give additional context to the recommendations you are making.\n\n\n\nList of sources\n\nAs well as naming your sources and telling people how to find them, you should also explain why you are recommending them, how they helped you in your career or studies, or other reasons why you find them to be of value. Sample quotes or small excerpts from the sources themselves might also be worth including.\n\n\n\nStart a dialogue\n\nConclude with a call for readers to share recommendations of their own, either in the article comments or on social media. Contributors are welcome to update their lists any time with new sources, including those suggested by site users.\n\n\n\n\n\nReviews\nUnlike the feeds described above, each submitted review should focus only on a single publication. It must be an honest summary of the reviewer’s thoughts, feelings and impressions, covering what they liked and didn’t like, the perceived strengths and weaknesses of the publication, and whether it is likely to be of interest and value to its intended audience. Reviews should of course provide an overview of the publication in question but must avoid dry, itemised descriptions of the publication’s constituent parts (e.g., listing out the chapters in a book).\nAll reviews should list the following information (if relevant):\n\nTitle of publication\nAuthor(s)\nDate of publication\nEdition or format used for review\nPublisher\nLength\nPrice\nWebsite address or other source of further information"
  },
  {
    "objectID": "contributor-docs/recommender.html#advice-and-recommendations",
    "href": "contributor-docs/recommender.html#advice-and-recommendations",
    "title": "Recommenders",
    "section": "Advice and recommendations",
    "text": "Advice and recommendations\nKeep lists to a sensible size. Feeds are meant to help data scientists to prioritise who and what to follow based on their interests and career stage – and it is much easier to keep tabs on 5 sources than it is 50, or even 15! So, the fewer the better.\nKeep your recommendations up to date. In this era of digital publishing, things can and do change overnight. So, if one of your recommended bloggers stops blogging, or the author of one of your favourite books makes a major update to the text, do be sure to let us – and your audience – know. We want to keep feeds and reviews current and useful.\nOf course you are brilliant, but… Please do not recommend or review your own publications or those in which you have a pecuniary or similar interest."
  },
  {
    "objectID": "contributor-docs/explainers.html",
    "href": "contributor-docs/explainers.html",
    "title": "Explainers",
    "section": "",
    "text": "On Real World Data Science, Explainers are the stories behind the stories of data science in action. They are deep-dive explorations of the ideas, concepts, tools, and methods that make data science projects possible. In particular, we are keen to explore and explain the statistical underpinnings of modern data science techniques.\nA good Explainer will lead audiences through the what, when, how, and why of its chosen topic. The ultimate goal is to equip data scientists with the information and insight they need to make smarter, more informed analytical choices.\nThere are many different but effective ways of structuring an explainer and plentiful written examples in major media outlets like The Guardian and Vox, but these are generally written for a non-technical audience. Examples of technical explainers (with interactive elements) can be found on Amazon’s Machine Learning University."
  },
  {
    "objectID": "contributor-docs/explainers.html#structure",
    "href": "contributor-docs/explainers.html#structure",
    "title": "Explainers",
    "section": "Structure",
    "text": "Structure\nThe following outline is a basic guide to structuring an Explainer:\n\n\nHook\n\nIntroduce your topic, and explain why audiences should pay attention. For example, does your Explainer link to one of our published case studies? Does it focus on a tool or method that has been the subject of recent attention? Is it a foundational idea that is relevant to all sorts of data science applications?\n\n\n\nHigh-level summary\n\nA short, largely non-technical explanation of your topic. A good way to view this section is as an accessible condensed version of your complete Explainer. In thinking of it in this way, you can subtly signpost to audiences the areas you’ll be covering and the questions you’ll be answering throughout the remainder of your contribution.\n\n\n\nHistory and background\n\nIt can be useful from a practical perspective to explain how ideas, concepts, tools, and methods have developed over time. Applications may have become more complex in recent years, so exploring the origins of data science techniques might lead you to discover simpler use cases that can help support and illustrate your high-level summary.\n\n\n\nThe how, the when, the why\n\nThis section of your Explainer will likely be split into multiple subsections as you seek to build up your audience’s understanding of your chosen topic. It can be helpful to think about the sorts of questions an audience member might ask and to structure your contribution so that it directly addresses those questions (Q&A/FAQ formats are commonly used in explainer-type articles). If the focus of your Explainer is a data science method, for example, you’ll want to address the following:\n\n\n\nHow does it work and how is it applied (perhaps with an example or simulation)?\nWhat are the underlying assumptions?\nHow is performance checked and assessed?\nHow should outputs be interpreted?\nWhat are the pros and cons, the strengths and limitations of the approach?\nWhat are the optimal use cases, and when should the method be avoided altogether?\nAre there alternatives that people should know about?\n\n\nKey takeaways\n\nThis serves as your final summary: a chance to remind your audience of what they’ve learned from your Explainer and the main points they should keep in mind.\n\n\n\nTell me more\n\nIt’s sensible to assume that some of your audience will have further questions and will want to learn more about the topic. If you have additional sources of information to recommend, make sure to share them here."
  },
  {
    "objectID": "contributor-docs/explainers.html#advice-and-recommendations",
    "href": "contributor-docs/explainers.html#advice-and-recommendations",
    "title": "Explainers",
    "section": "Advice and recommendations",
    "text": "Advice and recommendations\nFocus on what’s important. Your Explainer can’t hope to explain everything, so you need to be clear about what’s essential for your audience to know and what isn’t. Make good use of links and references to point audiences to other valuable sources of information that can enrich their understanding of your topic.\nBe clear about your target audience and their expected prior level of knowledge. In keeping with the point above, you need to be clear in your own mind about how much you expect your audience to know already about the general topic or subject matter. You can then structure your contribution accordingly. It might also be helpful to state explicitly, at the outset of your contribution, what assumptions you’ve made about your audience and highlight any background reading that might be beneficial.\nPlan out your route. To help you decide what to cover in your Explainer, we recommend first writing out your high-level summary of the topic and also your key takeaways. This provides you with a start point (A) and an end point (B) for your contribution. The challenge then is to figure out the main points or questions you will need to address to help your audience progress from point A to point B in a way that’s logical and intuitive for them to follow."
  },
  {
    "objectID": "contributor-docs/training-guides.html",
    "href": "contributor-docs/training-guides.html",
    "title": "Training guides",
    "section": "",
    "text": "In data science, there’s no one-size-fits-all solution to every problem and challenge. So, part of the job of the data scientist is to rapidly learn about different sub-domains, tools and techniques, and put those learnings into practice.\nBut it can be time-consuming to figure out what you need to learn and in what order, and to identify the best resources for doing so. This is where our Training guides come in. Each will set out a learning pathway for data scientists to follow, with recommendations of textbooks, videos, practical exercises and other teaching material to use every step of the way."
  },
  {
    "objectID": "contributor-docs/training-guides.html#structure",
    "href": "contributor-docs/training-guides.html#structure",
    "title": "Training guides",
    "section": "Structure",
    "text": "Structure\nContributors should think about their training guides as being short online courses that are constructed from existing high-quality material. You do not need to create your own “course” content. Rather, you should focus on recommending texts and other material for users to follow in a logical ordered way, so that they may build up and secure their knowledge of a particular topic.\nGuides should feature a mix of content types – not only text, but audio and video – and they should provide ample opportunities for users to practice what they are learning.\nA brief and extremely simplified example of a guide is as follows:\n\nStep 1: Watch this introductory video on Topic X.\nStep 2: Now you are familiar with the basics of Topic X, you will want to read Chapter 2 of Textbook Y, which delves into more of the mathematical underpinnings.\nStep 3: Let’s try Topic X ourselves. This GitHub repository has code for you to run it in Python. Copy the code and give it a go.\nStep 4: You should now be ready to apply Topic X to a simple data challenge. Check out this Kaggle page and practice what you have learned so far.\nStep 5: We’re now moving from the “beginner” level to “intermediate”, and Training Course Z gives a thorough overview of what you need to know for the next stage of your learning journey.\n… etc."
  },
  {
    "objectID": "contributor-docs/training-guides.html#advice-and-recommendations",
    "href": "contributor-docs/training-guides.html#advice-and-recommendations",
    "title": "Training guides",
    "section": "Advice and recommendations",
    "text": "Advice and recommendations\nBe mindful of different learning styles. Some people prefer to read, others prefer to watch or listen. So, wherever possible, for each stage of your training guide, try to provide a mix of resources that meet the same learning objectives.\nConsider barriers to entry. Data scientists in large organisations may have access to training budgets or mechanisms to apply for training funds. But that isn’t the case for all data scientists, meaning that paid-for materials and training courses might not be accessible to everyone. Recommend them sparingly, and if there are ways to access the material at reduced rates do let users know. However, you must not link to illicit copies of material – e.g., unauthorised PDF reproductions of textbooks.\nIf there are resource gaps, please tell us. While planning out your training guide, you may well struggle to find the perfect piece of content to recommend at a particular stage of your learning journey. If that is the case, do get in touch with us. One of the goals of Real World Data Science is to identify and plug these sorts of gaps, so that all in the data science community can benefit. We’ll sketch out a commission and take it out to our network of contacts. Or perhaps it’ll be something you want to create for the site!"
  },
  {
    "objectID": "contributor-docs/contributor-guidelines.html",
    "href": "contributor-docs/contributor-guidelines.html",
    "title": "Contributor guidelines",
    "section": "",
    "text": "Thank you for your interest in contributing to Real World Data Science. This page will walk you through the process of preparing and submitting your idea. If you haven’t done so already, please review our call for contributions before continuing."
  },
  {
    "objectID": "contributor-docs/contributor-guidelines.html#site-functionality-and-ethos",
    "href": "contributor-docs/contributor-guidelines.html#site-functionality-and-ethos",
    "title": "Contributor guidelines",
    "section": "Site functionality and ethos",
    "text": "Site functionality and ethos\nReal World Data Science is built on Quarto, the new open-source publishing system developed by RStudio. The site has been designed from the ground up as a platform for data scientists, created by data scientists. Here’s what this means in practice:\n\nContributors can use data science software and tools to create content – e.g. Visual Studio Code, RStudio, Jupyter Lab; Python, R, Observable, and Shiny – allowing for the full integration of text, code, figures, equations, and other elements.\nReview and editing are transparent and collaborative, again making use of tools data scientists are familiar with – e.g. GitHub, Google Docs – for sharing and revising documents prior to publication.\nContent can be both engaging and interactive. Many data scientists learn by doing, so code can be made available as R Markdown or Jupyter Notebook files to be reused and experimented with offline. Or, the same documents can be used online through tools like Google Colab and Binder. Where appropriate, the use of interactive displays and Shiny apps is encouraged, allowing for data visualisations to be interrogated and regenerated on the fly.\nSite users are contributors too. Through annotation and commenting functionality, site users can interact and converse with authors and other members of the Real World Data Science community. And with all source files hosted on GitHub, users of our site can raise issues, or fork and propose improvements – leading to a true exchange of knowledge."
  },
  {
    "objectID": "contributor-docs/contributor-guidelines.html#the-submission-process",
    "href": "contributor-docs/contributor-guidelines.html#the-submission-process",
    "title": "Contributor guidelines",
    "section": "The submission process",
    "text": "The submission process\n\nContact site editor Brian Tarran to discuss your proposed submission.\nWorking with the editor, draw up a short content brief, containing the following:\n\nTitle of submission\nAuthor name(s) and affiliation(s)\nTheme/topic area\nTarget audience\nSynopsis or sell line, summarising the story and its importance/value (100 words max.)\nKey audience takeaways\nFormats and features (e.g., text, audio, video; code blocks, interactive data visualisations, etc.)\nAccessibility considerations\nTarget length/word count\nFirst draft to be submitted by…\n\nOnce a content brief is finalised and approved, content is to be prepared in the agreed format and with reference to our style guide. For simple text-based articles, we recommend using Google Docs or Microsoft Word; for submissions that incorporate technical or multimedia content, such as code, equations or interactive graphics, we recommend the Quarto (.qmd) file format, but documents can also be submitted in Jupyter notebook (.ipynb) and R Markdown (.Rmd) formats.\nDraft submissions should be sent via email to the editor. Alternatively, contributors can commit their drafts to their own GitHub accounts and add the Real World Data Science GitHub account as a collaborator."
  },
  {
    "objectID": "contributor-docs/contributor-guidelines.html#copyright-and-content-licencing",
    "href": "contributor-docs/contributor-guidelines.html#copyright-and-content-licencing",
    "title": "Contributor guidelines",
    "section": "Copyright and content licencing",
    "text": "Copyright and content licencing\nContributors retain copyright of their work, but agree to publish their work under a Creative Commons licence. Contributors are free to choose the licence that best suits their content. The chosen licence should be indicated on the draft submission."
  },
  {
    "objectID": "contributor-docs/contributor-guidelines.html#the-review-process",
    "href": "contributor-docs/contributor-guidelines.html#the-review-process",
    "title": "Contributor guidelines",
    "section": "The review process",
    "text": "The review process\nDraft submissions will be shared for review with members of the Real World Data Science Editorial Board. Comments and edits to documents will be made via Google Docs/MS Word/GitHub, allowing for (a) version control, (b) open dialogue between reviewers and contributors, and (c) a transparent and well-documented review process.\nOnce revisions are complete and content is accepted for publication, authors will be provided with HTML files to preview published content. Following sign-off by author and editor, HTML files will be made live."
  },
  {
    "objectID": "contributor-docs/contributor-guidelines.html#post-publication",
    "href": "contributor-docs/contributor-guidelines.html#post-publication",
    "title": "Contributor guidelines",
    "section": "Post-publication",
    "text": "Post-publication\nContributors and editors will work together to promote content via social media platforms – Twitter, LinkedIn, blogs – and in other channels as appropriate – e.g., in response to related questions on Quora or Stack Overflow.\nContributors are encouraged to monitor their content regularly for user comments and discussions. Engaging in discussions with users – whether through the Real World Data Science platform or via social media and other channels – is an effective way of developing an audience: it builds profile for the contributor and their content, and encourages other users to find and interact with content."
  },
  {
    "objectID": "contributor-docs/datasets.html",
    "href": "contributor-docs/datasets.html",
    "title": "Datasets",
    "section": "",
    "text": "It’s easy to find datasets online. What’s more difficult is finding quality datasets that are suitable for specific training and development needs. On Real World Data Science we aim to solve that problem.\nOur Datasets section will provide a curated list of recommended datasets along with detailed notes and guidance on what each dataset contains, how it is structured, and how best to make use of it. In particular, we want to highlight messy rather than pristine datasets – ones that capture the imperfections and oddities found in real-world data – so that users can practice not only data analysis and modelling, but data cleaning and preparation too!"
  },
  {
    "objectID": "contributor-docs/datasets.html#structure",
    "href": "contributor-docs/datasets.html#structure",
    "title": "Datasets",
    "section": "Structure",
    "text": "Structure\nIf you have a dataset to recommend, your submission must cover the following areas:\n\nDataset name\nLink to source\nWhat data science tasks/methods can this dataset be used to demonstrate?\nHave you used this dataset for your own teaching/learning? (see Advice and recommendations below)\nWhy was the dataset originally created?\nWhen was it created?\nWho created it?\nLicences/restrictions?\nSize of dataset\nData types/description\nReal/synthetic data?"
  },
  {
    "objectID": "contributor-docs/datasets.html#advice-and-recommendations",
    "href": "contributor-docs/datasets.html#advice-and-recommendations",
    "title": "Datasets",
    "section": "Advice and recommendations",
    "text": "Advice and recommendations\nHelp others to make good use of your recommended dataset. If you’ve had experience using a recommended dataset for your own teaching and learning, please consider creating an exercise for platform users to complete. If you encountered the dataset as part of a training course, competition or exercise created by a third party, make sure to give them a namecheck."
  },
  {
    "objectID": "news-and-views/index.html",
    "href": "news-and-views/index.html",
    "title": "News and views",
    "section": "",
    "text": "Four themes for potential contributors to think about\n\n\n\n\n\n\n\nUpdates\n\n\nKey themes\n\n\nContent ideas\n\n\n\n\nCan data science save the world? What is a data scientist? What statistical ideas do data scientists need to know? And, what’s happening in the world of data science?\n\n\n\n\n\n\nDec 1, 2022\n\n\nBrian Tarran\n\n\n\n\n\n\n  \n\n\n\n\nWhy large language models should come with a content warning\n\n\n\n\n\n\n\nMachine learning\n\n\nLarge language models\n\n\nAI\n\n\n\n\nThe outputs of LLMs seem impressive, but users need to be wary of possible bias, plagiarism and model ‘hallucinations’\n\n\n\n\n\n\nNov 23, 2022\n\n\nBrian Tarran\n\n\n\n\n\n\n  \n\n\n\n\nMeet the team\n\n\n\n\n\n\n\nPeople\n\n\nBiographies\n\n\n\n\nIntroducing the editors of Real World Data Science\n\n\n\n\n\n\nOct 18, 2022\n\n\nEditorial Board\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "news-and-views/editors-blog/index.html",
    "href": "news-and-views/editors-blog/index.html",
    "title": "Editors’ blog",
    "section": "",
    "text": "Four themes for potential contributors to think about\n\n\n\n\n\n\n\nUpdates\n\n\nKey themes\n\n\nContent ideas\n\n\n\n\nCan data science save the world? What is a data scientist? What statistical ideas do data scientists need to know? And, what’s happening in the world of data science?\n\n\n\n\n\n\nDec 1, 2022\n\n\nBrian Tarran\n\n\n\n\n\n\n  \n\n\n\n\nWhy large language models should come with a content warning\n\n\n\n\n\n\n\nMachine learning\n\n\nLarge language models\n\n\nAI\n\n\n\n\nThe outputs of LLMs seem impressive, but users need to be wary of possible bias, plagiarism and model ‘hallucinations’\n\n\n\n\n\n\nNov 23, 2022\n\n\nBrian Tarran\n\n\n\n\n\n\n  \n\n\n\n\nMeet the team\n\n\n\n\n\n\n\nPeople\n\n\nBiographies\n\n\n\n\nIntroducing the editors of Real World Data Science\n\n\n\n\n\n\nOct 18, 2022\n\n\nEditorial Board\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "news-and-views/editors-blog/posts/2022-10-18-meet-the-team/meet-the-team.html",
    "href": "news-and-views/editors-blog/posts/2022-10-18-meet-the-team/meet-the-team.html",
    "title": "Meet the team",
    "section": "",
    "text": "Brian Tarran\n\n\n\nI am a writer and editor with 20 years of experience covering the research and data space. I have worked for the Royal Statistical Society (RSS) for the past 8 years, and was editor of Significance Magazine (a joint publication of the RSS, the American Statistical Association and the Statistical Society of Australia) prior to the launch of Real World Data Science. I am a former editor of Research-Live.com and was launch editor of Impact magazine, both published by the Market Research Society."
  },
  {
    "objectID": "news-and-views/editors-blog/posts/2022-10-18-meet-the-team/meet-the-team.html#editorial-board",
    "href": "news-and-views/editors-blog/posts/2022-10-18-meet-the-team/meet-the-team.html#editorial-board",
    "title": "Meet the team",
    "section": "Editorial Board",
    "text": "Editorial Board\nSophie Carr (chair)\n\n\n\nI am the founder and owner of Bays Consulting. I trained as an engineer and took a PhD in Bayesian belief networks, and have worked in data analytics ever since. Or to put it another way, I have made a living out of finding patterns. I am the vice-president for education and statistical literacy at the RSS, officially one of the World’s Most Interesting Mathematicians and was a member of the first cohort of data scientists to achieve the new, defined standard of professionalism award from the Alliance for Data Science Professionals.\nI am delighted to be chairing the editorial board of the new data science project from the RSS and am excited to be a part of this project as it evolves into a key resource for all data science practitioners and leaders. To make this a place that helps everyone learn and develop within this field, I’d like to encourage all practitioners, no matter what stage of their career, to submit the type of resource they learn best from (whether that be an article, some code, a data set, a case study or a problem/exercise to solve) on a topic that is important to them – from ethics to analysis plans through to tips on how code. Whatever it is you’re working on that you care about, I’d like to ask you to become an active part of the wonderful community of data scientists by sharing your knowledge.\nSayma Chowdhury\n\n\n\nI am a freelance data scientist on Upwork, with a client portfolio ranging from start-ups to commercial businesses such as supermarkets, pharmaceuticals and automotive manufacturers. I transitioned into data science from law in 2017, having completed a MicroMasters in statistics and data science with MIT and a Professional Certificate in data science with Harvard University. In advance of a PhD in digital humanities, I am currently completing a MicroMasters in data, economy and development policy with MIT and an MSc in data science with the University of Aberdeen. My research interests are in text analytics, natural language processing and machine learning.\nThe RSS was instrumental in my training and professional development as a data scientist in the early stages of my career, particularly in mastering statistics and R. Data science is a rapidly growing field with employment opportunities in many sectors but there is an increasing need to uphold a realistic and accurate expectation of competency within the industry. I will endeavour to present expert practical guidelines for data scientists as well as demonstrate the versatility of the profession. I hope the site will be a benchmark for academic and professional resources by expert data scientists from industry, accessible to data scientists at all levels, anywhere in the world.\nLee Clewley\n\n\n\nI am head of applied AI in GSK’s AI and Machine Learning Group, R&D. I began my career as an astrophysicist, initially working out the mass of our galaxy, before pondering the bigger universe. After six years at Oxford as a post-doc lecturer publishing in theoretical cosmology, I entered the very real world of manufacturing at GSK. For the first five years I applied statistical modelling techniques across manufacturing, such as the first end-to-end continuous manufacturing prototype for tablets. The past decade has been spent as a lead data scientist delivering high value projects across R&D and manufacturing.\nI joined this editorial board because the impulse to assemble and present complex data science ideas to a wide range of folks has never left me. I have been a data scientist leader since it became a distinct profession but also have a decent understanding of classical and modern predictive analytics tools and statistics. I have spent a good deal of my adult life teaching students and non-technical adults alike.\nI am passionate about delivering useful, pragmatic data science ideas and products to a wide range of people. I enjoy trying to communicate complex scientific information simply. Alongside my peers in the team, I want to support and develop data scientists at whatever stage in their career. I want to help cut through the hype and nonsense to give the best advice possible in a highly respected institution like the RSS.\nJonathan Gillard\n\n\n\nI am a professor at the School of Mathematics, Cardiff University, where I am also research group lead for statistics. I have a history of publications in statistical methods and an interest in the theoretical underpinnings of data science, but I have also worked with industry on applied and practical projects. Recent industrial partners of mine include the Office for National Statistics (ONS) and the National Health Service, on projects such as anomaly detection and understanding heterogeneity. Indeed, I am academic chair for Cardiff University’s strategic partnership with the ONS which serves to spur and catalyse collaboration between both organisations.\nI am excited to see what this site can achieve. I’m particularly keen to support articles describing the latest, cutting-edge methodology, as well as contributions from data professionals in industry who can explain how data science has managed to offer insights into important problems. Data science is a broad church and I want to ensure that the full array of work in this area is represented on this site. I think the diversity of the editorial board will help promote this objective.\nJuhi Gupta\n\n\n\nI am a lecturer in health data sciences and the deputy programme director of the health data science MSc in the School of Health Sciences, University of Manchester (UoM). I have a background in genetics, pharmacology and bioinformatics, and my doctoral thesis focussed on multi-omics data analysis using machine learning methods for precision medicine. I have worked with scientists, clinical academics and technologists to produce translational research. I am currently investigating adverse health outcomes in people with common diseases using electronic health record data, and I also teach on the health informatics MSc joint programme with UoM and UCL.\nI would like to see this platform encourage collaborations and the sharing of ideas and good practice across different disciplines that apply data science skills in their work (or as a hobby). I would like to support budding data scientists to gain useful advice and guidance for upskilling as well as application in real-world situations involving health data and biological data.\nHollie Johnson\n\n\n\nI am a data scientist at the National Innovation Centre for Data (NICD), based in Newcastle upon Tyne. Following my undergraduate degree in mathematics, I worked as a software developer both in industry and as a technical research assistant in academia. I later joined the Centre for Doctoral Training in Cloud Computing for Big Data at Newcastle and obtained a PhD in topological data analysis in 2020. Now at the NICD, I specialise in transferring statistics and machine learning skills into industry, through collaborative data science projects.\nI am excited to be a member of the editorial board and look forward to seeing Real World Data Science develop into a valuable source of information for aspiring data scientists and professionals alike. I would particularly encourage submissions that demonstrate the use of data science in SMEs and the non-profit sector, as well as perspectives from those with non-standard backgrounds.\nHarvey Lewis\n\n\n\nI am a senior technology leader, with a diverse background spanning rocket science, data science and research. I have 30 years of experience in artificial intelligence and other emerging technologies and am currently pioneering the use of AI in Ernst & Young’s tax and law practice. I’m a former member of the Open Data User Group, the Public Sector Transparency Board and the Advisory Committee to the All-Party Parliamentary Group on AI. I am a member of techUK’s leadership committee for data analytics and AI, and an honorary senior visiting fellow at The Bayes Business School in London.\nI’m passionate about data science but I’m also a fierce advocate for human skills, which are as often underrated as AI is over-hyped. As a member of the editorial board, I’m keen to explore the interplay between artificial and human intelligence in businesses. I’m going to encourage all data scientists to think about the fundamentally human aspects of their work, such as trust and safety, so that we maintain perspective and proportionality in the face of ever-more sophisticated technology.\nDetlef Nauck\n\n\n\nI am a BT Distinguished Engineer and the head of AI and data science research for BT’s Applied Research Division located at Adastral Park, Ipswich, UK. I have over 30 years of experience in AI and machine learning and lead a programme spanning the work of a large team of international researchers who develop capabilities underpinning future AI systems. A key part of this work is to establish best practices in data science and machine learning, leading to the deployment of responsible and auditable AI solutions that are driving real business value.\nI am a computer scientist by training and hold a PhD and a Postdoctoral Degree (Habilitation) in machine learning and data analytics. I am also a visiting professor at Bournemouth University and a private docent at the Otto-von-Guericke University of Magdeburg, Germany. I have published 3 books and over 120 papers, and I hold 15 patents and have 30 active patent applications.\nI am passionate about promoting best practice in data science and believe that in the UK the RSS is the ideal professional body to pursue this goal. For me, Real World Data Science is an opportunity to share my experience and inspire a new generation of data scientists.\nFatemeh Torabi\n\n\n\nI am a research officer and data scientist at Health Data Research UK and a fellow of the RSS. My background is in mathematical statistics and health data science, and my research interests span novel analytical and computational methods for statistical inference in panel data and population health. I am supporting the development of the Real World Data Science platform in the context of health with a specific focus on how health data can be harnessed through data linkage and analysis to answer important questions and improve the lives of our population.\nIsabel Sassoon\n\n\n\nI am a senior lecturer in computer science (data science) at Brunel University and the programme lead for the data science and analytics MSc programme. My research interests are in data-driven automated reasoning and its transparency and explainability, which brings in data science and artificial intelligence with applications within the health space. I am also championing open science and reproducible analysis in both my research and teaching. I have a PhD in informatics from King’s College London and it was on the topic related to the use of AI to support statistical model selection. Prior to Brunel I was a teaching fellow and research associate at King’s College London and before that I worked for more than 10 years as a data science consultant in industry, including 8 years at SAS UK. \nI have been working, researching, consulting and teaching in the data science space for a while and I am passionate about the domain and its applications. I am always interested in sharing and hearing what else is being done to support, inform and inspire all those studying and working in the field of data science. I look forward to sharing case studies, how-to guides and data science profiles through this website.\nChristopher Thiele\n\n\n\nI’m a principal data scientist at Uniper where I lead a team that focuses mainly on financial business processes and upskilling initiatives. We run projects end to end: from use case ideation, requirement collection and translation to prototyping, assessment, deployment and maintenance. Besides the core analytical and data engineering duties, overarching topics such as data design, data governance and data strategy predominate my days. In my previous role, at the German Economic Institute, I contributed to the development of a cross-functional department that helps apply data science methods in economic research. Projects often involve geospatial analyses or natural language processing. Before that, I worked as a data scientist in customer and marketing analytics, doing statistical analyses such as marketing mix modelling. I have a master’s degree in statistics from Warwick University, a bachelor’s degree in economics from the University of Cologne and I’m trained as an assistant tax consultant in Germany.\nI see data science as a creative way to solve problems using software engineering and quantitative modelling techniques and I like to build software pieces that people can interact with. I think that there still exists a lot of confusion about data science as a discipline. Reducing it would promote the realisation of its potential for individuals, as a profession, and our society, as a form of digitalisation. I hope that with Real World Data Science we can provide guidance and clarification to everybody engaged or interested in the field and accompany this young profession’s development."
  },
  {
    "objectID": "news-and-views/editors-blog/posts/2022-11-23-LLMs-content-warning/LLM-content-warning.html",
    "href": "news-and-views/editors-blog/posts/2022-11-23-LLMs-content-warning/LLM-content-warning.html",
    "title": "Why large language models should come with a content warning",
    "section": "",
    "text": "Anyone who has ever been set a writing task will probably have wished at some point that somebody else could write it for them. As a journalist of 20-plus years, the thought has certainly crossed my mind more than a few times. Which probably explains why a recent headline in Nature caught my attention: “Could AI help you to write your next paper?”\nThe article, by Matthew Hutson, looks at how researchers are using artificial intelligence (AI) tools built on large language models (LLMs) as “assistants”. Starting with a prompt, such as “Write a headline for a blog post about large language models being used by academic researchers as research assistants”, an LLM will produce a text output. For example, using the same prompt with OpenAI’s GPT-3, I got:\nAsked to “Write a headline for a blog post that critiques academic researchers’ use of large language models as research assistants”, GPT-3 produced:\nAnd when I asked “Why can too much reliance on large language models hinder research?”, GPT-3 wrote:\nA fair point, I suppose. But I sense there’s more to this story, and rather than continue quizzing GPT-3, I sat down with Detlef Nauck, a member of the Real World Data Science Editorial Board and head of AI and data science research for BT’s Applied Research Division, to ask a few more questions."
  },
  {
    "objectID": "news-and-views/editors-blog/posts/2022-11-23-LLMs-content-warning/LLM-content-warning.html#qa",
    "href": "news-and-views/editors-blog/posts/2022-11-23-LLMs-content-warning/LLM-content-warning.html#qa",
    "title": "Why large language models should come with a content warning",
    "section": "Q&A",
    "text": "Q&A\n\nThanks for joining me today, Detlef. To start, could you give a brief overview of these large language models, what they are, and how they work?\n\nDetlef Nauck (DN): Essentially, LLMs match sequences to sequences. Language is treated as a sequence of patterns, and this is based on word context similarity. The way these things work is that they either reuse or create a word vector space, where a word is mapped to something like a 300-dimensional vector based on the context it’s normally found in. In these vector spaces, words like “king” and “queen”, for example, would be very similar to each other, because they appear in similar contexts in the written texts that are used to train these models. Based on this, LLMs can produce coherent sequences of words.\n\n\nBut the drawback of this approach is that these models have bias, because they are trained with biased language. If you talk about “women”, for example, and you look at which job roles are similar to “women” in a vector space, you find the stereotypically “female” professions but not technical professions, and that is a problem. Let’s say you take the word vector for “man” and the word vector for “king”, and you subtract “man” and then add this to “woman”, then you end up with “queen”. But if you do the same with “man”, “computer scientist”, and “woman”, then you end up maybe at “nurse” or “human resources manager” or something. These models embed the typical bias in society that is expressed through language.\nThe other issue is that LLMs are massive. GPT-3 has something like 75 billion parameters, and it cost millions to train it from scratch. It’s not energy efficient at all. It’s not sustainable. It’s not something that normal companies can afford. You might need something like a couple of hundred GPUs [graphics processing units] running for a month or so to train an LLM, and this is going to cost millions in cloud environments if you don’t own the hardware yourself. Large tech companies do own the hardware, so for them it’s not a problem. But the carbon that you burn by doing this, you could probably fly around the globe once. So it’s not a sustainable approach to building models.\nAlso, LLMs are quite expensive to use. If you wanted to use one of these large language models in a contact centre, for example, then you would have to run maybe a few hundred of them in parallel because you get that many requests from customers. But to provide this capacity, the amount of memory needed would be massive, so it is probably still cheaper to use humans – with the added benefit that humans actually understand questions and know what they are talking about.\n\n\n\n\n\n\n\nLetter Word Text Taxonomy by Teresa Berndtsson / Better Images of AI / CC-BY 4.0\n\nResearchers are obviously quite interested in LLMs, though, and they are asking scientific questions of these models to see what kinds of answers they get.\n\nDN: Yes, they are. But you don’t really know what is going to come out of an LLM when you prompt it. And you may need to craft the input to get something out that is useful. Also, LLMs sometimes make up stuff – what the Nature article refers to as “hallucinations”.\n\n\nThese tools have copyright issues, too. For example, they can generate computer code because code has been part of their training input, but various people have looked into it and found that some models generate code verbatim from what others have posted to GitHub. So, it’s not guaranteed that what you get out is actually new text. It might be just regurgitated text. A student might find themselves in a pickle where they think that they have created a text that seems new, but actually it has plagiarism in some of the passages.\nThere’s an article in Technology Review that gives some examples of how these systems might fail. People believe these things know what they’re talking about, but they don’t. For them, it’s just pattern recognition. They don’t have actual knowledge representation; they don’t have any concepts embedded.\n\nTo summarise, then: LLMs are expensive. They sometimes produce nonsense outputs. And there’s a risk that you’ll be accused of plagiarism if you use the text that’s produced. So, what should our response be to stories like this recent Nature article? How should we calibrate our excitement for LLMs?\n\nDN: You have to treat them as a tool, and you have to make sure that you check what they produce. Some people believe if you just make LLMs big enough, we’ll be able to achieve artificial general intelligence. But I don’t believe that, and other people like Geoffrey Hinton and Yann LeCun, they say there’s no way that you get artificial general intelligence through these models, that it’s not going to happen. I’m of the same opinion. These models will be forever limited by the pattern recognition approach that they use.\n\nBut, still, is this a technology that you have an eye on in your professional capacity? Are you thinking about how these might be useful somewhere down the line?\n\nDN: Absolutely, but we are mainly interested in smaller, more energy efficient, more computationally efficient models that are built on curated language, that can actually hold a conversation, and where you can represent concepts and topics and context explicitly. At the moment, LLMs can only pick up on context by accident – if it is sufficiently expressed in the language that they process – but they might lose track of it if things go on for too long. Essentially, they have a short-term memory: if you prompt them with some text, and they generate text, this stays in their short term memory. But if you prompt them with a long, convoluted sentence, they might not have the capacity to remember what was said at the beginning of the sentence, and so then they lose track of the context. And this is because they don’t explicitly represent context and concepts.\n\n\nThe other thing is, if you use these systems for dialogues, then you have to script the dialogue. They don’t sustain a dialogue by themselves. You create a dialogue tree, and what they do is they parse the text that comes from the user and then generate a response to it. And the response is then guided by the dialogue tree. But this is quite brittle; it can break. If you run out of dialogue tree, you need to pass the conversation over to a person. Systems like Siri and Alexa are like that, right? They break very quickly. So, you want these systems to be able to sustain conversations based on the correct context."
  },
  {
    "objectID": "news-and-views/editors-blog/posts/2022-12-01-themes/2022-12-01-themes.html",
    "href": "news-and-views/editors-blog/posts/2022-12-01-themes/2022-12-01-themes.html",
    "title": "Four themes for potential contributors to think about",
    "section": "",
    "text": "We’ve had a fantastic early response to our call for contributions, and it has been pleasing to see and hear how our plans for Real World Data Science chime with the wants and needs of the data science community. But one question we’ve been asked frequently is: “What particular topics are you most interested in?”\nThe honest answer to that question is this: we’re interested in any and all topics that are of interest and importance to you, the data science community at large. However, we thought it might be helpful to identify some themes around which potential contributors could construct different types of content.\nThese themes are outlined below. If you’d like to discuss any of them further, please do not hesitate to contact us."
  },
  {
    "objectID": "news-and-views/editors-blog/posts/2022-12-01-themes/2022-12-01-themes.html#can-data-science-save-the-world",
    "href": "news-and-views/editors-blog/posts/2022-12-01-themes/2022-12-01-themes.html#can-data-science-save-the-world",
    "title": "Four themes for potential contributors to think about",
    "section": "Can data science save the world?",
    "text": "Can data science save the world?\nEarth today faces major challenges – from the global to the regional to the local, and from the natural and physical to the social and digital. We have rich sources of data to help us understand many of these challenges, and there are teams of data scientists around the world who are working with, analysing, and extracting insights from that data in the hope of delivering positive lasting change.\nOn Real World Data Science we want to highlight this vital work, through case studies of data science projects and applications in such areas as:\n\nmonitoring and mitigating climate change and biodiversity loss\nbuilding sustainable futures\nsafeguarding public health and developing new medical treatments\nunderstanding human happiness and wellbeing\nidentifying and preventing online harms\nmeasuring national, regional, and local economies\n\nAs well as exploring the benefits that data science can deliver, we also want to have an informed conversation about the unintended negative consequences that can arise without careful consideration of data ethics and responsibilities."
  },
  {
    "objectID": "news-and-views/editors-blog/posts/2022-12-01-themes/2022-12-01-themes.html#what-is-a-data-scientist",
    "href": "news-and-views/editors-blog/posts/2022-12-01-themes/2022-12-01-themes.html#what-is-a-data-scientist",
    "title": "Four themes for potential contributors to think about",
    "section": "What is a data scientist?",
    "text": "What is a data scientist?\nDon’t be misled by the title of this theme. Definitions abound, but we’re not interested in establishing the exact boundaries of what a data scientist is or isn’t. Rather, our goal is to profile actual working data scientists. We want to hear about their skillsets, their experiences, and their career journeys so far. We want to learn about the ways in which they work, who they work with, the challenges they face, and their thoughts on where data science is heading next.\nIf you’re a working data scientist and you are happy to share your own career story, please get in touch."
  },
  {
    "objectID": "news-and-views/editors-blog/posts/2022-12-01-themes/2022-12-01-themes.html#statistical-ideas-all-data-scientists-need-to-know",
    "href": "news-and-views/editors-blog/posts/2022-12-01-themes/2022-12-01-themes.html#statistical-ideas-all-data-scientists-need-to-know",
    "title": "Four themes for potential contributors to think about",
    "section": "Statistical ideas all data scientists need to know",
    "text": "Statistical ideas all data scientists need to know\nStatistics is a crucial component of data science, but not all data scientists have a background in statistics. For those just starting out in their data science careers, or for those coming in from other fields, we want to highlight some of the statistical ideas that are absolutely vital to know.\nWe’re particularly interested in explainers that serve as an introduction to these ideas, alongside which we’ll be looking to publish exercises and example datasets to help people put what they’ve learned into practice.\nWe are also keen to explore the origins of modern data science techniques, including tracing their roots back to some of the foundational ideas in statistics and other disciplines."
  },
  {
    "objectID": "news-and-views/editors-blog/posts/2022-12-01-themes/2022-12-01-themes.html#whats-happening-in-the-world-of-data-science",
    "href": "news-and-views/editors-blog/posts/2022-12-01-themes/2022-12-01-themes.html#whats-happening-in-the-world-of-data-science",
    "title": "Four themes for potential contributors to think about",
    "section": "What’s happening in the world of data science?",
    "text": "What’s happening in the world of data science?\nData science is such a fast-moving, fast-developing field that it’s difficult to stay on top of all the latest news and developments. But racing to keep up can be counterproductive. It leaves little time to sit back and reflect on what the genuinely important new developments are, and what these might mean for data science longer term.\nOn Real World Data Science, we want to create a space for people to have these conversations – to step outside the news hype cycle, to ask big questions about what’s happening in the field, and to discuss new papers and ideas that otherwise might be lost amid the daily rush and noise.\nSo, if you have thoughts to share, a question you want to ask, or a new paper you want to talk about (one you’ve not written yourself, of course!), let us know."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "A showcase for data science in action",
    "section": "",
    "text": "Welcome to the home of Real World Data Science, a new project from the Royal Statistical Society. This site and its content are being created and curated by data science practitioners and leaders with a single goal in mind: to help you deliver high quality, ethical, impactful data science in your workplace."
  },
  {
    "objectID": "index.html#what-are-our-aims",
    "href": "index.html#what-are-our-aims",
    "title": "A showcase for data science in action",
    "section": "What are our aims?",
    "text": "What are our aims?\nReal World Data Science aims to be a trusted, go-to source for high-quality, engaging and inspiring content which helps data science students, practitioners and leaders to:\n\ndiscover and learn more efficiently;\n\nacquire practical problem-solving skills;\n\nshare their knowledge and accomplishments publicly;\n\nwork smarter, ethically, and more effectively."
  },
  {
    "objectID": "index.html#what-will-we-provide",
    "href": "index.html#what-will-we-provide",
    "title": "A showcase for data science in action",
    "section": "What will we provide?",
    "text": "What will we provide?\nResources will be created to meet the needs of our target audiences. These include:\n\nCase studies – showing how data science is used to solve real-world problems in business, public policy and beyond.\nExplainers – interrogating the underlying assumptions and limitations of data science tools and methods, to help data scientists make smarter, more informed analytical choices.\nExercises – to challenge and develop the analytical mindset that all data scientists need to succeed.\n\nAdvice – interviews, Q&As, and FAQs on such topics as data science ethics, career paths, and communication, to support professional development.\n\nResources will also be curated to help data scientists identify trustworthy, high-quality content. These include:\n\nTraining guides – step-by-step approaches and recommended sources for learning new skills and methods.\nDatasets – tagged and sorted to help educators and practitioners find data to meet their teaching and training needs.\nFeeds – who and what to follow to keep up with new ideas and developments."
  },
  {
    "objectID": "index.html#how-you-can-get-involved",
    "href": "index.html#how-you-can-get-involved",
    "title": "A showcase for data science in action",
    "section": "How you can get involved",
    "text": "How you can get involved\nSee our open call for contributions."
  }
]