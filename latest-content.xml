<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/latest-content.html</link>
<atom:link href="https://realworlddatascience.net/latest-content.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://realworlddatascience.net/images/rwds-logo-150px.png</url>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/latest-content.html</link>
<height>83</height>
<width>144</width>
</image>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Thu, 17 Aug 2023 10:38:01 GMT</lastBuildDate>
<item>
  <title>Live from Toronto: Real World Data Science at the Joint Statistical Meetings</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html</link>
  <description><![CDATA[ 




<section id="sunday-august-6" class="level2">
<h2 class="anchored" data-anchor-id="sunday-august-6">Sunday, August 6</h2>
<section id="use-of-color-in-statistical-charts" class="level3">
<h3 class="anchored" data-anchor-id="use-of-color-in-statistical-charts">Use of color in statistical charts</h3>
<p><em>Haley Jeppson, Danielle Albers Szafir, and Ian Lyttle</em></p>
<p>JSM 2023 is underway, and the first session I attended today was this panel on the use of colour in statistical charts.</p>
<p>The topic appealed to me for two reasons:</p>
<ul>
<li>Before my trip to Toronto, I interviewed <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html">Alberto Cairo about the many “dialects” of data visualisation</a>.</li>
<li>I’ve recently been working with Andreas Krause and Nicola Rennie to create new guidance for improving statistical graphics, titled “<a href="https://royal-statistical-society.github.io/datavisguide/">Best Practices for Data Visualisation</a>”.</li>
</ul>
<p>The “Best Practices…” guide links to several useful data visualisation tools, and this session today has put a few more on my radar:</p>
<ul>
<li><p><a href="https://cmci.colorado.edu/visualab/ColorCrafting/">Color Crafting</a>, by Stephen Smart, Keke Wu, and Danielle Albers Szafir. The authors write: “Visualizations often encode numeric data using sequential and diverging color ramps. Effective ramps use colors that are sufficiently discriminable, align well with the data, and are aesthetically pleasing. Designers rely on years of experience to create high-quality color ramps. However, it is challenging for novice visualization developers that lack this experience to craft effective ramps as most guidelines for constructing ramps are loosely defined qualitative heuristics that are often difficult to apply. Our goal is to enable visualization developers to readily create effective color encodings using a single seed color.”</p></li>
<li><p><a href="https://observablehq.com/collection/@ijlyttle/color">Computing on color</a>, a collection of Observable notebooks by Ian Lyttle that allow users to see how different colour spaces and colour scales work with different types of colour vision deficiency.</p></li>
</ul>
</section>
</section>
<section id="monday-august-7" class="level2">
<h2 class="anchored" data-anchor-id="monday-august-7">Monday, August 7</h2>
<section id="astronomers-speak-statistics" class="level3">
<h3 class="anchored" data-anchor-id="astronomers-speak-statistics">Astronomers Speak Statistics</h3>
<p>Astrophysicist Joel Leja kicked off his JSM talk with a video of the launch of the James Webb Space Telescope – an inspiring way to start the day, and a prelude to a discussion of the statistical challenges involved in studying the deep universe.</p>
<p>James Webb, since launch, has “completely expanded our point of view”, said Leja, allowing astronomers to explore the first stars and galaxies at greater resolution than ever before.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/james-webb.png" class="img-fluid figure-img" alt="Image from the James Webb telescope showing two galaxies in the process of merging, twisting each other out of shape." width="500"></p>
<figcaption class="figure-caption">Image from the James Webb telescope showing two galaxies in the process of merging, twisting each other out of shape. Credit: ESA/Webb, NASA &amp; CSA, L. Armus, A. Evan, licenced under CC BY 2.0.</figcaption>
</figure>
</div>
<p>Already, after only 13 months of operation, the images and data sent back by the telescope have left observers astounded: for example, finding suspected early galaxies that are bigger than thought possible based on extreme value analysis.</p>
<p>But the big challenge facing those studying the early universe is trying to work out how early galaxies evolved over time. “We can’t watch this happen,” said Leja, joking that this process lasts longer than a typical PhD. So, instead, he said, “We need to use statistics to understand this, to figure out how they grow up.”</p>
</section>
<section id="teaching-statistics-in-higher-education-with-active-learning" class="level3">
<h3 class="anchored" data-anchor-id="teaching-statistics-in-higher-education-with-active-learning">Teaching statistics in higher education with active learning</h3>
<p>Great talk from Nathaniel T. Stevens of the University of Waterloo, explaining how a posting for a Netflix job inspired the creation of a final project for students to learn response surface methodology.</p>
<p>The job ad in question “really opened my eyes” to the use of online controlled experiments by companies, said Stevens. He told delegates how LinkedIn, the business social networking site, runs over 400 experiments per day, trying to optimise user experience and other aspects of site engagement.</p>
<p>Netflix’s job ad highlighted just how sophisticated these experiments are, said Stevens. People might hear companies refer to their use of A/B tests, but the term trivialises what’s involved, Stevens explained.</p>
<p>Having encountered a job ad from Netflix, looking for someone to design, run, and analyse experiments and support internal methodological research, Stevens was inspired to present students with a hypothetical business problem, based on the Netflix homepage. That homepage, for those not familiar, features rows and rows of movies and TV shows sorted by theme, each show presented as a tile that, when hovered over, leads to a pop-up with a video preview and a match score – a prediction of how likely a viewer is to enjoy the show.</p>
<p>Stevens explained the hypothetical goal as trying to minimise “browsing time” – the time it takes a Netflix user to pick something to watch. Browsing time was defined as time spent scrolling and searching, not including time spent watching previews.</p>
<p>Students were given four factors that might influence browsing time – tile size, match score, preview length, and preview type – and through a sequence of experiments based on data generated by a Shiny app, students sought to minimise browsing time.</p>
<p>The response from the students? Two Netflix-style thumbs up. Ta-dum!</p>
</section>
</section>
<section id="tuesday-august-8" class="level2">
<h2 class="anchored" data-anchor-id="tuesday-august-8">Tuesday, August 8</h2>
<section id="the-next-50-years-of-data-science" class="level3">
<h3 class="anchored" data-anchor-id="the-next-50-years-of-data-science">The Next 50 Years of Data Science</h3>
<p>Stanford University’s David Donoho wrestled with the question of whether a singularity is approaching in this post-lunch session on the future of data science.</p>
<p>Taking his cue from the 2005 Ray Kurzweil book, <em>The Singularity is Near</em>, Donoho reviewed recent – and sometimes rapid – advances in data science and artificial intelligence to argue that a singularity may have already arrived, just not in the way Kurzweil supposed.</p>
<p>Kurzweil’s book argues that at some point after the 2030s, machine intelligence will supersede human intelligence, leading to a takeover or disruption of life as we know it.</p>
<p>At JSM, Donoho argued that we have certainly seen a “massive scaling” of compute over the past decade, along with expanded communications infrastructure and the wider spread of information – all of which is having an impact on human behaviour.</p>
<p>That human behaviour can often now be directly measured thanks to the proliferation of digital devices with data collection capabilities, and this in turn is leading to a major scaling in data sets and performance scaling for machine learning models.</p>
<p>But does this mean that an AI singularity is near? Not according to Donoho. The notion of an AI singularity “is a kind of misdirection”, he said. Something very profound is happening, Donoho argued, and it is the culmination of three long-term initiatives in data science that have come together in recent years. “They constitute a singularity on their own.”</p>
<p>These three initiatives, as Donoho described, are: datafication and data sharing; adherence to the “challenge problem” paradigm; and documentation and sharing of code. These are solid achievements that came out of the last decade, said Donoho, and they are “truly revolutionary” when they come together to form what he refers to as “frictionless reproducibility.”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/donoho-talk.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/donoho-talk.png" class="img-fluid figure-img" alt="Slide text reads: Today's data scientists: typical interactions: What's your package name? What's your URL? QR Code? What's your stack? Today's data scientists: implicit demands: Data sharing, Specific numerical performance measures, Code sharing, Single-click access. Frictionless replications." width="500"></a></p>
<figcaption class="figure-caption">Photo of David Donoho’s slide, describing the scientific revolution of the “data science decade”. Photo by Brian Tarran, licenced under CC BY 4.0.</figcaption>
</figure>
</div>
<p>Frictionless reproducibility, when achieved, leads to a “reproducibility singularity” – the moment where it takes almost no time at all for an idea to spread. “If there is an AI singularity,” said Donoho, “it will be because this came first.”</p>
</section>
</section>
<section id="wednesday-august-9" class="level2">
<h2 class="anchored" data-anchor-id="wednesday-august-9">Wednesday, August 9</h2>
<section id="new-frontiers-of-statistics-in-trustworthy-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="new-frontiers-of-statistics-in-trustworthy-machine-learning">New frontiers of statistics in trustworthy machine learning</h3>
<p>Data, data everywhere, but is it safe to “drink”? A presentation this morning from Yaoliang Yu of the University of Waterloo looked at the issue of data poisoning attacks on algorithms and the effectiveness of current approaches.</p>
<p>Yu began by explaining how machine learning algorithms require a lot of data for training, and that large amounts of data can be obtained cheaply by scraping the web.</p>
<p>But, he said, when researchers download this cheap data, they are bound to worry about the quality of it. Drawing an analogy to food poisoning, Yu asked: What if the data we “feed” to algorithms is not clean? What is the impact of that?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/data-hazards.png" class="img-fluid figure-img" alt="A person is illustrated in a warm, cartoon-like style in green. They are looking up thoughtfully from the bottom left at a large hazard symbol in the middle of the image. The hazard symbol is a bright orange square tilted 45 degrees, with a black and white illustration of an exclamation mark in the middle where the exclamation mark shape is made up of tiny 1s and 0s like binary code. To the right-hand side of the image a small character made of lines and circles (like nodes and edges on a graph) is standing with its ‘arms’ and ‘legs’ stretched out, and two antenna sticking up. It faces off to the right-hand side of the image." width="500"></p>
<figcaption class="figure-caption">Illustration by Yasmin Dwiputri &amp; Data Hazards Project / Better Images of AI / Managing Data Hazards / Licenced by CC-BY 4.0.</figcaption>
</figure>
</div>
<p>As a real-world example of a data poisoning attack, Yu pointed to TayTweets, the Microsoft Twitter chatbot that spewed racism within hours of launch <a href="https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist">after Twitter users began engaging with it</a>.</p>
<p>Yu then walked delegates through some experiments showing how, generally, indiscriminate data poisoning attacks are ineffective when the ratio of poisoned data to clean data is small. A poisoning rate of 3%, for example, leads to model accuracy drops of 1.5%–2%, Yu said.</p>
<p>However, he then put forward the idea of “parameter corruption” – an attack that seeks to modify a model directly. Yu showed that this would be more effective in terms of accuracy loss, though – fortunately – perhaps less practical to implement.</p>
</section>
<section id="data-science-and-product-analysis-at-google" class="level3">
<h3 class="anchored" data-anchor-id="data-science-and-product-analysis-at-google">Data Science and Product Analysis at Google</h3>
<p>Our final session at JSM 2023, before heading home, was a whistle-stop tour of various data science projects at Google, covering YouTube, Google Maps, and Google Search.</p>
<p>Jacopo Soriano kicked us off with a brief intro to the role and responsibilities of statisticians and data scientists at Google, and within YouTube specifically – the main task being to make good decisions based on uncertain data.</p>
<p>Soriano also spoke about the key role randomised experiments play in product development – harking back to Nathaniel Stevens’ earlier talk on this subject. YouTube runs hundreds, if not thousands, of concurrent experiments, Soriano said; statisticians can’t, therefore, be involved in each one. As Soriano’s colleague, Angela Schoergendorfer, explained later in the session, the role of the data scientist is to build methodology and metrics that others in the business can use to run their own experiments.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/google-sign.png" class="img-fluid figure-img" alt="Google logo on top of building, against a blue sky." width="500"></p>
<figcaption class="figure-caption">Photo by Pawel Czerwinski on Unsplash.</figcaption>
</figure>
</div>
<p>For every experiment YouTube runs, a portion of its voluminous daily traffic will be assigned to control arms and treatment arms, with traffic able to be diverted to different groups based on user type, creators, videos, advertisers, etc. Once experiments are running, metrics such as search clickthrough rates, watch time using specific devices, or daily active user numbers are monitored. Teams tend to look at percentage change as the scale to measure whether something is working or not, said Soriano, rather than comparing treatment to control group.</p>
<p>Next up was Lee Richardson, who spoke about the use of proxy metrics. Technology companies like Google are often guided by so-called “<a href="https://www.forbes.com/sites/forbesbusinesscouncil/2022/11/11/what-is-your-startups-north-star-metric/">north star metrics</a>”, which executive leadership use to guide the overall strategy and priorities of an organisation. However, Richardson said, these can be hard to design experiments around, and so proxy metrics stand in for the north star metrics. Proxies need to be sensitive, he said, and move in the same direction as, e.g., a long-term positive user experience.</p>
<p>On the subject of user experience, Christopher Haulk then explained how YouTube measures user satisfaction through single-question surveys – typically asking a YouTube user to rate the video they just watched. The company doesn’t send out that many surveys, Haulk said, and response rates are in the single-digit percentage range, so it can be hard to evaluate whether changes YouTube makes to, e.g., its video recommendation algorithm are working to improve user satisfaction. Haulk then went on to explain a modelling approach the company uses to predict how users are likely to respond in order to “fill in” for missing responses.</p>
<p>Over at Google Search, user feedback is also regularly sought to help support the evolution of the product. Angela Schoergendorfer explained how, with so many people already using Google Search, statistically significant changes in top-line metrics like daily active users can take months to see. Decision metics should ideally capture user value quickly, said Schoergendorfer – within days. For this, Google has 10,000 trained “search quality” raters they can call on. Random samples of user search queries and results are sent to these raters, who are asked to evaluate the quality of the search results. Users can also be asked in the moment, or offline through the Google Rewards app.</p>
<p>In 2021, Schoergendorfer said, Google conducted approximately 800,000 experiments and quality tests. But perhaps the most impressive statistic of the day came from Sam Morris, who works on Google Maps. Something, somewhere, is always changing in the world, said Morris – be it a road closure or a change to business hours. The Maps team cannot evaluate every single piece of data – a lot of changes are automated or algorithmic, he explained. “So far this year, we have probably processed 16 billion changes to the map,” said Morris – a staggering figure!</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Live from Toronto: Real World Data Science at the Joint Statistical Meetings.” Real World Data Science, August 6, 2023, updated August 15, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>Conferences</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html</guid>
  <pubDate>Thu, 17 Aug 2023 10:38:01 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/google-sign.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Where do AI, data science, and computer games intersect?</title>
  <dc:creator>Alice-Maria Toader and Liam Brierley</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/08/17/data-science-and-games.html</link>
  <description><![CDATA[ 




<p>Game studios have cemented their place among the fastest-growing media industries. In recognition of this, we hosted an event in June through the <a href="https://rss.org.uk/membership/rss-groups-and-committees/groups/merseyside/">Royal Statistical Society (RSS) Merseyside Local Group</a> to explore AI and data science in computer game development. This was an amazing opportunity to engage with a different, in-vogue domain that has unique ties to data science. We showcased two fantastic presentations covering both academic and industry perspectives.</p>
<p>Stanley Wang, a data scientist at SEGA Europe, opened the event by showing the methods that SEGA uses to collect, process, and apply data on player decisions in-game. It was a revealing glimpse at how smoothly in-game data collection is integrated into SEGA’s digital platforms and the ways these data can be used to engage game-centred communities – for example, running special celebrations once milestones are hit for in-game events (revenue made, goals scored, etc.) or offering real-time integration with streaming platforms so viewers can see detailed statistics on in-game progress. Stanley showed one particular example where data collection fed directly into development decisions for <em>Endless Space</em>, a competitive strategy game where players vie for galactic conquest. During the beta (a period where a game is available to play but still considered in-testing before commercial release), SEGA were able to monitor how well-balanced the playable alien factions were based on real-time win rate data, which led to improvements to game mechanics for the final release.</p>
<p>We also learned how SEGA’s data science teams are using clustering methods to identify different game-playing behaviours in <em>Two Point Hospital</em>, a simulation game where players design, build, and manage a hospital through various scenarios. After compiling high-dimensional in-game data such as objectives achieved, treatment of staff, and even furniture choices, various clustering algorithms (including <a href="https://towardsdatascience.com/a-practical-guide-on-k-means-clustering-ca3bef3c853d">k-means clustering</a>) were used to identify common sets of player behaviour. Stanley highlighted that when using these sorts of <em>unsupervised learning methods</em>, it’s useful to get insights from multiple models to inform methodological decisions like number of clusters chosen or how to treat outliers. SEGA identified four distinct types of player from these analyses, which you can hear more about from Stanley in the video below. The approach allowed the company to better understand gamers’ motivations and experiences with a view to designing future game content.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/KAg3YDHvvqE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Our second speaker, Dr Konstantinos Tsakalidis, a lecturer in the Department of Computer Science at the University of Liverpool, presented exciting new ideas to teach computer games developers of the future. Dr Tsakalidis walked us through the curriculum for a dynamic new undergraduate program that reflects the latest software development technologies and the theory behind them. The course outline was designed around building knowledge and practice from the fundamentals upwards, starting from game physics as a prerequisite for game mechanics, game mechanics being a prerequisite for game content, and game content being a prerequisite for game AI. Combined with the continuous active involvement of students at each stage, this represented a great model of <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8049623/">constructivist teaching</a>. Dr Tsakalidis also proposed that practical game development (and subsequent assessments) should follow the latest <a href="https://www.datacamp.com/podcast/data-science-and-ai-in-the-gaming-industry">research on data science and AI in computer games</a>.</p>
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Alice-Maria Toader</strong> is a PhD student at the University of Liverpool and a committee member of the RSS Merseyside Local Group. <strong>Liam Brierley</strong> is a research fellow in health data science at the University of Liverpool and chair of the RSS Merseyside Local Group.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Alice-Maria Toader and Liam Brierley
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/posts/2023/08/17/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/posts/2023/08/17/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://unsplash.com/@jezar?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jezael Melgoza</a> on <a href="https://unsplash.com/photos/FOx3_4_2O1E?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Toader, Alice-Maria and Liam Brierley. 2023. “Where do AI, data science, and computer games intersect?” Real World Data Science, August 17, 2023. <a href="https://realworlddatascience.net/viewpoints/posts/2023/08/17/data-science-and-games.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Events</category>
  <category>Video games</category>
  <category>Education</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/08/17/data-science-and-games.html</guid>
  <pubDate>Thu, 17 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/08/17/images/sega-store.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>The many ‘dialects’ of data visualization: Alberto Cairo and ‘The Art of Insight’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html</link>
  <description><![CDATA[ 




<p>Alberto Cairo is Knight Chair in Visual Journalism at the School of Communication of the University of Miami (UM). He’s also the director of visualization at UM’s Institute for Data Science and Computing. He joins Real World Data Science to discuss his upcoming book, <em>The Art of Insight: How Great Visualization Designers Think</em>, in which Cairo reflects on his conversations with data artists, data journalists, and information designers.</p>
<p>“If we can conceptualise data visualization as language, this language can have multiple dialects,” says Cairo. “And these dialects – let’s say the statistical dialect, the data journalism dialect, the art dialect – they are not mutually exclusive. They exist, or they should exist, ideally, in constant conversation with each other. So, we can borrow ideas from each other, learn from each other.”</p>
<p>Listen to the full interview below or on <a href="https://www.youtube.com/watch?v=htUWWVzYTUI">YouTube</a>.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/htUWWVzYTUI" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Find out more about Cairo’s work and his upcoming book at <a href="http://www.thefunctionalart.com/">thefunctionalart.com</a>.</p>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to Real World Data Science. I’m Brian Tarran. And today I’m joined by Alberto Cairo, Knight chair in visual journalism at the School of Communication of the University of Miami. He’s also the director of visualization at UM’s Institute for data science and computing. Alberto, welcome. Thanks for joining us.</p>
<p><strong>Alberto Cairo</strong><br>
Hi, Brian. Very nice to be here. Thank you for inviting me.</p>
<p><strong>Brian Tarran</strong><br>
No worries. Well, today we’re excited to be discussing your new book, The Art of Insight: How Great Visualization Designers Think. I think it’s a really– I’ve not read all of it yet. I’ve dipped in and out of some chapters that you kindly sent me ahead of time. I think it’s really interesting and unique. I think the thing that struck me was often when we talk about visualization design, we tend to concentrate on what designers do, not necessarily about how they think about what they do, or how they think generally. And so, that was to be my first question for you is like, what aspects of their thought processes, these experts, what were you really trying to understand and why?</p>
<p><strong>Alberto Cairo</strong><br>
Yeah, yeah, this latest book of mine is very different to the previous one that I– that I wrote. The book is not out yet, by the way, the book will be out in November of 2023. I am in the process of copy editing it, getting rid of typos. But as you said, I mean the book focuses not so much on the– on the work itself, but more on the people who produce the work and the motivations and values that lie behind the work that they do. It is also, in comparison to my previous books, it is also a shift of perspective, I would say because my previous books, particularly The Truthful Art and How Charts Lie which came out in 2019, focus mostly on statistical visualization. Right, so it has a very strong, they both have a very strong statistical focus – how to make sure that your graphs and your data maps don’t deceive people. I teach elementary principles of visualization, of communication through visualization. But visualization is much more than that. And that is what I wanted to convey with this book. More and more throughout the years, I have come to understand data visualization not so much as a representation of data for insight or for communication, but as a language, a language that can be used for many different purposes. And I try to reflect that in the book. Obviously, a great part of the book is devoted to people who come from the same world where I come from, the professional world where I come from, the world of data journalism, so plenty of them are data journalists. Many of them are data analysts and statisticians and researchers. But a good portion of the book is devoted to people who use– who use visualization for other purposes such as self expression, self discovery, art in some cases. I wanted to provide a sort of like a broader understanding of the language of visualization and I also talk about– I also discussed the fact that if we can conceptualize data visualization as language, this language can have multiple dialects. And that is what I wanted to convey in the book. And these are not, these dialects – let’s say the statistical dialect, the data journalism dialect, the art dialect – they are not mutually exclusive. They exist, or they should exist, ideally, in constant conversation with each other. So we can borrow ideas from each other, learn from each other. So I wanted to provide sort of like an overview of the huge diversity that exists in the world of visualization – in terms of people, in terms of race, in terms of gender, but also in terms of the dialects that people use.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, and is that almost pushing back a little bit at this idea that, you know, if visualization is a language in the same way that English is or Spanish is or whatever it might be, that there are– there must be rules that people have to follow?</p>
<p><strong>Alberto Cairo</strong><br>
Yeah, I push back against that a little bit in the book because obviously, I mean, what I have taught and what I continue talking– talking about at the– talking about at the University of Miami, what I teach my classes, is what you could call let’s say standard data visualization, right? Data visualization for communication. I discuss a lot about, you know, cognitive science, you know, perception, you know, how to apply that, colour palettes – I just do standard data visualization. But that is just one of the dialects that data visualization has, right? Data visualization can be used for journalism, for business analytics, for statistics, for art, for expression, for self discovery – some of the people who I interviewed, plot their own data, for example, their own health metrics, as a way to reduce their own anxiety. So I interviewed, for example, a person who has gone through– who in the past went through very serious health problems like cancer, brain cancer and other health problems, and he discovered that the process of designing visualizations based on his own data was similar to– had similar effects as meditating about your own thoughts, right. It was a way to pour your anxiety and your dark feelings onto the graphic, so they will not overburden your mind. I find that absolutely fascinating. And it shows you that, I believe, that’s what I– what I reflect in the book, that there are really no universal rules in data visualization. There are parochial rules that are applicable to different– to the different dialects. But it is it is wrong, it is a mistake, to apply the standards of one of the dialects of data visualization to a completely different dialect of data visualization. Every visualization, I feel or I think, should be judged according to their own terms, to the terms in which they were created.</p>
<p><strong>Brian Tarran</strong><br>
The book is essentially set out as a series of discussions with these visualization designers, right. And then it’s your interspersed reflections on the conversations and things that you’re sort of taking away from them. And when you were saying in the introduction about why you wanted to have these conversations, you say you were kind of looking to, or needing to, rekindle your love for the design of information. So I wanted to ask you, maybe I’ve misjudged that sentence, but you know, had you fallen out of love with the design of information? Or did you just kind of get to that point where you thought, oh, there must be more to it than this, the way I– the way I work. What was the– what was the motivating force driving you down this path?</p>
<p><strong>Alberto Cairo</strong><br>
It’s not that I stopped, you know, being in love with data visualization, or more broadly with information design, because I teach information design – data visualization is one of the branches of information design. So I also teach, you know, illustration driven visual explanations – how an airplane works, and you do a cutaway of the airplane and you show the engines and how they work. I also do that type of information design. So it’s not that I ever stopped being in love with– with the work that I do. As I explain, by the way, in the conclusions of the book, in the epilogue of the book, which circles back to the themes in the prologue, information design and data visualization are a great part of who I am as a person. To me, it’s a way of life. I use visualization not only to communicate with other people, I use visualization also to study. When I am reading a book, I am probably producing a visualization of the book, like some sort of network diagram, in which I plot all the ideas from the book. That’s a technique, a mnemonic technique, that I learned from my– from my father, who is a medical doctor, but also a humanist. He taught me this technique to study: when you’re reading a book, just write down the concepts that you’re learning about, and then connect them with arrows make little comments on the side. Indirectly he was teaching me to make data visualization. So data visualization, information design has permeated my life since I was very, very young – since I– since I didn’t have the language to talk about what I was doing. But at the same time, in the past three or four years, many personal circumstances led me to feel, let’s say, my morale went down quite a lot, the pandemic also and then some personal problems and stuff. And I started feeling a little bit disillusioned with my own– with my own work, like having self doubts, right? Am I doing the right thing? Am I in the right career? Should I be doing something else? Have I written everything that I wanted to write about this field? Have I designed every graphic that was worthy to be designed? And I felt the need to connect with other people. Because something that I discovered throughout the years is that we human beings, we don’t think well when we are alone, we think better when we are in connection with others. So my conversations with the many friends that are showcased in the book, obviously I wanted to give their work and their lives and their values visibility because I believe that they are worthy to be explored and understood by readers. But it was also a way for me to sort of like recover a little bit of the passion that I had about information design in the past – and I was successful. I mean, I went out of– The process of writing a book can be grueling. So, while you’re writing a book, you’re always thinking, you know, this is crap. What is it that I’m doing? I don’t know where I’m going. But in hindsight, now that the book is written, and I am reviewing it, I am thinking, hmm, this is not bad. This is not bad, right? And I discovered that I was– I felt energized, thanks to all these conversations with tons of inspiring people from all over the world.</p>
<p><strong>Brian Tarran</strong><br>
I think I can sort of sympathize with that, you know, the process of creating – I don’t do data visualization myself – but creating content, it can be quite a lonely process sometimes. And you do have that, I always talk about the roller coaster of emotions – of the peaks, were you think you’re doing a great job, and then the troughs where you’re like, Oh, my God, why or I should just throw it all in. So actually being able to sit down and talk to people and share ideas does inspire you, does sort of bring you back up again, doesn’t it? But I was worried, actually, that because the last time we spoke was, I think, around the time that How Charts Lie had come out, and you were interviewed by one of our freelance writers on Significance magazine – where I was at the time – and I thought, oh, no, maybe– maybe all that encountering the dark side of data visualization and all that misinformation that was out there…</p>
<p><strong>Alberto Cairo</strong><br>
That I felt depressed, right, because the book was useless, or not useless. But I mean, it was not read by the people – How Charts Lie, I mean – it was not read by the people who needed to read the book.</p>
<p><strong>Brian Tarran</strong><br>
That is always the case with these books, isn’t it? So they– they’re really valuable, if only you could get them in the hands of the right people. That’s the challenge.</p>
<p><strong>Alberto Cairo</strong><br>
We preach– We preach to the choir a little bit with these type of books, unfortunately, yeah.</p>
<p><strong>Brian Tarran</strong><br>
Well, I still enjoyed it anyway. And it’s always valuable to, to listen to experts like yourself and take learnings from those. So the, the things that– the interviews I’ve read, I’ve not read all of them, but I think the things that jumped out for me – the interviews with people like Ed Hawkins, talking about the Warming Stripes, you know, talking about how their focus is less about – and tell me if I’m mischaracterizing this – it’s less about direct communication of information or data, it’s more about conveying like a feeling or an intuitive understanding of something. And obviously, warming stripes, most people have seen those, you know – the kind of plots of changes in temperature against a baseline over time and the kind of rapid shift to deeper, darker shades of red as we get closer to the present, you know – I think they do create a sense of the urgency of the climate crisis when you just look at them. But what lessons do you as a kind of, you know, as a data visualization designer, a journalistic data visualization designer, what do you take from those sorts of examples, where it isn’t direct communication, of information or data, it’s about feeling? What can you– what can you take from that and bring to your own work?</p>
<p><strong>Alberto Cairo</strong><br>
Well, the fact, as I was saying before, that not all visualizations are alike, as I explained in that chapter. Hawkins got a little bit of pushback, because that visualization broke some rules – and I’m doing sort of like scare quotes with my fingers right now, right? It broke some rules because it doesn’t have axes, it doesn’t have scales. It’s just a beautiful picture. But that is valuable, that is valuable, and it’s proven that it is valuable. It’s one of the most popular data visualizations in history already. And he, it’s a perfect example of a match between purpose and outcomes. And that is what needs to be explored when evaluating a data visualization. So, Hawkins told me when I interviewed him that he didn’t want to create an analytical data visualization. If he wanted to do that, he will do a line chart with like error bars or whatever, right? Something that you could publish in a paper. He has done thousands of those types of graphs. But this graphic was originally designed to bring to a festival, to be displayed in the background while there was a conversation going on about climate change. So it was designed with the specific and explicit purpose not to provide an analytical tool to explore the data but as something that brought attention to the information, something that ignited curiosity in the viewers. And I think that if that is the purpose, the outcomes actually match really well what he had in mind, and therefore the visualization works. That’s a visualization that works. So that’s just one of the many examples that appear in the book, of graphics that somehow defy conventions but at the same time, according to their own predefined purposes, work pretty well. So we have the example, for example, from Jaime Serra, who is a designer from Spain who is a– he’s a data visualization designer, he has worked for many, many years for newspapers. But the type of graphics that he creates blend the artistic with the– with the statistical and the analytical. He uses objects, for example, to create data visualizations to– he comes up with these beautiful pieces that sometimes he has showcased in exhibits all over the– all over the world. But then I also talked to people who produce what we could call more conventional data visualizations, right – people who work in public health, right, people who work in data journalism, people who live in countries where, you know, producing accurate and truthful data visualization can be dangerous to your career, right? I talk, for example, to Attila Bátorfy, who is a data journalist working in Hungary, and obviously Hungary, right now, considering the Viktor Orban regime, it’s not very friendly to journalists who want to be accurate and truthful. And he tries to be, and he’s very successful in Hungary right now, right? He’s a, he’s a voice against authoritarianism in his country. Or Anatoly Bondarenko, who is a data journalist and data visualization designer from Ukraine, who years ago created an organization called Texty, which is an investigative reporting newsroom in Ukraine, a nonprofit in Ukraine, to investigate corruption in the Ukrainian government but also Russian interference in Ukraine prior to the war. And, and that is one of my favorite chapters, because I’m Anatoly is a good friend of mine, and he’s, he’s fighting. He’s part of the Ukrainian army. And I think about him on a regular basis. And I am in touch with him just to make sure that he’s– that he’s safe, that he’s doing good. That chapter begins with a sentence that says that I sometimes wake up in shock thinking about, you know, my friend is at war, right? That’s such a strange thought and his work is so valuable, it’s so impressive. Again, what I find inspiring in all the people I talk to, I talk with, in the book is not just the work itself, it’s the values and the motivations behind the work and sometimes the resilience of the people producing that work. That’s what I find inspiring.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah, I was– when you were talking there about the Hawkins warming stripes examples, the– the idea of evaluating visualizations, you know, on their own terms, on their kind of their stated purposes, I think is quite important. But do you think people creating data visualizations, do they spend enough time thinking through generally – not the experts you’ve talked to, obviously, they’re the maybe the exception – but about what the purpose– what is it that I want to achieve with this data visualization? Is that kind of one of the things that all your interviewees have in common, a very clear sense of purpose?</p>
<p><strong>Alberto Cairo</strong><br>
They do. They do have that sense of purpose. That doesn’t mean that they don’t sometimes create these great visualizations out of a whim – say, I’m gonna just create a pretty graphic based on that, no purpose whatsoever. And that’s perfectly fine. Again, the analogy with writing. Not all writing can be technical writing. That’s just one of the types of writing that we could use. And conventional, traditional visualization is analogous to technical writing – you want to communicate something effectively, clearly, and therefore you try to create something that doesn’t use too many words, or too many, you know, verbal flourishes, you just go directly to the point and try to communicate directly. But that’s not the only way you can use writing. You can write poetry, so why not using data visualization to create visual poetry? That’s perfectly, perfectly fine. Again, every visualization needs to be judged based on their own– on their own stated purposes. As to the question of whether people in general – like, not the people I talked to in the book, for the book – but, you know, people in general think about purpose when designing data visualizations, that’s a question that I cannot answer. But that’s the core of my classes and workshops. It’s like my classes and workshops outline, both at the university but also as a consultant, put a lot of emphasis on the purpose part. I mean, just list what do you want to communicate? What do you want to achieve? Create an actually a bullet point list of what you want to communicate, and based on that list, then you can make choices. The way that I teach data visualization these days is not about teaching rules, right? Like, you know, use a bar graph to compare, use this graphic for that, use a scatterplot to show associations between, you know, continuous variables or whatever. No, that’s not the way I teach visualization. I teach visualization based on a process of reasoning, right? Reason that takes you from the purpose to the outcome. And every decision down the road in between those two points needs to be somehow justified. You need to justify every decision that you make in the visualization in a way that is– that can be persuasive to other people who may be in your team. I use this colour palette because, and what comes after the because is the important part. I use this type of graphic because, and what comes after the because is the important part, and so on and so forth.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, there’s something that struck me. I think it was a podcast producer who came up this idea of the XY story formula – that’s how you assess the value of a kind of an article pitch. Now, I’m writing a story about X, and it is interesting because Y – and it’s the bit that follows after the “because” that determines– you have to work on that and refine that, and that’s what shapes your story and your outputs. I’m glad you brought up teaching as well, because I was reading through the epilogue, and it said about you having “anarchic leanings and sympathies” and I was kind of curious about how those sympathies and leanings manifest in your work or in your teaching. And obviously, you said you don’t teach rules. So maybe that’s part of it. But…</p>
<p><strong>Alberto Cairo</strong><br>
What sympathies are you referring to?</p>
<p><strong>Brian Tarran</strong><br>
I don’t know. It was just that phrase jumped out: I have, I have anarchic– I think it’s “despite my anarchic leanings and sympathies”, and I was kind of curious as to what are those, and how do they– how do they manifest?</p>
<p><strong>Alberto Cairo</strong><br>
Well, one of the points that I make, particularly in the epilogue, which I think that is the most important part of the book, because it’s where I lay out my own thinking – is that, one of the points that I make is that you cannot really separate the work from the people. And I make the analogy with philosophy, I read a lot of philosophy. There is this book that I absolutely love about philosophy, titled “What is Ancient Philosophy?” by Pierre Hadott, who was, I think that he was French – wonderful book, absolutely wonderful book if you’re interested in the ancient history of philosophy, that book is amazing. Talks about the Hellenistic tradition of philosophy. I could go on and on and talk about that book. I absolutely love it. I think that I read it four times, something like that. And the point that Hadott makes in “What is Ancient Philosophy?” is that it takes you a long way to understand the philosophy of the, you know, the classics – Plato, Aristotle, and then the Hellenists like the Epicureans, or the Stoics, or whatever – it takes you a long way if you sort of like understand the temperament of those people, and their lived experiences, what they went through in their lives, right? If you understand, for example, what Plato lived, his times and his temperament, and also the history of the times when he lived, you can understand the Republic better, his best book, right? You, you sort of like guess where it comes from, right, where his thinking comes from. And I think that’s something similar can be said about visualization, right? I have my own temperament. I have a– I have a very driven temperament. So I’m quite a strong will – when I decide that I’m going to do something, I usually put the energy to do it. But at the same time, I’m quite anarchic, not in the sense of being disorganized, but in the sense that I don’t deal with authority well. I just want to be left alone, right? Just leave me alone. I will figure things out on my own. I work well with other people, right. But in horizontal organizations, I enjoy horizontal teams, rather than hierarchical teams, right. I work really well in horizontal teams. And that is somehow reflected, I think, in the way that I think about data visualization. I somehow rebelled against, you know, the 1980s, 1990s tradition of data visualization teaching around what I call the Tuftean – after Edward Tufte – the Tuftean tradition of saying, this is the only way to do visualization well, these are the rules of data visualization. Well, why? Why are those the rules? Tell me what is this based on, or is it just your own opinion? I mean, I enjoy reading Tufte and I enjoy reading, you know, people like Steven Few, who is a friend of mine, etc. But at the same time I rebelled against that tradition, because in many cases, as I explain in The Art of Insight, many of those so called rules are merely the opinions of people. This is just my opinion. I like this stuff. I like this style, and therefore, I’m going to try to pass my own opinion as if it were a rule of design. I think that we need to be a little bit more honest about what we are doing. Many of those rules are not really grounded on any sort of empirical evidence, and therefore they are still valuable – I think that people should keep reading Tufte, they should keep reading [unclear] and many of the, we should keep reading them. But always with a pinch of salt, taking everything that we read with a pinch of salt, and this applies to my own books as well. We need to be a little bit more skeptical, a little bit more flexible in some sense, knowing that we are on these together and what really matters, I think, is the conversation between people in the field. Conversation is a word that appears a lot in The Art of Insight. I see my work, and I see the work of everybody else who writes or thinks or makes data visualizations as part of an ongoing conversation between people in which we can learn from each other, borrow from each other – always understanding that our opinions can be strongly stated, but sometimes they have very, very shaky foundations.</p>
<p><strong>Brian Tarran</strong><br>
What you’re saying about the importance of still reading these kinds of texts, where the rules – again, in inverted commas – are set, the importance of doing that, that kind of reminded me of like in my, in my own world of, you know, the written word, people like James Ellroy, the author of American Tabloid, you know, about understanding the rules of grammar so that you know how to break them for effect and for impact and things like that. So I can see how that applies to data visualization.</p>
<p><strong>Alberto Cairo</strong><br>
It is, yeah, that’s sort of like already has become a cliche, right: learn the rules, so you can break them. I think that that is valuable. But at the same time, I think that we need to go beyond that and say, there are really no rules. I mean, there are a few things that could be considered rules. For example, we know that, you know, if you want to compare numbers, a bar graph is usually superior to a pie chart, for example. We know that, there is empirical evidence behind that, so you can sort of like derive a principle out of that, right? But beyond those very basic things, there are really not many rules. What there are is a lot of conventions, inherited conventions, right, that historically have developed and we have– we have inherited. So we could say, you know, it’s good to learn the conventions. It is still good to learn about perception and cognition to guide your decisions. But after you do that, all that matters is the choices that you make with the knowledge that you have, and with the guesses that you can make. Right? So it’s not that you’re breaking the rules, you’re creating your own path, based on the inherited knowledge that you have under your belt.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. My last question for you – because I don’t want to take up too much of your time, I know you are very busy, Alberto – is, you mentioned, again, going back to the previous question, or two, the people that you work with, and one of those sometime collaborators is Shirley Wu, who you refer to in your introduction, and I was really struck by the description of the installation, the number of COVID deaths each week, and this this dripping valve. I think what struck me most was that, you know, obviously, Shirley had this idea that the drips would represent the number of COVID deaths each week, these drips into a bowl, but that this wasn’t explicitly stated to people viewing the installation, right? She created space for viewers to bring their own interpretations, and they did. And again, it’s one of these things that I think is a beautiful idea – being able to, to withhold some information – but I don’t know, how does that manifest if you’re, you know, a data scientist or whatever, and you’re trying to create visualizations for, you know, an internal client or whatever it might be. How do you kind of bring some of that, that flavor and that interpretation and that space, to a graphic? I think that’s something that I was thinking about when reading that book, that part of the book.</p>
<p><strong>Alberto Cairo</strong><br>
There are many examples like that in the book. For example, in the chapter about Jaime Serra, Jaime created once a graphic in which– he drinks a lot of coffee, and he wanted to – remember that one – he wanted to, he wanted to see how much coffee he was actually drinking throughout a year. And if I have to do that, I will, you know, I will get my mug, the mug that I use every day to drink my coffee, I will draw a scale on top of that, and then I will measure the number of ounces of coffee that I’m drinking. At the end of the year, I will probably design a line graph, a time series line graph, to see whether there is any seasonality in my coffee consumption. I will design an analytical chart or so to speak, right, a graphic to analyze my own data. But he wanted to design something a little bit more fun, a little bit more expressive, a little more artistic and what he did was to create a graphic in which he plotted the amount of coffee that he drinks throughout a year through coffee stains. He got 12 pieces of paper, each one of them corresponding to a month. He folded those pieces of paper to subdivide them into quadrants, each one corresponding to a day. And then whenever he was drinking coffee, he tried to leave a coffee stain on the corresponding quadrant of the corresponding paper. And the result was sort of like it was a physic– it’s a physical data visualization. And it is amazing. Now, does that mean that you can insert that type of graphic, let’s say, in a business dashboard, or on a quarterly report in a company? No, that’s not the purpose of that type of visualization. The way that I usually explain the value of that type of visualization is to create this sort of like hypothetical scenario. And I have used these many times with clients when presenting you know, Shirley’s work or Jaime’s work. I say this is not the type of graphic that you use for analysis, right. For analysis, you need to use line graphs, bar graphs, scatter plots, traditional conventional data visualizations. But let’s suppose that you, for some reason, one year you conduct a survey internally in your company to analyze how much coffee people drink in the company, right? And you do sort of like this beautiful report that you print out as a hardcover book to give to your own clients as a gift when they come to visit you. What do you put inside of the book? The analytical graphics, right? The analytical charts that slice and dice the data by gender, by location, by whatever? You put all the conventional traditional graphics? What do you put on the cover? What you put on the cover is the beautiful artistic data visualization, which is still a data visualization. And same thing with Shirley’s work, right. Shirley’s installation about COVID: true, it’s not a graphic. It’s not a visualization. It’s not really a graphic because it’s physical. It’s a physical installation. But it is not a visualization that is intended to communicate the data in any sort of like, with accuracy or anything, it just tries to create a feeling. So again, imagine that you work for let’s say, a company focusing on public health or whatever. And every day, what you produce will be conventional charts and graphs and maps. That’s what we need to use to analyze data. But let’s suppose that you want to create some sort of like beautiful piece of artwork to display in your headquarters. That will be an amazing piece to display in your headquarters. It will get people– it will get visitors curious about what you do, it may drive– it may lead you to conversations about the data that they deal with everyday, the same way that Ed Hawkins’s warming stripes graphic did. It’s just a different type of data visualization that needs to be judged according to its own purposes, under its own terms.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, fantastic. Well, that’s a really nice idea to end on. Hope some people take it forward, and future visits to offices will be more visually appealing as we get to explore those spaces. So, Alberto, thank you very much. So the book is out in November, yes?</p>
<p><strong>Alberto Cairo</strong><br>
November the 15th. Yeah.</p>
<p><strong>Brian Tarran</strong><br>
Is there a website yet that people can go and find out more details?</p>
<p><strong>Alberto Cairo</strong><br>
No, still working on it. For now, there is some information in my weblog, which is the title of my first book, The Functional Art. So, it’s thefunctionalart.com. That’s my web blog. And there’s some information about The Art of Insight there, including some, you know, some sneak peeks.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Well, we’ll put a link to that in the in the show notes. So, Alberto, thank you for joining us today. Best of luck finishing up the book and the website. And I hope you can join us again soon because there’s so much more that I could discuss about the book with you, but it’s been great talking to you today.</p>
<p><strong>Alberto Cairo</strong><br>
Thank you, Brian.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Images are not covered by this licence. Photo of Alberto Cairo is copyright JCA Photography.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “The many ‘dialects’ of data visualization: Alberto Cairo and ‘The Art of Insight.’” Real World Data Science, August 1, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Data visualisation</category>
  <category>Communication</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html</guid>
  <pubDate>Tue, 01 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/images/alberto-cairo.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘Go out and talk about data science, particularly to schoolchildren’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/schools-outreach.html</link>
  <description><![CDATA[ 




<p>Rachel Hilliam, statistics professor at The Open University, used her inaugural lecture this month to make “a real plea” to the data science community “for outreach into schools”, to help build excitement and awareness of the promise and potential for careers in data science.</p>
<p>“We have a plethora of jobs that we cannot fill in data science at the moment,” said Hilliam. “We’ve had all sorts of initiatives in terms of trying to retrain people, and that’s great, and those are gaps that we need to plug. But unless we get that pipeline coming through, we’re always going to have this problem at the top.”</p>
<p>Hilliam, who is chair of the <a href="https://alliancefordatascienceprofessionals.co.uk">Alliance for Data Science Professionals</a>, wants schoolchildren and teachers to be made more aware of the benefits of, and opportunities for, data science careers. “Let me tell you,” she said, “if you go out into a school and say, ‘Do your kids want to be a data scientist?’, the teachers will look at you and go, ‘A what?’. They have no idea, generally, that data science actually exists, which is a shame.”</p>
<p>But there are plentiful opportunities to introduce data science to children, Hilliam suggests. She began her talk by saying that: “Data is everywhere – in every single thing that we do, in all of our walks of life.” And she concluded by saying: “Whatever it is that these kids are interested in, […] there is lots of data out there, so there is absolutely no reason why we can’t excite children in a career in data science. So, that’s where I’d like to finish. Go out and talk about data science, particularly to schoolchildren!”</p>
<p>Watch the lecture in full below or on YouTube. Skip to <a href="https://www.youtube.com/live/tCQhU4yP0OU?feature=share&amp;t=1024">17:04</a> for the start of the talk.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/tCQhU4yP0OU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@neonbrand?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Kenny Eliason</a> on <a href="https://unsplash.com/photos/zFSo6bnZJTw?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘Go out and talk about data science, particularly to schoolchildren.’” Real World Data Science, July 27, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/schools-outreach.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Education</category>
  <category>Data literacy</category>
  <category>Outreach</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/schools-outreach.html</guid>
  <pubDate>Thu, 27 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/images/kenny-eliason-zFSo6bnZJTw-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Testing out ChatGPT’s new Code Interpreter</title>
  <dc:creator>Lee Clewley</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/code-interpreter.html</link>
  <description><![CDATA[ 




<p>On July 6, 2023, <a href="https://twitter.com/OpenAI/status/1677015057316872192?s=20">OpenAI began rolling out the Code Interpreter plugin</a> to users of its ChatGPT Plus service. But what exactly is this, and what functionality does it offer?</p>
<p>Code Interpreter runs code and allows for uploading data so you can use ChatGPT for data cleaning, preprocessing, analysis, visualisation and predictive modelling tasks, among other things. This tool holds great promise for programmers and analysts alike, with the potential to streamline coding workflows as well as having an automated data analyst at your fingertips.</p>
<p>To use Code Interpreter, you need to enable it in the ChatGPT settings (at time of writing this only works with a paid ChatGPT Plus subscription).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic1.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic1.png" class="img-fluid figure-img" alt="Screenshot of ChatGPT Plus setting, showing Code Interpreter plugin option." width="700"></a></p>
</figure>
</div>
<p>Now, let’s take it for a bit of a spin by uploading the <a href="https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset">stroke prediction dataset from Kaggle</a>.</p>
<section id="the-stroke-prediction-dataset" class="level2">
<h2 class="anchored" data-anchor-id="the-stroke-prediction-dataset">The stroke prediction dataset</h2>
<p>The World Health Organization (WHO) identifies stroke as the second leading cause of death worldwide, accounting for roughly 11% of all fatalities.</p>
<p>Kaggle’s stroke prediction dataset is used to forecast the likelihood of a patient suffering a stroke, taking into account various input parameters such as age, gender, presence of certain diseases, and smoking habits. Each row in the dataset offers pertinent information about an individual patient.</p>
<p>Loading this dataset into ChatGPT Code Interpreter, one is treated with:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic2.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic2.png" class="img-fluid figure-img" alt="Screenshot from ChatGPT, showing Code Interpreter's initial review of an uploaded stroke prediction dataset." width="700"></a></p>
</figure>
</div>
<p>The user is asked: “Please let me know what analysis or operations you’d like to perform on this dataset. For instance, we can perform exploratory data analysis, data cleaning, data visualization, or predictive modelling.”</p>
<p>It seems quite a bold claim. So, I asked it to do all of the above.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic3.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic3.png" class="img-fluid figure-img" alt="Screenshot from ChatGPT, showing Code Interpreter's overview explanation of planned analysis steps." width="700"></a></p>
</figure>
</div>
<section id="exploratory-data-analysis" class="level3">
<h3 class="anchored" data-anchor-id="exploratory-data-analysis">Exploratory Data Analysis</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic4.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic4.png" class="img-fluid figure-img" alt="Screenshot of ChatGPT Code Interpreter's exploratory data analysis outputs." width="700"></a></p>
</figure>
</div>
<p>This is a good, useful summary. The missing values in <code>bmi</code> are set to the median, which the user can later decide to change for themselves as the code is available to do so.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic5.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic5.png" class="img-fluid figure-img" alt="Screenshot of code output from ChatGPT Code Interpreter, showing how to set missing values in dataset to the median value." width="700"></a></p>
</figure>
</div>
</section>
<section id="data-visualisation" class="level3">
<h3 class="anchored" data-anchor-id="data-visualisation">Data visualisation</h3>
<p>Next, the visualisations of the variables are shown along with a correlation heatmap. Users can toggle between the visualisations and the code. The outputs are pretty useful, except for one mistake: <code>id</code> shouldn’t be included as part of the heatmap.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic6.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic6.png" class="img-fluid figure-img" alt="Screenshot of ChatGPT Code Interpreter's description of visualisations it will create, along with partial code for doing so." width="700"></a></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic7.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic7.png" class="img-fluid figure-img" alt="Histograms and bar plots created by ChatGPT Code Interpreter for variables in the Kaggle stroke prediction dataset." width="700"></a></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p>Histograms and bar plots created by ChatGPT Code Interpreter for variables in the Kaggle stroke prediction dataset.</p>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic8.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic8.png" class="img-fluid figure-img" alt="Correlation heatmap for variables in the Kaggle stroke prediction dataset." width="700"></a></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p>Correlation heatmap for variables in the Kaggle stroke prediction dataset.</p>
</div>
<p>Things start to go seriously awry when Code Interpreter tries to create a predictive model.</p>
</section>
<section id="the-predictive-model-is-garbage" class="level3">
<h3 class="anchored" data-anchor-id="the-predictive-model-is-garbage">The predictive model is garbage</h3>
<p>From the screenshot below, you can see that lumping all the data into a predictive model creates some highly spurious results. Age is a factor, as it should be, as is hypertension – indeed, those with hypertension in this dataset are around three times more likely to have a stroke than those without. In reality, there are also significant effects from glucose level and smoking, and also a slight BMI effect in this small, unbalanced dataset. However, <code>work_type_children</code> having a large positive effect is alarming and plainly wrong.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic9.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic9.png" class="img-fluid figure-img" alt="Screenshot showing ChatGPT Code Interpreter's most important features for predicting stroke. The inclusion of 'work_type_children' is wrong: it says that 'individuals who are children are more likely to have a stroke', but goes on to explain that 'this might be the result of an imbalance in the dataset or noise, as in reality, children generally have a lower risk of stroke." width="700"></a></p>
</figure>
</div>
<p>It is very evident from the table below that the positive coefficient on children is spurious.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic10.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic10.png" class="img-fluid figure-img" alt="Screenshot of table from ChatGPT code interpreter, showing 'number of individuals' and 'number of strokes' for each 'work type'. Figures for children are 687 individuals and 2 strokes." width="700"></a></p>
</figure>
</div>
<p>So, where does this leave our thinking about Code Interpreter?</p>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>My test case is possibly an unfair one. The sort of study presented to Code Interpreter is one that requires careful analysis, and it uses a relatively small, tricky dataset whose difficulties are compounded by missing data. It’s therefore not surprising that, in this context, an automated analysis fails to shine in all respects.</p>
<p>To be fair, OpenAI themselves describe the plugin as an “<a href="https://openai.com/blog/chatgpt-plugins">eager junior programmer</a>”. And as would be the case with a real junior programmer or junior data scientist, you’d expect a more experienced hand to be guiding an analysis like the one I asked for – someone who can sense-check results, point out errors, and offer suggestions for fixes and improvements.</p>
<p>Despite some stumbles in this demo, OpenAI’s “junior programmer” presents a real step forward in the ChatGPT offering, and it is particularly impressive that one can toggle between code and charts without having to worry about coding at all.</p>
<p>At this stage, I would argue that Code Interpreter may be useful for quick summaries, visualisations and a little basic data cleaning and some preliminary investigations. However, based on what I’ve seen so far, it is clear to me that highly trained statisticians won’t be replaced anytime soon.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Lee Clewley</strong> is a member of the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/10/18/meet-the-team.html">editorial board of Real World Data Science</a> and head of applied AI in GSK’s AI and Machine Learning Group, R&amp;D.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Lee Clewley
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://unsplash.com/@charlesdeluvio?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">charlesdeluvio</a> on <a href="https://unsplash.com/photos/pjAH2Ax4uWk?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Clewley, Lee. 2023. “Testing out ChatGPT’s new Code Interpreter.” Real World Data Science, July 19, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/code-interpreter.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Coding</category>
  <category>Data analysis</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/code-interpreter.html</guid>
  <pubDate>Wed, 19 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/charlesdeluvio-pjAH2Ax4uWk-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Heading to a conference this summer? Share your learnings here</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/ideas/datasciencebites/posts/2023/07/17/dsb-live.html</link>
  <description><![CDATA[ 




<p>Three major events in the statistics and data science calendar are taking place over the next few months, and we want to give the wider community the opportunity to sample some of the exciting ideas being discussed. For that, we need your help!</p>
<p>If you’re a student or early career researcher and you’re attending one or all of the…</p>
<ul>
<li><a href="https://www.isi2023.org/">World Statistics Congress</a></li>
<li><a href="https://ww2.amstat.org/meetings/jsm/2023/">Joint Statistical Meetings</a></li>
<li><a href="https://rss.org.uk/training-events/conference-2023/">Royal Statistical Society International Conference</a></li>
</ul>
<p>…we invite you to write about your favourite paper or session as a “Bites” post.</p>
<p>Bites posts are digestible, engaging, non-technical summaries of research papers and presentations, written for an undergraduate-level audience. The goal is to draw attention to key findings, potential applications, and the wider implications of new ideas and developments in statistics and data science. <a href="https://realworlddatascience.net/contributor-docs/datasciencebites.html">Advice and guidance on how to write a Bites post can be found here</a>, and <a href="https://realworlddatascience.net/ideas/datasciencebites/">example posts can be found on our DataScienceBites page</a>.</p>
<p>For our summer conference coverage, Real World Data Science is partnering with our friends at <a href="https://mathstatbites.org/">MathStatBites</a>. If you write a Bites post and it is accepted for publication, the post will appear on one or both of our sites – depending on the focus of the research you’re writing about.</p>
<p>If you have any questions, please feel free to <a href="https://realworlddatascience.net/contact.html">contact us</a>. Otherwise, safe travels, enjoy the conference(s), and we look forward to hearing from you soon!</p>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About DataScienceBites</dt>
<dd>
<a href="../../../../../../ideas/datasciencebites/index.html"><strong>DataScienceBites</strong></a> is written by graduate students and early career researchers in data science (and related subjects) at universities throughout the world, as well as industry researchers. We publish digestible, engaging summaries of interesting new pre-print and peer-reviewed publications in the data science space, with the goal of making scientific papers more accessible. Find out how to <a href="../../../../../../contributor-docs/datasciencebites.html">become a contributor</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/ideas/datasciencebites/posts/2023/07/17/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/ideas/datasciencebites/posts/2023/07/17/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image includes photo by <a href="https://unsplash.com/@productschool?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Product School</a> on <a href="https://unsplash.com/photos/nOvIa_x_tfo?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Heading to a conference this summer? Share your learnings here.” Real World Data Science, July 17, 2023. <a href="https://realworlddatascience.net/news-and-views/datasciencebites/posts/2023/07/17/dsb-live.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Content ideas</category>
  <category>Call for contributions</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/ideas/datasciencebites/posts/2023/07/17/dsb-live.html</guid>
  <pubDate>Mon, 17 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/datasciencebites/posts/2023/07/17/images/dsb-live.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Choosing the right forecast</title>
  <dc:creator>Brian King</dc:creator>
  <link>https://realworlddatascience.net/ideas/datasciencebites/posts/2023/07/13/choosing-right-forecast.html</link>
  <description><![CDATA[ 




<p>Nobel laureate Niels Bohr is famously quoted as saying, “Prediction is very difficult, especially if it’s about the future.” The science (or perhaps the art) of forecasting is no easy task and lends itself to a large amount of uncertainty. For this reason, practitioners interested in prediction have increasingly migrated to probabilistic forecasting, where an entire distribution is given as the forecast instead of a single number, thus fully quantifying the inherent uncertainty. In such a setting, traditional metrics of assessing and comparing predictive performance, such as mean squared error (MSE), are no longer appropriate. Instead, proper scoring rules are utilized to evaluate and rank forecast methods. A scoring rule is a function that takes a predictive distribution along with an observed value and outputs a real number called the score. Such a rule is said to be proper if the expected score is maximized when the predictive distribution is the same as the distribution from which the observation was drawn.</p>
<p>Many proper scoring rules exist, such as the continuous ranked probability score (CRPS) and the logarithmic score. Choosing which rule to use is not necessarily straightforward. Furthermore, forecast methods are often selected not based on a single score, but rather averages of scores from many probabilistic forecasts, which can introduce new challenges affecting how one might rank competing forecasts. In the paper under discussion, <a href="https://projecteuclid.org/journals/statistical-science/volume-38/issue-1/Local-scale-invariance-and-robustness-of-proper-scoring-rules/10.1214/22-STS864.short">Bolin and Wallin</a> define several properties of scoring rules that help clarify how the rules behave when multiple forecast scores are averaged. Additionally, they introduce a new class of proper rules that aims to overcome some of the deficiencies of other common scoring rules.</p>
<div class="callout callout-style-default callout-note callout-titled" style="margin-top: 0rem;">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
About the paper
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p><strong>Title:</strong> Local scale invariance and robustness of proper scoring rules</p>
<p><strong>Author(s) and year:</strong> David Bolin and Jonas Wallin (2023)</p>
<p><strong>Status:</strong> Published in <em>Statistical Science</em>, DOI: <a href="https://projecteuclid.org/journals/statistical-science/volume-38/issue-1/Local-scale-invariance-and-robustness-of-proper-scoring-rules/10.1214/22-STS864.short">10.1214/22-STS864</a>.</p>
</div>
</div>
</div>
<p>The authors argue that situations are often encountered where forecasts are derived and subsequently averaged for observations with different inherent variability. One example might be financial data, such as stock returns, where there are commonly periods with much higher variance (known as volatility in the financial setting). Such processes can be represented using a model known as stochastic volatility, where the variance of observed data evolves randomly over time. Figure 1 plots an example path of the data-generating process under such a model. When data exhibits this varying uncertainty, many proper scoring rules will assign a score whose magnitude changes for those observations with more variability, a characteristic the authors term scale dependence. Some rules will ‘punish’ observations with higher uncertainty, and others may ‘reward’ such observations. Hence, when averaging multiple scores, observations will not be treated symmetrically, which the authors argue can “lead to unintuitive forecast rankings.”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/ideas/datasciencebites/posts/2023/07/13/images/fig1.png" class="img-fluid figure-img" alt="Left panel of figure shows a time series of volatility, rendered as a line chart. Right panel shows the resulting observations under a standard stochastic volatility model, in scatter plot form."></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p><strong>Figure 1:</strong> Left, a time series of volatility, and right, the resulting observations under a standard stochastic volatility model.</p>
</div>
<p>Thus, an ideal scoring rule will not suffer from scale dependence. The lack of scale dependence is a property that the authors term local scale invariance. The logarithmic score possesses this attribute, but the CRPS and other scoring rules, like the Hyvärinen score, do not. To address this issue, the authors propose a new class of scoring rules which exhibits local scale invariance. Among this class is a scoring rule dubbed the scaled CRPS (SCRPS), which features many of the desirable qualities of the CRPS but overcomes the scale dependence issue.</p>
<p>Of course, if local scale invariance is all that matters, then we could just use the logarithmic score in all scenarios. But there is another issue to consider when averaging forecast scores – the presence of outliers. In many scenarios, we might encounter observations that are very far outside the normal range, and we don’t want our average forecast performance measure to be greatly thrown off if such an oddity is observed. In other words, we want our proper scoring rules to be robust. In their article, Bolin and Wallin formalize the concept of robustness for scoring rules and show that, in many cases, the logarithmic score is not robust. Yet they also prove their proposed class of scaled scoring rules is not generally robust, although they show that the scoring rules can be modified to be robust (a new scoring rule they term robust SCRPS). Under such a modification, however, the scoring rule would no longer be local scale invariant in the strict sense. Indeed, under the proposed definitions of local scale invariance and robustness, finding a scoring rule that can simultaneously satisfy both criteria seems difficult. The authors conjecture that it may even be impossible.</p>
<p>Hence, this paper raises many questions for future consideration but achieves its goal of showing that evaluating probabilistic forecasts by averaging proper scoring rules is not necessarily a simple matter. Different scoring rules will lead to different rankings of forecasting methods, and the underlying properties of each scoring rule must be considered on a case-by-case basis. Although not discussed in this summary, the authors also compare scoring rules in several scenarios and present the theory behind the ideas examined here. For interested readers who want to dig more into these ideas, check out <a href="https://projecteuclid.org/journals/statistical-science/volume-38/issue-1/Local-scale-invariance-and-robustness-of-proper-scoring-rules/10.1214/22-STS864.short">the full paper published in <em>Statistical Science</em></a>.</p>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>About the author</dt>
<dd>
<strong>Brian King</strong> is currently a senior machine learning research engineer at Arm, working on applying machine learning to hardware verification. He recently completed his PhD in statistics at Rice University, where his research focused on Bayesian modeling and forecasting for time series of counts.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>About DataScienceBites</dt>
<dd>
<a href="../../../../../../ideas/datasciencebites/index.html"><strong>DataScienceBites</strong></a> is written by graduate students and early career researchers in data science (and related subjects) at universities throughout the world, as well as industry researchers. We publish digestible, engaging summaries of interesting new pre-print and peer-reviewed publications in the data science space, with the goal of making scientific papers more accessible. Find out how to <a href="../../../../../../contributor-docs/datasciencebites.html">become a contributor</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Brian King
</dd>
</dl>
<p>This post is republished with permission from <a href="https://mathstatbites.org/choosing-the-right-forecast/">MathStatBites</a>. Thumbnail image by <a href="https://unsplash.com/@bdchu614?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Brendan Church</a> on <a href="https://unsplash.com/photos/pKeF6Tt3c08?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
King, Brian. 2023. “Choosing the right forecast.” Real World Data Science, July 13, 2023. <a href="https://realworlddatascience.net/ideas/datasciencebites/posts/2023/07/13/choosing-right-forecast.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Forecasting</category>
  <category>Prediction</category>
  <category>Robustness</category>
  <guid>https://realworlddatascience.net/ideas/datasciencebites/posts/2023/07/13/choosing-right-forecast.html</guid>
  <pubDate>Thu, 13 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/datasciencebites/posts/2023/07/13/images/brendan-church-pKeF6Tt3c08-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Teaching a chatbot about love, and other adventures from London Data Week</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/LDW.html</link>
  <description><![CDATA[ 




<p><a href="https://www.londondataweek.org/">London Data Week</a> wraps up on Sunday, and what a week it’s been! Kudos to organisers <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/london-data-week.html">Sam Nutt and Jennifer Ding</a> for the huge amount of energy and passion they invested in making this idea a reality, and I’m looking forward to seeing what they have in store for us next year.</p>
<p>My highlights of the week? Well, of course, I really enjoyed being part of the event that was hosted at the Royal Statistical Society on Tuesday. The <a href="https://rss.org.uk/membership/volunteering-and-promoting/statisticians-for-society-initiative/">Statisticians for Society</a> workshop brought together charities and statisticians to explore ways in which data and statistics can support third sector organisations to deliver on their charitable aims as well as demonstrate to communities and funders the impact they are having. There’s a nice selection of <a href="https://rss.org.uk/membership/volunteering-and-promoting/statisticians-for-society-initiative/case-studies/">case studies of successful past projects on the RSS website</a>, and hopefully the London Data Week event will result in several new additions to this collection in due course.</p>
<p>I wasn’t able to attend this event myself, but I’m really looking forward to viewing the outputs of the <a href="https://betterimagesofai.org/images">Better Images of AI</a> workshop, which was also held on Tuesday. Real World Data Science has used several of the group’s images to illustrate past articles (<a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/11/23/LLM-content-warning.html#qa">here</a>, <a href="https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html">here</a> and <a href="https://realworlddatascience.net/ideas/posts/2023/07/03/trusted-AI.html">here</a>), so I’m excited to see what gets added to the image gallery in the coming weeks.</p>
<p>Sticking with the AI theme, I also got to explore the <a href="https://london.sciencegallery.com/ai-season">“AI: Who’s Looking After Me?” exhibition</a> at the Science Gallery, where I found myself unexpectedly moved by one installation in particular – <a href="https://london.sciencegallery.com/ai-artworks/newly-forgotten-technologies">an artificial landfill of broken and discarded tablets and smart speakers</a>, explaining matter-of-factly, but with an unmistakable air of mournfulness, that they had been replaced “by a newer model that is better because it is lighter, or heavier, or bigger, or smaller…”. Fortunately I was able to cheer myself up with another exhibit, which tasks visitors with <a href="https://london.sciencegallery.com/ai-artworks/looking-for-love">helping a chatbot to define and understand love</a>.</p>
<p>Later on in my visit to the Science Gallery (which was actually last Thursday, before London Data Week officially began), I listened to a panel debate on “Building Better AI in the Open”, featuring Margaret Mitchell of HuggingFace, Lara Groves of the Ada Lovelace Institute, and Irini Papadimitriou of FutureEverything, facilitated by artist and machine learning design researcher Caroline Sinders. A recording of the panel is below, and well worth a watch for discussion of:</p>
<ul>
<li>the advantages of open source versus closed source</li>
<li>the role of public participation in AI</li>
<li>what transparency in AI development should look like</li>
<li>issues of accountability in AI applications.</li>
</ul>
<p>Jennifer Ding followed up the panel with <a href="https://loti.london/blog/building-better-ai-in-the-open/">a thoughtful post on the benefits of open source AI</a>, and for more on trustworthy AI – and the need for transparency, explainability, and fairness – check out Maxine Setiawan and Mira Pijselman’s recent Real World Data Science article, <a href="https://realworlddatascience.net/ideas/posts/2023/07/03/trusted-AI.html">“Trusted AI: translating AI ethics from theory into practice”</a>.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/xddQq3opSzU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://unsplash.com/it/@bendavisual?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Benjamin Davies</a> on <a href="https://unsplash.com/photos/Oja2ty_9ZLM?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Teaching a chatbot about love, and other adventures from London Data Week.” Real World Data Science, July 7, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/LDW.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>AI</category>
  <category>Open source</category>
  <category>Accountability</category>
  <category>Public opinion</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/LDW.html</guid>
  <pubDate>Fri, 07 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/images/benjamin-davies-Oja2ty_9ZLM-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Trusted AI: translating AI ethics from theory into practice</title>
  <dc:creator>Maxine Setiawan and Mira Pijselman</dc:creator>
  <link>https://realworlddatascience.net/ideas/posts/2023/07/03/trusted-AI.html</link>
  <description><![CDATA[ 




<p>With artificial intelligence (AI) becoming increasingly prevalent across sectors, so too have conversations about AI ethics. AI ethics provides a repeatable and comprehensive way to assess what we should and should not be doing with AI, and sets out how we ought to design, use, and govern AI products in accordance with key principles. Ethical frameworks are essential to derive sustainable value from AI products and services and build trust.</p>
<p>A myriad of AI tools that leverage automated or semi-automated decision-making processes have raised important questions that have become foundational in the AI ethics community, such as ‘What does it mean for an algorithm to be fair?’ As an example, AI tools that are used in recruitment may perpetuate biases arising from historical training data. If a model used to generate a shortlist of applicants has been trained on data from past candidates, say, and those candidates – both successful and unsuccessful – are predominantly men, historical patterns that contain various biases will perpetuate to become algorithmic biases that form the model’s decisions. Thus, the model may algorithmically discriminate against women or gender minorities, as individuals from these groups are not well represented in the training data.</p>
<p>To ensure the safe and responsible use of AI, the focus moving forward needs to be on the operationalisation of AI ethics into the day-to-day development lifecycle. But, what does this look like in practice? And how might you get started as an ethical AI practitioner? In this article, we unpack these questions and give you, the data scientist, a foundation to begin your journey towards trusted AI. Read along to get an overview of key principles that you should be aware of, what they mean, their underlying technical grounding, and what implementation might look like practically.</p>
<section id="ethical-ai-principles" class="level2">
<h2 class="anchored" data-anchor-id="ethical-ai-principles">Ethical AI principles</h2>
<p>You have likely heard of several principles in relation to ethical AI, such as fairness or transparency. The context in which you’ve encountered such principles is most probably due to their inclusion in a broader ethical framework. Some of the most popular ethical AI frameworks include the <a href="https://www.nist.gov/itl/ai-risk-management-framework">National Institute of Standards and Technology’s AI Risk Management Framework</a>, the <a href="https://www.gov.uk/government/publications/data-ethics-framework/data-ethics-framework-2020">UK Data Ethics Framework</a>, and the <a href="https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai">European Commission’s Ethics Guidelines for Trustworthy AI</a>. Among these and many other frameworks, we can run into what <a href="https://dx.doi.org/10.2139/ssrn.3831321">Floridi and Cowls (2019)</a> call “principle proliferation,” whereby it becomes overwhelming for those contributing to AI programmes to know where to begin with ethics due to an excess of choice (p.&nbsp;2).</p>
<p>At the time of writing, there is no single universally accepted standard that dictates which essential ethical AI values or principles should be adhered to during AI development and deployment. However, there are common themes that emerge. In our organisation, EY, we’ve learned from the variety of principles, frameworks, and white papers in the AI ethics community and developed our own Trusted AI Framework comprising five key attributes that we believe assure the trustworthiness of AI:</p>
<ul>
<li>Transparent</li>
<li>Explainable</li>
<li>Unbiased</li>
<li>Resilient</li>
<li>High-performing</li>
</ul>
<p>In this article, we take a deeper dive into the first three attributes – transparency, explainability, and unbiasedness (or fairness). These are areas where data scientists can act as critical enablers of ethical AI when they have the right knowledge and toolkits at their disposal.</p>
<section id="transparency" class="level3">
<h3 class="anchored" data-anchor-id="transparency">Transparency</h3>
<p>Transparency is the ability to provide meaningful information to foster awareness and understanding of an AI system. It starts with documenting AI systems in a way that is accessible for a broad audience with a spectrum of technical abilities. It is a simple yet powerful way to build trust in AI. It empowers non-technical stakeholders to critically evaluate AI development decisions, thereby unlocking multi-disciplinary insights that can mitigate reputational or performance risks. Further, it also builds trust with society, as it can enable everyday users to interrogate AI design decisions, product capabilities, and system limitations, thereby permitting users to make informed judgements about technology. Unfortunately, transparency is often misunderstood as disclosing trade secrets or proprietary information, such as source code and datasets. However, transparency can be achieved without disclosing such technically complex information. Instead, it can be as simple as disclosing where and when an AI system is being used, or for what purposes a model should be employed.</p>
<p>But what exactly does “documenting AI systems” look like? Documentation should consist of a mix of technical components (system architecture, dataset selection determination, model selection techniques, etc.) and non-technical components (business case, product purpose of use, alignment to overall AI strategy, etc.). The research community has recommended AI documentation standards, such as <a href="https://arxiv.org/pdf/1803.09010.pdf">datasheets for datasets</a> and <a href="https://arxiv.org/pdf/1810.03993.pdf">model cards for model reporting</a>. You can liken datasheets or model cards to the importance placed upon commenting your code – the more information there is available around decisions throughout model development, the greater the certainty that these artefacts will be understood and used as intended moving forward. Proper documentation and governance will help ensure accountability, improve internal and external oversight, and initiate discussions around model optimisation goals and their trade-offs, such as including fairness and accuracy in optimisation objectives.</p>
<p>With upcoming AI regulations, transparency requirements will become more integral. For example, the <a href="https://artificialintelligenceact.eu/">European Union (EU) AI Act</a> introduces specific transparency obligations, such as bot disclosures, for both users and providers of AI systems, which would allow users to opt out of interacting with an AI system. Furthermore, in higher risk use cases, specific technical documentation is needed, which would include details of a system’s intended purpose and descriptions of its development process.</p>
</section>
<section id="explainability" class="level3">
<h3 class="anchored" data-anchor-id="explainability">Explainability</h3>
<p>Once transparency is enabled, explainability is a natural next step, especially when an AI product is implemented in a more regulated or high-risk environment. Explainability is the ability to express why an AI system reached a particular decision or understand the features that affect model behaviour. Explainability is a key concern within the field of explainable AI, which, as a discipline, strives to improve trustworthiness by enabling a better understanding of a system’s underlying logic via a suite of technical methods.</p>
<p>Fundamentally, different model architectures mean that some models are more interpretable than others, as the steps used to evaluate their predictions are easier for humans to comprehend. Decision trees, for example, have more human-interpretable characteristics than deep learning models. Different model architectures also mean that there are interpretation tools that are only applicable to certain models, such as regression weights in a linear model.</p>
<p>Another approach to consider, then, is model-agnostic interpretation, which encompasses both global interpretability (explanation of an entire model’s behaviour) and local interpretability (explanation of a single prediction). While there are fast-developing techniques and tools for model-agnostic interpretability, let’s take a look at two of the more popular methods available:</p>
<ul>
<li><dl>
<dt><a href="https://dl.acm.org/doi/10.1145/2939672.2939778">Local interpretable model-agnostic explanations (LIME)</a></dt>
<dd>
This is an explanation technique that trains local surrogate models, using explainable models such as Lasso or decision trees, to approximate the predictions of a model that is not interpretable by design in order to explain individual model predictions. The idea is to use interpretable features from the surrogate models to create human-friendly explanations where the underlying model cannot. For example, in an image classification model that detects a flower in an image, LIME is able to highlight the parts of the image that explain why the model classifies the image as a flower (see illustration below). This provides an interpretable explanation between the input variable and prediction, which is an essential part of interpretability.
</dd>
</dl></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/lime.png"><img src="https://realworlddatascience.net/ideas/posts/2023/07/03/images/lime.png" class="img-fluid figure-img" alt="Illustration of explainable AI processes using LIME on an image classification AI system. In this example, an image classification system receives an image of a sunflower and classifies it as a flower with 70% likelihood. The LIME approach then sees parts of the input image perturbed, or masked, leading to different classification likelihoods from the AI system. From this, a model is able to determine the parts of the input image that best explain the initial classification of 'flower'."></a></p>
<figcaption class="figure-caption">Illustration of explainable AI processes using LIME on an image classification AI system. Adapted from “Local Interpretable Model-Agnostic Explanations (LIME): An Introduction” and <a href="https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/">O’Reilly</a>.</figcaption>
</figure>
</div>
<ul>
<li><dl>
<dt><a href="https://papers.nips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html">Shapley Additive Explanations (SHAP)</a></dt>
<dd>
SHAP (<a href="https://github.com/slundberg/shap">GitHub repo</a>) uses tools and theoretical foundations from game theory, one of which is Shapley values. It works by assigning each feature an importance value for a particular prediction to numerically explain the contribution of various features to a model’s output. For example, in a model that predicts flu, SHAP calculates the importance of sneezing as a feature by removing and adding the subset of other features, leading to different combinations of features that contribute to the prediction. This method provides interpretable solutions for more complex models similar to the equivalent of “weights” in linear models.
</dd>
</dl></li>
</ul>
</section>
<section id="fairness" class="level3">
<h3 class="anchored" data-anchor-id="fairness">Fairness</h3>
<p>The area of AI ethics that is central to impending AI regulations, such as the EU AI Act and the New York City AI Law,<sup>1</sup> is fairness. AI models are inherently biased because of their underlying training data.<sup>2</sup> Thus, when we speak of fairness in the context of AI ethics, we are referring to a combination of technical and non-technical ways to minimise the impacts of algorithmic bias.</p>
<p>Let’s begin with the technical approaches to fairness. To achieve equitable, reliable, and fair decisions, a diverse and balanced set of examples is needed in training datasets. However, data often contains disparities that, if left unchecked, can perpetuate algorithmic biases and harms. There are various approaches to detect sources of bias, guarantee fairness, or “debias” models. To strive for algorithmic fairness, many papers have proposed various quantitative measures of fairness, with some based on unstated assumptions about fairness in society. Unfortunately, <a href="https://arxiv.org/pdf/1609.07236.pdf">these assumptions are often mutually incompatible</a>, making it difficult to compare fairness metrics to one another – consider, for example, the longstanding debate between equality of outcome and equality of treatment.</p>
<p>Although metrics incompatibilities exist, fairness broadly focuses on equality of opportunity (group fairness), and equality of outcome (individual fairness) to prevent discrimination against certain attributes. Drawing definitions from legal frameworks, the term “protected attribute” refers to the characteristics that are often protected under anti-discrimination laws, such as gender or race. Mathematically, the following metrics are often used to demonstrate scores that support fairness:</p>
<ul>
<li><dl>
<dt>Statistical parity</dt>
<dd>
This measure seeks to uncover whether a model is fair towards protected attributes by measuring the difference between the majority and protected class in receiving a favourable outcome. A value of 0 demonstrates the model to be fair.
</dd>
</dl></li>
<li><dl>
<dt>Disparate impact</dt>
<dd>
This compares the percentage of favourable outcomes for the monitored group to the percentage of favourable outcomes for a reference group. The groups compared can be the majority group and minority group, and this score will highlight in whose direction decisions are biased. For example, if a model grants loans to 60% of people in a middle-aged group and only 50% for those of other age cohorts, then the disparate impact is 0.8, which indicates a positive bias towards the middle-aged group and an adverse impact on the remaining cohorts.
</dd>
</dl></li>
<li><dl>
<dt>Equality of odds</dt>
<dd>
This measures the balance of the true positive rate and false positive rate between protected and unprotected groups, which seeks to uncover whether a model performs similarly for the two groups.
</dd>
</dl></li>
</ul>
<p>It is important to remember that statistics are only one side of the fairness problem for machine learning, and one that treats the symptoms of bias as opposed to the underlying causes. In addition to the aforementioned technical approaches, there are a variety of non-technical measures that teams developing AI systems can adopt to augment fairness and inclusion:</p>
<ul>
<li><dl>
<dt>Definition of fairness</dt>
<dd>
Organisations that develop or use AI systems need to define, practically, what it means to be fair. Although there are various quantitative fairness measures, these are based on assumptions of fairness in society, which could be defined for each specific use case.
</dd>
</dl></li>
<li><dl>
<dt>Diversity on teams</dt>
<dd>
There’s been a sharpened focus on the value of team diversity to areas such as productivity and creativity. The same is true for ethics. Ensuring that product teams are composed of a broad cross-section of identities can help to organically drive fairness through diversity of thought and experience.
</dd>
</dl></li>
<li><dl>
<dt>Education and self-reflection</dt>
<dd>
Developing knowledge within individuals and teams about the socio-technical aspects of AI – that is, the ways in which AI shapes our social, political, economic, and environmental lives. The more critical a person can be as a data scientist in questioning why something is being built, the more likely they are to proactively recognise risks surrounding fairness.
</dd>
</dl></li>
<li><dl>
<dt>Consider the end user</dt>
<dd>
Imagine that you are on a development team building an AI solution for a problem in the agricultural sector pertaining to livestock health. Who is best suited to solving the problem: a data scientist or a farmer? As a data scientist, you may have the tools to develop a solution, but given your distance from the end user, you are unlikely to intimately understand the problem in the same way a farmer would. If you cannot understand the problem, you cannot hope to find a solution, much less an ethical one. Recognising the importance of consulting individuals that are representative of end users is key to ensure that your design is fair.
</dd>
</dl></li>
<li><dl>
<dt>AI ethics review boards</dt>
<dd>
Data science teams should not operate in isolation. Increasingly, organisations are establishing AI ethics review boards or similar forums that are intended to act as checks on the design decisions made throughout AI development. Does your organisation have one?
</dd>
</dl></li>
</ul>
</section>
</section>
<section id="in-conclusion" class="level2">
<h2 class="anchored" data-anchor-id="in-conclusion">In conclusion</h2>
<p>These three areas – transparency, explainability, and fairness – are the starting points to embed and operationalise AI ethics in technical development. Transparency relies on both technical and non-technical documentation to facilitate discussions with non-technical stakeholders, as well as to create and enforce accountabilities. Explainability helps to build trust in AI output by vesting us with an ability to explain “why”. Finally, adopting both technical and non-technical measures of fairness can ensure that AI products in development do not adversely impact certain groups.</p>
<p>In addition to these three areas of AI ethics, within EY we have two other focus areas – resilience and high-performance – that form part of our Trusted AI Framework. We will discuss these in a future article. We’re also keen to explore topics such as generating trust in generative AI! Until then, please share your stories of developing ethical AI projects in the comments below. How are you translating AI ethics from theory into practice?</p>
<div class="callout callout-style-simple callout-note callout-titled" style="margin-top: 2.25rem;">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Further reading
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For further technical reading, we suggest:</p>
<ul>
<li><a href="https://christophm.github.io/interpretable-ml-book/">Interpretable Machine Learning</a>, by Christoph Molnar</li>
<li><a href="https://fairmlbook.org/">Fairness and Machine Learning</a>, by Solon Barocas, Moritz Hardt, and Arvind Narayanan</li>
</ul>
<p>For further socio-technical reading on AI and data ethics, we suggest:</p>
<ul>
<li><em>The Age of Surveillance Capitalism</em>, by Shoshana Zuboff</li>
<li><em>Invisible Women</em>, by Caroline Criado Pérez</li>
<li><em>Race after Technology</em>, by Ruha Benjamin</li>
<li><em>Algorithms of Oppression</em>, by Safiya Noble</li>
<li><em>Atlas of AI</em>, by Kate Crawford</li>
<li><em>Weapons of Math Destruction</em>, by Cathy O’Neil</li>
<li><em>Data Feminism</em>, by Catherine D’Ignazio and Lauren Klein</li>
</ul>
</div>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../ideas/index.html">Explore more data science ideas</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<a href="https://www.ey.com/en_uk/people/maxine-setiawan">Maxine Setiawan</a> is a social data scientist specialising in trusted AI, and AI and data risk in EY UK&amp;I. With her multi-disciplinary background, she works to help clients understand and manage risks from their data and AI systems, and to ensure AI governance that is fair, accountable, and trustworthy. Maxine holds an MSc in social data science from the University of Oxford.
</dd>
<dd>
<p><a href="https://www.ey.com/en_uk/people/mira-pijselman">Mira Pijselman</a> is the digital ethics lead for EY UK&amp;I, where she focuses on the responsible governance of key emerging technologies, including artificial intelligence, quantum technologies, and the metaverse. A social scientist and philosopher by training, she helps clients to map, understand, secure, and capitalise on their data and technology potential safely. Mira holds an MSc in the social science of the internet from the University of Oxford.</p>
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Maxine Setiawan and Mira Pijselman
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/ideas/posts/2023/07/03/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/ideas/posts/2023/07/03/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
<p>Thumbnail image by <a href="https://www.burg-halle.de/en/xlab">Alexa Steinbrück</a> / <a href="https://www.betterimagesofai.org">Better Images of AI</a> / Explainable AI / <a href="https://creativecommons.org/licenses/by/4.0/">Licenced by CC-BY 4.0</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Setiawan, Maxine and Mira Pijselman. 2023. “Trusted AI: translating AI ethics from theory into practice.” Real World Data Science, July 3, 2023. <a href="https://realworlddatascience.net/ideas/posts/2023/07/03/trusted-AI.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>New York City Local Law 144.↩︎</p></li>
<li id="fn2"><p>Not statistical bias (usually known as bias-variance trade-off), which compares the training data and target value to approximate errors.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>AI ethics</category>
  <category>Principles</category>
  <category>Regulation</category>
  <guid>https://realworlddatascience.net/ideas/posts/2023/07/03/trusted-AI.html</guid>
  <pubDate>Mon, 03 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/ideas/posts/2023/07/03/images/explainable-AI.png" medium="image" type="image/png" height="102" width="144"/>
</item>
<item>
  <title>‘I was inspired by the power that numerical data have to tell stories and promote policy change’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/career-profiles/posts/2023/06/28/claire-morton.html</link>
  <description><![CDATA[ 




<p>This week, in celebration of Pride, Real World Data Science is collaborating with the <a href="https://datascijedi.org/">JEDI Outreach Group</a> of the <a href="https://www.amstat.org/">American Statistical Association</a> (ASA) and the <a href="https://sites.google.com/view/asa-lgbtq/home">ASA LGBTQ+ Advocacy Committee</a> to highlight the achievements of statisticians and data scientists from across the LGBTQ+ spectrum.</p>
<p>Members of the committee nominated two individuals to be featured as part of our <a href="https://realworlddatascience.net/careers/career-profiles/">career profile</a> series, and so we are pleased to bring you interviews with Claire Morton (below) and <a href="../../../../../../careers/career-profiles/posts/2023/06/28/albert-lee.html">Albert Lee</a>.</p>
<p>Read on to discover more about Claire’s data science career (so far).</p>
<div class="keyline">
<hr>
</div>
<p><strong>Hi, Claire. Thank you for sharing your career story with Real World Data Science. Please tell us a little about yourself and your role in data science.</strong><br>
My name is Claire Morton, and I’m an undergraduate student studying mathematical and computational science and environmental justice at Stanford University. I’m particularly interested in using statistics and data science to work with community-based organizations and advance evidence-based environmental justice policy. I have conducted quantitative research on tools to classify disadvantaged communities, oil wells, climate resilience, housing justice, and the connections between soil and health.</p>
<p><strong>What drew you to study statistics and data science?</strong><br>
I really enjoyed my math, statistics, and coding classes in school. I was also inspired by the power that numerical data have to tell stories and promote policy change.</p>
<p><strong>What do you think is your most important skill as a data scientist?</strong><br>
Listening to others. Listening allows me to learn new statistics skills from my mentors and to learn about how best I can work with community partners on their priorities in my research.</p>
<p><strong>How does your gender and/or sexual identity factor into your career?</strong><br>
I am a lesbian, and, at the start of college, I didn’t have any mentors who shared my identity. I’ve now found several through the ASA and queer communities at my university, and I’m continually inspired by the achievements of queer statisticians, mathematicians, and computer scientists. My research hasn’t explicitly connected statistics and queerness yet, but I’m interested in working on projects involving hard-to-reach populations, such as queer people, in the future.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/career-profiles/posts/2023/06/28/images/claire-morton.png" class="img-fluid figure-img" alt="Portrait photo of Claire Morton"></p>
<figcaption class="figure-caption">Claire Morton</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>It’s important to be able to take initiative to learn skills, talk to people, and solve problems as they come up – but it’s also critical to not be afraid of asking for help when you need it.</p>
</div>
</div>
</div>
<p><strong>How did you get into data science?</strong><br>
In high school, I worked in a cell biology lab. As part of that work, I learned to model cellular processes and analyze data from my experiments. I realized that those elements were my favorite parts of the science I was doing, so I decided to study math, computer science, and/or statistics in college. I had always been interested in environmental issues, and so I got involved in quantitative research about environmental justice. I realized that this type of research allowed me to connect the skills I have to my passions, so I’ve kept working in these areas ever since.</p>
<p><strong>What, or who, first inspired you to pursue this career path?</strong><br>
My mom! She’s also a statistician, and she has encouraged and mentored me throughout my academic journey. I’m inspired by her success as a woman in statistics.</p>
<p><strong>What hurdles or challenges have you faced in your studies?</strong><br>
My classes can be tough, which makes it hard to stay motivated sometimes. I also struggled to maintain a healthy work-life balance at the start of college. Finally, it has been tough to learn some of the ins and outs of the research process and publications – how best to engage with research mentors, what it looks like to write and submit a paper, and some of the nuances of working in academia. I think my next big challenge is deciding what to do after college, though I’ve been trying to reframe the question as an opportunity rather than a hurdle. I’m excited to continue doing research at the intersection of statistics and public policy in the future.</p>
<p><strong>What was your first job in data science, and how does it compare to your current role?</strong><br>
My first job in data science was as a researcher, working at a non-profit called Physicians, Scientists, and Engineers for Healthy Energy (PSE). As part of this job, I worked with community-based organizations to code quantitative optimization models to locate climate resilience hubs in California that took community priorities into account. I’m currently a student, which involves less research but gives me the chance to focus on learning new skills for my next job. I hope to be able to work in a role like my job at PSE, combining statistics/data science, community engagement, and policy impact, in the future.</p>
<p><strong>What was the most important thing you learned in your first year on the job?</strong><br>
The importance of being adaptable and self-directed. Research projects shift and change as you uncover new information, and it’s useful to be able to shift with them. It’s important to be able to take initiative to learn skills, talk to people, and solve problems as they come up – but it’s also critical to not be afraid of asking for help when you need it.</p>
<p><strong>What have been your career highlights so far?</strong><br>
One was publishing research about the demographics of people living near oil wells in California, which informed policymakers about racial and socioeconomic differences in exposure to oil wells and is part of a long-standing effort from activists and researchers to protect the health of Californians. I’ve also gotten to work directly with organizers on several mapping projects, which was deeply fulfilling. Finally, I loved getting to present my research at the Joint Statistical Meetings last year, and I look forward to presenting my undergraduate thesis this year.</p>
<p><strong>What three things are at the top of your reading/study list?</strong><br>
Some statistical areas I’m hoping to learn more about are spatial statistics and survey methods. Some books I’m excited to read are <em>The Color of Law</em>, <em>Data Feminism</em>, and <em>Thicker Than Blood: How Racial Statistics Lie</em>. </p>
<p><strong>What advice would you give for anyone wanting to study statistics and data science?</strong><br>
Find mentors that inspire you, support your career goals, and challenge you to learn and grow as a statistician.</p>
<p><strong>What new ideas or developments in the field are you most excited about or intrigued by?</strong><br>
I’m really interested in combining quantitative research with community-based research, so I think that cross-disciplinary developments are exciting. I’m intrigued by AI tools, and I’m interested to see how these tools change what the day-to-day of being a statistician looks like and the skills that are most sought after in a statistician.</p>
<p><strong>And what do you think will be the main challenges facing the profession over the next few years?</strong><br>
The main challenges will be related to statistical literacy, both for the people consuming and doing statistics. While statistical methods and data becoming more accessible is a positive development, it has meant that more analyses are done incorrectly and that more misleading results are publicized (and absorbed) as truth. It’s getting much easier to twist numbers to support whatever we want them to say, and I think this will continue to challenge both statisticians and non-statisticians in the future.</p>
<div class="callout callout-style-simple callout-note callout-titled" style="margin-top: 2.25rem;">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
About the ASA Pride Scholarship
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <a href="https://www.amstat.org/the-asa-celebrates-pride!">ASA Pride Scholarship</a> was established to raise awareness for and support the success of LGBTQ+ statisticians and data scientists and allies. The scholarship will celebrate their diverse backgrounds and showcase the invaluable skills and perspectives these individuals bring to the ASA, statistics, and data science.</p>
<p><a href="https://www.amstat.org/your-career/awards/asa-pride-scholarship">Apply or nominate someone</a> for the ASA Pride Scholarship.</p>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../../careers/career-profiles/index.html">Discover more Career profiles</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/06/28/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/06/28/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photo of Claire Morton is not covered by this licence.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘I was inspired by the power that numerical data have to tell stories and promote policy change.’” Real World Data Science, June 28, 2023. <a href="https://realworlddatascience.net/careers/career-profiles/posts/2023/06/28/claire-morton.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Education</category>
  <category>Research</category>
  <category>Policy</category>
  <category>Mentoring</category>
  <category>Statistical literacy</category>
  <guid>https://realworlddatascience.net/careers/career-profiles/posts/2023/06/28/claire-morton.html</guid>
  <pubDate>Wed, 28 Jun 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/career-profiles/posts/2023/06/28/images/claire-morton.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘Living my identity takes courage. It is the same courage necessary to start a new business’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/career-profiles/posts/2023/06/28/albert-lee.html</link>
  <description><![CDATA[ 




<p>This week, in celebration of Pride, Real World Data Science is collaborating with the <a href="https://datascijedi.org/">JEDI Outreach Group</a> of the <a href="https://www.amstat.org/">American Statistical Association</a> (ASA) and the <a href="https://sites.google.com/view/asa-lgbtq/home">ASA LGBTQ+ Advocacy Committee</a> to highlight the achievements of statisticians and data scientists from across the LGBTQ+ spectrum.</p>
<p>Members of the committee nominated two individuals to be featured as part of our <a href="https://realworlddatascience.net/careers/career-profiles/">career profile</a> series, and so we’re pleased to bring you interviews with Albert Lee (below) and <a href="../../../../../../careers/career-profiles/posts/2023/06/28/claire-morton.html">Claire Morton</a>.</p>
<p>Read on to discover more about Albert’s data science career (so far).</p>
<div class="keyline">
<hr>
</div>
<p><strong>Hi, Albert. Thank you for sharing your career story with Real World Data Science. Please tell us a little about yourself and your role in data science.</strong><br>
My name is Albert Lee. I’m the founding partner at Summit Consulting, a quantitative and financial consulting firm in Washington, DC. Summit delivers data-driven solutions to help make government effective and society just. I started Summit in 2003, and we recently celebrated our 20th anniversary.</p>
<p>I received my PhD in economics from UCLA in 1999. My professional practice is focused on econometrics – an academic specialty that blends economic theory with statistical practices – and statistical sampling.</p>
<p><strong>What does your job involve?</strong><br>
A large portion of my time is spent running Summit and making decisions about management, personnel, and business development. That said, I am still pretty active in technical topics. I am a testifying expert in econometrics and statistical sampling. Recently, I have been leading a team of data scientists who are reformulating the edit and imputation algorithms for the US Department of Agriculture’s National Agriculture Statistical Service, which collects survey data from US agriculture sectors.</p>
<p><strong>What do you think is your most important skill as a data scientist?</strong><br>
Explaining technical concepts is a big part of my job, and it requires the ability to consume the technical literature and know the concepts well enough that I can explain them to a lay audience (such as lawyers, judges, and program staff).</p>
<p><strong>How has your gender and/or sexual identity factored into your career?</strong><br>
My gender and identity have given me important perspective as a data scientist and an entrepreneur. Living my identity takes courage. It is the same courage necessary to start a new business. From a young age, my identity has conditioned me to be comfortable with differences.</p>
<p>My identity has also taught me to see similarity among differences. Empathy is essential in client services and especially in quantitative consulting, where some of my clients feel disempowered by the complex subject matter.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/career-profiles/posts/2023/06/28/images/albert-lee.png" class="img-fluid figure-img" alt="Portrait photo of Albert Lee"></p>
<figcaption class="figure-caption">Albert Lee</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>The data science field is moving very fast. Every day brings a new algorithm, software program, and hardware innovation. Since data science is a multidisciplinary field, keeping up with it has been challenging.</p>
</div>
</div>
</div>
<p><strong>How did you get into data science?</strong><br>
Although I studied mathematics and economics as an undergraduate student and economics as a graduate student, my academic training was very theoretical. I didn’t work with data and computers extensively until my first job outside of academia in the early 2000s. Little did I know that it was the advent of the “big data” revolution.</p>
<p>At Summit we serve mostly federal agencies, who are sitting on decades of administrative data – information they collected as part of their mission but not of research quality. These agencies want to use their administrative data to automate their routine tasks (like predicting which loans will default first) and evaluate program efficacy (determining whether a training program reached its goals). Extracting and analyzing administrative data has been a big part of my career.</p>
<p>When I founded Summit, data science was not a recognized discipline. But as the datasets get larger, decisions about hardware setup, software programs, estimation algorithms, and data virtualization have become increasingly intertwined and interdependent. This really was my first taste of data science as we know it today.</p>
<p><strong>What, or who, first inspired you to become a data scientist?</strong><br>
There are too many people to mention by name. I owe a lot of my career to my first two managers at KPMG, Alan Salzberg and Rick Holt. They taught me how to code and reason quantitatively. And Rob Gould at UCLA has patiently converted a theorist to an empiricist. Once a convert, now a zealot.</p>
<p><strong>What were the hurdles or challenges that you needed to overcome on your route into the profession?</strong><br>
I am an immigrant and a first-generation college graduate. My journey was full of unknowns. Figuring out my academic and professional career has taken a lot of exploration. In this regard, the same exploration that guided my identity also guided my academic and professional journey.</p>
<p><strong>And what are the challenges that you face now that you are working in data science?</strong><br>
The data science field is moving very fast. Every day brings a new algorithm, software program, and hardware innovation. Since data science is a multidisciplinary field, keeping up with it has been challenging. As I progress along my professional journey, striking the right balance between management, hands-on practice, and learning has been difficult as well.</p>
<p><strong>What was your first job in data science, and how does it compare to your current role?</strong><br>
As an entrepreneur, I was given a lot of professional freedom to actualize my career. To a large extent, I have the career that I envisioned. To me, data science lives in the intersection of methods, software, and hardware. I have spent a large part of my career in this intersection.</p>
<p>Of course there are many things that were not part of the original vision, such as running a 100-person organization. My approach has always been intention with openness. By this metric, my current role is not far off from my original vision.</p>
<p><strong>What was the most important thing you learned in your first year on the job?</strong><br>
The ability and the love of learning constantly, regardless of the topic.</p>
<p><strong>What have been your career highlights so far?</strong><br>
The biggest highlight was that on June 15, 2023, Summit celebrated its 20th anniversary! Reformulating the National Agricultural Statistics Service’s edit and imputation systems is also a big deal. And being a testifying expert in some of the most consequential legal cases in the United States was a highlight as well.</p>
<p><strong>What three things are at the top of your current reading/study list?</strong><br>
In recent years, I have been binge-reading Stoic philosophy. I have read most books by Ryan Holiday. His most recent book was <em>Ego Is the Enemy</em>. In between the Stoics, you will find me reading Buddhist meditation literature, including Thich Nhat Hanh’s <em>The Heart of the Buddha’s Teaching</em>. David McCullough’s <em>Truman</em> is also by my bedside.</p>
<p><strong>What advice would you give for anyone wanting to be a data scientist?</strong><br>
Be open and multidisciplinary. Many good ideas in statistics come from other fields, such as economics, medicine, sociology, and education. Computer science enables computational statistics. Having the openness to these topics is key.</p>
<p><strong>What new ideas or developments in the field are you personally most excited about or intrigued by?</strong><br>
Machine learning has transformed statistics both as a consumer and a contributor. It consumes statistics in that it requires cutting-edge statistical techniques and algorithms for its estimation. Machine learning has important applications in many of the statistical sciences.</p>
<p><strong>And what do you think will be the main challenges facing the profession over the next few years?</strong><br>
The proper use of statistics or statistical ethics is an important societal challenge. Machine learning is becoming increasingly sophisticated, and its applications are more broad and pervasive. Machine learning algorithms are making more and more decisions in society, including mortgage loan approvals, residential home prices, and which prisoners receive parole. These are important and weighty decisions. How do we know that these decisions are unbiased and fair?</p>
<div class="callout callout-style-simple callout-note callout-titled" style="margin-top: 2.25rem;">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
About the ASA Pride Scholarship
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <a href="https://www.amstat.org/the-asa-celebrates-pride!">ASA Pride Scholarship</a> was established to raise awareness for and support the success of LGBTQ+ statisticians and data scientists and allies. The scholarship will celebrate their diverse backgrounds and showcase the invaluable skills and perspectives these individuals bring to the ASA, statistics, and data science.</p>
<p><a href="https://www.amstat.org/your-career/awards/asa-pride-scholarship">Apply or nominate someone</a> for the ASA Pride Scholarship.</p>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../../careers/career-profiles/index.html">Discover more Career profiles</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/06/28/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/06/28/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photo of Albert Lee is not covered by this licence.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘Living my identity takes courage. It is the same courage necessary to start a new business.’” Real World Data Science, June 28, 2023. <a href="https://realworlddatascience.net/careers/career-profiles/posts/2023/06/28/albert-lee.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Consulting</category>
  <category>Leadership</category>
  <category>Econometrics</category>
  <category>Sampling</category>
  <category>Machine learning</category>
  <guid>https://realworlddatascience.net/careers/career-profiles/posts/2023/06/28/albert-lee.html</guid>
  <pubDate>Wed, 28 Jun 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/career-profiles/posts/2023/06/28/images/albert-lee.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘Once I started to see what was possible with data science, there was no going back’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/career-profiles/posts/2023/06/20/chanuki-seresinhe.html</link>
  <description><![CDATA[ 




<p><strong>Hi, Chanuki. Thank you for sharing your career story with Real World Data Science. Please tell us a little about yourself and your role in data science.</strong><br>
I am Chanuki Seresinhe, head of data science at Zoopla and Hometrack. My commercial career in data science began in 2018 at Channel 4. Since then, I have worked at a few different companies – from startups to scale-ups – before ending up here at Zoopla in 2022.</p>
<p>I am also the founder of <a href="https://www.beautifulplaces.ai/">beautifulplaces.ai</a>, which is a continuation of my University of Warwick and Alan Turing Institute PhD work where I provided the first large-scale evidence that beautiful places are connected to our wellbeing.</p>
<p><strong>What does your job involve?</strong><br>
My role at Zoopla involves managing data scientists both for Zoopla and Hometrack. At Zoopla, we use data science to create an engaging experience for users who want to buy, sell and rent properties. At Hometrack, the data scientists mainly work on an automated valuation model that provides property valuations to most of the major mortgage lenders in the UK.</p>
<p>As a leader in data science, my role primarily involves helping stakeholders across the business to best leverage data science to reach our business goals, as well as ensuring my data science team has all the support and mentoring they need to design, develop and maintain high performing data science algorithms.</p>
<p><strong>What does “data science” mean to you?</strong><br>
That is a really good question! One thing I have noticed is that people who aren’t familiar with the field often confuse data science and data analytics. There are indeed many similarities – both require quite a bit of knowledge to be able to leverage the correct insights from both structured and unstructured data (data hidden within images, for example). However, data science is essential when you need to make inferences. For instance, you are not only analysing data to see what certain consumers may prefer, but you are also predicting what similar consumers might prefer. Thus, having a strong grounding in statistics is really important for anyone working in this field.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/career-profiles/posts/2023/06/20/images/chanuki-seresinhe.png" class="img-fluid figure-img" alt="Portrait photo of  Chanuki Seresinhe"></p>
<figcaption class="figure-caption">Chanuki Seresinhe</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>In data science, getting the model right is not enough, and working with people across the business to make sure the model can be integrated into the business processes is essential.</p>
</div>
</div>
</div>
<p><strong>What do you think is your most important skill as a data scientist?</strong><br>
Aside from a good grounding in the technical aspects of data science (which is possible for really anyone to pick up from the many good courses that are available), the most important skill is how you can leverage data science to create products that actually create value for the business. I find this to be the most challenging journey that junior data scientists find themselves having to navigate. They are really excited about the technology, and get carried away with wanting to perfect their algorithms. But when you are building commercial products, what is really important is to constantly engage with stakeholders to make sure you are building something that actually has a tangible business benefit. Early release of a model for user testing is also essential, as models only really get better once you have real user input.</p>
<p><strong>How did you get into data science?</strong><br>
It was somewhat by accident. I previously had a long career in digital and decided to take a career break to return to university and study economics. When I was working on my Master’s degree in behavioral economic science at the University of Warwick, I saw an ad for a PhD to “use online data to understand human behaviour” and I thought this was perfect, as it combined my prior knowledge with a new area I was increasingly becoming drawn to. I quickly taught myself how to program in Python and convinced my supervisors to take me on, and from there on, I came to love data science!</p>
<p><strong>What, or who, first inspired you to become a data scientist?</strong><br>
It was more about realising what you could do with data science. In my PhD, I was quantifying the connection between beautiful places and our wellbeing. While this has long been an intuitive connection, we were not able to test this on a large scale due to lack of data. Being able to use data science to start predicting the beauty of outdoor images was fascinating as it opened up a whole new method for potential research combining beauty with various wellbeing ratings. Once I started to see what was possible with data science, there was no going back.</p>
<p><strong>What were the hurdles or challenges that you needed to overcome on your route into the profession?</strong><br>
For me personally it was the challenge of moving sideways into a leadership role after my PhD and not having to start all the way from the bottom. I would have loved to continue in academia and expand my research even further, but starting from the bottom earning a tiny salary after I had taken quite a large career break to do my PhD wasn’t an option for me. So I decided to go back into the commercial world and look for a senior role from the get go and luckily Channel 4 agreed to give me my first commercial stab at data science.</p>
<p><strong>What are the challenges that you face now, as a working data scientist?</strong><br>
Trying to keep up with everything that is constantly changing in the world of data science. I love the rapid change but it can also be quite time consuming to make sure you are on top of it and giving the right advice to people.</p>
<p><strong>What was your first job in data science, and how does it compare to your current role?</strong><br>
My first job was working as a senior data scientist at Channel 4. As a senior data scientist, even though you have additional goals to help run the team and be a mentor to more junior data scientists, you still get a great deal of time to do coding and develop your own projects. When you move more into a management role, the time you have to develop data science models diminishes. People also expect you to give in-depth guidance when you haven’t actually had much time to deep dive into a project. So, I am often trying hard to make sure I am on top of what is going on even when I have limited time, and really focus on building a strong team that can support each other and collaborate often to create better data science products. Learning to delegate is key!</p>
<p><strong>What was the most important thing you learned in your first year on the job?</strong><br>
How hard it is to actually get organisational buy-in to use data science at scale. It is really easy to get approval to build a proof of concept (POC). However, if you do not use the time when developing your POC to also make sure to get the right stakeholder on board, your project is dead before it even starts. So, in data science, getting the model right is not enough, and working with people across the business to make sure the model can be integrated into the business processes is essential.</p>
<p><strong>What have been your career highlights so far?</strong><br>
It has been great being able to give talks about my research, and data science in general, all around the world. I have actually come to love public speaking, and I hope that as I continue to be recognised for my expertise, I can encourage and aid potential data scientists with their careers – especially minority women, as I think that diversity in the field is very important. This is a role that is fit for people from all kinds of backgrounds and I hope I am exemplifying this.</p>
<p><strong>Have there been any mistakes or regrets along the way?</strong><br>
In smaller companies, it can easily happen that the founders don’t fully understand data science and often use data science as a buzzword to get investors on board. Whenever you take on a new job, and data science is just getting established, make sure the founders or leaders are actually fully onboard with integrating data science into the product and understand what this means. See if they know how tricky data science can be when first integrating into a product and are actually willing to overcome the challenges with you to eventually reap the huge benefits data science can bring.</p>
<p><strong>How do you think your role will evolve over the rest of your career?</strong><br>
I see my role evolving into being more strategic and less about the data science day-to-day modelling. It is more about being able to advise companies on how to make use of data science as a strategy and helping them figure out where in the product or process to inject it to get the most out of it for the business as a whole.</p>
<p><strong>If you were starting out in data science now, what would you put at the top of your reading or study list?</strong><br>
Practise how you would apply using data science for a real life problem. Seek a placement, as this will pay dividends in being able to speed up your learning.</p>
<p>If you don’t understand the statistics involved in data science, make sure to upskill in that area before starting your first role. A lot of junior data scientists focus on learning how to code or get carried away with the modelling without first learning the importance of preparing the data in the correct way so that your predictions can work well in a real life setting.</p>
<p><strong>What personal or professional advice would you give for anyone wanting to be a data scientist now?</strong><br>
Try to find ways to stand out from the average data scientist. When we open up applications for data science jobs, I get hundreds of applications for each one. I am looking for people who can not only do data science but who also have other stand-out qualities that they can bring to the business. This can be something along the lines of effective stakeholder engagement to deep expertise in a certain domain or technology.</p>
<p><strong>What new ideas or developments in the field of data science are you personally most excited about or intrigued by?</strong><br>
I am really interested to see where generative AI will take us – particularly about how it can help us improve the speed of our own performance. It feels like generative AI can be a technology that can help everyone – even the everyday person – as it can help speed up so many processes, from coding to writing to ideating. While the technology is still in its early days, it is progressing rapidly and I am very curious to see where this will lead in the next year!</p>
<p><strong>What do you think will be the main challenges facing data science as a field in the next few years?</strong><br>
Generative AI’s latest breakthroughs have made AI capabilities accessible to the broader public, but it has also stoked fears around the use of AI. The headline-grabbing narratives around AI and existential threat is distracting from other conversations that are really important. There are some very real issues we do need to solve – from biases in AI to the impact generative AI can have on wages and workforce – but this needs to be approached in a constructive and thoughtful way.</p>
<p>We need to find a way to engage with the public in a more meaningful way – rather than scaremongering – to have public debates on issues that actually matter.</p>
<div class="article-btn">
<p><a href="../../../../../../careers/career-profiles/index.html">Discover more Career profiles</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/06/20/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/06/20/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photo of Chanuki Seresinhe is not covered by this licence.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘Once I started to see what was possible with data science, there was no going back.’” Real World Data Science, June 20, 2023. <a href="https://realworlddatascience.net/careers/career-profiles/posts/2023/06/20/chanuki-seresinhe.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Internet</category>
  <category>Real estate</category>
  <category>Leadership</category>
  <category>Statistics</category>
  <category>Stakeholder engagement</category>
  <guid>https://realworlddatascience.net/careers/career-profiles/posts/2023/06/20/chanuki-seresinhe.html</guid>
  <pubDate>Tue, 20 Jun 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/career-profiles/posts/2023/06/20/images/chanuki-seresinhe.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>The road to reproducible research: hazards to avoid and tools to get you there safely</title>
  <dc:creator>Davit Svanidze, Andre Python, et al.</dc:creator>
  <link>https://realworlddatascience.net/case-studies/posts/2023/06/15/road-to-reproducible-research.html</link>
  <description><![CDATA[ 




<p>Reproducibility, or “<a href="https://www.nsf.gov/sbe/AC_Materials/SBE_Robust_and_Reliable_Research_Report.pdf">the ability of a researcher to duplicate the results of a prior study using the same materials as the original investigator</a>”, is critical for sharing and building upon scientific findings. Reproducibility not only verifies the correctness of processes leading to results but also serves as a prerequisite for assessing generalisability to other datasets or contexts. This we refer to as replicability, or “<a href="https://www.nsf.gov/sbe/AC_Materials/SBE_Robust_and_Reliable_Research_Report.pdf">the ability of a researcher to duplicate the results of a prior study if the same procedures are followed but new data are collected</a>”. Reproducibility, which is the focus of our work here, can be challenging – especially in the context of deep learning. This article, and associated material, aims to provide practical advice for overcoming these challenges.</p>
<p>Our story begins with Davit Svanidze, a master’s degree student in economics at the London School of Economics (LSE). Davit’s efforts to make his bachelor’s thesis reproducible are what inspires this article, and we hope that readers will be able to learn from Davit’s experience and apply those learnings to their own work. Davit will demonstrate the use of Jupyter notebooks, GitHub, and other relevant tools to ensure reproducibility. He will walk us through code documentation, data management, and version control with Git. And, he will share best practices for collaboration, peer review, and dissemination of results.</p>
<p>Davit’s story starts here, but there is much more for the interested reader to discover. At certain points in this article, we will direct readers to other resources, namely a <a href="https://github.com/dsvanidze/replicability/blob/master/notebooks/main.ipynb">Jupyter notebook</a> and <a href="https://github.com/dsvanidze/replicability">GitHub repository</a> which contain all the instructions, data and code necessary to reproduce Davit’s research. Together, these components offer a comprehensive overview of the thought process and technical implementation required for reproducibility. While there is no one-size-fits-all approach, the principles remain consistent.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/06/15/images/computer.png" class="img-fluid figure-img" alt="A young man sits in front of a computer keyboard, surrounded by monitors and books and with computer cables covering various surfaces"></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p><strong>Credit:</strong> Discord software, Midjourney bot.</p>
</div>
<section id="davits-journey-towards-reproducibility" class="level2">
<h2 class="anchored" data-anchor-id="davits-journey-towards-reproducibility">Davit’s journey towards reproducibility</h2>
<section id="more-power-please" class="level3">
<h3 class="anchored" data-anchor-id="more-power-please">More power, please</h3>
<p>The focus of my bachelor’s thesis was to better understand the initial spread of Covid-19 in China using deep learning algorithms. I was keen to make my work reproducible, but not only for my own sake. The “reproducibility crisis” is a well-documented problem in science as a whole,<sup>1</sup> <sup>2</sup> <sup>3</sup> <sup>4</sup> with studies suggesting that around one-third of social science studies published between the years 2010 and 2015 in top journals like <em>Nature</em> and <em>Science</em> could not be reproduced.<sup>5</sup> Results that cannot be reproduced are not necessarily “wrong”. But, if findings cannot be reproduced, we cannot be sure of their validity.</p>
<p>For <a href="https://github.com/dsvanidze/replicability/blob/master/notebooks/main.ipynb">my own research project</a>, I gathered all data and started working on my computer. After I built the algorithms to train the data, my first challenge to reproducibility was computational. I realised that training models on my local computer was taking far too long, and I needed a faster, more powerful solution to be able to submit my thesis in time. Fortunately, I could access the university server to train the algorithms. Once the training was complete, I could generate the results on my local computer, since producing maps and tables was not so demanding. However…</p>
</section>
<section id="bloody-paths" class="level3">
<h3 class="anchored" data-anchor-id="bloody-paths">Bloody paths!</h3>
<p>In switching between machines and computing environments, I soon encountered an issue with my code: the <a href="https://en.wikipedia.org/wiki/Path_(computing)">paths</a>, or file directory locations, for the trained algorithms had been hardcoded! As I quickly discovered, hardcoding a path can lead to issues when the code is run in a different environment, as the path might not exist in the new environment.</p>
<p>As my code became longer, I overlooked the path names linked to algorithms that were generating the results. This mistake – which would have been easily corrected if spotted earlier – resulted in incorrect outputs. Such errors could have enormous (negative) implications in a public health context, where evidence-based decisions have real impacts on human lives. It was at this point that I realised that my code is the fundamental pillar of the validity of my empirical work. How can someone trust my work if they are not able to verify it?</p>
<p>The following dummy code demonstrates the hardcoding issue:</p>
<div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{python}</span></span>
<span id="cb1-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Hardcoded path</span></span>
<span id="cb1-3">file_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"/user/notebooks/toydata.csv"</span></span>
<span id="cb1-4"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">try</span>:</span>
<span id="cb1-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(file_path) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>:</span>
<span id="cb1-6">        data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.read()</span>
<span id="cb1-7">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(data)</span>
<span id="cb1-8"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">FileNotFoundError</span>:</span>
<span id="cb1-9">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"File not found"</span>)</span>
<span id="cb1-10"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/06/15/images/hardcoded-paths-1.gif" class="img-fluid"></p>
<p>In the code above, a dummy file (<code>toydata.csv</code>) is used. The dummy file contains data on the prices of three different toys, but only the path of the file is relevant to this example. If the hardcoded file path – <code>"/user/notebooks/toydata.csv"</code> – exists on the machine being used, the code will run just fine. But, when run in a different environment without said path, the code will result in a <code>"File not found error"</code>. Better code that uses relative paths can be written as:</p>
<div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb2-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{python}</span></span>
<span id="cb2-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Relative path</span></span>
<span id="cb2-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb2-4"></span>
<span id="cb2-5">file_path <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> os.path.join(os.getcwd(), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"toydata.csv"</span>)</span>
<span id="cb2-6"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">try</span>:</span>
<span id="cb2-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(file_path) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>:</span>
<span id="cb2-8">        data <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">file</span>.read()</span>
<span id="cb2-9">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(data)</span>
<span id="cb2-10"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">except</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">FileNotFoundError</span>:</span>
<span id="cb2-11">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"File not found"</span>)</span>
<span id="cb2-12"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/06/15/images/hardcoded-paths-2.gif" class="img-fluid"></p>
<p>You can see that this code has successfully imported data from the dataset <code>toydata.csv</code> and printed its two columns (toy and price) and three rows.</p>
<p>The following example is a simplified version of what happened when I wrote code to train several models, store the results and run a procedure to compare results with the predictive performance of a benchmark model:</p>
<div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb3-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{python}</span></span>
<span id="cb3-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set an arbitrary predictive performance value of a benchmark model</span></span>
<span id="cb3-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># and accept/reject models if the results are above/below the value.</span></span>
<span id="cb3-4">benchmark <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span></span>
<span id="cb3-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the model details in one place for a better overview</span></span>
<span id="cb3-6">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb3-7">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model1"</span>: {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model1"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"simple"</span>}, </span>
<span id="cb3-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model2"</span>: {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model2"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"complex"</span>}</span>
<span id="cb3-9">}</span>
<span id="cb3-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the current model to "model1" to use it for training and check its results</span></span>
<span id="cb3-11">current_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model1"</span>]</span>
<span id="cb3-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train a simple model for "model1" and a complex model for "model2"</span></span>
<span id="cb3-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Training result of the "model1" is 30 and for "model2" is 70</span></span>
<span id="cb3-14">model_structure <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train(current_model[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>])</span>
<span id="cb3-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save the model and its result in a .csv file</span></span>
<span id="cb3-16">model_structure.to_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'/all/notebooks/results-of-model1.csv'</span>, index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb3-17"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb4-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{python}</span></span>
<span id="cb4-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the model result and compare with benchmark</span></span>
<span id="cb4-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Model name: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(current_model[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>]))</span>
<span id="cb4-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Model type: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(current_model[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>]))</span>
<span id="cb4-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the result of the current model</span></span>
<span id="cb4-6">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'/all/notebooks/results-of-model2.csv'</span>).iloc[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb4-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Result: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(result))</span>
<span id="cb4-8"></span>
<span id="cb4-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> benchmark:</span>
<span id="cb4-10">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\033</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">[3;32m&gt;&gt;&gt; Result is better than the benchmark -&gt; Accept the model and use it for calculations"</span>)</span>
<span id="cb4-11"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb4-12">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\033</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">[3;31m&gt;&gt;&gt; Result is NOT better than the benchmark -&gt; Reject the model as it is not optimal"</span>)</span>
<span id="cb4-13"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/06/15/images/hardcoded-paths-3.gif" class="img-fluid"></p>
<p>Everything looks fine at a glance. But, if you examine the code carefully, you may spot the problem. Initially, when I coded the procedure (training the model, saving and loading the results), I hardcoded the paths and had to change them for each tested model. First, I trained <code>model2</code>, a complex model, and tested it against the benchmark (70 &gt; 50 → accepted). I repeated the procedure for <code>model1</code> (a simple model). Its result was identical to <code>model2</code>, therefore I kept <code>model1</code> following the <a href="https://www.sciencedirect.com/topics/computer-science/parsimony-principle">parsimony principle</a>.</p>
<p>However, for the code line loading the result for the current model (line 5, second cell), I forgot to amend the path and so mistakenly loaded the result of <code>model2</code>. As a consequence, I accepted a model which should have been rejected. These wrong results were then spread further in the code, including all charts and maps and the conclusions of my analysis.</p>
<p>A small coding error like this can therefore be fatal to an analysis. Below is the corrected code:</p>
<div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb5-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{python}</span></span>
<span id="cb5-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> os</span>
<span id="cb5-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set an arbitrary predictive performance value of a benchmark model</span></span>
<span id="cb5-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># and accept/reject models if the results are above/below the value.</span></span>
<span id="cb5-5">benchmark <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50</span></span>
<span id="cb5-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the model details (INCLUDING PATHS) in one place for a better overview</span></span>
<span id="cb5-7">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb5-8">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model1"</span>: {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model1"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"simple"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"path"</span>: os.path.join(os.getcwd(), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"results-of-model1.csv"</span>)}, </span>
<span id="cb5-9">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model2"</span>: {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model2"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"complex"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"path"</span>: os.path.join(os.getcwd(), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"results-of-model2.csv"</span>)}</span>
<span id="cb5-10">}</span>
<span id="cb5-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the current model to "model1" to use it for training and check its results</span></span>
<span id="cb5-12">current_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"model1"</span>]</span>
<span id="cb5-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Train a simple model for "model1" and a complex model for "model2"</span></span>
<span id="cb5-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Training result of the "model1" is 30 and for "model2" is 70</span></span>
<span id="cb5-15">model_structure <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> train(current_model[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>])</span>
<span id="cb5-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save the model and its result in a .csv file</span></span>
<span id="cb5-17">model_structure.to_csv(current_model[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"path"</span>], index<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>)</span>
<span id="cb5-18"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb6-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{python}</span></span>
<span id="cb6-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the model result and compare with the benchmark</span></span>
<span id="cb6-3"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Model name: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(current_model[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>]))</span>
<span id="cb6-4"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Model type: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(current_model[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>]))</span>
<span id="cb6-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Load the result of the current model WITH a VARIABLE PATH</span></span>
<span id="cb6-6">result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> pd.read_csv(current_model[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"path"</span>]).iloc[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>, <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb6-7"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Result: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(result))</span>
<span id="cb6-8"></span>
<span id="cb6-9"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">if</span> result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> benchmark:</span>
<span id="cb6-10">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\033</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">[3;32m&gt;&gt;&gt; Result is better than the benchmark -&gt; Accept the model and use it for calculations"</span>)</span>
<span id="cb6-11"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">else</span>:</span>
<span id="cb6-12">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\033</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">[3;31m&gt;&gt;&gt; Result is NOT better than the benchmark -&gt; Reject the model as it is not optimal"</span>)</span>
<span id="cb6-13"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/06/15/images/hardcoded-paths-4.gif" class="img-fluid"></p>
<p>Here, the paths are stored with other model details (line 7–8, first cell). Therefore, we can use them as variables when we need them (e.g., line 16, first cell, and line 5, second cell). Now, when the current model is set to <code>model1</code> (line 11, first cell), everything is automatically adjusted. Also, if the path details need to be changed, we only need to change them once and everything else is automatically adjusted and updated. The code now correctly states that <code>model1</code> performs worse than the benchmark and is therefore rejected and we should keep <code>model2</code>, which performs best.</p>
<p>I managed to catch this error in time, but it often can be difficult to spot our own mistakes. That is why making code available to others is crucial. A code review by a second (or third) pair of eyes can save everyone a lot of time and avoid spreading incorrect results and conclusions.</p>
</section>
<section id="solving-compatibility-chaos-with-docker" class="level3">
<h3 class="anchored" data-anchor-id="solving-compatibility-chaos-with-docker">Solving compatibility chaos with Docker</h3>
<p>One might think that it would be easy to copy code from one computer to another and run it without difficulties, but it turns out to be a real headache. Different operating systems on my local computer and the university server caused multiple compatibility issues and it was very time-consuming to try to solve them. The university server was running on Ubuntu, a Linux distribution, which was not compatible with my macOS-based code editor. Moreover, the server did not support the Python programming language – and all the deep learning algorithm packages that I needed – in the same way as my macOS computer did.</p>
<p>As a remedy, I used Docker containers, which allowed me to create a virtual environment with all the necessary packages and dependencies installed. This way, I could integrate them with different hardware and use the processing power of that hardware. To get started with Docker, I first had to install it on my local computer. The installation process is straightforward and <a href="https://docs.docker.com/desktop/">the Docker website</a> provides step-by-step instructions for different operating systems. In fact, I found the Docker website very helpful, with lots of resources and tutorials available. Once Docker was installed, it was easy to create virtual environments for my project and work with my code, libraries, and packages, without any compatibility issues. Not only did Docker containers save me a lot of time and effort, but they could also make it easier for others to reproduce my work.</p>
<p>Below is an example of a Dockerfile which recreates an environment with Python 3.7 on Linux. It describes what, how, when and in which order operations should be carried out to generate the environment with all Python packages required to run the main Python script, <code>main.py</code>.</p>
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/06/15/images/Dockerfile-example.png" class="img-fluid" alt="An example of a Dockerfile, showing the various steps required to recreate the correct environment for running Python file, main.py."></p>
<div class="figure-caption">
<p>An example of a Dockerfile.</p>
</div>
<p>In this example, by downloading the project, including the Dockerfile, anyone can run <code>main.py</code> without installing packages or worrying about what OS was used for development or which Python version should be installed. You can view Docker as a great robot chef: show it a recipe (Dockerfile), provide the ingredients (project files), push the start button (to build the container) and wait to sample the results.</p>
</section>
<section id="why-does-nobody-check-your-code" class="level3">
<h3 class="anchored" data-anchor-id="why-does-nobody-check-your-code">Why does nobody check your code?</h3>
<p>Even after implementing Docker, I still faced another challenge to reproducibility: making the verification process for my code easy enough that it could be done by anyone, without them needing a degree in computer science! Increasingly, there is an expectation for researchers to share their code so that results can be reproduced, but there are as yet no widely accepted or enforced standards on how to make code readable and reusable. However, if we are to embrace the concept of reproducibility, we must write and publish code under the assumption that someone, somewhere – boss, team member, journal reviewer, reader – will want to rerun our code. And, if we expect that someone will want to rerun our code (and hopefully check it), we should ensure that the code is readable and does not take too long to run.</p>
<p>If your code <em>does</em> take too long to run, some operations can often be accelerated – for example, by reducing the size of the datasets or by implementing computationally efficient data processing approaches (e.g., using <a href="https://pytorch.org/">PyTorch</a>). Aim for a running time of a few minutes – or about as long as it takes to make a cup of tea or coffee. Of course, if data needs to be reduced to save computational time, the person rerunning your code won’t generate the same results as in your original analysis. This therefore will not lead to reproducibility, <em>sensu stricto</em>. However, as long as you state clearly what are the expected results from the reduced dataset, your peers can at least inspect your code and offer feedback, and this marks a step towards reproducibility.</p>
<p>We should also make sure our code is free from bugs – both the kind that might lead to errors in analysis and also those that stop the code running to completion. Bugs can occur for various reasons. For example, some code chunks written on a Windows machine may not properly execute on a macOS machine because the former uses <code>\</code> for file paths, while the latter uses <code>/</code>:</p>
<div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb7-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{python}</span></span>
<span id="cb7-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Path works on macOS/Linux</span></span>
<span id="cb7-3"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"../../all/notebooks/toydata.csv"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"r"</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> f:</span>
<span id="cb7-4">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(f.read())</span>
<span id="cb7-5"></span>
<span id="cb7-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Path works only on Windows    </span></span>
<span id="cb7-7"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(<span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">r"..\..\all\notebooks\toydata.csv"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"r"</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> f:</span>
<span id="cb7-8">   <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(f.read())</span>
<span id="cb7-9"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/06/15/images/path-cross-platform-compatibility-1.gif" class="img-fluid"></p>
<p>Here, only the macOS/Linux version works, since the code this capture was taken from was implemented on a Linux server. There are alternatives, however. The code below works on macOS, Linux, and also Windows machines:</p>
<div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb8-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{python}</span></span>
<span id="cb8-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pathlib <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Path</span>
<span id="cb8-3"></span>
<span id="cb8-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Path works on every OS: macOS/Linux/Windows</span></span>
<span id="cb8-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># It will automatically replace the path to "..\..\all\notebooks\toydata.csv" when it runs on Windows</span></span>
<span id="cb8-6"><span class="cf" style="color: #003B4F;
background-color: null;
font-style: inherit;">with</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">open</span>(Path(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"../../all/notebooks/toydata.csv"</span>), <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"r"</span>) <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> f:</span>
<span id="cb8-7">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(f.read())</span>
<span id="cb8-8"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/06/15/images/path-cross-platform-compatibility-2.gif" class="img-fluid"></p>
<p>The extra Python package, <code>pathlib</code>, is of course unnecessary if you build a Docker container for your project, as discussed in the previous section.</p>
</section>
<section id="jupyter-king-of-the-notebooks" class="level3">
<h3 class="anchored" data-anchor-id="jupyter-king-of-the-notebooks">Jupyter, King of the Notebooks</h3>
<p>By this stage in my project, I was feeling that I’d made good progress towards ensuring that my work would be reproducible. I’d expended a lot of effort to make my code readable, efficient, and also absent of bugs (or, at least, this is what I was hoping for). I’d also built a Docker container to allow others to replicate my computing environment and rerun the analysis. Still, I wanted to make sure there were no barriers that would prevent people – my supervisors, in particular – from being able to review the work I had done for my undergraduate thesis. What I wanted was a way to present a complete narrative of my project that was easy to understand and follow. For this, I turned to Jupyter Notebook.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/06/15/images/jupyter.png" class="img-fluid figure-img" alt="A rendering of the god Jupiter, holding a pencil and sat in front of an open laptop computer"></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p><strong>Credit:</strong> Discord software, Midjourney bot.</p>
</div>
<p>Jupyter notebooks combine <a href="https://www.markdownguide.org/cheat-sheet/">Markdown text</a>, code, and visualisations. The notebook itself can sit within an online directory of folders and files that contain all the data and code related to a project, allowing readers to understand the processes behind the work and also access the raw resources. From <a href="https://github.com/dsvanidze/replicability/blob/master/notebooks/main.ipynb">the notebook I produced</a>, readers can see exactly what I did, how I did it, and what my results were.</p>
<p>While creating my notebook, I was able to experiment with my code and iterate quickly. Code cells within a document can be run interactively, which allowed me to try out different approaches to solving a problem and see the results almost in real time. I could also get feedback from others and try out new ideas without having to spend a lot of time writing and debugging code.</p>
</section>
<section id="version-control-with-git-and-github" class="level3">
<h3 class="anchored" data-anchor-id="version-control-with-git-and-github">Version control with Git and GitHub</h3>
<p>My Jupyter notebook and associated folders and files are all available via <a href="https://github.com/dsvanidze/replicability">GitHub</a>. <a href="https://git-scm.com/">Git</a> is a version control system that allows you to keep track of changes to your code over time, while GitHub is a web-based platform that provides a central repository for storing and sharing code. With Git and GitHub, I was able to version my code and collaborate with others without the risk of losing any work. I really couldn’t afford to redo the entire year I spent on my dissertation!</p>
<p>Git and GitHub are great for reproducibility. By sharing code via these platforms, others can access your work, verify it and reproduce your results without risking changing or, worse, destroying your work – whether partially or completely. These tools also make it easy for others to build on your work if they want to further develop your research. You can also use Git and GitHub to share or promote your results across a wider community. The ability to easily store and share your code also makes it easy to keep track of the different versions of your code and to see how your work has evolved.</p>
<p>The following illustration shows the tracking of very simple changes in a Python file. The previous version of the code is shown on the left; the new version is shown on the right. Additions and deletions are highlighted in green and red, and with <code>+</code> and <code>-</code> symbols, respectively.</p>
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/06/15/images/Git-example.png" class="img-fluid" alt="A simple example of GitHub version tracking, showing how changes to a file are tracked and highlighted"></p>
<div class="figure-caption">
<p>A simple example of GitHub version tracking.</p>
</div>
</section>
</section>
<section id="the-deep-learning-challenge" class="level2">
<h2 class="anchored" data-anchor-id="the-deep-learning-challenge">The deep learning challenge</h2>
<p>So far, this article has dealt with barriers to reproducibility – and ways around them – that will apply to most, if not all, modern research projects. While I’d encourage any scientist to adopt these practices in their own work, it is important to stress that these alone cannot guarantee reproducibility. In cases where standard statistical procedures are used within statistical software packages, reproducibility is often achievable. However, in reality, even when following the same procedures, differences in outputs can occur, and identifying the reasons for this may be challenging. Cooking offers a simple analogy: subtle changes in room temperature or ingredient quality from one day to the next can impact the final product.</p>
<p>One of the challenges for research projects employing machine learning and deep learning algorithms is that outputs can be influenced by the randomness that is inherent in these approaches. Consider the four portraits below, generated by the Midjourney bot.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/06/15/images/DL_bkg.png" class="img-fluid figure-img" alt="Four portraits rendered by generative AI. Each portrait looks broadly similar, but there are noticeable differences in facial features and the abstract patterns overlaid on the portraits"></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p><strong>Credit:</strong> Discord software, Midjourney bot.</p>
</div>
<p>Each portrait looks broadly similar at first glance. However, upon closer inspection, critical differences emerge. These differences arise because deep learning models rely on numerous interconnected layers to learn intricate patterns and representations. Slight random perturbations, such as initial parameter values or changes in data samples, can propagate through the network, leading to different decisions during the learning process. As a result, even seemingly negligible randomness can amplify and manifest as considerable differences in the final output, as with the distinct features of the portraits.</p>
<p>Randomness is not necessarily a bad thing – it mitigates overfitting and helps predictions to be generalised. However, it does present an additional barrier to reproducibility. If you cannot get the same results using the same raw materials – data, code, packages and computing environment – then you might have good reasons to doubt the validity of the findings.</p>
<p>There are many elements of an analysis in which randomness may be present and lead to different results. For example, in a classification (where your dependent variable is binary, e.g., success/failure with 1 and 0) or a regression (where your dependent variable is continuous, e.g., temperature measurements of 10.1°C, 2.8°C, etc.), you might need to split your data into training and testing sets. The training set is used to estimate the model (hyper)parameters and the testing set is used to compute the performance of the model. The way the split is usually operationalised is as a random selection of rows of your data. So, in principle, each time you split your data into training and testing sets, you may end up with different rows in each set. Differences in the training set may therefore lead to different values of the model (hyper)parameters and affect the predictive performance that is measured from the testing set. Also, differences in the testing set may lead to variations in the predictive performance scores, which in turn lead to potentially different interpretations and, ultimately, decisions if the results are used for that purpose.</p>
<p>This aspect of randomness in the training of models is relatively well known. But randomness may hide in other parts of code. One such example is illustrated below. Here, using Python, we set the seed number to 0 using <code>np.random.seed(seed value)</code>. The <code>random.seed()</code> function from the package <code>numpy</code> (abbreviated <code>np</code>) saves the state of a random function so that it can create identical random numbers independently of the machine you use, and this is for any number of executions. A seed value is an initial input or starting point used by a pseudorandom number generator to generate a sequence of random numbers. It is often an integer or a timestamp. The number generator takes this seed value and uses it to produce a deterministic series of random numbers that appear to be random but can be recreated by using the same seed value. Without providing this seed value, the first execution of the function typically uses the current system time. The animation below generates two random arrays <code>arr1</code> and <code>arr2</code> using <code>np.random.rand(3,2)</code>. Note that the values <code>3,2</code> indicate that we want random values for an array that has 3 rows and 2 columns.</p>
<div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb9-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{python}</span></span>
<span id="cb9-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> numpy <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">as</span> np</span>
<span id="cb9-3"></span>
<span id="cb9-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#Set the seed number e.g. to 0</span></span>
<span id="cb9-5">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb9-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate random array</span></span>
<span id="cb9-7">arr1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.rand(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb9-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## print("Array 1:")</span></span>
<span id="cb9-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## print(arr1)</span></span>
<span id="cb9-10"></span>
<span id="cb9-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#Set the seed number as before to get the same results</span></span>
<span id="cb9-12">np.random.seed(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>)</span>
<span id="cb9-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Generate another random array</span></span>
<span id="cb9-14">arr2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.rand(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb9-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## print("\nArray 2:")</span></span>
<span id="cb9-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## print(arr2)</span></span>
<span id="cb9-17"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/06/15/images/randomisation-with-seed.gif" class="img-fluid"></p>
<p>If you run the code yourself multiple times, the values of <code>arr1</code> and <code>arr2</code> should remain identical. If this is not the case, check that the seed value is set to 0 in lines 4 and 11. These identical results are possible because we set the seed value to 0, which ensures that the random number generator produces the same sequence of numbers each time the code is run. Now, let’s look at what happens if we remove the line <code>np.random.seed(0)</code>:</p>
<div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb10-1"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```{python}</span></span>
<span id="cb10-2"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#Generate random array</span></span>
<span id="cb10-3">arr1 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.rand(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb10-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## print("Array 1:")</span></span>
<span id="cb10-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## print(arr1)</span></span>
<span id="cb10-6"></span>
<span id="cb10-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#Generate another random array</span></span>
<span id="cb10-8">arr2 <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> np.random.rand(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3</span>,<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)</span>
<span id="cb10-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## print("\nArray 2:")</span></span>
<span id="cb10-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">## print(arr2)</span></span>
<span id="cb10-11"><span class="in" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">```</span></span></code></pre></div>
<p><img src="https://realworlddatascience.net/case-studies/posts/2023/06/15/images/randomisation-without-seed.gif" class="img-fluid"></p>
<p>Here, the values of <code>arr1</code> and <code>arr2</code> will be different each time we run the code since the seed value was not set and is therefore changing over time.</p>
<p>This short code demonstrates how randomness that can be controlled by the seed value may affect your code. Therefore, unless randomness is required, e.g., to get some uncertainty in the results, setting the seed value will contribute to making your work reproducible. I also find it helpful to document the seed number I use in my code so that I can easily reproduce my findings in the future. If you are currently working on some code that involves random number generators, it might be worth checking your code and making all necessary changes. In our work (see code chunk 9 in <a href="https://github.com/dsvanidze/replicability/blob/master/notebooks/main.ipynb">the Jupyter notebook</a>) we set the seed value in a general way, using a framework (config) so that our code always uses the same seed to train our algorithm.</p>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<p>We hope you have enjoyed learning more about our quest for reproducibility. We have explained why reproducibility matters and provided tips for how to achieve it – or, at least, work towards it. We have introduced a few important issues that you are likely to encounter on your own path to reproducibility. In sum, we have mentioned:</p>
<ul>
<li>The importance of having relative instead of hard-coded paths in code.</li>
<li>Operating system compatibility issues, which can be solved by using Docker containers for a consistent computing environment.</li>
<li>The convenience of Jupyter notebooks for code editing – particularly useful for data science projects and work using deep learning because of the ability to include text and code in the same document and make the work accessible to everyone (so long as they have an internet connection).</li>
<li>The need for version control using, for example, Git and GitHub, which allows you to keep track of changes in your code and collaborate with others efficiently.</li>
<li>The importance of setting the seed values in random number generators.</li>
</ul>
<p>The graphic below provides a visual overview of the different components of our study and shows how each component works with the others to support reproducibility.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/docker-workflow.png"><img src="https://realworlddatascience.net/case-studies/posts/2023/06/15/images/docker-workflow.png" class="img-fluid figure-img" alt="A diagrammatic overview of the interlinking systems and processes created by the authors to allow their research to be reproduced"></a></p>
</figure>
</div>
<p>We use (A) the version control system, Git, and its hosting service, GitHub, which enables a team to share code with peers, efficiently track and synchronise code changes between local and server machines, and reset the project to a working state in case something breaks. Docker containers (B) include all necessary objects (engine, data, and scripts). Docker needs to be installed (plain-line arrows) by all users (project leader, collaborator(s), reviewer(s), and public user(s)) on their local machines (C); and (D) we use a user-friendly interface (JupyterLab) deployed from a local machine to facilitate the operations required to reproduce the work. The project leader and collaborators can edit (upload/download) the project files stored on the GitHub server (plain-line arrows) while reviewers and public users can only read the files (dotted-line arrows).</p>
<p>Now, it is over to you. Our <a href="https://github.com/dsvanidze/replicability/blob/master/notebooks/main.ipynb">Jupyter notebook</a> provides a walkthrough of our research. Our <a href="https://github.com/dsvanidze/replicability">GitHub repository</a> has all the data, code and other files you need to reproduce our work, and this <a href="https://github.com/dsvanidze/replicability#readme">README file</a> will help you get started.</p>
<p>And with that, we wish you all the best on the road to reproducibility!</p>
<div class="article-btn">
<p><a href="../../../../../case-studies/index.html">Find more case studies</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Davit Svanidze</strong> is a master’s degree student in economics at the London School of Economics (LSE). <strong>Andre Python</strong> is a young professor of statistics at Zhejiang University’s Center for Data Science. <strong>Christoph Weisser</strong> is a senior data scientist at BASF. <strong>Benjamin Säfken</strong> is professor of statistics at TU Clausthal. <strong>Thomas Kneib</strong> is professor of statistics and dean of research at the Faculty of Business and Economic Sciences at Goettingen University. <strong>Junfen Fu</strong> is professor of pediatrics, chief physician and director of the Endocrinology Department of Children’s Hospital, Zhejiang University, School of Medicine.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-12">
<dl>
<dt>Acknowledgement</dt>
<dd>
Andre Python has been funded by the National Natural Science Foundation of China (82273731), the National Key Research and Development Program of China (2021YFC2701905) and Zhejiang University global partnership fund (188170-11103).
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Davit Svanidze, Andre Python, Christoph Weisser, Benjamin Säfken, Thomas Kneib, and Junfen Fu.
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/case-studies/posts/2023/06/15/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/case-studies/posts/2023/06/15/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Svanidze, Davit, Andre Python, Christoph Weisser, Benjamin Säfken, Thomas Kneib, and Junfen Fu. 2023. “The road to reproducible research: hazards to avoid and tools to get you there safely.” Real World Data Science, June 15, 2023. <a href="https://realworlddatascience.net/case-studies/posts/2023/06/15/road-to-reproducible-research.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">References</h2>

<ol>
<li id="fn1"><p>Peng, Roger D. 2011. “Reproducible Research in Computational Science.” <em>Science</em> 334 (6060): 1226–1227.↩︎</p></li>
<li id="fn2"><p>Ioannidis, John P. A., Sander Greenland, Mark A. Hlatky, Muin J. Khoury, Malcolm R. Macleod, David Moher, Kenneth F. Schulz, and Robert Tibshirani. 2014. “Increasing Value and Reducing Waste in Research Design, Conduct, and Analysis.” <em>The Lancet</em> 383 (9912): 166–175.↩︎</p></li>
<li id="fn3"><p>Open Science Collaboration. 2015. “Estimating the Reproducibility of Psychological Science.” <em>Science</em> 349 (6251): aac4716.↩︎</p></li>
<li id="fn4"><p>Baker, Monya. 2016. “Reproducibility Crisis?” <em>Nature</em> 533 (26): 353–366.↩︎</p></li>
<li id="fn5"><p>Camerer, Colin F., Anna Dreber, Felix Holzmeister, Teck-Hua Ho, Jürgen Huber, Magnus Johannesson, Michael Kirchler, Gideon Nave, Brian A. Nosek, Thomas Pfeiffer, <em>et al</em>. 2018. “Evaluating the Replicability of Social Science Experiments in <em>Nature</em> and <em>Science</em> between 2010 and 2015.” <em>Nature Human Behaviour</em> 2: 637–644.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Deep learning</category>
  <category>Reproducibility</category>
  <category>Coding</category>
  <category>Collaboration</category>
  <guid>https://realworlddatascience.net/case-studies/posts/2023/06/15/road-to-reproducible-research.html</guid>
  <pubDate>Thu, 15 Jun 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/case-studies/posts/2023/06/15/images/computer-intro.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>How do people feel about AI? Well, it’s complicated</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/how-do-people-feel-about-ai.html</link>
  <description><![CDATA[ 




<p>How do people feel about AI? That was a question recently explored in a survey of 4,000 British residents. The answer is that, well, it depends.</p>
<p>Researchers at the Ada Lovelace Institute and the Alan Turing Institute designed the survey to ask about specific AI use cases, rather than the concept of AI more broadly. Use cases included face recognition for policing, border control and security, targeted advertising for political campaigns and consumer products, virtual assistants, driverless cars, and so on.</p>
<p>Roshni Modhvadia, a researcher at the Ada Lovelace Institute and member of the survey team, reported that respondents overall were broadly positive towards most of the use cases they were asked about. Healthcare applications (using AI to assess the risk of cancer, for example) or face recognition for border security were seen as very or somewhat beneficial by more than 80% of those surveyed. More than half of respondents thought that other applications, such as virtual reality in education, climate research simulations, and robotic care assistants were very or somewhat beneficial.</p>
<p>Views were less positive towards applications including driverless cars, autonomous weapons and targeted advertising. These were the applications that respondents expressed most concern about, and for each of these use cases perceived risks were felt to outweigh perceived benefits.</p>
<p>And yet, even for applications that were seen as being overwhelmingly beneficial – assessing cancer risk and face recognition for border control – respondents still expressed concern about the potential for overreliance on the technologies, the issue of who is accountable for mistakes, and the impact the technologies might have on jobs and employment opportunities.</p>
<p>Three-fifths (62%) of respondents said laws and regulations would make them more comfortable with AI technologies being used. This is an important finding given where the national AI conversation is at the moment, said Professor Helen Margetts, director of the public policy programme at The Alan Turing Institute.</p>
<p>The current national conversation has been fuelled by the success of ChatGPT and the growing adoption of generative AI tools. The Lovelace/Turing survey, fielded in November 2022, did not ask about ChatGPT <em>et al.</em>, but the results do at least provide a baseline against which to measure any shifts in attitudes brought on by what Professor Shannon Vallor, Baillie Gifford Chair in the Ethics of Data and Artificial Intelligence at the Edinburgh Futures Institute at the University of Edinburgh, described as “this latest round of AI hype and confusion”.</p>
<ul>
<li>For more on that theme, see Michael Timothy Bennett’s recent article, <a href="https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html">“No, AI probably won’t kill us all – and there’s more to this fear campaign than meets the&nbsp;eye”</a>.</li>
</ul>
<p>Modhvadia, Margetts and Vallor were speaking at an online event last week to mark the launch of the survey report. Video of the event is below. The <a href="https://www.adalovelaceinstitute.org/report/public-attitudes-ai/">full report</a> is available from the Ada Lovelace Institute website.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/sUG6y_E2UD4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="how-do-people-feel-about-ai-in-statistics-and-data-science-education" class="level2">
<h2 class="anchored" data-anchor-id="how-do-people-feel-about-ai-in-statistics-and-data-science-education">How do people feel about AI in statistics and data science education?</h2>
<p>A new paper in the <em>Journal of Statistics and Data Science Education</em> considers the potential for using ChatGPT in statistics and data science classrooms. Authors Amanda R. Ellis and Emily Slade of the University of Kentucky give suggestions for using ChatGPT to generate course content: lecture notes and new material such as practice quizzes or exam questions, or pseudocode for introducing students to statistical programming. It could also be used as a code debugging tool and integrated into set tasks – e.g., have students prompt ChatGPT to write code, then run the code themselves and assess whether the code works as intended.</p>
<p>“We recognize that educators have valid concerns regarding the implementation and integration of AI tools in the classroom,” write the authors, later adding that: “We encourage readers to consider other technologies, such as the calculator, WolframAlpha, and Wikipedia, all of which were met with initial wariness but are now commonly used as learning tools. As statistics and data science educators, we can actively shape and guide the incorporation of AI tools within our classrooms.”</p>
<p><strong>Read the paper:</strong> <a href="https://amstat.tandfonline.com/doi/full/10.1080/26939169.2023.2223609">A new era of learning: Considerations for ChatGPT as a tool to enhance statistics and data science education</a></p>
</section>
<section id="ok-but-how-do-people-feel-about-ai-generated-music" class="level2">
<h2 class="anchored" data-anchor-id="ok-but-how-do-people-feel-about-ai-generated-music">OK, but how do people feel about AI-generated music?</h2>
<p>A new demo on Hugging Face allows users to <a href="https://huggingface.co/spaces/facebook/MusicGen">generate short samples of music based on text descriptions</a>. Users can also “condition on a melody” by uploading audio files. The results are… interesting, as I discovered while playing around with the demo yesterday.</p>
<center>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Text-to-music-generation is now a thing (via <a href="https://twitter.com/huggingface?ref_src=twsrc%5Etfw"><span class="citation" data-cites="huggingface">@huggingface</span></a>: <a href="https://t.co/fpBDLuB4yh">https://t.co/fpBDLuB4yh</a>) so I thought I'd try creating some new genre mashups <a href="https://t.co/y93w7x9pNW">pic.twitter.com/y93w7x9pNW</a>
</p>
— Brian Tarran (<span class="citation" data-cites="brtarran">@brtarran</span>) <a href="https://twitter.com/brtarran/status/1668301878751375369?ref_src=twsrc%5Etfw">June 12, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
<p><strong>Read the paper:</strong> <a href="https://huggingface.co/papers/2306.05284">Simple and controllable music generation</a></p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://unsplash.com/@askkell?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Andy Kelly</a> on <a href="https://unsplash.com/photos/0E_vhMVqL9g?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “How do people feel about AI? Well, it’s complicated.” Real World Data Science, June 13, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/how-do-people-feel-about-ai.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Accountability</category>
  <category>Regulation</category>
  <category>Public opinion</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/how-do-people-feel-about-ai.html</guid>
  <pubDate>Tue, 13 Jun 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/images/andy-kelly-0E_vhMVqL9g-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>London Data Week is almost here. What’s it all about?</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/london-data-week.html</link>
  <description><![CDATA[ 




<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/nLzL-swPBgg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to Real World Data Science. I’m Brian Tarran. And today I’m joined by the organisers of the upcoming London Data Week, Sam Nutt and Jennifer Ding. Sam, Jennifer, how are you? Nice to see you here. Thank you for joining us. I wanted to start, maybe you can introduce yourselves to our viewers, tell them a little bit about your background. Sam, I don’t know if you want to go first.</p>
<p><strong>Sam Nutt</strong><br>
So I’m Sam Nutt. I’m the researcher and data ethicist at the London Office of Technology and Innovation, or LOTI. We’re about four years old. We’re an innovation unit that sits across 26 of the boroughs of London, and the Mayor of London, the GLA and we work sort of through collaborative processes to sort of foster innovation within local government, in the public sector in London. And I lead partly on our work on data ethics, as the title suggests, but also I lead our work on innovative public participation, which I guess leads nicely into maybe talking a little bit later about London Data Week. But yeah, that’s kind of my background and where I’m coming from. My interest in data, I guess, more originally came from the governance side, and how we use it properly and best in public sector context.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Thanks, Sam. Jennifer?</p>
<p><strong>Jennifer Ding</strong><br>
Hi, I’m Jennifer. I’m from the Alan Turing Institute, and I– the Turing, I should say is the UK’s national institute for data science and AI. And I sit on a team called Tools, Practices and Systems, or TPS, which we sometimes colloquially call the Turing’s open science team. So we focus on open, reproducible, and ethical data science practices. And at the Turing, I co-lead a team of research application managers, and our focus is making sure that the research that happens at Turing is more usable, and also actually used by more people outside of academia. In a previous life, I was a data scientist at various US tech startups, working on applied machine learning, mostly for local and national government partners. And in New York, where I was for many years, I participated in something called New York Open Data Week, which was a great introduction to the open data world, and also the civic technology world and how vibrant and exciting those communities are.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Okay, so that– so you’ve had the exposure to data weeks before? Tell us how did London Data Week as an idea first germinate?</p>
<p><strong>Sam Nutt</strong><br>
Yeah, well, I mean, maybe I can go because it was it was something LOTI, last year, we had a sort of anniversary event, we sort of tried to bring together our community, across local government, and also partners. And so we invited [the] Alan Turing [Institute], we’ve done some work with them. And Jen came, and it was just something Jen raised to me, with me last July, you know, the idea of maybe doing something a little bit, like, inspired by some of the bits we’ve seen, for example, in New York, but also thinking, you know, what’s, what’s the London version of that? What’s the opportunity we have, given, you know, our different context to New York, and we don’t just mean in terms of, you know, you’ve got a different, like, legal context for how you use data and regulation stuff, but the cultural bits, you know, what is the physical space? How does that make London different? The people who live here, you know, what are the opportunities of London. And I think, you know, partly also inspired at the time by, you know, at least from my perspective, a real want to include, you know, ordinary people, Londoners, the public at large – all of those terms can be broken down – but effectively, to increase participation in how we think about data and how we, you know, think also about the future of the city, in a, you know, a future that we know is going to be defined by how we use data. So it kind of, it was a perfect thing where I was very inspired by, you know, I was thinking about those things, and then Jen came along. I don’t know, maybe Jen, you can talk about why you came along with that idea in the first place.</p>
<p><strong>Jennifer Ding</strong><br>
Yeah, absolutely. Yeah. Sam and I sometimes talk about how funny that chance encounter was really. I think the LOTI event was a really great example of how London’s flavour of data innovation is actually quite unique. Just gathered there with all the local councils and various other data organisations that LOTI works with. It was such a cool display of how much the public sector is involved in defining data innovation in London, and also how much academic and private tech in London is also committed to creating data and tech outputs that are for the public good. And coming from the US, I think it was very inspiring to see that organisations like LOTI, organisations like the Turing Institute, like the Ada Lovelace Institute, the Open Data Institute – there is such a great network of data for public good institutions here that are committed to, you know, centering Londoners in the conversation. And I think something that Sam and I really got to talking about was, you know, was this an opportunity also to clearly articulate what this new thing, this unique thing, is that exists in London, that if you’re here, and you work in the space, you know it, but it hasn’t really been formally articulated in the way that I think many of us know that Silicon Valley is associated with a certain kind of innovation – and may be Europe as well with regulation – but what’s happening in London is really special. And we hope that with all our great partners and our London Data Week team, we can begin to start to articulate what makes data innovation in London so special.</p>
<p><strong>Brian Tarran</strong><br>
Please do, Jen.</p>
<p><strong>Brian Tarran</strong><br>
And before we get carried away, we should probably pin down exactly when London Data Week is taking place. It’s beginning of July, is that correct?</p>
<p><strong>Jennifer Ding</strong><br>
That’s right, first week of July 3rd to 9th July.</p>
<p><strong>Brian Tarran</strong><br>
And so from what you’ve said, my understanding, broadly, maybe the aims of the week are to kind of bring together people who are working in data, who are using data and people who are affected by data, or for whom data helps sort of shape their lives, to kind of have maybe, I don’t know, a broader understanding, a kind of commonality of purpose, whatever it might be, is that is that how you would summarise it or…</p>
<p><strong>Sam Nutt</strong><br>
Very nicely summarised, are you available for comms help?</p>
<p><strong>Brian Tarran</strong><br>
I am. Very expensive, though, I’m afraid.</p>
<p><strong>Sam Nutt</strong><br>
Okay. It’s all pro bono stuff. No, I think, yeah, I think that’s really well put. It’s, yeah, it’s articulating that– coming together to start to actually build that imagination, that vision for what London is, and articulate it more, in more clear terms. But it’s also, you know, actually trying to do some things in line with that as well. Some of the activities and events we have, you know, we’re running, it’s kind of in this distributed format. So different organisations across London, who are sort of value aligned across the sector, who might have their own communities, their own publics, can run things – different types of events, you know, engaging people in different ways. And then, you know, all together, we think, sort of the sum of the parts of doing these things across a week, in this distributed format, testing different engagement methods, you know, not only sort of builds a community of organisations around these, like common values, but also lets us, you know, actually reach out to the public, you know, the public with all the different people in London, from different backgrounds, there are so many different communities, you know, as much as possible, to connect to different communities and make them part of the conversation about how we use data and AI and in ways that they kind of historically haven’t been. Not just for data and AI, for lots of other things. But, you know, we know that these technologies are going to be so important for the future. And it’s, you know, designing events and activities that can try and ensure that they’re sort of have a, you know, a seat at the table, thinking about what that future is.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. And you mentioned there a range of events. Jen, can you give us a flavour of some of the events coming up, the highlights, things that you might personally be most looking forward to?</p>
<p><strong>Jennifer Ding</strong><br>
Yeah, happy to Brian. And maybe something to add to is something Sam and I were really hoping to go for is to not have, you know, maybe the typical talk or panel style format for all of our events that might be really common in a conference, but rather have different kinds of events that can focus on different kinds of activities. So having public conversations and debates, having exhibits and experiences, having resident or citizen science opportunities where people can actually be a part of creating data, and also learning opportunities if people want to upskill or learn about a concept. So to shout out some of the events I’m really excited for, maybe to start with the more wacky ones first. The Turing is hosting a “Cabaret of Dangerous Ideas” which will be a comedy show at the Camden Club where they will dig into topics like technology and data, but over a pint and through humour. So apparently, this is an 18+ show. So that might give you a little bit of a flavour of what’s to come. Another event we’re really excited about is an event called All the Docks, where a team of cyclists attempt this challenge in one day to hit every single Santander bike dock. They’ve done it before, and this year for London Data Week, they’re doing a round to hit, I think, the now over 800 docks that now exist in London. And this time, for London Data Week, what they’re also doing is making it a data collection exercise. So as they cross the streets of London, they’ll collect data on the road conditions, the cycling infrastructure, which can be then an open data set that people can use after the event as well. So those are two that jumped to mind. I don’t know, Sam, if there’s anything you want to highlight, or Brian because I know there’s a really exciting on that the RSS is…</p>
<p><strong>Brian Tarran</strong><br>
Yeah, I’ll put a quick plug in for the, so <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/statisticians-for-society-london-data-week/#fulleventinfo">the Royal Statistical Society are organising an event associated with our Statisticians for Society initiative</a>, which offers pro bono support to charities under a million turnover in the UK. So I can, I’ll post a link in the show notes so that people can find out more about that and sign up if they meet the criteria and are interested in taking part. But Sam, sorry, I, I hijacked there. But go ahead.</p>
<p><strong>Sam Nutt</strong><br>
No, Brian, I was going to only mention your event. But no, a couple of others, I think just to show the like breadth of the types of activities. So you know, for example, it’s also it’s about partnering with organisations who are thinking and you know, already doing things like this, so the Science Gallery, for example, there’s– they’ve got an exhibition called “AI: Who’s looking after me?”, which is, you know, looks at some of the playful ways that AI is already involved in people’s lives and brings sort of people on a critical journey. That’s more of that sort of art exhibition type thing. In local government, where, in LOTI, we’re helping some boroughs with developing basically, a toolkit, a resource to help officers in boroughs in some of the data teams, who maybe haven’t had that history of engaging with residents, as seen as more sort of technical back office staff, actually, you know, give them the confidence to go out and have a conversation with residents about some of their practice and see how they can improve it. So there’s been a lot of interest there, in particular, around having conversations about how we do data linkage better, which, you know, in some ways, feels– it’s quite a straightforward data topic. But actually, the huge thing is that these teams in boroughs have never thought, we need to speak with residents at the design stage of data projects, you know, the public, what might a digitally excluded, relatively low sort of data literacy person be able to tell us about our data work that’s helpful to me as, you know, a data scientist, that was sort of some of the historical thinking, but actually, we’re sort of bringing boroughs on the journey of thinking, actually realising, you know, the value of doing that. So that’s sort of, I guess, the range of types of things as well.</p>
<p><strong>Brian Tarran</strong><br>
Fantastic. So where, if people do want to sign up for any of these events, is there a good way for them to do that? Is it go to the LOTI website– not LOTI website, the London Data Week website, I’m guessing?</p>
<p><strong>Jennifer Ding</strong><br>
There is a good amount of info on both the Turing and the LOTI website, but the best place we’d suggest is <a href="https://www.londondataweek.org/">londondataweek.org</a>. There you’ll find a list of events. And if you click on an event, there’s more information. And also, if you click “Find out more”, you can access a link for more information on how you express interest or sign up.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. And if people– when we’re speaking, we are almost exactly a month away from London Data Week. If someone’s listening to this and they think, Oh, I’ve got a great idea for an event I want to organise, is it too late for them to squeeze onto the programme now? Should they get in touch somehow if, if inspiration strikes?</p>
<p><strong>Sam Nutt</strong><br>
We’ll never say never. Probably there is a very late point in which we would say never. I think realistically, you know, the way it’s being run, it’s being run often with the time of volunteers and this sort of thing. And it is sort of the first year of us running it. So a lot of it’s coming through, through Jen and I. So if you are interested in running something, please do reach out to us. You know, we’ve got very good, Jen and I, at finding creative ways to slot people into programs and this sort of thing. But equally I think at this point, it’s really more about you know, bringing together people and organisations who are interested and actually, you know, I think we’ve got a really good exciting, fun set of events and activities across London that would be great to be part of even if you yourself haven’t been able to organise something, and then maybe it’s something for next year, for London Data Week 2024. Fingers crossed, we might be able to do something there.</p>
<p><strong>Brian Tarran</strong><br>
So the stress of day jobs and organising a week-long event, or week-long collection of activities, hasn’t put you off doing it again? No.&nbsp;</p>
<p><strong>Jennifer Ding</strong><br>
So far, so good, Brian.</p>
<p><strong>Sam Nutt</strong><br>
Yeah, we’ll “no comment” some of that.</p>
<p><strong>Jennifer Ding</strong><br>
We’re definitely really excited though. And if anyone does have an idea or wants to start a conversation, there’s a contact form on our website, drop us an email. <a href="https://twitter.com/londondataweek">We also have a Twitter</a> if you want to send us a message through that. So at the very least, we love, we’d love to chat.</p>
<p><strong>Brian Tarran</strong><br>
Great, well, we’ll put all those contact details, social media accounts, etc., into the show notes so people can find you. But thank you very much for joining us today. I know this must be a very busy time for you. But Sam Nutt, Jennifer Ding, thank you for joining us and talking about the upcoming London Data Week. I’m looking forward to it.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
<p>© 2023 Royal Statistical Society</p>
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Images are not covered by this licence. Thumbnail image by <a href="https://unsplash.com/@fakearthur?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">ARTHUR YAO</a> on <a href="https://unsplash.com/photos/HTicW9-i4xY?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
<p>Tarran, Brian. 2023. “London Data Week is almost here. What’s it all about?” Real World Data Science, June 8, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/london-data-week.html">URL</a></p>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Data</category>
  <category>Innovation</category>
  <category>Events</category>
  <category>Communities</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/london-data-week.html</guid>
  <pubDate>Thu, 08 Jun 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/images/arthur-yao-HTicW9-i4xY-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>No, AI probably won’t kill us all – and there’s more to this fear campaign than meets the eye</title>
  <dc:creator>Michael Timothy Bennett</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html</link>
  <description><![CDATA[ 




<p>Doomsaying is an old occupation. Artificial intelligence (AI) is a complex subject. It’s easy to fear what you don’t understand. These three truths go some way towards explaining the oversimplification and dramatisation plaguing discussions about AI.</p>
<p>Last week, outlets around the world were plastered with news of yet another <a href="https://www.safe.ai/statement-on-ai-risk">open letter claiming</a> AI poses an existential threat to humankind. This letter, published through the nonprofit Center for AI Safety, has been signed by industry figureheads including <a href="https://theconversation.com/ai-pioneer-geoffrey-hinton-says-ai-is-a-new-form-of-intelligence-unlike-our-own-have-we-been-getting-it-wrong-this-whole-time-204911">Geoffrey Hinton</a> and the chief executives of Google DeepMind, Open AI and Anthropic.</p>
<p>However, I’d argue a healthy dose of scepticism is warranted when considering the AI doomsayer narrative. Upon close inspection, we see there are commercial incentives to manufacture fear in the AI space.</p>
<p>And as a researcher of artificial general intelligence (AGI), it seems to me the framing of AI as an existential threat has more in common with 17th-century philosophy than computer science.</p>
<section id="was-chatgpt-a-breakthrough" class="level2">
<h2 class="anchored" data-anchor-id="was-chatgpt-a-breakthrough">Was ChatGPT a ‘breakthrough’?</h2>
<p>When ChatGPT was released late last year, people were delighted, entertained and horrified.</p>
<p>But ChatGPT isn’t a research breakthrough as much as it is a product. The technology it is based on is several years old. An early version of its underlying model, GPT-3, was released in 2020 with many of the same capabilities. It just wasn’t easily accessible online for everyone to play with.</p>
<p>Back in 2020 and 2021, <a href="https://ieeexplore.ieee.org/document/9495946">I</a> and many <a href="https://link.springer.com/article/10.1007/s11023-020-09548-1">others</a> wrote papers discussing the capabilities and shortcomings of GPT-3 and similar models – and the world carried on as always. Forward to today, and ChatGPT has had an incredible impact on society. What changed?</p>
<p>In March, Microsoft researchers <a href="https://futurism.com/gpt-4-sparks-of-agi">published a paper</a> claiming GPT-4 showed “sparks of artificial general intelligence”. AGI is the subject of a variety of competing definitions, but for the sake of simplicity can be understood as AI with human-level intelligence.</p>
<p>Some immediately interpreted the Microsoft research as saying GPT-4 <em>is</em> an AGI. By the definitions of AGI I’m familiar with, this is certainly not true. Nonetheless, it added to the hype and furore, and it was hard not to get caught up in the panic. Scientists are no more immune to <a href="https://link.springer.com/book/10.1007/978-3-030-36822-7">group think</a> than anyone else.</p>
<p>The same day that paper was submitted, The Future of Life Institute <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">published an open letter</a> calling for a six-month pause on training AI models more powerful than GPT-4, to allow everyone to take stock and plan ahead. Some of the AI luminaries who signed it expressed concern that AGI poses an existential threat to humans, and that ChatGPT is too close to AGI for comfort.</p>
<p>Soon after, prominent AI safety researcher Eliezer Yudkowsky – who has been commenting on the dangers of superintelligent AI <a href="https://intelligence.org/files/AIPosNegFactor.pdf">since well before</a> 2020 – took things a step further. <a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/">He claimed</a> we were on a path to building a “superhumanly smart AI”, in which case “the obvious thing that would happen” is “literally everyone on Earth will die”. He even suggested countries need to be willing to risk nuclear war to enforce compliance with AI regulation across borders.</p>
</section>
<section id="i-dont-consider-ai-an-imminent-existential-threat" class="level2">
<h2 class="anchored" data-anchor-id="i-dont-consider-ai-an-imminent-existential-threat">I don’t consider AI an imminent existential threat</h2>
<p>One aspect of AI safety research is to address potential dangers AGI might present. It’s a difficult topic to study because there is little agreement on what intelligence is and how it functions, let alone what a superintelligence might entail. As such, researchers must rely as much on speculation and philosophical argument as on evidence and mathematical proof.</p>
<p>There are two reasons I’m not concerned by ChatGPT and its <a href="https://lablab.ai/blog/what-is-babyagi-and-how-can-i-benefit-from-it">byproducts</a>.</p>
<p>First, it isn’t even close to the sort of artificial superintelligence that might conceivably pose a threat to humankind. The models underpinning it are slow learners that require immense volumes of data to construct anything akin to the versatile concepts humans can concoct from only a few examples. In this sense, it is not “intelligent”.</p>
<p>Second, many of the more catastrophic AGI scenarios depend on premises I find implausible. For instance, there seems to be a prevailing (but unspoken) assumption that sufficient intelligence amounts to limitless real-world power. If this was true, more scientists would be billionaires.</p>
<p>Moreover, cognition as we understand it in humans takes place as part of a physical environment (which includes our bodies), and this environment imposes limitations. The concept of AI as a “software mind” unconstrained by hardware has more in common with 17th-century <a href="https://plato.stanford.edu/entries/dualism/">dualism</a> (the idea that the mind and body are separable) than with contemporary theories of the mind existing as <a href="https://plato.stanford.edu/entries/embodied-cognition/">part of the physical world</a>.</p>
</section>
<section id="why-the-sudden-concern" class="level2">
<h2 class="anchored" data-anchor-id="why-the-sudden-concern">Why the sudden concern?</h2>
<p>Still, doomsaying is old hat, and the events of the last few years probably haven’t helped – but there may be more to this story than meets the eye.</p>
<p>Among the prominent figures calling for AI regulation, many work for or have ties to incumbent AI companies. This technology is useful, and there is money and power at stake – so fearmongering presents an opportunity.</p>
<p>Almost everything involved in building ChatGPT has been published in research anyone can access. OpenAI’s competitors can (and have) replicated the process, and it won’t be long before free and open-source alternatives flood the market.</p>
<p>This point was made clearly in a memo <a href="https://www.semianalysis.com/p/google-we-have-no-moat-and-neither">purportedly leaked</a> from Google entitled “We have no moat, and neither does OpenAI”. A moat is jargon for a way to secure your business against competitors.</p>
<p>Yann LeCun, who leads AI research at Meta, says these models should be open since they will become public infrastructure. He and many others are <a href="https://www.businesstoday.in/technology/news/story/completely-ridiculous-metas-chief-ai-scientist-yann-lecun-dismisses-elon-musks-civilisation-destruction-fear-383371-2023-05-30">unconvinced by the AGI doom</a> narrative.</p>
<center>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
A NYT article on the debate around whether LLM base models should be closed or open.<br><br>Meta argues for openness, starting with the release of LLaMA (for non-commercial use), while OpenAI and Google want to keep things closed and proprietary.<br><br>They argue that openness can be…
</p>
— Yann LeCun (<span class="citation" data-cites="ylecun">@ylecun</span>) <a href="https://twitter.com/ylecun/status/1659172655663030272?ref_src=twsrc%5Etfw">May 18, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
<p>Notably, <a href="https://fortune.com/2023/05/05/meta-mark-zuckerberg-not-invited-ai-meeting-white-house/">Meta wasn’t invited</a> when US President Joe Biden recently met with the leadership of Google DeepMind and OpenAI. That’s despite the fact that Meta is almost certainly a leader in AI research; it produced PyTorch, the machine-learning framework OpenAI used to make GPT-3.</p>
<p>At the White House meetings, OpenAI chief executive Sam Altman suggested the US government should issue licences to those who are trusted to responsibly train AI models. Licences, as Stability AI chief executive Emad Mostaque <a href="https://twitter.com/EMostaque/status/1658653142429450242?s=20">puts it</a>, “are a kinda moat”.</p>
<p>Companies such as Google, OpenAI and Microsoft have everything to lose by allowing small, independent competitors to flourish. Bringing in licensing and regulation would help cement their position as market leaders and hamstring competition before it can emerge.</p>
<p>While regulation is appropriate in some circumstances, regulations that are rushed through will favour incumbents and suffocate small, <a href="https://www.forbes.com/sites/hessiejones/2023/04/19/amid-growing-call-to-pause-ai-research-laion-petitions-governments-to-keep-agi-research-open-active-and-responsible/?sh=1b21161a62e3">free and open-source competition</a>.</p>
<center>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Think Google or Microsoft are encouraging legislation for your safety? But of course! These are honorable companies.<br><br>You might think they'd like less competition too though. Maybe a monopoly? Maybe legal red tape preventing free and open source alternatives? Perhaps other… <a href="https://t.co/Z7vSpMyuHg">https://t.co/Z7vSpMyuHg</a>
</p>
— Michael Timothy Bennett (<span class="citation" data-cites="MiTiBennett">@MiTiBennett</span>) <a href="https://twitter.com/MiTiBennett/status/1654357631514079233?ref_src=twsrc%5Etfw">May 5, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
<!-- Below is The Conversation's page counter tag. Please DO NOT REMOVE. -->
<p><img src="https://realworlddatascience.net/viewpoints/posts/2023/06/05/https:/counter.theconversation.com/content/206614/count.gif?distributor=republish-lightbox-basic" alt="The Conversation" width="1" height="1" style="border: none !important; box-shadow: none !important; margin: 0 !important; max-height: 1px !important; max-width: 1px !important; min-height: 1px !important; min-width: 1px !important; opacity: 0 !important; outline: none !important; padding: 0 !important" referrerpolicy="no-referrer-when-downgrade"></p>
<!-- End of code. If you don't see any code above, please get new code from the Advanced tab after you click the republish button. The page counter does not collect any personal data. More info: https://theconversation.com/republishing-guidelines -->
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<a href="https://theconversation.com/profiles/michael-timothy-bennett-1283108">Michael Timothy Bennett</a> is a PhD student in the School of Computing, <a href="https://theconversation.com/institutions/australian-national-university-877">Australian National University</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-12">
<dl>
<dt>Copyright and licence</dt>
<dd>
This article is republished from <a href="https://theconversation.com">The Conversation</a> under a Creative Commons license. Read the <a href="https://theconversation.com/no-ai-probably-wont-kill-us-all-and-theres-more-to-this-fear-campaign-than-meets-the-eye-206614">original article</a>.
</dd>
<dd>
<p>Thumbnail image by <a href="https://alanwarburton.co.uk/">Alan Warburton</a> / © BBC / <a href="https://www.betterimagesofai.org">Better Images of AI</a> / Social Media / <a href="https://creativecommons.org/licenses/by/4.0/">Licenced by CC-BY 4.0</a>.</p>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Regulation</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html</guid>
  <pubDate>Mon, 05 Jun 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/06/05/images/AlanWarburton-SocialMedia.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>What’s the future of data science and AI in an LLM world?</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/future.html</link>
  <description><![CDATA[ 




<p>The impact ChatGPT and large language models (LLMs) are having on the practice and profession of data science is something <a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">we discussed recently with data scientists from Unilever, BT, Deliveroo, and others</a>. So, it was interesting to hear a perspective this week from Osama Rahman, director of the <a href="https://datasciencecampus.ons.gov.uk/">Data Science Campus</a> at the UK Office for National Statistics.</p>
<p>Speaking Tuesday at <a href="https://rss.org.uk/training-events/events/events-2023/local-groups/what-is-the-future-of-data-science-and-ai-online/">an online event</a>, Rahman mused on how LLMs brought both potential benefits and risks. For example, those who can already code can code more efficiently now with the help of LLM-powered tools. However, those same tools also allow non-coders to code – and inexpert use of tools and code presents risks. How do we guard against this, he was asked. “I don’t know,” came the response, “other than you have to observe and clampdown on it.”</p>
<p>Such problems are by no means new or unique to the post-ChatGPT era, of course. As someone with a background in economics, Rahman said he has, over the years, observed “inexpert uses of economics.” His advice was to “make sure experts are plugged in” – to teams, conversations, decision-making processes, etc. – “and are seen as the experts in the use of these tools.”</p>
<p>The discussion was wide-ranging, and also took in questions on whether data scientists have the right skills at this moment – “Skills evolve, it’s just a natural process… We need to keep a culture of curiosity…” – and whether enough is being done to address ethical issues – “My key issue is that ethical frameworks need a lot more discussion and debate than it takes to put out a new tool… I don’t have much to add, other than that there is a problem.”</p>
<p>However, two questions – and answers – jumped out at me as particularly interesting. Rahman was asked: Have we delivered on the promise of data science from 5 years ago? “No, but that’s because expectations were wrong,” he said. “Data science wasn’t going to completely and utterly transform government. But where it has delivered is in an evolving set of tools, people, and skills coming in and allowing us to do impactful stuff. It hasn’t delivered on the false promise that it would change the world, but it has delivered a lot.”</p>
<p>He was also asked: How will data science and AI have changed the world in 5–10 years? “I’m not sure it will,” he said. “It will do certain things. It will allow us to address certain analytical problems more efficiently.” Rahman then offered a salutary reminder. Email once made life more efficient; now, we’re all at risk of “death by email.”</p>
<p>We’ll be sure to update this post with a link to a video or other recording of the event, if/when it becomes available. For now, be sure to check out our two-part discussion on LLMs and data science:</p>
<ul>
<li><a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">How is ChatGPT changing data science?</a></li>
<li><a href="https://realworlddatascience.net/careers/posts/2023/05/18/chatgpt-data-science-pt2.html">Large language models: Do we need to understand the maths, or simply recognise the limitations?</a></li>
</ul>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “What’s the future of data science and AI in an LLM world?” Real World Data Science, May 26, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/future.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Large language models</category>
  <category>Skills</category>
  <category>Tools</category>
  <category>Ethics</category>
  <category>People</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/future.html</guid>
  <pubDate>Fri, 26 May 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/images/binoculars.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘For me, data science is about bridging the gap between business requirements and the data that businesses have’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/jasmine-holdsworth.html</link>
  <description><![CDATA[ 




<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/Plga2ldbcTE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<section id="what-does-your-job-at-expedia-involve" class="level3">
<h3 class="anchored" data-anchor-id="what-does-your-job-at-expedia-involve">What does your job at Expedia involve?</h3>
<p>I would probably call myself more on the analyst side. So, while my day-to-day job doesn’t necessarily involve AI, ML and productionalising models, it’s more taking business goals or requirements and taking the data and essentially bridging the gap between the two. I am on the incrementality analytics team. So, what that means is I measure the short-term returns from our marketing efforts that we have. And I do that via geotesting. So, I’m essentially working in the geotesting part of the company if you like. And before that I worked in the customer data section. So, essentially looking at customer data and working with that.</p>
</section>
<section id="how-long-have-you-been-working-in-data-science" class="level3">
<h3 class="anchored" data-anchor-id="how-long-have-you-been-working-in-data-science">How long have you been working in data science?</h3>
<p>More in an analyst role, but probably about seven years now, I began in Stack Overflow just as a data analyst, and then worked at DAZN – which is like a Netflix for sports – as a data analyst, and then joined here as a senior analyst, and then moved into data science in the last couple of years. I would, I would credit Stack Overflow as the place where my career kind of was birthed, if you like. I started there as an account manager, so with hardly any technical background at all required, and then moved into a role that was essentially looking after, or reporting the metrics of advertising campaigns for companies that would advertise on Stack Overflow. So that required a little technical knowledge, not much – a few pivot tables and things like that. But then the longer I stayed there, the further my career developed, and they had, at the time – probably still do – some fantastically smart people that work there, as you can imagine. I was sponsored to do a General Assembly data analytics course, which was focused around Excel, dashboarding, and SQL and essentially fell in love with data analysis. It was the most technical subject matter that I had experienced to that point, and I found a real natural affinity to it, particularly SQL. And then [I] moved into more of a data analyst role within Stack Overflow, so – as you can probably imagine – an absolute sea of proprietary data that needed analysing, and started learning R, or rather being taught R within Stack Overflow, and loved it. I think I was there for three-and-a-half years, and then moved into a data analyst role at DAZN. At this point, I did a data science General Assembly bootcamp course, and fell in love with that. And then I decided that I really loved General Assembly as a concept; I actually started a second job teaching there, so the courses that I had previously taken I was now teaching, first as a teaching assistant, and then as a lead instructor, which was one of the most, yeah, one of the most amazing experiences I’ve had actually, I learned a lot from that. And then I got a job as a senior analyst within Expedia Group, which is where I am now, and then moved into a data science role, which is what I’m doing currently. So, I actually left school at 16, and had to go into a full-time employment. And the General Assembly education that I took a part in was my first of that type. So, when I realised that data science was absolutely something that I really wanted to dedicate the rest of my life to, I decided to take on a part-time data science bachelor’s degree, which I am now about a year away from finishing. Because I’m doing it part time it takes a bit longer. But yeah, so I will have my data science bachelor’s completed, hopefully, by 2024.</p>
</section>
<section id="who-or-what-inspired-you-to-work-in-data-science" class="level3">
<h3 class="anchored" data-anchor-id="who-or-what-inspired-you-to-work-in-data-science">Who or what inspired you to work in data science?</h3>
<p>There were two big inspirations into getting into data sciences. So, they were actually the data scientists that I worked with at Stack Overflow. They were the first two data scientists, I believe, that Stack Overflow had ever hired. I worked very closely with them as an analyst and one of them was, had previously worked – I don’t know if it was officially an astrophysicist – but had studied black holes, and I remember thinking that was just amazing. And the other was, was very famous within the field. And they spent a lot of time giving me one-on-one training on R and SQL and basic analysis, and I was so inspired by these two individuals that I, it was also a career path that I didn’t really know existed.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/images/jh-photo.png" class="img-fluid figure-img" alt="Portrait photo of Jasmine Holdsworth"></p>
<figcaption class="figure-caption">Jasmine Holdsworth</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>What was impressed upon me in that first year [in data science] was the importance of statistics and interpreting statistics in a way that’s honest.</p>
</div>
</div>
</div>
</section>
<section id="what-does-data-science-mean-to-you" class="level3">
<h3 class="anchored" data-anchor-id="what-does-data-science-mean-to-you">What does data science mean to you?</h3>
<p>For me, it is bridging the gap between the business requirements and the data that businesses have. So, you’ll have business goals, requirements that kind of come down the line and there’s a lot of data that’s being collected, and, essentially, you have to try and be the bridge between the two. So, not just doing very complicated analyses, with very sophisticated models – at least not in my role – it’s about being able to create analysis that’s interpretable, that you can present to non-technical stakeholders that they’re going to understand to a degree. So, I do know that in different roles in different companies, it will be slightly different. But yeah, for me, it’s about making data, yeah, interpretable, to the non-technical stakeholders to enable them to do their job better.</p>
</section>
<section id="what-is-your-most-important-skill-as-a-data-scientist" class="level3">
<h3 class="anchored" data-anchor-id="what-is-your-most-important-skill-as-a-data-scientist">What is your most important skill as a data scientist?</h3>
<p>I like to think that there is one responsibility around how statistics are interpreted. So, just making sure that when you’re giving someone a statistic, that they understand what it can be used for, what it can’t be used for, and that it doesn’t kind of get halfway around the company before, you know, without any danger of it being misinterpreted. And I do think that the other is just being a translator. So, as well as teaching with General Assembly, I teach people within my company, things like SQL, R, and some basic data analysis. And I feel like it’s taking what is quite a technical, complicated subject and almost translating it into, if you like, English, so that people can kind of get some sense of what something may mean, without necessarily having to have the degree to back it up.</p>
</section>
<section id="what-hurdles-did-you-face-in-becoming-a-data-scientist" class="level3">
<h3 class="anchored" data-anchor-id="what-hurdles-did-you-face-in-becoming-a-data-scientist">What hurdles did you face in becoming a data scientist?</h3>
<p>Towards the beginning of my career to say – 5, 6 years ago – it was quite hard to get interviews. It was never hard to get interviews with technical people within companies, because you can– a technical person can see whether or not you know what you’re talking about. But recruiters don’t, and if someone is a recruiter for a technical role, their proxy for whether or not you can do the role is what’s your level of education, which is completely understandable and that’s what education is for. But it did mean that sometimes I applied for roles that were well below my, my level, and if I did so through a recruiter, then I wouldn’t hear anything back. But if I spoke to a technical person within that company, then it would be fine.</p>
</section>
<section id="how-did-you-overcome-those-hurdles" class="level3">
<h3 class="anchored" data-anchor-id="how-did-you-overcome-those-hurdles">How did you overcome those hurdles?</h3>
<p>Actually, I guess the story of how I joined Expedia is quite relevant in that way. So, I presented some, just some fun analysis that I did at an R-Ladies meetup, and I was already talking to a recruiter within Expedia Group and I said to them, oh, well, I happen to be visiting your offices to present at this meetup, so maybe I can meet you there. And they actually sent the manager of the team that they wanted me to join. So, this manager attended the meetup, watched me present, and then they ended up hiring me, which is really great. But I do really think that that was a result of being able to see me on stage, talking about stuff that I had done, showing code that I had written, and it kind of bypassed a few steps. So yeah, I would definitely say meetups and connections are very helpful to overcome that.</p>
</section>
<section id="the-most-important-lesson-from-your-first-year-in-data-science" class="level3">
<h3 class="anchored" data-anchor-id="the-most-important-lesson-from-your-first-year-in-data-science">The most important lesson from your first year in data science?</h3>
<p>I think that what was impressed upon me in that first year – and what really drove me to do the bootcamp courses and then, ultimately, the degree – above everything, actually, was the importance of statistics and interpreting statistics in a way that’s honest. So, I feel like– I feel like with coding, that comes quite naturally to me, and writing SQL queries, R, that was all kind of fine. That didn’t require a lot. But I really, I had an amazing manager who taught me a lot about, essentially, if you’re going to go and speak to this company about the campaign that they’ve run on our website, then you need to impress that X doesn’t necessarily mean Y, it just gives evidence to, or alludes to, and essentially just making sure that how you’re communicating things is as accurate as possible.</p>
</section>
<section id="any-mistakes-or-regrets-in-your-career-so-far" class="level3">
<h3 class="anchored" data-anchor-id="any-mistakes-or-regrets-in-your-career-so-far">Any mistakes or regrets in your career so far?</h3>
<p>When I look back on my career, I think the things that have really stayed with me that I’ve really learned from, mistakes wise, are around small little mistakes around how you interpret data. Maybe it was a, like, years ago, summing the wrong cell in Excel but not checking two or three or four times before that goes out. I’m now quite– I over-check everything. I think that the most important part of our job, as well as being the translation, is being the correct translation. You need to be reliable. People need to know that if you put out analysis that they can trust you. So, I would say I regret every small, tiny little data error that I ever made, which I can’t even recall right now, but I know have kind of cumulated enough that it has made me a very fastidious checker, I suppose.</p>
</section>
<section id="how-do-you-see-your-role-in-data-science-evolving" class="level3">
<h3 class="anchored" data-anchor-id="how-do-you-see-your-role-in-data-science-evolving">How do you see your role in data science evolving?</h3>
<p>I definitely see myself being an individual contributor in a consumer-facing company, just because that is basically what I’ve been doing up to this point. I don’t really have any desire to get into people management. I very much love being stuck in a room with my laptop, solving problems. Above all else, it still makes me happy. However, I do also love knowledge sharing – I love teaching, whether it’s with General Assembly, or whether it’s within the company that I work now. And I would like to kind of balance those two goals moving forward. So, keeping my role within my company as like an individual contributor and actually being like the front face for the, for the analysis that’s happening rather than kind of managing it. But also making sure that I carve out time to upskill others, because data science as a field, I mean, as you all know, is growing so much and people are coming in from different backgrounds. And I’m lucky enough to be able to kind of speak to a few people like that and do some very casual mentorship. And it makes me happy to see, so I hope that as my career develops, I will see more people maybe with backgrounds a little bit more like mine, come through and bring some diversity to the sector.</p>
</section>
<section id="new-developments-or-ideas-you-are-most-excited-about" class="level3">
<h3 class="anchored" data-anchor-id="new-developments-or-ideas-you-are-most-excited-about">New developments or ideas you are most excited about?</h3>
<p>It would be remiss of me to not mention like ChatGPT or generative AI, etc. But honestly, I am more interested in – or vaguely interested, I should say – in wearable technology. So, I’ve read a few very, very interesting papers and articles that talk about the development of wearable technology, not just your kind of watches, but potentially clothing, etc., that can be used for people with specific health problems to really help pinpoint, like, inflection points in time when something might happen. For example, a heart attack is about to happen, or is imminent, or is happening. So I actually feel like at the moment, this is perhaps going slightly under the radar, compared with more, you know, sexy developments like chatbots and things. But I’m very interested to see in the next one to two decades how ubiquitous wearables will be, and how closely entwined that will become with healthcare. So that’s something that I’m keeping half an eye on.</p>
</section>
<section id="any-words-of-advice-for-budding-data-scientists" class="level3">
<h3 class="anchored" data-anchor-id="any-words-of-advice-for-budding-data-scientists">Any words of advice for budding data scientists?</h3>
<p>You will never stop learning at all because, frankly, the field is moving very, very quickly. So, even if you were to kind of consider yourself an absolute expert today, tomorrow that may not be the case. You will constantly be learning. And I have found that learning the same thing several times through different mediums and having things explained to you different ways is so valuable. Because you may think that you understand something from, say, your bootcamp, but then when you read about it as part of your degree – this is obviously personal to me – you read about it in a different way. And you think, Oh, I’ve never thought of it like that. And then you watch a YouTube video and someone visualises it and you think, okay, I understand this all a little bit deeper now. So, constantly revising what you do know and learning anything that’s new as it comes up, I think everyone at every stage of career can kind of, can do that.</p>
<div class="article-btn">
<p><a href="../../../../../../careers/career-profiles/index.html">Discover more Career profiles</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘For me, data science is about bridging the gap between business requirements and the data that businesses have.’” Real World Data Science, May 24, 2023. <a href="https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/jasmine-holdsworth.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>Data analysis</category>
  <category>SQL</category>
  <category>R</category>
  <category>Bootcamps</category>
  <category>Education</category>
  <guid>https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/jasmine-holdsworth.html</guid>
  <pubDate>Wed, 24 May 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/images/jh-photo.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Large language models: Do we need to understand the maths, or simply recognise the limitations?</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/posts/2023/05/18/chatgpt-data-science-pt2.html</link>
  <description><![CDATA[ 




<p><a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">Part 1 of our conversation with the Royal Statistical Society’s Data Science and AI (DS&amp;AI) Section</a> ended on a discussion around the need to verify that large language models (LLMs), when embedded in workflows and operational processes, are working as intended. But there was also acknowledgement that this could be difficult to achieve, not least of all because, as Giles Pavey said, “nobody knows exactly how these things work – not even the people who build them.” And then, of course, there is the speed at which developments are taking place: Trevor Duguid Farrant made the point that an expert may not even have a chance to finish reviewing the latest version of an LLM before a new iteration is rolled out.</p>
<p>These issues – of verification, explainability and interpretability – are of particular interest to data scientists like Anjali Mazumder, whose work focuses on the impact AI technologies could have, and are having, on society and individuals.</p>
<p>In part 2 of our Q&amp;A about ChatGPT and other LLM-powered advances, and what all of this might mean for data science, Mazumder kicks off the conversation by setting out her perspective.</p>
<p>Our full list of interviewees, in order of appearance, are:</p>
<ul>
<li><p><strong>Anjali Mazumder</strong>, AI and Justice &amp; Human Rights Theme Lead at the Alan Turing Institute, and DS&amp;AI committee member.</p></li>
<li><p><strong>Detlef Nauck</strong>, head of AI and data science research at BT, and editorial board member, Real World Data Science.</p></li>
<li><p><strong>Martin Goodson</strong>, CEO and chief scientist at Evolution AI, and DS&amp;AI committee member.</p></li>
<li><p><strong>Louisa Nolan</strong>, head of public health data science, Public Health Wales, and DS&amp;AI secretary.</p></li>
<li><p><strong>Piers Stobbs</strong>, VP science at Deliveroo, and DS&amp;AI committee member.</p></li>
<li><p><strong>Trevor Duguid Farrant</strong>, senior principal statistician at Mondelez International, and DS&amp;AI committee member.</p></li>
<li><p><strong>Giles Pavey</strong>, global director for data science at Unilever, and DS&amp;AI vice-chair.</p></li>
<li><p><strong>Adam Davison</strong>, head of data science at the Advertising Standards Authority, and DS&amp;AI committee member.</p></li>
</ul>
<div class="keyline">
<hr>
</div>
<p><strong>Anjali Mazumder:</strong> I work in research, but I also sit in the crux of government, industry, and civil society, looking at how they’re using these technologies. For me, it’s about knowing what the opportunities are but also understanding the limitations, the risks and the harms, and how we balance those and put in place oversight mechanisms that act as safeguards to ensure that these technologies don’t cause harm. We’re taking a very socio-technical approach that requires an interdisciplinary team to understand these issues and what should be done. Part of this is about not only the outcomes and the impact but also the upstream side of it – recognising that these models have been built on the work of people who have done the labelling, and that this also has implications – to say nothing of the associated environmental issues or energy issues!</p>
<p><strong>Detlef Nauck:</strong> I think the regulators really have to look at this. It has come completely out of left field for them. All the regulators that we are monitoring, they regulate the space as it was three years ago – they are mainly concerned about predictive models and bias. But if you look at, say, what Microsoft wants to do – putting GPT into Office 365 and into Bing – that will completely change how people interact with and consume information. I think the large tech companies really have a responsibility here, when they make this public, to make sure that people understand what this technology actually is, and how it can be used and has to be used.</p>
<p>Also, they need to open up about how these things have been built. There are a lot of stories around <a href="https://time.com/6247678/openai-chatgpt-kenya-workers/">how OpenAI used cheap labour in order to do the labelling and reinforcement learning for ChatGPT</a>, and these things have to become public knowledge; they need to become part of some kind of Kitemark for these models: “Ethically built, properly checked, hallucinate only a little bit. Whatever you do, don’t take it for granted. Check it!” That’s the kind of disclaimer they need to put on these models.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-12 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>If you look at what Microsoft wants to do – putting GPT into Office 365 and into Bing – that will completely change how people interact with and consume information. Large tech companies really have a responsibility here, when they make this public, to make sure that people understand what this technology actually is.</p>
</div>
</div>
</div>
<p><strong>Regulatory principles always seem to stress that AI systems should be understandable, and we should be able to explain how we get particular outputs. But a lot of our conversation has focused on how we don’t really know how these models work. So, is that, in itself, a problem, and is it something that the data science community can help with – to dig into how these things work and try and get that across – to help meet these principles of explainability and interpretability?</strong></p>
<p><strong>DN:</strong> That’s a very specialist job, I would say – specialist research into how these mathematical structures work. It’s not something I could do, and I’ve not seen any significant work there. One thing that we are interested in is whether we can do knowledge embedding, so that you can “teach” concepts that these models can then use to communicate, and that would lead to smaller systems where you have some understanding of what’s inside. But all of this kind of work, I think, is very much just beginning.</p>
<p><strong>Martin Goodson:</strong> Do we actually need this? There’s sort of a big assumption there that you need to understand how LLMs work in order to build in the kinds of things that we care about as a society. But we don’t understand how humans think. Of course, we can ask a human, “Why did you make that decision?” You can’t understand the cause of that decision – that’s a complex neuroscience question. But you can ask what the reason is for making a decision, and you can ask an LLM what its reasoning is as well. I think a lot of these questions about explainability are stuck in the past, when you’re trying to explain how a linear model works. It’s really not the same thing when you’ve got an LLM where you can just say, “Why did you make that decision?”</p>
<p><strong>Louisa Nolan:</strong> I was going to say something very similar. Most people don’t know how most things work…</p>
<p><strong>DN:</strong> My point was, these things are largely still like the Improbability Drive in the <em>Hitchhiker’s Guide to the Galaxy</em>. You press a button, and you don’t really know what comes out, and that’s the problem we need to get our heads around.</p>
<p><strong>LN:</strong> But people don’t know what percentages are, and yet we still use them for decision making. I don’t think people need to understand the maths behind LLMs, and I think it would be a hopeless job to expect everybody to do that. What we do need to understand is what LLMs can and can’t do. What’s the body of work that they are drawing from? What isn’t in there? What are the things that you need to check? So, for some things, it’ll be brilliant: if you’ve written something and you want it rewritten for a nine-year-old; if you want to summarise a paper; if you want to write code, as long as you already know how to code – these could be real labour-saving tasks. If you’re using ChatGPT to write a thesis about something that you haven’t looked at, that’s where the danger is. It’s this kind of simple understanding that people need to get in their heads – and the maths, except for the people who care about it, is beside the point, and probably detrimental, because it means that people won’t engage with it.</p>
<p><strong>DN:</strong> I agree, but I wasn’t talking about the general public. I meant, the people who build these things – they should know what they’re doing.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-12 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>There’s a big assumption that you need to understand how LLMs work in order to build in the kinds of things that we care about as a society. But we don’t understand how humans think. You can ask a human what their reason is for making a decision, and you can ask an LLM what its reasoning is as well.</p>
</div>
</div>
</div>
<p><strong>We talked there about communication. There was a webinar recently by the <a href="https://rss.org.uk/membership/rss-groups-and-committees/groups/glasgow/">Royal Statistical Society’s Glasgow Local Group</a>, and the presenter, <a href="https://www.hannahrosekirk.com/">Hannah Rose Kirk</a>, showed how you can take tabular data and statistical results and ask ChatGPT to produce a nice paragraph or two that explains the numbers. Is this the sort of thing that any of you have experimented with? Have you had any successes at using ChatGPT to translate data into readable English that decision makers can act on?</strong></p>
<p><strong>Piers Stobbs:</strong> I have an interesting use case. We had a basic survey: 200-odd responses, multiple languages, and we just said, “Please summarise the results of this survey contained in this CSV file.” And it came up with five or six relevant bullet points. What was amazing was that we could then interrogate it. For example, “Please compare the results that were in English versus in French, and describe the differences.” Again, it did it, but then you have the issue of, was it all correct? Well, the bulk of it was. Now I am intrigued by whether you can ask it to do correlations and some actual statistical things on a dataset, and does it get that right? I don’t know. We’ve not really got to that. But, to go back to one of the earlier discussion points around productivity, that initial survey work could have easily taken a week of someone’s time if we didn’t run it through ChatGPT.</p>
<p><strong>Trevor Duguid Farrant:</strong> Piers, in this case you’re interested in checking and seeing if it’s right. If you’d asked a group of people to do that survey for you and get the results, you’d have just accepted whatever they gave you back. You wouldn’t have questioned it.</p>
<p><strong>PS:</strong> That’s true. And the results were plausible, certainly.</p>
<p><strong>AM:</strong> I think one of the challenges is that the results could seem like they’re plausible, right – whether that’s a statistical output or a text output. This was not a proper experiment, but I asked ChatGPT about colleagues and friends who are quite prominent researchers, asking, “Who is so-and-so?”, and it produced biographies that were quite plausibly them, but it wasn’t them. It might have listed the correct PhD, say, but the date was off by a year, or the date was correct but it was from the wrong institution. So, depending on what the issue is, these seemingly plausible results could have more serious implications.</p>
<p><strong>LN:</strong> So, just to join those two things together: for me, the question is not, “Do we understand how ChatGPT works?” As Martin says, we don’t understand how humans work, and surely we’re trying to develop something that enhances human thinking in some way. The more important question for me is, “How do we know that what is produced is useful?”</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-12 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>For me, the question is not, ‘Do we understand how ChatGPT works?’ We don’t understand how humans work, and surely we’re trying to develop something that enhances human thinking in some way. The more important question is, ‘How do we know that what is produced is useful?’</p>
</div>
</div>
</div>
<p><strong>Giles, <a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">you mentioned previously that you’re doing some work at Unilever around how to minimise hallucination</a>. I don’t know how much you can say on what direction that’s going in, and how successful you expect that to be, but that’s obviously going to be a really important part of refining these models to be more widely usable.</strong></p>
<p><strong>Giles Pavey:</strong> I’m by no means an expert, but there’s quite a lot you can do with both the architecture of it and also the pre-prompts that you put in – more or less saying, “Quote what the source is, and if you’re not sure, then tell me you’re not sure.” I think what’s interesting is the question of whether we’ll have to rely on OpenAI or Microsoft to do that work, and it will be just another thing that we have to trust them for. Or, will it be something that people within an organisation can put in themselves?</p>
<p><strong>MG:</strong> I think it’s absolutely critical that open-source models are developed that can compete with these tech companies, otherwise there’s going to be a huge transfer of power to these companies.</p>
<p><strong>GP:</strong> Arguably, the single biggest issue is, who elected Sam Altman (no-one) and are we as society happy with him having so much power over our future?</p>
<p><strong>To close us out, I’d like to return to <a href="http://localhost:5404/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">a question Trevor posed earlier</a>, which is: How might organisations like the Royal Statistical Society help companies to embrace LLMs and start using them, so that everyone can benefit from the technology?</strong></p>
<p><strong>Adam Davison:</strong> My instinct is that there’s some great parallel here with the stuff that the Data Science and AI Section have been doing in general, where we’ve said, “OK, there’s lots of good advice out there on how to do things in data science, but how do you make it practical? How do you make it real? How do you apply those ethical principles? How do you make sure you have people with the right technical understanding in charge of projects to get value?” If, five years ago, the hype around data science was leading organisations to hire 100 data scientists in the hope that something innovative would happen, well then, we don’t want those same organisations now thinking that they need to hire 100 prompt engineers and keep their fingers crossed for something special. Our focus has been on “<a href="https://realworlddatascience.net/viewpoints/newsletter/">industrial strength data science</a>”, so I think we can extend that to show what “industrial strength LLM usage” looks like in practice.</p>
<div class="callout callout-style-simple callout-note" style="margin-top: 2.25rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Want to hear more from the RSS Data Science and AI Section? Sign up for its newsletter at <a href="https://rssdsaisection.substack.com/">rssdsaisection.substack.com</a>.</p>
</div>
</div>
</div>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../careers/posts/2023/05/11/chatgpt-data-science-pt1.html">← Read part one</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../careers/index.html">Back to Careers</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/careers/posts/2023/05/18/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/careers/posts/2023/05/18/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Images are not covered by this licence. Thumbnail image by <a href="https://unsplash.com/@deepmind?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Google DeepMind</a> on <a href="https://unsplash.com/photos/52afknBiUk4?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-12">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Large language models: Do we need to understand the maths, or simply recognise the limitations?” Real World Data Science, May 18, 2023. <a href="https://realworlddatascience.net/careers/posts/2023/05/18/chatgpt-data-science-pt2.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Large language models</category>
  <category>AI</category>
  <category>Communication</category>
  <category>Regulation</category>
  <guid>https://realworlddatascience.net/careers/posts/2023/05/18/chatgpt-data-science-pt2.html</guid>
  <pubDate>Thu, 18 May 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/posts/2023/05/18/images/google-deepmind-52afknBiUk4-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>How is ChatGPT changing data science?</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html</link>
  <description><![CDATA[ 




<p>For many people, it starts with a question. Something simple, something they already know the answer to. A test, in other words, to see what these AI-powered chatbots are all about. But spend any amount of time with ChatGPT and other such tools and you’ll quickly start to wonder what else they might do, and how useful they might be in your day-to-day working life.</p>
<p>Data scientists certainly have been thinking along these lines, and to find out more about current use cases, proofs of concepts and potential applications, Real World Data Science got together with members of the <a href="https://rss.org.uk/membership/rss-groups-and-committees/sections/data-science-section/">Royal Statistical Society’s Data Science and AI Section</a> (DS&amp;AI) for a group discussion.</p>
<p>Our interviewees, in order of appearance, are:</p>
<ul>
<li><strong>Piers Stobbs</strong>, VP science at Deliveroo, and DS&amp;AI committee member.</li>
<li><strong>Detlef Nauck</strong>, head of AI and data science research at BT, and editorial board member, Real World Data Science.</li>
<li><strong>Adam Davison</strong>, head of data science at the Advertising Standards Authority, and DS&amp;AI committee member.</li>
<li><strong>Trevor Duguid Farrant</strong>, senior principal statistician at Mondelez International, and DS&amp;AI committee member.</li>
<li><strong>Giles Pavey</strong>, global director for data science at Unilever, and DS&amp;AI vice-chair.</li>
<li><strong>Martin Goodson</strong>, CEO and chief scientist at Evolution AI, and DS&amp;AI committee member.</li>
</ul>
<p>The first part of our discussion focuses on how large language models are becoming part of the data science toolkit, and what this new development means for data science teams and skillsets. Stay tuned for part two, which we’ll be publishing soon!</p>
<p>(<strong>UPDATE:</strong> Part two is now published: <a href="../../../../../careers/posts/2023/05/18/chatgpt-data-science-pt2.html">“Large language models: Do we need to understand the maths, or simply recognise the limitations?”</a>)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/05/11/images/chatgpt-homescreen.png" class="img-fluid figure-img" alt="Photo of ChatGPT homescreen, by Levart_Photographer on Unsplash." width="500"></p>
</figure>
</div>
<p><strong>As data scientists, how has ChatGPT – and other tools built on large language models (LLMs) – changed your working lives?</strong></p>
<p><strong>Piers Stobbs:</strong> Up to about a year ago, although I was really impressed with the developments in deep learning and the improvements in computer vision and natural language models, it felt in line with general improvements in machine learning. And then, probably about six months ago, with things like DALL·E and ChatGPT, it felt like something changed – properly ground-breaking capabilities. And I still can’t quite get my head around the fact that you can basically have a model that tries to predict the next token, and it comes up with outputs that really feel quite sensible and human-like – if prone to <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/11/23/LLM-content-warning.html">hallucination</a>.</p>
<p>The way I think about it is, this feels like a brand-new capability that we’ve just not really had before. It’s almost like an interface with unstructured information. Historically, you sort of have to turn text into something, and then turn something back into text, if you want to have this interface with humans. Now, we’ve got this really quite elegant way of plugging the gaps, which feels full of opportunities.</p>
<p>I’m having great fun playing around with the code co-pilots – GitHub’s Copilot is amazing and, productivity wise, is helping me a lot. I am now a much faster coder because there’s all those Stack Exchange lookups that I don’t have to do anymore. Again, from a personal productivity perspective, I’m using [ChatGPT] for initial drafts of documents and other things. And then I use it almost for validating things. For instance, I had a random discussion the other night with ChatGPT about logistic algorithms. It’s not going to solve problems for you, but I asked it to give some pointers of things I could be thinking about – some of which I had, some of which I hadn’t. So, it’s almost like a brainstorming helper, somehow.</p>
<p>But probably the thing I’m most excited about is the knowledge sharing side of it – plugging it into, or on top of, private information, and surfacing all that knowledge that is locked away in documents and intranet pages.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/05/11/images/piers-stobbs.png" class="img-fluid figure-img" alt="Portrait photo of Piers Stobbs"></p>
<figcaption class="figure-caption">Piers Stobbs</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>This feels like a brand-new capability – an interface with unstructured information. Historically, you have to turn text into something, and then turn something back into text, if you want to have this interface with humans. Now, we’ve got this elegant way of plugging the gaps.</p>
</div>
</div>
</div>
<p><strong>Detlef Nauck:</strong> We’re looking into running proof of concepts to see whether LLMs do bring value. Software engineering is the most obvious one, and easiest to set up and run. And then we want to look at making use of internal documents – so, either summarization or creation of internal documents in appropriate language. The latter use cases are trickier to evaluate. We want to know whether the outputs produced are any good. With software engineering you can track GitHub statistics, for example. But if you give ChatGPT to somebody to write marketing material, or to get information out of a document, how do you know that the results are good? We need to get our head around metrics for evaluation.</p>
<p><strong>Adam Davison:</strong> I’ve been using it for basically anything where I don’t remember the API very well or it’s a bit confusing. <a href="https://pandas.pydata.org/">Pandas</a> is the key, right? We all use pandas, but you don’t really remember how to do some complicated thing with <code>apply()</code>, say, so you just ask GPT-4 to give you the answer, and it saves you that hassle. Also, I read some insightful tweet that said these chat systems are really good for things where generating the solution is hard, but verifying it is easy. And I think that’s true for some of these things. You know, you get a short piece of Python code, you can basically look at that and you can tell if it’s right.</p>
<p>In data science, you’re a bit of a jack-of-all-trades. You need to do little bits of everything, but you’re not a specialist in anything. And so, I think for software development, it’s been really helpful. For example, right now, I’m doing a bit of frontend development in a project to visualise something. I’m never going to be a professional frontend developer, but GPT-4 can help deal with the oddities of JavaScript much more easily than it would be for me to trawl through Stack Overflow posts.</p>
<p>But the thing that we’re using it for, practically, is natural language processing (NLP) and classification. We have this particular problem at the Advertising Standards Authority (ASA) where we are running lots of different models that are completely unconnected to each other because every project is a different topic. So, one week we’re looking at, “Do these gambling ads appeal to young people?” and then the week after it’s, “Are these cryptocurrency ads being clear about the risks involved?” It’s very disparate, we don’t have a lot of time to iterate on models, and we don’t have huge amounts of training data. Ten years ago, when you were doing sentiment classification, you were on Mechanical Turk getting 10,000 examples, and even then it didn’t work very well after these really complicated models. Now, you’ve got a couple of hundred examples and with the embeddings [from LLMs] you can get to a pretty decent classifier quite quickly. We’re also starting to experiment with using OpenAI’s fine-tuning tools, and the performance that we’ve seen from that is very impressive, to the extent that it’s making us rethink whether we bother doing anything else in some of our classifiers.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/05/11/images/adam-davison.png" class="img-fluid figure-img" alt="Portrait photo of Adam Davison"></p>
<figcaption class="figure-caption">Adam Davison</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>Five years ago, if you had a sophisticated problem involving text or images, you’d need a big research team with a big budget to tackle it. But increasingly we find, like many other people, that you can take models off the shelf and repurpose them for quite diverse tasks.</p>
</div>
</div>
</div>
<p><strong>Trevor Duguid Farrant:</strong> My organisation is not as far forward as the rest of you. I’ve introduced it to the leadership team, and the digital services team – what was IT – are looking to make a decision on whether we can use it or not. I think there’ll be so much pressure they’ll have to use it, but there’s still a feeling of discomfort with it, whereas I think it’s really good and have started using it. Everyone else on the call seems to have started using it. So, can organisations like the Royal Statistical Society help companies to embrace this and start using it, and then everyone can benefit from it?</p>
<p><strong>Giles Pavey:</strong> I wish I could be with Piers and Adam – actually using it – but my life has been taken over as the guy who goes and explains it to the business. Unilever is a massive business, and we are concerned about privacy, confidentiality and trustworthiness. We’ve now built an initial GPT instance on Azure and fed it with some of our own documents, and a lot of my time has been working with legal to convince ourselves that that’s okay. Now we are really trying to work out just how we manage the amazing demand for proofs of concepts and use cases – and what we’re just about to uncover, I think, is the unknown but potentially massive expense of running it.</p>
<p>In pure proofs of concepts, departments that have large knowledge banks are using it: research and development, and marketing, for example. And one of the big technical things that we’re working on – and, because of the size that we are, we’re doing a lot of work with OpenAI and Microsoft on this – is how to stop the models from hallucinating.</p>
<p><strong>Have your experiences with ChatGPT and other tools changed your thinking about the skillsets required of data scientists and data science teams?</strong></p>
<p><strong>AD:</strong> A little bit. As someone at a small organisation, I think it’s quite exciting because, five years ago, maybe you were in a world where if you had a sophisticated problem involving text or images, you’d need a big research team with a big budget to tackle it. But increasingly we find, like many other people, that you can take models off the shelf and repurpose them for quite diverse tasks. So, I think it’s becoming increasingly viable to have a small team of people who are implementers, who aren’t necessarily backed up by a big research organisation, doing increasingly sophisticated stuff.</p>
<p>I don’t think it does away with the sort of things that we always bang on about in the Data Science and AI Section, like the need for an understanding of statistics and how the underlying systems really work, because I think you still need to understand what you’re doing with LLMs, as with any other machine learning technique. But, if I had to guess, what we’re going to be seeing now is that for a lot of problems, you’re going to have more of a division – so, you’re either in one of a small number of very large labs doing research on very cutting-edge big models, or you can be an implementer who is taking things off the shelf and applying them. And maybe that space in between is going to get a little bit squeezed – that would be my guess, but obviously it’s very unpredictable.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/05/11/images/giles-pavey.png" class="img-fluid figure-img" alt="Portrait photo of Giles Pavey"></p>
<figcaption class="figure-caption">Giles Pavey</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>We’ve built an initial GPT instance on Azure. Now we are really trying to work out just how we manage the amazing demand for proofs of concepts and use cases – and what we’re just about to uncover, I think, is the unknown but potentially massive expense of running it.</p>
</div>
</div>
</div>
<p><strong>PS:</strong> That’s exactly my view. When I first started hiring data scientists, a long time ago, you basically had to write stuff from scratch, and you needed PhDs – people who really understood, at a deep level, how the maths all works. But I think there’s been a steady progression towards valuing software engineering skills, and I think, in some ways, this is another step along that path. If I think now about implementing a chatbot over your own knowledge base, it’s basically like plugging APIs together with some Python. Adam’s point is still hugely important, though, because I think we still need the background knowledge about what’s actually going on – OK, I’m creating embeddings here, and that’s allowing this search to work so I can surface the right docs – that whole process, which an average software engineer is maybe not going to know. But I think it’s definitely blurring the lines.</p>
<p><strong>Martin Goodson:</strong> It’s just as important now to understand how to evaluate performance. The difference is, it used to be that you were trying to figure out whether it’s 80% accurate, or 85%. Now, it’s like 99.9%. But you still need to figure it out. You still need to understand what the failure modes are, what caused it; how is it actually working, and is it doing what you need it to do for the product? Is it actually satisfying our needs as users or as customers of the products.</p>
<p><strong>DN:</strong> I think in the future, the skills we will need are people who can run and build these models. Giles made the point about how expensive it is to run these things. Right now, you have two options: subscribe to an API, and then you are limited in how you can modify these models; or build your own – take an open-source LLM and modify it. But then you need people who know how to build a high-performance computing environment and operate this efficiently. You need to know how to actually train the models, how to curate the data, how to set the model parameters. And I always think there’s too much alchemy still going on in this field, right? It’s not proper science. People build these things and then are surprised at what they can do; they didn’t know such things would be possible. A lot of these capabilities only emerge when you make the models really, really big and, essentially, you also have no control over them – you can’t stop them hallucinating. So, these are the kinds of issues we need to get under control if we want to get any value out of them.</p>
<p>Prompt engineering is another one – you really need to understand how these models work and how to prompt them. If you want to give them to, say, a marketer to generate copywriting, they may not have the right ideas of how to prompt the machine. So, I could see roles developing out of data science that understand how to influence these models and make them do what we want them to do.</p>
<p><strong>MG:</strong> The other angle to this is junior engineers. Now, the bar for being a useful junior engineer is that you’re better than GitHub Copilot. Why do you need a really junior person if you can just use a large language model to be the junior developer?</p>
<p><strong>DN:</strong> I’m not thinking about the data science person who needs to write some code for a project here, but if you have a large software team in an organisation that produces production code, they will become more efficient by using these tools. But still, with all this overhead of testing and putting it all together, there will be a lot of manual work that needs to be done. But the teams will get more efficient and junior people will get up to speed quicker. That’s probably another advantage.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/05/11/images/trevor-duguid-farrant.png" class="img-fluid figure-img" alt="Portrait photo of Trevor Duguid Farrant"></p>
<figcaption class="figure-caption">Trevor Duguid Farrant</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>Can the Royal Statistical Society help non-tech companies embrace large language models, extolling their virtues and dispelling the myths?</p>
</div>
</div>
</div>
<p><strong>PS:</strong> I think Detlef’s point about understanding is an interesting one. It definitely feels like there’s been this sort of continuum from, you know, “OK, it’s a linear regression, we know what’s going on” to complex models to ensemble models where, again, you’re combining these things you can individually understand. Even with big ImageNet architectures, billions of parameters, at least conceptually you can understand how these work and build out tools where you can understand the layers. To me, what’s different now is you’ve got this reinforcement learning layer on top, or diffusion layer, or some other additional approach – this combination of really complicated things. I honestly don’t know where to start with trying to understand why a specific output is generated, and I think that is a proper concern. That’s definitely an area of research, because I think we need to understand this.</p>
<p><strong>GP:</strong> I think there’s also a question in large companies of just who owns these things. Up until this point, everybody’s been happy that AI is the realm of data science. And, suddenly, generative AI looks like it might be the realm of the IT team – that it’s a service that you get off the shelf. It’s going to be interesting to see how that plays out. I really liked the point that Martin was making about being able to tell what the systems are actually doing, what they are supposed to do and how to check them, because if you don’t have a background in that area, you might just assume they work. Now, nobody knows exactly how these things work – not even the people who build them. But having a background in how you test things, for potential causes for things not working, is actually going to be incredibly powerful or useful.</p>
<p><strong>TDF:</strong> Will experts like us actually be able to check it because of the speed that new versions are coming out and the developments that are happening? Is it going to take us six months to check that GPT-3.5 works? Well, too late, a month later GPT-4’s out! I just think that pace is going to keep accelerating.</p>
<div class="callout callout-style-simple callout-note" style="margin-top: 2.25rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Want to hear more from the RSS Data Science and AI Section? Sign up for its newsletter at <a href="https://rssdsaisection.substack.com/">rssdsaisection.substack.com</a>.</p>
</div>
</div>
</div>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../careers/index.html">Back to Careers</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../careers/posts/2023/05/18/chatgpt-data-science-pt2.html">Read part two →</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/careers/posts/2023/05/11/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/careers/posts/2023/05/11/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photos are not covered by this licence. Portrait photos are supplied by interviewees and used with permission. ChatGPT homescreen photo by <a href="https://unsplash.com/@siva_photography?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Levart_Photographer</a> on <a href="https://unsplash.com/photos/drwpcjkvxuU?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-12">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “How is ChatGPT changing data science?” Real World Data Science, May 11, 2023. <a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Large language models</category>
  <category>AI</category>
  <category>Skills</category>
  <category>People</category>
  <guid>https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html</guid>
  <pubDate>Thu, 11 May 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/posts/2023/05/11/images/chatgpt-homescreen.png" medium="image" type="image/png" height="105" width="144"/>
</item>
</channel>
</rss>
