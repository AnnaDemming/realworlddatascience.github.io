<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/latest-content.html</link>
<atom:link href="https://realworlddatascience.net/latest-content.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://realworlddatascience.net/images/rwds-logo-150px.png</url>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/latest-content.html</link>
<height>83</height>
<width>144</width>
</image>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Tue, 10 Oct 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>Join Real World Data Science at three events this October!</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/10/october-events.html</link>
  <description><![CDATA[ 




<p>Summer 2023 for us was a blur of excellent data science and statistics events. There was the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html">Joint Statistical Meetings in Toronto</a>, the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/rss-conference.html">Royal Statistical Society Conference in Harrogate</a>, and <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.html">posit::conf(2023) in Chicago</a>. But if that wasn’t enough, autumn promises more good stuff, and more opportunities to meet with Real World Data Science in person and online.</p>
<section id="an-introduction-to-real-world-data-science" class="level3">
<h3 class="anchored" data-anchor-id="an-introduction-to-real-world-data-science">An introduction to Real World Data Science</h3>
<p><strong>Date:</strong> Monday, October 16, 2023 <strong>Time:</strong> 12 pm – 1 pm <strong>Location:</strong> Online</p>
<p>Next week is Members’ Week at the Royal Statistical Society (RSS), and the RSS calendar is full of events targeted at members – prospective members, new members, and established members. Kicking things off on Monday lunchtime is <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/the-real-world-data-science/">an online event to introduce Real World Data Science</a>. We’ll discuss the aims of this project, our guiding ethos and content plans, and we’ll explain the various ways in which people can contribute to the site.</p>
<p>Chances are, if you’re reading this blog, you won’t need much of an introduction to Real World Data Science. But do please help spread the word to potential new readers, and encourage them to <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/the-real-world-data-science/">register for this free event</a>.</p>
</section>
<section id="nhs-r-community-annual-conference" class="level3">
<h3 class="anchored" data-anchor-id="nhs-r-community-annual-conference">NHS-R Community Annual Conference</h3>
<p><strong>Date:</strong> Tuesday, October 17, 2023 <strong>Time:</strong> 9:30 am – 10:00 am <strong>Location:</strong> Edgbaston Stadium, Birmingham (in person) and online</p>
<p>It’s a real honour for us to be invited to give a keynote talk at <a href="https://nhsrcommunity.com/events/nhs-r-community-conference-2023-ticket-for-in-person-attendance-on-tuesday-17th-october-2023/">this annual gathering of the NHS-R Community</a>, a group dedicated to promoting the use of R in the National Health Service. Our talk is titled, “Forging community links: NHS-R, the Royal Statistical Society and Real World Data Science,” and we’ll explain how the Real World Data Science project came about, how we embraced open-source tools and the idea of collaborative content development, and why there’s so much to be gained from sharing data science case studies across domains.</p>
</section>
<section id="evaluating-artificial-intelligence-how-data-science-and-statistics-can-make-sense-of-ai-models" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-artificial-intelligence-how-data-science-and-statistics-can-make-sense-of-ai-models">Evaluating artificial intelligence: How data science and statistics can make sense of AI models</h3>
<p><strong>Date:</strong> Tuesday, October 31, 2023 <strong>Time:</strong> 4 pm – 6 pm <strong>Location:</strong> RSS, London (in person only)</p>
<p>Real World Data Science has partnered with colleagues and volunteers across the RSS to organise another <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/evaluating-artificial-intelligence-how-data-scienc/#fulleventinfo">AI panel debate</a>, following up on the AI discussion at the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/rss-conference.html">RSS Annual Conference</a>.</p>
<p>This event forms part of the <a href="https://aifringe.org/">AI Fringe programme of events</a>, which coincides with <a href="https://www.gov.uk/government/publications/ai-safety-summit-introduction">the UK government’s AI Safety Summit on 1–2 November</a>.</p>
<p>Our free event focuses on big questions around AI model evaluation, which will also be a key topic of discussion at the summit. One of the government’s stated objectives is for the summit to identify “areas for potential collaboration on AI safety research, including evaluating model capabilities and the development of new standards to support governance,” and so we’ll be asking:</p>
<ul>
<li>What should AI evaluation look like?</li>
<li>How will it work in practice?</li>
<li>What metrics are most important?</li>
<li>Who gets to decide all of this?</li>
</ul>
<p><a href="https://rss.org.uk/training-events/events/events-2023/rss-events/evaluating-artificial-intelligence-how-data-scienc/#fulleventinfo">Register via the RSS website</a> to attend this free in-person event, chaired by RSS president Andy Garrett. Panellists will be announced soon, so stay tuned!</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/10/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/10/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Join Real World Data Science at three events this October!” Real World Data Science, October 10, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/10/october-events.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Communities</category>
  <category>Events</category>
  <category>Updates</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/10/october-events.html</guid>
  <pubDate>Tue, 10 Oct 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/10/images/oct-events.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘I fell in love with math, really, and fell into data science because of that’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/career-profiles/posts/2023/10/04/niclas-thomas.html</link>
  <description><![CDATA[ 




<p>A passion for maths and solving mathematical problems led Niclas Thomas to a PhD in machine learning with a focus on medical research. But then a conversation with a recruiter steered his career towards data science in the retail sphere. After stints at Tesco, Sainsbury’s, and Gousto, Thomas is now head of data science for Next, the clothing retailer.</p>
<p>In this interview with Real World Data Science, Thomas reflects on his career journey so far, from hands-on coding work to team leadership and management. He also argues for the importance of communication and storytelling as part of the data science skill set.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/0y6yye1A9vU?si=oea60bsc8r83icom" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Niclas Thomas, thank you for joining us today. I hope you’re well.</p>
<p><strong>Niclas Thomas</strong><br>
I am indeed thanks. Thank you for having me.</p>
<p><strong>Brian Tarran</strong><br>
Today we’re meeting because we want to find out a little bit about your career in data science, how you got into it, what you’re doing now, where you see both your career and data science as a profession going next. So do you mind– can we start by giving us a brief introduction to who Niclas Thomas is?</p>
<p><strong>Niclas Thomas</strong><br>
Yeah, of course. Yeah. So I’m currently working as head of data science at Next. My background is academia originally, a maths degree. I did my PhD in machine learning, and more in medical research, so more of an applied machine learning position where the idea was to try and predict, ultimately, predict disease from a given sample of data from blood – can you actually predict future disease? – which I think is a really interesting area; I love medical research. And then [I] switched over to more commercial role and worked in several retail data science roles: so, Tesco, Sainsbury’s, Gousto, and then now, as I said, currently head of data science at Next, where I run a team, and I imagine most listeners will be familiar with what Next do: a retail, a clothing brand on the whole, where the idea is, obviously to sell some great stuff, great products and put the right product in front of the right customer.</p>
<p><strong>Brian Tarran</strong><br>
Can you tell us, what does your job involve? What are your sort of main tasks and responsibilities in that role?</p>
<p><strong>Niclas Thomas</strong><br>
Yeah, so I suppose I’m lucky enough to have been head of data science at several different companies: Sainsbury’s, Gousto, and Next. So it’s always interesting to compare the role of the head of data science in each of those three. At the moment, I think there’s a core focus on, well, ultimately making sure the teams are efficient as possible. And that really means just making sure our tech stack – what tools, what programming languages, what software we use on a day to day basis – is set up for success and make sure the team have what they need to be able to do the job as efficiently as possible, whether that’s using Python or R, whether that’s how we develop code, and how we work with other people as well, being a big part of that, then. So how do we work with other software engineers? How do we work with web developers, then, to make sure that the work we do actually gets in the hands of the business and ultimately in the hands of the customer. So that’s one aspect: it’s just making sure the team is set up for success, both in terms of the ways they work and what tools they have to work as well, then. I guess the other side of that coin is what we actually work on. So understanding the value of potential work we could do, and helping the team understand what that value is, and, and ultimately giving direction of what things we want to work on next. Obviously, that’s not my decision in isolation, but understanding on the one hand, what other stakeholders want to do, what my superiors wants to do, as well. And trying to put that all into the mix to understand these are the next best projects to work on given a finite amount of people to work on these problems. And then ultimately, then, the last part, then, is ultimately helping the team deliver those projects, those products as well then, which usually means calling on my experience of having solved these problems myself, either directly when I was earlier in my career or indirectly through leading others then or, you know, being the head of a team and working with some other great people and to learn from their experiences as well.</p>
<p><strong>Brian Tarran</strong><br>
What does data science mean to you, personally? I’m not asking you to define it for everybody. But for you, what is what is data science?</p>
<p><strong>Niclas Thomas</strong><br>
Yeah, I wish I’d come up over the years with a great definition of this. But yeah, I mean, really, it just, I mean, at the very highest level, it just means using data to drive business value, I suppose, as I guess in my– which probably reflects the fact that it’s more of a business role that I have. But I think that in its broadest sense, I think that’s true: using data to drive insights and make decisions for the business. There are more, I guess, detailed definitions of that. So, for example, the way I’ve always differentiated between data analytics and data science is that if you want to make repeated decisions on a daily or weekly basis, then that’s when it becomes more about a data science question versus a data analytics question, because data analytics is generally about answering large one off ad hoc questions, rather than making the same decision over and over again and using methods appropriate for that. But, ultimately, that’s what data science means to me, I think: making repeated decisions using data and the scientific method to use data for good.</p>
<p><strong>Brian Tarran</strong><br>
And so what do you think is your most important skill as a data scientist given that definition that you have of data science?</p>
<p><strong>Niclas Thomas</strong><br>
In my role, I suppose communication ultimately becomes the most important thing. I’d say definitely earlier in my career, and I think if you’re the person actually delivering and implementing the algorithm, I think that the technical skill set obviously is really important then. But ultimately, I almost see my role as the head of data science as a hybrid– as a link between my team and the rest of the business, then. So it’s really about being able to, on the one hand, translate technical concepts into non technical descriptions of what we’re actually doing, making sure the rest of the business can understand and vice versa, then making sure I understand the business process and business terminology well enough to be able to translate that for the team, as and when needed, into a vision for a project, a product, then, and develop a strategy for that. So I think that the communication both in the strictest sense of being able to talk that through with, with my team, with other team members, with stakeholders, as well, but also more in the looser sense, then, of being able to define that strategy, being able to define what the roadmap for a particular project or a product might look like.</p>
<p><strong>Brian Tarran</strong><br>
Can you talk us through your so your education and your training that led up to your kind of first data science job, your first data science role.</p>
<p><strong>Niclas Thomas</strong><br>
I suppose the first time, the first time I– actually, I’d never heard about it, I think, when a recruiter approached me. This is probably going back into 2014, when I was maybe eight months into my postdoc after my PhD. I think– obviously it did exist before that, although I suppose the terminology wasn’t quite as widespread going back almost 10 years now where the term is a lot more rife. So my original background, I did a master’s in maths originally, four years. And then I remember being– the last year of that, then, I was applying for a few jobs, and I applied for one at the Met Office, where the focus obviously was predicting weather, forecasting. And I wasn’t successful in that job. But I did notice that the, on the job spec at the time, it was PhD preferred was one of the specs on that role. It was probably the first time I thought about taking on a PhD as more of a career move rather than as the natural progression to an academic career, more of a business career move if you like, then of actually how it can help you in more business settings. So that was at least when I decided to do my PhD and thought it’s certainly not going to be– and this was back in 2008, so at the time of the financial issues at the time when getting jobs was harder anyway, so it felt like a win-win of doing something that would be– I was clear I wanted to work in a data role of some sort. And that combined with the fact that I thought it would be a good career move and the financial climate at the time wasn’t brilliant. So I took on a PhD then. And then in terms of actually getting into, into my first data science position was, as I said, just after I finished my PhD, I had been working about six months, eight months as a postdoc, and then a recruiter just described a role that was available at Tesco at the time. And it sounded a lot of what I was doing in my current postdoc role at the time – making predictions based on data and exactly the same techniques – sounded really interesting. And it must have been the way the recruiter sold it at the time as well then, because it’s something I was really keen to take on and then made my move off the back of that then. So yeah, kind of moved into it a little bit, I guess, semi deliberately from taking a PhD on first, but always with the view of moving over to a business role at some point after that.</p>
<p><strong>Brian Tarran</strong><br>
But it wasn’t like you started out your further education thinking, “I want to be a data scientist, what do I need to do to kind of get there? What are the subjects I need to focus on? What are the topics I need to research?</p>
<p><strong>Niclas Thomas</strong><br>
Yeah. Oh, absolutely. Yeah, it certainly wasn’t by design at the very start of my journey. I fell in love with math, really, and just fell into data science because of that, really, I loved numbers and loved solving maths problems. So that’s why I did a degree in it first of all, then and certainly, you know, even midway through my degree, then I wasn’t really sure what I wanted to do. It was more, as you say, just by chance, then, that there were a few opportune moments that came around then, that opportunities came around at the right time to fall into that career.</p>
<p><strong>Brian Tarran</strong><br>
Doing a PhD in machine learning as you did, that was quite a – in hindsight – a smart choice of PhD to pursue, I think, right?</p>
<p><strong>Niclas Thomas</strong><br>
I think so. Yeah, I suppose it was– still even at that stage it wasn’t necessarily, again, the terminology ‘data science’ wasn’t really around. Certainly, when I started my PhD in 2009 2010. It wasn’t really terminology, at least it may have been in usage a little bit in terms of being on, you know, if you look for jobs on LinkedIn or Indeed, but it certainly wasn’t terminology that that I would have been particularly familiar with.</p>
<p><strong>Brian Tarran</strong><br>
Your first job in data science was at Tesco. You mentioned that you were you were kind of recruited to that role there. How does it compare to your current role? So I guess, you know, what’s the difference between being a data scientist versus head of data science as you are now?</p>
<p><strong>Niclas Thomas</strong><br>
Yeah, I think there are probably more similarities than differences, I would say. We were quite lucky in the setup in Tesco that the recruitment strategy seemed to be more focused around people who already had some experience in, generally, either already had business experience or a PhD. So we were fairly independent in solving our own– the project that we were working on and working on that. Not necessarily with the head of data science guiding us, you know, day by day, in terms of the actual nitty gritty and the technical detail, which is great, then. So it did mean that we had responsibility and ownership for our product quite early on. So yeah, I really enjoyed that. I suppose I was writing a lot more code in those days than I do now. I rarely, if ever write code at the moment. So I think that’s probably true for the last maybe three or four years, I think, only occasionally getting my hands dirty. And even when it is, it’s not really to build an algorithm, it’s more to inquire about what data we have to solve the algorithm then. So even when I do get my hands dirty, it’s more in the very early stages of the whole algorithm development lifecycle. So I think that’s probably the biggest difference is just the actual ownership of development there – probably expected, I would say, but it’s– I think that’s one of the beauties of being in your first job or two in data science. I think the– I think in most places I’ve seen, I think you’ll get ownership of, of the work, the stuff that you work on, on a day to day basis, quite early on. And you’ll be expected to contribute code and ideas for that as well, which I think most people would love. I certainly loved it at the time.</p>
<p><strong>Brian Tarran</strong><br>
What was the most important thing you learned in your first year in that job?</p>
<p><strong>Niclas Thomas</strong><br>
I think, again, it’s probably a lot around the ways of working, I would say – of the various ways you can [work], which I never really thought about it before. Working in academia, it was quite isolated, I suppose. You work on your own project, you work on your own work and don’t really– or at least, I found I didn’t really work with anyone else that much. Maybe that was the nature of my work as well, we’d obviously be dependent on people working in a lab to get data. But I think the day to day work, I was working quite in isolation, whereas the team aspect of working, I think, was a steep learning curve then – so agile methodology, and everything around that, which was very, very new to me. And the various ways you can do that. I’m generally not someone for overly putting processes in place in a team, only where necessary. But I think there’s some great learnings from that as well. It certainly started to shape how I think I would want to run a team if and when I got to that position.</p>
<p><strong>Brian Tarran</strong><br>
So, Nick, what have been your career highlights so far?</p>
<p><strong>Niclas Thomas</strong><br>
I think in terms of– there was one product we built in Sainsbury’s in particular. So in terms of, on a product level of replenishment. So how do you most efficiently get products from the back of the store onto the shelves of an individual store? And what’s the most optimal strategy to do that, which I love for a variety of reasons. A, it was one of the first full data science products that we had deployed and worked on as a team in Sainsbury’s. So there was that kind of milestone about it. I think it also stood out as a really nice move away from classic machine learning – i.e., making a prediction, a classification model – to something that was a bit more operations research based and more based on optimization. So using graph theory, making a graph network of a store. And using that to solve the problem of taking a route through the store, for example, a bit like a Google Maps for a store basically, was how we always pitched it to our stakeholders, and how can you choose the best route and again, moving more into a bit more of a vehicle routing problem, then: if you’ve got two different trolleys, how do you decide what items to put on trolley one versus trolley two? So there’s loads of interesting stuff on the technical side of things and it was, again, I felt it was probably one of the highlights – as well as the end product, it was also the one I worked on at the very start. So actually, the understanding whether it would be possible to do that, what kind of technical approach. So I think certainly from a product perspective, that’s probably stuck in my mind. Aside from that, on a more personal level, I guess, I did decide to write a book off the back of my PhD. Just mainly on my experiences from my PhD and postdoc. I mean, it’s not like a confessional. But more on the– just working with non data scientists and making it more accessible was really what I really focused on there. So having worked with clinicians, immunologists and others as part of the medical research that I did, I felt that data can be accessible if you pitch it in a way and make it easy to use. And so that was the purpose of what was largely an educational textbook.</p>
<p><strong>Brian Tarran</strong><br>
Do you want to give a short plug for the book, what it’s called and where people can find it?</p>
<p><strong>Niclas Thomas</strong><br>
Yeah, so it’s, Data Science for Immunologists is the name of the book. It’s available on Amazon. I’m one of the two co-authors on that then. And we do have a website, <a href="https://datascienceforimmunologists.com/">datascienceforimmunologists.com</a>, as well then if you did want to visit and you can either buy the book, there’s a link on that website or just go straight to Amazon and it’s available there.</p>
<p><strong>Brian Tarran</strong><br>
This next question, we’ve gone from highlights to lowlights. Have there been any mistakes or regrets that you’ve had along the way in your data science career so far?</p>
<p><strong>Niclas Thomas</strong><br>
The main mistakes I think I’ve made before is not valuing, A, communication or soft skills, but B, the leadership and management as well then. And I think especially it’s something, when working at Gousto as well that was something that was a big focus of the team and something that I really took from my time there as well was the, I guess, the art of good management and good leadership, you know, what the difference is between the two. So I wouldn’t say there’s any one bang event that’s a mistake or regret, but it’s probably, as ever, it’s probably I would have put more emphasis on it sooner had I known that how important those skills would be.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, but I think that’s understandable to a certain extent. If you’re coming from, I guess, a role that’s very hands on, doing things yourself, getting into the messy details of a project, it can sometimes be hard to kind of take a step back and adopt more of a kind of leadership, management position, can’t it?</p>
<p><strong>Niclas Thomas</strong><br>
Yeah, definitely. Yeah, definitely. I would agree with that. And I think it’s also, I’d probably say for a lot of people starting out, and certainly it was for me, that the technical– the technical aspect is probably why you get into a role in data science in the first place, that you just love solving problems, basically, whether that’s with code or with pen and paper. And so that’s, that’s what you want to do. And getting your mind focused elsewhere away from that is probably not viewed as the most fun thing to do, I probably wouldn’t have, when I was starting out in 2014, 2015, I probably wouldn’t have thought it was as fun or as interesting to do that as I do now, maybe. So I think that’s the other reason why it probably doesn’t get as much focus earlier on in my career anyway, at least, as it probably deserved.</p>
<p><strong>Brian Tarran</strong><br>
How do you think your– how do you see your role, I guess, evolving over the rest of your career in data science?</p>
<p><strong>Niclas Thomas</strong><br>
I suppose on a personal level, for me it’s, I’m always thinking of what, 10 years down the line, do I still want to be focused just on data science? Or do I want to be focused on a data role, more broadly? I suppose that’s always the main question to ask. And so by that I mean, looking at data engineering as well, data analytics, and being responsible for a wider group. I think the way the field is going anyway, I think a lot more companies seem to move to vertical management rather than horizontal. So by that, I mean having heads of data in different areas of the business. So rather than having a head of data and a head of analytics, you might have a head of data for certain aspects of the business and another head of data then that’s responsible for both in other areas of the business, then. So either way, I think that the broadening of responsibilities and not just being responsible for data science is probably one way I would see my career potentially moving. At the moment, I love just focusing just on the data science, I’m really happy doing that now. But I think that could be one way that my focus changes in the future.</p>
<p><strong>Brian Tarran</strong><br>
What personal or professional advice would you give for anyone wanting to be a data scientist?</p>
<p><strong>Niclas Thomas</strong><br>
Yeah, so first of all, the balance between the soft and hard skills. I think I’ve alluded to it before, but the– don’t put too much– I mean, still emphasise on the technical skills are really important, but don’t feel like it’s the be all end all. I think just understanding the softer side of how you communicate, how you tell a story, for example, and storytelling with data, I think is really important. So I’d say that’s probably one focus area. I think that the second would probably, and maybe it’s a harder one to act on, but being passionate, I think, because whenever I’m looking to recruit anyone new into my team, I think it’s as much about understanding what the potential of that person is as is what is their current performance or where their current capability is – how good they could be in the future is arguably more important. And I think a lot of that comes to ultimately someone’s– whether they have a fixed or growth mindset. So by that, I mean, ultimately, do they want to learn or not, and if they really want to learn, as a lot of data scientists do, but if they have a huge passion for or about data science, and wanting to learn about just how to get better – whether that’s a better coder, better at maths, anything around that – then if you have that attitude, I think then it’s, A, you can have a great impact on our team, but B, I think it’s a sign of someone who can be a great performer in the future.</p>
<p><strong>Brian Tarran</strong><br>
So what do you think will be the main challenges facing data science as a field over the next few years?</p>
<p><strong>Niclas Thomas</strong><br>
I think probably, certainly, currently maybe living up to the hype, I suppose. And matching I suppose the classic Gartner Hype Cycle of, it feels like we’re probably at the stage where there’s a lot of– the hype has been around for a few years of data science now and I think making sure we tackle the right problems, I suppose, is one of the – and by ‘we’ I mean, Next as a business or whatever business we’re working in at the time – I think it’s making sure we’re working on the right things. Because I think a lot of people will be keen to have data scientists as part of their work and the product they’re trying to build. What is the best place to spend our time, and what projects we should be working on most I think is– becomes important then because, as I say, there’s a huge demand for data scientists time, I think, in every company. And so choosing where we spend that time wisely, I think, becomes the key challenge and the important decisions for, especially for a head of data science like myself to make then, to make sure we’re best using the team’s capacity, then.</p>
<div class="article-btn">
<p><a href="../../../../../../careers/career-profiles/index.html">Discover more Career profiles</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/10/04/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/10/04/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘I fell in love with math, really, and fell into data science because of that.’” Real World Data Science, October 4, 2023. <a href="https://realworlddatascience.net/careers/career-profiles/posts/2023/10/04/niclas-thomas.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Leadership</category>
  <category>Management</category>
  <category>Communication</category>
  <guid>https://realworlddatascience.net/careers/career-profiles/posts/2023/10/04/niclas-thomas.html</guid>
  <pubDate>Wed, 04 Oct 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/career-profiles/posts/2023/10/04/images/niclas-thomas.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>American Statistical Association joins Real World Data Science as partner</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/02/asa-partner.html</link>
  <description><![CDATA[ 




<p>The first version of Real World Data Science was launched almost one year ago by the <a href="https://rss.org.uk/">Royal Statistical Society</a> (RSS). As we approach our first birthday, we’re delighted to announce that the <a href="https://www.amstat.org/">American Statistical Association</a> (ASA) has become a partner in this project.</p>
<p>ASA shares our goal of developing Real World Data Science as a free and beneficial resource for the entire data science community – one that informs, inspires and strengthens the community by bringing together students, practitioners, leaders, and educators to share knowledge about real-world applications of data science.</p>
<p>The data science profession is geographically and academically diverse. We believe that Real World Data Science can best achieve its goal of being a trusted, go-to resource for all data scientists if a range of partner organisations work together to develop the site and its content, so we’re thrilled that ASA is taking the first step with us towards fulfilling this vision.</p>
<p>Ron Wasserstein, executive director of the American Statistical Association, shared: “We are delighted to be partnering with RSS on Real World Data Science. This is important for our community and serves to further strengthen our valuable relationship with RSS.”</p>
<p>Sarah Cumbers, chief executive of the Royal Statistical Society, commented: “We’re thrilled to have ASA on board as a partner for Real World Data Science. We have big plans for the project and this partnership will help us achieve these by allowing us to reach more of the data science community and strengthen our content offering.”</p>
<p>As part of this new partnership with ASA, we will shortly welcome two ASA members to our <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/10/18/meet-the-team.html">editorial board</a>. So, on behalf of the entire – and soon-to-be expanded – editorial board, we’d like to say a huge thanks to ASA for their support and endorsement of Real World Data Science.</p>
<p>ASA members, groups, and sections interested in contributing to the site are encouraged to review our <a href="https://realworlddatascience.net/contributor-docs/call-for-contributions.html">call for contributions</a> and to <a href="https://realworlddatascience.net/contact.html">contact us</a> via email or our social media channels to discuss content ideas.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/02/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/02/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “American Statistical Association joins Real World Data Science as partner.” Real World Data Science, October 2, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/02/asa-partner.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>News</category>
  <category>Updates</category>
  <category>Call for contributions</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/02/asa-partner.html</guid>
  <pubDate>Mon, 02 Oct 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/10/02/images/laptop-connect.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Live from Chicago: Real World Data Science at posit::conf(2023)</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.html</link>
  <description><![CDATA[ 
<script src="https://cdn.jsdelivr.net/npm/monaco-editor@0.43.0/min/vs/loader.js"></script>
<script type="module" id="webr-monaco-editor-init">

  // Configure the Monaco Editor's loader
  require.config({
    paths: {
      'vs': 'https://cdn.jsdelivr.net/npm/monaco-editor@0.43.0/min/vs'
    }
  });
</script>




<div class="callout callout-style-simple callout-note" style="margin-top:0">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>posit::conf(2023) is over, but this blog remains open for contributions. If you want to share personal highlights or reflections on your time at conference: 1. Fork <a href="https://github.com/realworlddatascience/realworlddatascience.github.io">our repo</a>, 2. update <a href="https://github.com/realworlddatascience/realworlddatascience.github.io/blob/positconf-blog/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.qmd">this file</a> in the <code>positconf-blog</code> branch (or create a new branch of your own), and 3. make a pull request! You can also <a href="https://realworlddatascience.net/contact.html">email contributions</a>.</p>
</div>
</div>
</div>
<section id="tuesday-september-19" class="level2">
<h2 class="anchored" data-anchor-id="tuesday-september-19">Tuesday, September 19</h2>
<section id="from-data-confusion-to-data-intelligence" class="level3">
<h3 class="anchored" data-anchor-id="from-data-confusion-to-data-intelligence">From data confusion to data intelligence</h3>
<p>An inspiring start to posit::conf(2023) this morning, with keynote talks from Elaine McVey, senior director of analytics at Chief, and David Meza, head of analytics for human capital at NASA, sharing stories and insights on how to build strong data science foundations in organisations.</p>
<p>McVey spoke about the frequent mismatch between high levels of hope for what data science can achieve within organisations, and low levels of understanding about how to set up data science teams for success. The best chance for success, she said, is if data scientists take the lead in helping organisations learn how to make best use of data science expertise.</p>
<p>From there, McVey went on to present a set of “guerilla data science tactics” that data scientists can use to get around any obstacles they may encounter, as illustrated in the slide below:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/images/mcvey-slide.png" class="img-fluid figure-img" alt="Elaine McVey's 'guerilla data science tactics' for building successful data science teams. Start by 'scanning for opportunities', then 'show, don't tell', 'take the data and run', 'nail the landing', and 'up the ante'."></p>
<figcaption class="figure-caption">Elaine McVey’s “guerilla data science tactics” for building successful data science teams.</figcaption>
</figure>
</div>
<p>Data scientists should start by scanning for opportunities to help the organisation, before building a small-scale version of what it is they propose to do. Once buy-in is achieved, and data is made available, it’s time to run with the project. Once complete, you need to “nail the landing,” McVey said, and make sure to communicate results broadly – not just to primary stakeholders, but across the organisation. Then comes time to “up the ante”: if your first project has built some organisational goodwill, leverage that and look for something higher risk, with higher potential reward for the organisation.</p>
<p>Throughout this process, McVey said, data scientists should be building foundations for future projects – creating data pipelines, R packages, etc., that can be reused later. This was a point picked up and developed upon by Meza, who walked through in detail the steps required to establish “data foundations” within organisations, drawing on his own past experiences. Typically, he said, organisations seem to collect data just to store it – but always data should be collected, stored, and managed with analysis in mind.</p>
</section>
<section id="a-hackers-guide-to-open-source-llms" class="level3">
<h3 class="anchored" data-anchor-id="a-hackers-guide-to-open-source-llms">A hacker’s guide to open source LLMs</h3>
<p>Fast.ai’s Jeremy Howard lifted the hood on large language models (LLMs) in the second of two keynotes this morning.</p>
<p>Beginning with an accessible overview of what LLMs are, how they work, and how they are trained, Howard then addressed some of the criticisms made of LLMs – that they “can’t reason” or give correct answers.</p>
<p>As Howard explained, a model like OpenAI’s GPT-4 is not trained at any point to give correct answers to prompts – only to predict the most likely next word, or word token, in a sequence.</p>
<p>The pre-training step, for example, does not involve only feeding the model with “correct answers,” instead relying on a corpus of text from the internet – some (or, maybe, much) of which may consist of factual inaccuracies, errors, falsehoods, etc. And in the fine-tuning stage, when human feedback is used to either reward or penalise model outputs, Howard said there is a preference for confident-sounding responses – and so, again, this doesn’t necessarily reward the model for giving correct answers.</p>
<p>Howard made the case that users have to help language models to give good answers, and that custom instructions can be used to change the way models respond. He then walked delegates through a series of demos using open-source LLMs, to show how outputs can be refined and improved.</p>
<p>“My view is that if you are going to be good at language modelling in any way,” said Howard, “you have to be good at using language models.”</p>
</section>
<section id="documenting-things-openly-for-future-us" class="level3">
<h3 class="anchored" data-anchor-id="documenting-things-openly-for-future-us">Documenting Things: Openly for Future Us</h3>
<p>Julia Stewart Lowndes, founding director of <a href="https://openscapes.org/">Openscapes</a>, gave a compelling talk advocating for the importance of documentation for data science projects.</p>
<p>Documenting things, Lowndes said, should be done for the benefit of “Future Us”: not only ourselves but our teams and our communities who may be contributing to or revisiting the project in the next hours, days, weeks, months and years.</p>
<p>Documenting things does not have to be painful, Lowndes said. In fact, it’s supposed to be helpful. It does, however, take time and intention. And it means slowing down briefly to write things down now, in order that work speeds up in the longer term.</p>
<p>Lowndes then shared some pointers to help people get started with documentation:</p>
<ol type="1">
<li>Have a place to write things down – Google Docs, GitHub, wherever – ideally a place where people can work collaboratively.
<ol type="i">
<li>Develop the habit of writing things down as you go.</li>
<li>Write in a modular way – small bits of text are less daunting and easier to maintain collaboratively.</li>
</ol></li>
<li>Have an audience in mind – you are writing this for someone, so make it engaging for them.
<ol type="i">
<li>write in an inclusive tone.</li>
<li>Narrate code in small chunks, and in a way that you’d say out loud if teaching.</li>
<li>Share, and share early – you want to be able to iterate on your documentation and receive feedback. Also, sharing openly does not always mean publicly – manage permissions as necessary.</li>
</ol></li>
<li>Design for readability and accessibility.
<ol type="i">
<li>Use section headers – particularly important for screen readers, but this also helps generally to describe the flow of a document. Plus, you can link readers directly to specific parts of a document.</li>
<li>Use text formatting.</li>
<li>Use alt-text for images, describing the take-home message of the image.</li>
</ol></li>
</ol>
</section>
<section id="teaching-data-science-in-adverse-circumstances-posit-cloud-and-quarto-to-the-rescue" class="level3">
<h3 class="anchored" data-anchor-id="teaching-data-science-in-adverse-circumstances-posit-cloud-and-quarto-to-the-rescue">Teaching Data Science in Adverse Circumstances: Posit Cloud and Quarto to the Rescue</h3>
<p>Professor Aleksander Dietrichson of the Universidad de San Martin brought a valuable perspective to posit::conf(2023) on the challenges of teaching data science in the face of technology and language barriers.</p>
<p>At the public, state-funded university in Argentina where Dietrichson works, more than half of students do not have access to laptops or computers at home, and those who do have access – whether at home or at school – may not have access to the latest kit. But “<a href="https://posit.cloud/">Posit Cloud</a> solves the resource issue,” Dietrichson said. The free-to-use, online browser-based version of Posit’s tools runs on anything; Dietrichson said he’s tested it successfully on both decade-old computers and cellphones – though he doesn’t recommend using it on a cellphone!</p>
<p>On language barriers, he pointed out that learning to code in R and Python can be challenging when English isn’t your first language – if you don’t have semantic access to function names, for example, there will be a steeper learning curve for students.</p>
<p>Dietrichson also has to deal with the problem of “arithmaphobia” among some of the liberal arts students he teaches. This has necessitated a reshuffling of the typical statistics curriculum, he said, in order to make it easier for students to access. But the work is worth it, Dietrichson explained: many of his students want to work in careers like journalism, and he believes that “journalists should be statistically literate.”</p>
</section>
<section id="dynamic-interactions-empowering-educators-and-researchers-with-interactive-quarto-documents-using-webr" class="level3">
<h3 class="anchored" data-anchor-id="dynamic-interactions-empowering-educators-and-researchers-with-interactive-quarto-documents-using-webr">Dynamic Interactions: Empowering Educators and Researchers with Interactive Quarto Documents Using webR</h3>
<p>Some of my favourite sessions at posit::conf(2023) were about <a href="https://quarto.org/">Quarto</a>. Understandable, really, when you consider that we used it to build this very site! Albert Rapp has described Quarto as a <a href="https://albert-rapp.de/posts/16_html_css_for_r/16_html_css_for_r.html">web dev gateway drug</a>, and I’d agree with him:</p>
<blockquote class="blockquote">
<p>Quarto is a powerful tool for creating beautiful and interactive documents. I think of it as a gateway drug to web development: While it offers a user-friendly interface for creating documents and blogs, it also allows users to delve into the world of HTML &amp; CSS without even realizing it.</p>
</blockquote>
<p>I spoke a bit about my own journey into web dev in one of the Quarto sessions at posit::conf, but what I loved most about these sessions was learning about all the cool new things I’ve yet to discover and try out. For example, <a href="https://thecoatlessprofessor.com/about/">James Balamuta</a>’s talk and demonstration of building interactive code cells into Quarto webpages was an eye-opener!</p>
<p>Since returning from Chicago I’ve tested out this functionality and added Balamuta’s example here. First run the code that’s already in the code block but also edit it to try out your own examples.</p>
<button class="btn btn-default btn-webr" disabled="" type="button" id="webr-run-button-1">Loading
  webR...</button>
<div id="webr-editor-1"></div>
<div id="webr-code-output-1" aria-live="assertive">
  <pre style="visibility: hidden"></pre>
</div>
<script type="module">
  // Retrieve webR code cell information
  const runButton = document.getElementById("webr-run-button-1");
  const outputDiv = document.getElementById("webr-code-output-1");
  const editorDiv = document.getElementById("webr-editor-1");

  // Add a light grey outline around the code editor
  editorDiv.style.border = "1px solid #eee";

  // Load the Monaco Editor and create an instance
  let editor;
  require(['vs/editor/editor.main'], function () {
    editor = monaco.editor.create(editorDiv, {
      value: `fit = lm(mpg ~ am, data = mtcars)
summary(fit)`,
      language: 'r',
      theme: 'vs-light',
      automaticLayout: true,           // TODO: Could be problematic for slide decks
      scrollBeyondLastLine: false,
      minimap: {
        enabled: false
      },
      fontSize: '17.5rem',               // Bootstrap is 1 rem
      renderLineHighlight: "none",     // Disable current line highlighting
      hideCursorInOverviewRuler: true  // Remove cursor indictor in right hand side scroll bar
    });

    // Dynamically modify the height of the editor window if new lines are added.
    let ignoreEvent = false;
    const updateHeight = () => {
      const contentHeight = editor.getContentHeight();
      // We're avoiding a width change
      //editorDiv.style.width = `${width}px`;
      editorDiv.style.height = `${contentHeight}px`;
      try {
        ignoreEvent = true;

        // The key to resizing is this call
        editor.layout();
      } finally {
        ignoreEvent = false;
      }
    };

    // Helper function to check if selected text is empty
    function isEmptyCodeText(selectedCodeText) {
      return (selectedCodeText === null || selectedCodeText === undefined || selectedCodeText === "");
    }

    // Registry of keyboard shortcuts that should be re-added to each editor window
    // when focus changes.
    const addWebRKeyboardShortCutCommands = () => {
      // Add a keydown event listener for Shift+Enter to run all code in cell
      editor.addCommand(monaco.KeyMod.Shift | monaco.KeyCode.Enter, () => {

        // Retrieve all text inside the editor
        executeCode(editor.getValue());
      });

      // Add a keydown event listener for CMD/Ctrl+Enter to run selected code
      editor.addCommand(monaco.KeyMod.CtrlCmd | monaco.KeyCode.Enter, () => {

        // Get the selected text from the editor
        const selectedText = editor.getModel().getValueInRange(editor.getSelection());
        // Check if no code is selected
        if (isEmptyCodeText(selectedText)) {
          // Obtain the current cursor position
          let currentPosition = editor.getPosition();
          // Retrieve the current line content
          let currentLine = editor.getModel().getLineContent(currentPosition.lineNumber);

          // Propose a new position to move the cursor to
          let newPosition = new monaco.Position(currentPosition.lineNumber + 1, 1);

          // Check if the new position is beyond the last line of the editor
          if (newPosition.lineNumber > editor.getModel().getLineCount()) {
            // Add a new line at the end of the editor
            editor.executeEdits("addNewLine", [{
            range: new monaco.Range(newPosition.lineNumber, 1, newPosition.lineNumber, 1),
            text: "\n", 
            forceMoveMarkers: true,
            }]);
          }
          
          // Run the entire line of code.
          executeCode(currentLine);

          // Move cursor to new position
          editor.setPosition(newPosition);
        } else {
          // Code to run when Ctrl+Enter is pressed with selected code
          executeCode(selectedText);
        }
      });
    }

    // Register an on focus event handler for when a code cell is selected to update
    // what keyboard shortcut commands should work.
    // This is a workaround to fix a regression that happened with multiple
    // editor windows since Monaco 0.32.0 
    // https://github.com/microsoft/monaco-editor/issues/2947
    editor.onDidFocusEditorText(addWebRKeyboardShortCutCommands);

    // Register an on change event for when new code is added to the editor window
    editor.onDidContentSizeChange(updateHeight);

    // Manually re-update height to account for the content we inserted into the call
    updateHeight();
  });

  // Function to execute the code (accepts code as an argument)
  async function executeCode(codeToRun) {
    // Disable run button for code cell active
    runButton.disabled = true;

    // Create a canvas variable for graphics
    let canvas = undefined;

    // Initialize webR
    await globalThis.webR.init();

    // Setup a webR canvas by making a namespace call into the {webr} package
    await webR.evalRVoid("webr::canvas(width=504, height=360)");

    // Capture output data from evaluating the code
    const result = await webRCodeShelter.captureR(codeToRun, {
      withAutoprint: true,
      captureStreams: true,
      captureConditions: false//,
      // env: webR.objs.emptyEnv, // maintain a global environment for webR v0.2.0
    });

    // Start attempting to parse the result data
    try {

      // Stop creating images
      await webR.evalRVoid("dev.off()");

      // Merge output streams of STDOUT and STDErr (messages and errors are combined.)
      const out = result.output.filter(
        evt => evt.type == "stdout" || evt.type == "stderr"
      ).map((evt) => evt.data).join("\n");

      // Clean the state
      const msgs = await webR.flush();

      // Output each image stored
      msgs.forEach(msg => {
        // Determine if old canvas can be used or a new canvas is required.
        if (msg.type === 'canvas'){
          // Add image to the current canvas
          if (msg.data.event === 'canvasImage') {
            canvas.getContext('2d').drawImage(msg.data.image, 0, 0);
          } else if (msg.data.event === 'canvasNewPage') {
            // Generate a new canvas element
            canvas = document.createElement("canvas");
            canvas.setAttribute("width", 2 * 504);
            canvas.setAttribute("height", 2 * 360);
            canvas.style.width = "700px";
            canvas.style.display = "block";
            canvas.style.margin = "auto";
          }
        }
      });

      // Nullify the outputDiv of content
      outputDiv.innerHTML = "";

      // Design an output object for messages
      const pre = document.createElement("pre");
      if (/\S/.test(out)) {
        // Display results as text
        const code = document.createElement("code");
        code.innerText = out;
        pre.appendChild(code);
      } else {
        // If nothing is present, hide the element.
        pre.style.visibility = "hidden";
      }
      outputDiv.appendChild(pre);

      // Place the graphics on the canvas
      if (canvas) {
        const p = document.createElement("p");
        p.appendChild(canvas);
        outputDiv.appendChild(p);
      }
    } finally {
      // Clean up the remaining code
      webRCodeShelter.purge();
      runButton.disabled = false;
    }
  }

  // Add a click event listener to the run button
  runButton.onclick = function () {
    executeCode(editor.getValue());
  };
</script>
<p>Visit the <a href="https://quarto-webr.thecoatlessprofessor.com/">quarto-webr website</a> for details on how to make full use of this capability. Once you’re up to speed, why not <a href="https://realworlddatascience.net/contributor-docs/contributor-guidelines.html">contribute a webR-enabled article for Real World Data Science</a>?</p>
<!-- ### Talk title
Add write-up here

*Add your name and affiliation here* -->
</section>
</section>
<section id="wednesday-september-20" class="level2">
<h2 class="anchored" data-anchor-id="wednesday-september-20">Wednesday, September 20</h2>
<section id="r-not-only-in-production" class="level3">
<h3 class="anchored" data-anchor-id="r-not-only-in-production">R Not Only In Production</h3>
<p>Kara Woo, senior data science engineer at InsightRX, began her Wednesday morning keynote with a rousing description of posit::conf(2023) being like a “great community garden” where things are being cultivated and shared for the benefit of all. This is an important feeling, Woo said, because it doesn’t always feel like that in our day jobs. Data scientists can feel siloed, not able to share ideas with like-minded people, and facing resistance from people who say “R can’t do that, R isn’t a real programming language” – a comment that elicited a groan of weary familiarity from sections of the crowd.</p>
<p>But as Woo went on to explain, “it is possible to build quality software in R” and “it is possible to have an organisation where the strengths of R and the people who use it influence the organisation as a whole.”</p>
<p>Woo was speaking from her experience at InsightRX, a precision medicine company, which makes software for clinicians to inform individualised dosing decisions for patients. Through a tool called Nova, clinicians feed in data about a patient’s unique characteristics, which is then passed to R for analysis, which then returns dosage recommendations to Nova.</p>
<p>In InsightRX, R has also been used to solve problems that are not strictly data science problems. Woo gave the example of working with a colleague to write an R package to identify data labels that have been changed and rollout translations for those labels in multiple languages for software users in different parts of the world.</p>
<p>“Our mindset of R being a first-class language empowers us to solve problems,” said Woo.</p>
</section>
<section id="its-abstractions-all-the-way-down" class="level3">
<h3 class="anchored" data-anchor-id="its-abstractions-all-the-way-down">It’s Abstractions All the Way Down…</h3>
<p>The second of the morning keynotes on day two of posit::conf(2023) was by JD Long, vice president of risk management at RenaissanceRe.</p>
<p>During Long’s insightful – and frequently very funny – talk, this slide appeared:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/images/jd-slide.PNG" class="img-fluid figure-img" alt="JD Long's slide reads: 'The single biggest business value derived from the data science movement in the last 13 years is making it legitimate to code outside of IT roles.'"></p>
<figcaption class="figure-caption">JD Long’s assertion #1.</figcaption>
</figure>
</div>
<p>Do you agree with Long’s assertion? If you don’t, what <em>is</em> the single biggest business value that’s been derived from the data science movement? Share your thoughts in the comments below.</p>
</section>
<section id="its-all-about-perspective-making-a-case-for-generative-art" class="level3">
<h3 class="anchored" data-anchor-id="its-all-about-perspective-making-a-case-for-generative-art">It’s All About Perspective: Making a Case for Generative Art</h3>
<p>Hobbies are important, right? They are a way to relax, to unwind. But also a great opportunity to learn things that might come in handy professionally. At least, that is the experience of Meghan Santiago Harris, a data scientist in the Prostate Cancer Clinical Trials Consortium at Memorial Sloan Kettering.</p>
<p>Harris shared with delegates her journey into generative art, and how skills acquired using ggplot2 for “fun stuff” had a positive impact on her work.</p>
<p>She first defined generative art as artwork created through a program in any language or interface, so long as the program itself executes the generation of the art. To make generative art, Harris said, you just need data and the ability to “think outside the grid” of your favourite graphics software or package. Harris’s tool of choice is ggplot2, but any will do: “If a tool lets you plot data, it will let you make art,” she said.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/images/gen-art.png" class="img-fluid figure-img" alt="The generative art image shows a setting sun on a red background, with the silhouettes of tall buildings in the foreground."></p>
<figcaption class="figure-caption">A slide from Meghan Santiago Harris’s talk, with an example of how to create an image of the sun setting on a city using lines of R code.</figcaption>
</figure>
</div>
<p>Harris’s passion for generative art bloomed during a recent period of maternity leave. She was coding for fun but also deepening her understanding and expertise in areas like code iteration, development and communication. And, in August, Harris published an R package called <a href="https://meghansaha.github.io/artpack/">artpack</a>, which is now available on CRAN and designed “to help generative artists of all levels create generative art in R.”</p>
<p>Generative art was a motivation to learn and do more, Harris said, and doing something she loved helped make programming and data science more digestible.</p>
</section>
<section id="how-the-r-for-data-science-r4ds-online-learning-community-made-me-a-better-student" class="level3">
<h3 class="anchored" data-anchor-id="how-the-r-for-data-science-r4ds-online-learning-community-made-me-a-better-student">How the R for Data Science (R4DS) Online Learning Community Made Me a Better Student</h3>
<p>Following straight after Meghan Santiago Harris was Lydia Gibson, a data scientist from Intel, with an inspiring talk about her route into data science. Gibson began by explaining how, when younger, “I wanted to be a fashion designer.” For her high school prom, Gibson even designed her own dress, which her grandmother made for her.</p>
<p>In 2011, Gibson earned a BS in economics and worked in retail customer service and state and local government for a time before deciding to return to school to do a Masters in statistics in 2021. She had “no experience of programming” when she made this decision, but soon learned that R is “a necessary evil if you have to go back to school to do statistics.”</p>
<p>Gibson told delegates that discovering data visualisation was what made her care about R. She could “feed [her] need for creativity” while also learning about things that were required for her course.</p>
<p>And it was the <a href="https://rfordatasci.com/">R for Data Science (R4DS) Online Learning Community</a> that helped take her learning to the next level. Gibson described R4DS as “an amazing, welcoming learning environment where beginners and advanced folks alike can come together to learn not only R but data science as a whole.”</p>
<p>“Being surrounded by folks more advanced than you is a gift, not a curse,” she said, and she urged delegates to find what they are passionate about and explore its depths.</p>
</section>
<section id="github-copilot-integration-with-rstudio-its-finally-here" class="level3">
<h3 class="anchored" data-anchor-id="github-copilot-integration-with-rstudio-its-finally-here">GitHub Copilot integration with RStudio, it’s finally here!</h3>
<p>Tom Mock, product manager for Posit Workbench and RStudio, had a full house for his talk about the upcoming integration of <a href="https://github.com/features/copilot">GitHub’s code Copilot product</a> into RStudio. Copilot, Mock said, is an AI pair programmer that offers autocomplete-style suggestions for code – and this integration is one of the most popular requested features among RStudio users on GitHub.</p>
<p>To make use of the integration, you’ll need a Copilot subscription from GitHub. But more than that, Mock said, users will need to experiment to learn how to get the most out of the “generative [AI] loop.”</p>
<p>See Mock’s slide deck below for more details.</p>
<iframe width="100%" height="563px" src="https://colorado.posit.co/rsc/rstudio-copilot/#/TitleSlide"></iframe>
<!-- ### Talk title
Add write-up here

*Add your name and affiliation here* -->
<div class="callout callout-style-simple callout-note" style="margin-top:0">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>posit::conf(2023) is over, but this blog remains open for contributions. If you want to share personal highlights or reflections on your time at conference: 1. Fork <a href="https://github.com/realworlddatascience/realworlddatascience.github.io">our repo</a>, 2. update <a href="https://github.com/realworlddatascience/realworlddatascience.github.io/blob/positconf-blog/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.qmd">this file</a> in the <code>positconf-blog</code> branch (or create a new branch of your own), and 3. make a pull request! You can also <a href="https://realworlddatascience.net/contact.html">email contributions</a>.</p>
</div>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Live from Chicago: Real World Data Science at posit::conf(2023).” Real World Data Science, September 19, 2023, updated September 27, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>Conferences</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.html</guid>
  <pubDate>Wed, 27 Sep 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/images/chicago-theatre.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘What if we try to bring R to the classroom? That was our wacky idea’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/09/25/rgirls-interview.html</link>
  <description><![CDATA[ 




<p><a href="https://rgirls.org.uk/">R-Girls</a> is an exciting new project launched by Green Oak Academy, a faith-based independent secondary school for girls based in Birmingham, England. The project aims to promote the use of R in schools through the development and delivery of R-based lesson plans for a range of subjects.</p>
<p>To find out more about R-Girls, its origins and ambitions, Real World Data Science met with <strong>Mohammed Mohammed</strong>, a governor at Green Oak Academy, principal consultant for the National Health Service (NHS) Midlands and Lancashire Strategy Unit, and a founder of the NHS-R Community.</p>
<section id="what-inspired-r-girls" class="level2">
<h2 class="anchored" data-anchor-id="what-inspired-r-girls">What inspired R-Girls?</h2>
<p>“It was the confluence of a few different things. Firstly, Dr Razia Ghani, head teacher at Green Oak Academy, has a PhD in mathematics from the University of Birmingham, has some experience of doing statistics in the pharmaceutical sector, and teaches mathematics. That meant we had a lot of shared capital in our background and thinking about things.</p>
<p>“When I became a governor of the school, the staff were doing progress reports for pupils, and I wrote a little programme in R to help them with this. So, that was one of the early uses of R in the school.</p>
<p>“I know R because of my experience in academia, and I had previously put in a proposal to the Health Foundation to introduce R to the National Health Service. The Health Foundation agreed to that, they funded it, and we now have an <a href="https://nhsrcommunity.com/">NHS-R Community</a> which is basically promoting the use of R in the health service.</p>
<p>“And so I said to the head teacher, ‘What about if we try to bring R to the classroom?’ That was our wacky idea, and we put in a bid to the <a href="https://www.r-consortium.org/">R Consortium</a>, and they gave us seed funding, and that’s how we got started.”</p>
</section>
<section id="what-are-the-aims-of-the-project" class="level2">
<h2 class="anchored" data-anchor-id="what-are-the-aims-of-the-project">What are the aims of the project?</h2>
<p>“The aims of the project are threefold:</p>
<ul>
<li>To promote the use of R in secondary schools for girls.</li>
<li>To inspire teachers to incorporate R into their lessons.</li>
<li>To enable students to experience the joy of R.</li>
</ul>
<p>“On our website, we have prepared 10 or so oven-ready lesson plans – they have to be oven-ready for any teacher to ever think about using them; they have to be polished, ready, and easy to use. As well as our website, we have a <a href="https://twitter.com/R_Girls_School">Twitter</a> page and a community on <a href="https://r-girls.slack.com/">Slack</a>.</p>
<p>“One key thing to note is that we didn’t set out to teach programming. The history of computer science in our school is that computer science was really not liked at all by the girls. They wouldn’t choose it as a subject to pursue further. So, we decided to use R to support other subjects. This was a key strategic decision, really.</p>
<p>“People have attempted to develop lesson plans to teach Python, but that would be a non-starter in my school because (a) there isn’t much curriculum space, and (b) no teacher is enthusiastic enough to take on that activity and learn Python and become the Python expert in class. Whereas using R as a tool to facilitate learning in other subjects just opens up the whole world of data science in a way that is so much more accessible and appealing. People may say we’re really not teaching students how to code – but we’re not putting them off coding either!”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/09/25/images/screenshot-1.png" class="img-fluid figure-img" alt="Screenshot of R-Girls website, showing a few taster lessons for setting up and using R in class."></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p>The R-Girls website includes <a href="https://rgirls.org.uk/getting_started.html">tutorials on how to get started using R in school</a>.</p>
</div>
</section>
<section id="how-is-r-being-used-in-different-subjects-in-school" class="level2">
<h2 class="anchored" data-anchor-id="how-is-r-being-used-in-different-subjects-in-school">How is R being used in different subjects in school?</h2>
<p>“In maths lessons we do things like generate sequences, plot graphs, do Pythagoras’ Theorem. In geography, we have mapping lessons and lessons on plotting rainfall data from Australian cities.</p>
<p>“Our lesson plans are set up in R Markdown, but the key thing from the teacher’s point of view is that they recognise the structure: What stage is it in terms of the curriculum? What are the objectives, the success criteria and keywords? Typically, we’ll show a worked example and then give the students an exercise to draw a different graph, say – they learn to tweak existing code rather than start from scratch.</p>
<p>“We first taught them how to use R using R Markdown – a way of writing script and code and data all together in one document. And after the first lesson, we were absolutely astonished. This is feedback from one of the girls: ‘Today’s lesson was very interesting and exciting. I’ve learnt a lot of new things about coding and found a new hobby…’ From subsequent lessons, here’s more feedback: ‘Programming and coding was actually quite fun… It was a great feeling knowing that I was able to code a whole bar chart all by myself…’</p>
<p>“A new thing that we’ve done recently is that one of the teachers has been inspired and has learned how to build a website in R, and she’s then decided to teach the Year 9 girls how to build their own websites. One quote from a student was: ‘I learnt how to make a website; I feel like an independent woman now.’ Another said: ‘This was very stressful. But it will look good on my CV.’</p>
<p>“One of the key challenges we face in education is that teachers are very stressed, and Covid didn’t help. Workloads are a massive issue in teaching, and of course that’s the same for our teachers. So, we had to make sure that whatever we do does not feel like it’s adding to the workload. One of the things we do is to use R in the cloud, so there is no installation and debugging on local computers. We try to minimise the pain, really.”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/09/25/images/screenshot-2.png" class="img-fluid figure-img" alt="Screenshot of R-Girls website, showing two geography lessons: one on plotting rainfall data from Australian cities, and one on mapping."></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p>Lesson plans developed so far include ones for maths, science, and geography classes (pictured).</p>
</div>
</section>
<section id="how-do-you-want-to-see-the-r-girls-project-grow-and-what-will-success-look-like-for-you" class="level2">
<h2 class="anchored" data-anchor-id="how-do-you-want-to-see-the-r-girls-project-grow-and-what-will-success-look-like-for-you">How do you want to see the R-Girls project grow, and what will success look like for you?</h2>
<p>“It would be really nice to see that girls introduced to R through the R-Girls project felt there was a natural progression for them to join the <a href="https://rladies.org/">R-Ladies Group</a>, so that data science becomes part of their future aspirations.</p>
<p>“The second thing is that I’d like to set up an annual conference for girls at school, which would be online and which becomes part of the extracurricular landscape, so that any girl interested in R can join.</p>
<p>“We’d also love to see other schools, especially girls schools, joining the project – and joining the project just means agreeing to take the lessons we have and trying them in class. We would welcome other schools contributing additional lessons to the library of lessons, so that it becomes an open community resource that anybody can use. There’s nothing in this which is designed to make it explicitly local to an English independent school in Birmingham!</p>
<p>“We are keen to hear from others, so please reach out to us on <a href="mailto:rgirlsschool@gmail.com">rgirlsschool@gmail.com</a>.”</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/09/25/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/09/25/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘What if we try to bring R to the classroom? That was our wacky idea’” Real World Data Science, September 25, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/09/25/rgirls-interview.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>R</category>
  <category>Education</category>
  <category>Outreach</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/09/25/rgirls-interview.html</guid>
  <pubDate>Mon, 25 Sep 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/09/25/images/rgirls.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘Pseudo data science’ and other pitfalls: lessons from the UK’s stats regulator on how not to be misleading</title>
  <dc:creator>Ed Humpherson</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/09/18/pseudo-data-science.html</link>
  <description><![CDATA[ 




<p>A typical article on data science hails new data sources, new tools, and new visualisations, and thereby supports the case for the value of data science.</p>
<p>But this article takes a different angle: it talks about potential pitfalls that can face data scientists. It is based on our work as the Office for Statistics Regulation (OSR), the UK’s regulator for official statistics. We see lots of great work done by statisticians in government. But we also see some of the challenges they face – and data scientists are also likely to encounter the same challenges.</p>
<p>The problems arise from the fact that neither statisticians nor data scientists do their work in isolation. The work usually takes places within organisations – businesses, government bodies, think tanks, academic institutions – and as a result, the statisticians and/or data scientists are not the only players who get to influence how data science is presented and used.</p>
<p>What are the pitfalls we see in our work as regulator?</p>
<section id="pseudo-data-science" class="level2">
<h2 class="anchored" data-anchor-id="pseudo-data-science">Pseudo data science</h2>
<p>The first type of pitfall is pseudo data science.</p>
<p>Pseudo data science is a term we use to describe attempts to pass off crude work as being more data science-y than it really is. That reflects a sense in public life that data science is new, innovative, somehow the Future. In this context, people who are not data scientists can be tempted to dress themselves up in the clothes of data science to enhance their credibility. This dressing up is usually well-intentioned – communications professionals who want to illuminate and explain complex issues in an engaging way.</p>
<p>The trouble is, it can sometimes backfire. In our work at OSR, we have over the last year seen several examples where organisations have sought to publish visualisations that look like they are the product of in-depth data analysis – when in fact they have been drawn by communications staff using graphic design packages. Examples include <a href="https://osr.statisticsauthority.gov.uk/correspondence/ed-humpherson-to-david-pares-treasury-inflation-infographic/">inflation</a>, <a href="https://uksa.statisticsauthority.gov.uk/correspondence/response-from-sir-robert-chote-to-andrew-gwynne-mp-dhsc-chart-on-nurses-pay/">nurses pay</a>, and <a href="https://uksa.statisticsauthority.gov.uk/correspondence/letter-to-rachel-reeves-mp-gdp-growth-chart/">comparisons of UK economic performance with other countries</a>. To be fair, whenever we have pointed out issues like this, organisations have responded well, putting in place new procedures to ensure that analysts sign off on this kind of visualisations. Nevertheless, we suspect that the temptations to indulge in pseudo data science will remain strong – and we may need to intervene on similar cases in future.</p>
</section>
<section id="unintelligent-transparency" class="level2">
<h2 class="anchored" data-anchor-id="unintelligent-transparency">Unintelligent transparency</h2>
<p>The second pitfall is a failure of <a href="https://osr.statisticsauthority.gov.uk/publication/regulatory-guidance-on-intelligent-transparency/">intelligent transparency</a>.</p>
<p>There is a raw form of transparency – quoting a single number (a naked number we call it); or dumping data out into the public domain with no explanation. This is not intelligent transparency. The latter involves being clear where data come from, what their source is, and making underlying data available so that others can understand and verify the statements that are being made. Raw transparency and naked numbers treat an audience with little respect; intelligent transparency helps the audience understand and appreciate what sits behind high level claims.</p>
<p>Data science outputs can sometimes seem to communications teams easy to cherry pick for the most attractive number. Again, like pseudo data science, this reflects largely good intentions – to communicate complex things through ideas. But it becomes easy for a single, unsupported number to be used and reused until it loses most of its meaning. We call this weaponization of data, and it is the antithesis of intelligent transparency. And there is a lot of it about – for example the way in which the former Prime Minister of the UK talked repeatedly about <a href="https://uksa.statisticsauthority.gov.uk/correspondence/sir-david-norgrove-to-prime-minister-employment-statistics/">employment</a>; or <a href="https://uksa.statisticsauthority.gov.uk/correspondence/response-from-sir-robert-chote-to-alex-cole-hamilton-msp-scottish-renewable-energy-statistics/">claims</a> about Scotland’s capacity for <a href="https://uksa.statisticsauthority.gov.uk/correspondence/sir-robert-chote-to-stephen-kerr-msp-renewable-energy/">renewable energy</a>. These examples indicate the pathology of weaponization that can impact data science outputs. They also act as a reminder that data scientists can counter weaponization of their own outputs by delivering engaging and insightful communication.</p>
</section>
<section id="context-collapse" class="level2">
<h2 class="anchored" data-anchor-id="context-collapse">Context collapse</h2>
<p>The third type of pitfall surrounds context collapse.</p>
<p>This idea comes from the work of the philosopher <a href="http://lucymcdonald.co.uk/wp-content/uploads/2023/02/Context-Collapse-Online-LMcDonald.pdf">Lucy McDonald</a> (who in turn has built on the ideas of <a href="https://www.danah.org/">danah boyd</a>). What is context collapse? Imagine a swimming pool – with neat divisions of the pool into different lanes. All is clearly labelled – fast, medium, slow – for lane swimmers, who are in turn separated from the splash area for families and the deep end for divers. Removing the lanes, and thus taking away any signposting, increases the likelihood for things to go wrong. The fast swimmers doing front crawl clash with the slower breaststroke swimmers; both are constantly having to avoid the families with young children; and all need to watch for the periodic big splashes created by the divers. This is the online communication environment, in which formerly private and casual statements can go viral; in which a brief statement in a media environment can be picked up on and circulated many times; and in which some bad actors (the divers) may wish to disrupt deliberately the debate by breaking all the rules.</p>
<p>How can this affect data science? It happens when individual bits of data are taken from their context, and used in service of a different, and bigger, argument. A good example is data on Covid vaccinations. Here, UK organisations like the Office for National Statistics and the UK Health Security Agency published comprehensive data in good faith about vaccinations and their impact. Some of the underlying data, however, was taken out of the broader context and used in isolation to support criticisms of vaccines – criticisms that the wider evidence base did not support.</p>
<p>The challenge then became how the organisations should respond. At an organisational level, they did not wish to withdraw the data – because that would reduce transparency. Instead they sought to both caveat their data more clearly; and directly rebut the more egregious misuses of the data. In a sense, then, what began as an individual analytical output became part of a broader organisational judgement on positioning in the face of misinformation.</p>
<p>It is fair to say that, against this third pitfall, there is not yet a clear consensus on how to address it. Practice is emerging all the time and we at OSR continue to support producers of data as they grapple with it.</p>
<p>There are other potential pitfalls to using data science. But what unites these three – pseudo data science; unintelligent transparency; and context collapse – is that they relate to situations where data science rubs up against broader organisational dynamics, around communications, presentation and organisational strategy.</p>
<p>And the meta-message is this: for data scientists to thrive in organisations, they need to be good at more than data science. They need to be skilled at working alongside and influencing colleagues from other functions. Only through this form of <a href="https://osr.statisticsauthority.gov.uk/analytical-leadership/">data leadership</a> can the pitfalls be dealt with effectively.</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This article is based on a presentation at the <a href="https://www.datascienceforhealthequity.com/">Data Science for Health Equity</a> group in May 2023.</p>
</div>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Ed Humpherson</strong> is head of the Office for Statistics Regulation, which provides independent regulation of all official statistics in the UK. The aim of OSR is to enhance public confidence in the trustworthiness, quality and value of statistics produced by government.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Ed Humpherson
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/posts/2023/09/18/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/posts/2023/09/18/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Humpherson, Ed. 2023. “‘Pseudo data science’ and other pitfalls: lessons from the UK’s stats regulator on how not to be misleading.” Real World Data Science, September 18, 2023. <a href="https://realworlddatascience.net/viewpoints/posts/2023/09/18/pseudo-data-science.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Communication</category>
  <category>Leadership</category>
  <category>Transparency</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/09/18/pseudo-data-science.html</guid>
  <pubDate>Mon, 18 Sep 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/09/18/images/distorted-data.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Contributors: check out the new Real World Data Science template repo on GitHub</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/template.html</link>
  <description><![CDATA[ 




<p>Thinking of contributing to Real World Data Science but not sure how to get started? Help is at hand, thanks to <a href="https://github.com/finnoh">Finn-Ole Höner</a>. The Amsterdam-based business data science student has created <a href="https://github.com/finnoh/RWDS_post_template">a template repository on GitHub</a> that allows anyone to create Real World Data Science content in our house style and format.</p>
<p>In this repository you’ll find two example Quarto (.qmd) documents, which is the main file type we use for generating site content. The “content-brief.qmd” file is a template for developing article ideas to discuss with our site editors, and the “report.qmd” file is a standard article template. Within that article template you’ll find examples of the range of Quarto features that we use, as well as the code you need to make use of them yourself.</p>
<p>These documents can be edited using tools including Visual Studio Code and R Studio. For details on how to work with Quarto documents, see the <a href="https://quarto.org/">Quarto website</a>. Once article drafts are finished they can be rendered into HTML format, and the output files will be displayed in the Real World Data Science style, thanks to the inclusion of our stylesheets in the template repository. This is a great way for contributors to see what their content will look like on Real World Data Science before anything is published.</p>
<p>To get started, head on over to the <a href="https://github.com/finnoh/RWDS_post_template">RWDS_post_template repository</a> and click the “Use this template” button. Also, be sure to <a href="https://realworlddatascience.net/contributor-docs/contributor-guidelines.html">review our contributor guidelines</a> for advice on how to integrate the .qmd templates into the content development and submission workflow.</p>
<p>Huge thanks to Finn-Ole Höner for building this valuable resource for Real World Data Science contributors.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@synkevych?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Roman Synkevych</a> on <a href="https://unsplash.com/photos/UT8LMo-wlyk?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Contributors: check out the new Real World Data Science template repository on GitHub.” Real World Data Science, September 12, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/template.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Call for contributions</category>
  <category>Tools</category>
  <category>Updates</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/template.html</guid>
  <pubDate>Tue, 12 Sep 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/images/roman-synkevych-UT8LMo-wlyk-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>For minorities, biased AI algorithms can damage almost every part of life</title>
  <dc:creator>Arshin Adib-Moghaddam</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/09/06/biased-algorithms.html</link>
  <description><![CDATA[ 




<p>Bad data does not only produce bad outcomes. It can also help to suppress sections of society, for instance vulnerable women and minorities.</p>
<p>This is the argument of <a href="https://www.bloomsbury.com/us/is-artificial-intelligence-racist-9781350374423/">my new book</a> on the relationship between various forms of racism and sexism and artificial intelligence (AI). The problem is acute. Algorithms generally need to be exposed to data – often taken from the internet – in order to improve at whatever they do, such as <a href="https://www.theguardian.com/us-news/2022/may/11/artitifical-intelligence-job-applications-screen-robot-recruiters">screening job applications</a>, or underwriting mortgages.</p>
<p>But the training data often contains many of the biases that exist in the real world. For example, algorithms could learn that most people in a particular job role are male and therefore favour men in job applications. Our data is polluted by a set of myths from the age of <a href="https://en.wikipedia.org/wiki/Age_of_Enlightenment#:%7E:text=The%20Enlightenment%20included%20a%20range,separation%20of%20church%20and%20state.">“enlightenment”</a>, including biases that lead to <a href="https://www.gaytascience.com/transphobic-algorithms/">discrimination based on gender and sexual identity</a>.</p>
<p>Judging from the history in societies where racism has played a role in <a href="https://sk.sagepub.com/books/racism-from-slavery-to-advanced-capitalism">establishing the social and political order</a>, extending privileges to white males –- in Europe, North America and Australia, for instance –- it is simple science to assume that residues of racist discrimination feed into our technology.</p>
<p>In my research for the book, I have documented some prominent examples. Face recognition software <a href="https://www.washingtonpost.com/technology/2019/12/19/federal-study-confirms-racial-bias-many-facial-recognition-systems-casts-doubt-their-expanding-use/">more commonly misidentified black and Asian minorities</a>, leading to false arrests in the US and elsewhere.</p>
<p>Software used in the criminal justice system has predicted that black offenders would have <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">higher recidivism rates</a> than they did. There have been false healthcare decisions. <a href="https://www.science.org/doi/10.1126/science.aax2342">A study found that</a> of the black and white patients assigned the same health risk score by an algorithm used in US health management, the black patients were often sicker than their white counterparts.</p>
<p>This reduced the number of black patients identified for extra care by more than half. Because less money was spent on black patients who have the same level of need as white ones, the algorithm falsely concluded that black patients were healthier than equally sick white patients. Denial of mortgages for minority populations is facilitated by biased data sets. The list goes on.</p>
<section id="machines-dont-lie" class="level2">
<h2 class="anchored" data-anchor-id="machines-dont-lie">Machines don’t lie?</h2>
<p>Such oppressive algorithms intrude on almost every <a href="https://www.newscientist.com/article/mg25033390-200-the-essential-guide-to-the-algorithms-that-run-your-life/">area of our lives</a>. AI is making matters worse, as it is sold to us as essentially unbiased. We are told that machines don’t lie. Therefore, the logic goes, no one is to blame.</p>
<p>This pseudo-objectiveness is central to the AI-hype created by the Silicon Valley tech giants. It is easily discernible from the speeches of Elon Musk, Mark Zuckerberg and Bill Gates, even if now and then they <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">warn us about the projects</a> that they themselves are responsible for.</p>
<p>There are various unaddressed legal and ethical issues at stake. Who is accountable for the mistakes? Could someone claim compensation for an algorithm denying them parole based on their ethnic background in the same way that one might for a toaster that exploded in a kitchen?</p>
<p>The <a href="https://umdearborn.edu/news/ais-mysterious-black-box-problem-explained#:%7E:text=This%20inability%20for%20us%20to,when%20they%20produce%20unwanted%20outcomes.">opaque nature of AI technology</a> poses serious challenges to legal systems which have been built around individual or human accountability. On a more fundamental level, basic human rights are threatened, as legal accountability is blurred by the maze of technology placed between perpetrators and the various forms of discrimination that can be conveniently blamed on the machine.</p>
<p>Racism has always been a systematic strategy to order society. It builds, legitimises and enforces hierarchies between the haves and have nots.</p>
</section>
<section id="ethical-and-legal-vacuum" class="level2">
<h2 class="anchored" data-anchor-id="ethical-and-legal-vacuum">Ethical and legal vacuum</h2>
<p>In such a world, where it’s difficult to disentangle truth and reality from untruth, our privacy needs to be legally protected. The right to privacy and the concomitant ownership of our virtual and real-life data needs to be codified as a human right, not least in order to harvest the real opportunities that good AI harbours for human security.</p>
<p>But as it stands, the innovators are far ahead of us. Technology has outpaced legislation. The ethical and legal vacuum thus created is readily exploited by criminals, as this brave new AI world is largely anarchic.</p>
<p>Blindfolded by the mistakes of the past, we have entered a wild west without any sheriffs to police the violence of the digital world that’s enveloping our everyday lives. The tragedies are already happening on a daily basis.</p>
<p>It is time to counter the ethical, political and social costs with a concerted social movement in support of legislation. The first step is to educate ourselves about what is happening right now, as our lives will never be the same. It is our responsibility to plan the course of action for this new AI future. Only in this way can a good use of AI be codified in local, national and global institutions.</p>
<!-- Below is The Conversation's page counter tag. Please DO NOT REMOVE. -->
<p><img src="https://realworlddatascience.net/viewpoints/posts/2023/09/06/https:/counter.theconversation.com/content/211778/count.gif?distributor=republish-lightbox-basic" alt="The Conversation" width="1" height="1" style="border: none !important; box-shadow: none !important; margin: 0 !important; max-height: 1px !important; max-width: 1px !important; min-height: 1px !important; min-width: 1px !important; opacity: 0 !important; outline: none !important; padding: 0 !important" referrerpolicy="no-referrer-when-downgrade"></p>
<!-- End of code. If you don't see any code above, please get new code from the Advanced tab after you click the republish button. The page counter does not collect any personal data. More info: https://theconversation.com/republishing-guidelines -->
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<a href="https://theconversation.com/profiles/arshin-adib-moghaddam-211780">Arshin Adib-Moghaddam</a> is professor in global thought and comparative philosophies, <a href="https://theconversation.com/institutions/soas-university-of-london-975">SOAS, University of London</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-12">
<dl>
<dt>Copyright and licence</dt>
<dd>
This article is republished from <a href="https://theconversation.com">The Conversation</a> under a Creative Commons license. Read the <a href="https://theconversation.com/for-minorities-biased-ai-algorithms-can-damage-almost-every-part-of-life-211778">original article</a>.
</dd>
<dd>
<p>Image by <a href="http://alanwarburton.co.uk/">Alan Warburton</a> / © BBC / <a href="https://www.betterimagesofai.org">Better Images of AI</a> / Quantified Human / <a href="https://creativecommons.org/licenses/by/4.0/">Licenced by CC-BY 4.0</a>.</p>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>AI ethics</category>
  <category>Bias</category>
  <category>Ethics</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/09/06/biased-algorithms.html</guid>
  <pubDate>Wed, 06 Sep 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/09/06/images/AlanWarburton-QuantifiedHuman-991x724.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>RSS Conference preview: Evaluating AI, machine learning, and data visualisation</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/rss-conference.html</link>
  <description><![CDATA[ 




<p>The Royal Statistical Society International Conference takes place in Harrogate, England, this September (Monday 4 to Thursday 7). Real World Data Science will be in attendance, and we’ve helped organise a couple of sessions we’d like to tell you about.</p>
<section id="evaluating-ai-how-data-science-and-statistics-can-shape-the-uks-ai-strategy" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-ai-how-data-science-and-statistics-can-shape-the-uks-ai-strategy">Evaluating AI: How data science and statistics can shape the UK’s AI strategy</h3>
<p><strong>Date:</strong> 6 September <strong>Time:</strong> 9:00 am - 10:20 am <strong>Room:</strong> Auditorium (moved from Queens Suite 8)</p>
<p>The launch of ChatGPT less than a year ago is a milestone moment in the story of artificial intelligence. Overnight, large language models were transformed from research projects into consumer products, now used by millions each month. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/code-interpreter.html">The capabilities are impressive</a>, <a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">the productivity gains undeniable</a>. But, what of the downsides? These are issues <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/04/28/stephanie-hare.html">societies, governments, and individuals are now starting to reckon with</a>.</p>
<p>In March 2023, <a href="https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper">the UK government published a white paper promising a “pro-innovation approach” to AI regulation</a>, while also acknowledging the risks AI poses to “people’s privacy, their human rights or their safety” and “concerns about the fairness of using AI tools to make decisions which impact people’s lives”. <a href="https://rss.org.uk/RSS/media/File-library/Policy/2023/RSS-AI-white-paper-response-v2-2.pdf">The Royal Statistical Society, in response, has called for investment in a centre for AI evaluation methodology</a>, arguing that users of AI systems should be able to judge the trustworthiness of claims made by AI companies as well as the outputs of their systems.</p>
<p>What should AI evaluation look like? How will it work in practice? What metrics are most important, and – crucially – who gets to decide this? Join us for <a href="https://virtual.oxfordabstracts.com/#/event/4019/program?session=66677&amp;s=700">a special panel debate at the RSS International Conference</a>, where these questions, and more, will be discussed.</p>
</section>
<section id="best-practices-for-data-visualisation-how-to-make-data-outputs-more-readable-accessible-and-impactful" class="level3">
<h3 class="anchored" data-anchor-id="best-practices-for-data-visualisation-how-to-make-data-outputs-more-readable-accessible-and-impactful">Best Practices for Data Visualisation: How to make data outputs more readable, accessible, and impactful</h3>
<p><strong>Date:</strong> 5 September <strong>Time:</strong> 11:40 am - 1:00 pm <strong>Room:</strong> Auditorium</p>
<p>The Royal Statistical Society (RSS) has published a new guide, “<a href="https://royal-statistical-society.github.io/datavisguide/">Best Practices for Data Visualisation</a>”, containing insights, advice, and examples (with code) to make data outputs more readable, accessible, and impactful. The guide is written primarily for contributors to Royal Statistical Society publications – including <em>Significance</em> magazine, the <em>Journal of the Royal Statistical Society Series A</em>, and Real World Data Science – but the information and advice within is also of broad relevance and use for any data visualisation task.</p>
<p>In the first half of this conference session, authors Andreas Krause, <a href="https://nrennie.rbind.io/">Nicola Rennie</a>, and Brian Tarran will introduce the guide and its key recommendations, and there will be a short demo of how to use the new <a href="https://github.com/nrennie/RSSthemes">{RSSthemes} R package</a>. For the second half of the session, attendees will be invited to share feedback with the authors, propose ideas, and start developing new and expanded sections of the guide. Attendees will be shown how to work with the guide’s source files and collaborate via GitHub, so feel free to bring along a laptop and become a contributor!</p>
<p>For more information, see <a href="https://royal-statistical-society.github.io/datavisguide/">rss.org.uk/datavisguide</a> and the <a href="https://virtual.oxfordabstracts.com/#/event/4019/program?session=65937&amp;s=0">RSS Conference website</a>.</p>
</section>
<section id="discussion-meeting-probabilistic-and-statistical-aspects-of-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="discussion-meeting-probabilistic-and-statistical-aspects-of-machine-learning">Discussion Meeting: Probabilistic and statistical aspects of machine learning</h3>
<p><strong>Date:</strong> 6 September <strong>Time:</strong> 5:00pm - 7:00 pm <strong>Room:</strong> Auditorium</p>
<p>We haven’t helped organise this session, but we are interested to see it. Two papers will be presented for discussion and debate. Paper 1 is “Automatic Change-Point Detection in Time Series via Deep Learning” by Jie Li, Paul Fearnhead, Piotr Fryzlewicz, and Tengyao Wang, while Paper 2 is “From Denoising Diffusions to Denoising Markov Models” by Joe Benton, Yuyang Shi, Valentin De Bortoli, George Deligiannidis, and Arnaud Doucet. Preprints of both papers are available now via the <a href="https://rss.org.uk/training-events/events/discussion-papers/">RSS Discussion Meetings webpage</a>, and you can also hear more about the session in this interview with Adam Sykulski, RSS Discussion Papers editor.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/1UL1H21v-Q0?si=WPftzqltawRknPPM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://flic.kr/p/YzNWJw">jcw1967</a>, licenced under a Creative Commons Attribution 2.0 Generic (CC BY 2.0) <a href="https://creativecommons.org/licenses/by/2.0/">licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “RSS Conference preview: Evaluating AI, machine learning, and data visualisation.” Real World Data Science, August 24, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/rss-conference.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Machine learning</category>
  <category>Data visualisation</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/rss-conference.html</guid>
  <pubDate>Thu, 24 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/images/harrogate-conference-centre.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Food for Thought: Third place winners – Loyola Marymount</title>
  <dc:creator>Yifan Hu and Mandy Korpusik</dc:creator>
  <link>https://realworlddatascience.net/case-studies/posts/2023/08/21/05-third-place-winners.html</link>
  <description><![CDATA[ 




<p>Undergraduate student Yifan (Rosetta) Hu was responsible for writing the Python script that pre-processes the 2015–2016 UPC, EC, and PPC data for training neural network models. Her script randomly sampled five negative EC descriptions for every positive match between a UPC and EC code. Professor Mandy Korpusik performed the remaining work, including setting up the environment, training the BERT model, and evaluation. Hu spent roughly 10 hours on the competition, and Korpusik spent roughly 40 hours of work (and many additional hours running and monitoring the training and testing scripts).</p>
<section id="our-perspective-on-the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="our-perspective-on-the-challenge">Our perspective on the challenge</h2>
<p>The goal of this challenge is to use machine learning and natural language processing (NLP) to link language-based entries in the IRI and FNDDS databases. Our proposed approach is based on our prior work using deep learning models to map users’ natural language meal descriptions to the FNDDS database <span class="citation" data-cites="7953245">(Korpusik, Collins, and Glass 2017b)</span> to retrieve nutrition information in a spoken diet tracking system. In the past, we found a trade-off between accuracy and cost, leading us to select convolutional neural networks over recurrent long short-term memory (LSTM) networks – with nearly 10x as many parameters and 2x the training time required, LSTMs achieved slightly lower performance on semantic tagging and food database mapping on meals in the breakfast category. Here, we propose to investigate state-of-the-art transformers, specifically the contextual embedding model (i.e., the entire sentence is used as context to generate the embedding) known as BERT <span class="citation" data-cites="DBLP:journals/corr/abs-1810-04805">(Bidirectional Encoder Representations from Transformers, Devlin et al. 2018)</span>.</p>
<section id="related-work" class="level5">
<h5 class="anchored" data-anchor-id="related-work">Related work</h5>
<p>Within the past few years, several papers have come out that learn contextual representations of sentences, where the entire sentence is used to generate embeddings.</p>
<p>ELMo <span class="citation" data-cites="DBLP:journals/corr/abs-1802-05365">(Peters et al. 2018)</span> uses a linear combination of vectors extracted from intermediate layer representations of a bidirectional LSTM trained on a large text corpus as a language model; in this feature-based approach, the ELMo vector of the full input sentence is concatenated with the standard context-independent token representations and passed through a task-dependent model for final prediction. This showed performance improvement over state-of-the-art on six NLP tasks, including question answering, textual entailment, and sentiment analysis.</p>
<p>OpenAI GPT <span class="citation" data-cites="radford2018improving">(Radford et al. 2018)</span> is a fine-tuning approach, where they first pre-train a multi-layer transformer <span class="citation" data-cites="NIPS2017_3f5ee243">(Vaswani et al. 2017)</span> as a language model on a large text corpus, and then conduct supervised fine-tuning on the specific task of interest, with a linear softmax layer on top of the pre-trained transformer.</p>
<p>Google’s BERT <span class="citation" data-cites="DBLP:journals/corr/abs-1810-04805">(2018)</span> is a fine-tuning approach similar to GPT, but with the key difference that instead of combining separately trained forward and backward transformers, they instead use a masked language model for pre-training, where they randomly masked out input tokens and predicted only those tokens. They demonstrated state-of-the-art performance on 11 NLP tasks, including the CoNLL 2003 named entity recognition task, which is similar to our semantic tagging task.</p>
<p>Finally, many models have recently been developed that improve upon BERT, including RoBERTa <span class="citation" data-cites="DBLP:journals/corr/abs-1907-11692">(which improves BERT’s pre-training by using bigger batches and more data, Y. Liu et al. 2019)</span>, XLNet <span class="citation" data-cites="NEURIPS2019_dc6a7e65">(which uses Transformer-XL and avoids BERT’s pretrain-finetune discrepancy through learning a truly bidirectional context via permutations over the factorization order, Yang et al. 2019)</span>, and ALBERT <span class="citation" data-cites="DBLP:journals/corr/abs-1909-11942">(a lightweight BERT, Lan et al. 2019)</span>.</p>
<p>In our prior work on language understanding for nutrition <span class="citation" data-cites="7078635 7472843 7902155 korpusik17_interspeech 8461769 8721137">(Korpusik et al. 2014, 2016; Korpusik and Glass 2017, 2018, 2019; Korpusik, Collins, and Glass 2017a)</span>, we used a similar binary classification approach for learning embeddings, which were then used at test time to map from user-described meals to USDA food database matches, but with convolutional neural networks (CNNs) instead of BERT. (BERT was not created until 2018, and due to limited memory available for deployment, we needed a smaller model than even BERT base, which has 100 million parameters.) Further work demonstrated that BERT outperformed CNNs on several language understanding tasks, including nutrition <span class="citation" data-cites="korpusik19_interspeech">(Korpusik, Liu, and Glass 2019)</span>.</p>
</section>
</section>
<section id="our-approach" class="level2">
<h2 class="anchored" data-anchor-id="our-approach">Our approach</h2>
<p>Our approach is to fine-tune a large pre-trained BERT language model on the food data. BERT was originally trained on a massive amount of text for a language modelling task (i.e., predicting which word should come next in a sentence). It relies on a transformer model, which uses an “attention” mechanism to identify which words the model should pay the most “attention” to. We are specifically using BERT for binary sequence classification, which refers to predicting a label (i.e., classification) for a sequence of words. In our case, during fine-tuning (i.e., training the model further on our own dataset) we will feed the model pairs of sentences (where one sentence is the UPC description of a food item and the other is the EC description of another food item), and the model will perform binary classification, predicting whether the sentences are a match (i.e., 1) or not (i.e., 0). We start with the 2015–2016 ground truth PPC data for positive examples, and five randomly sampled negative examples per positive example.</p>
<section id="training-methods" class="level5">
<h5 class="anchored" data-anchor-id="training-methods">Training methods</h5>
<p>Since we used a neural network model, the only features passed into our model were the tokenized words themselves of the EC and UPC food descriptions – we did not conduct any manual feature engineering <span class="citation" data-cites="dong_liu">(Dong and Liu 2018)</span>. The model was trained on a 90/10 split into 90% training and 10% validation data, where the validation data was used as a test set to fine-tune the model’s hyperparameters. We started with a randomly sampled set of 16,000 pairs, batch size of 16 (i.e., the model would train on batches of 16 samples at a time), AdamW <span class="citation" data-cites="DBLP:journals/corr/abs-1711-05101">(Loshchilov and Hutter 2017)</span> as the optimizer (which adaptively updates the learning rate, or how large the update should be to the model’s parameters), a linear schedule with warmup <span class="citation" data-cites="DBLP:journals/corr/abs-1908-03265">(i.e., starting with a small learning rate in the first few epochs of training due to large variance in early stages of training, L. Liu et al. 2019)</span>, and one epoch (i.e., the number of times the model passes through all the training data). We then added the next randomly sampled set of 16,000 pairs to get a model trained on 32,000 data points. Finally, we reached a total of 48,000 data samples used for training. Each pair of sequences was tokenized with the pre-trained BERT tokenizer, with the special CLS and SEP tokens (where CLS is a learned vector that is typically passed to downstream layers for final classification, and SEP is a learned vector that separates two input sequences), and was padded with zeros to the maximum length input sequence of 240 tokens, so that each input sequence would be the same length.</p>
</section>
<section id="model-development-approach" class="level5">
<h5 class="anchored" data-anchor-id="model-development-approach">Model development approach</h5>
<p>We faced many challenges due to the secure nature of the ADRF environment. Since our approach relies on BERT, we were blocked by errors due to the local BERT installation. Typically, BERT is downloaded from the web as the program runs. However, for this challenge, BERT must be installed locally for security reasons. To fix the errors, the BERT models needed to be installed with <code>git lfs clone</code> instead of git.</p>
<p>Second, we were unable to retrieve the test data from the database due to SQLAlchemy errors. We found a workaround by using DBeaver directly to save database tables as Excel spreadsheets, rather than accessing the database tables through Python.</p>
<p>Finally, we needed a GPU in order to efficiently train our BERT models. However, we initially only had a CPU, so there was a delay due to setting up the GPU configuration. Once the GPU image was set up, there was still a CUDA error when running the BERT model during training. We determined that the model was too big to fit into GPU memory, so we found a workaround using gradient checkpointing (trading off computation speed for memory) with the transformers library’s Trainer and TrainingArguments. Unfortunately, the version of transformers we were using did not have these tools, and the library was not updated until less than a week before the deadline, so we still had to train the model on the CPU.</p>
<p>To deal with the inability to run jobs in the background, our process was checkpointing our models every five batches, and saving the model predictions during evaluation to a csv file every five batches as well.</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Find the code in the <a href="https://github.com/realworlddatascience/realworlddatascience.github.io/tree/main/case-studies/posts/2023/08/21/_code">Real World Data Science GitHub repository</a>.</p>
</div>
</div>
</div>
</section>
</section>
<section id="our-results" class="level2">
<h2 class="anchored" data-anchor-id="our-results">Our results</h2>
<p>After training, the 48K model (so-called because it was trained on 48,000 data samples) was used at test time via ranking all possible 2017–18 EC descriptions given an unseen UPC description. The rankings were obtained through the model’s output value – the higher the output (or confidence), the more highly we ranked that EC description. To speed up the ranking process, we used blocking (i.e., only ranking a subset of all possible matches), specifically with exact word matches (using only the first six words in the UPC description, which appeared to be the most important), and fed all possible matches through the model in one batch per UPC description. Since we still did not have sufficient time to complete evaluation on the full set of test UPC descriptions, we implemented an expedited evaluation that only considered the first 10 matching EC descriptions in the BERT ranking process (which we call BERT-FAST). We also report results for the slower evaluation method that considers all EC descriptions that match at least one of the first six words in a given UPC description, but note that these results are based on just a small subset of the total test set. See Table 1 below for our results, where the <span class="citation" data-cites="5">(<strong>5?</strong>)</span> indicates how often the correct match was ranked among the top-5. See Table 2 for an estimate of how long it takes to train and test the model on a CPU.<br>
<br>
<br>
</p>
<div class="figure-caption">
<p><strong>Table 1:</strong> S@5 and NCDG@5 for BERT, both for fast evaluation over the whole test set, and slower evaluation on a smaller subset (711 UPCs out of 37,693 total).</p>
</div>
<table class="table">
<thead>
<tr class="header">
<th>Model</th>
<th style="text-align: center;">Success@5</th>
<th style="text-align: center;">NDCG@5</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>BERT-FAST</td>
<td style="text-align: center;">0.057</td>
<td style="text-align: center;">0.047</td>
</tr>
<tr class="even">
<td>BERT-SLOW</td>
<td style="text-align: center;">0.537</td>
<td style="text-align: center;">0.412</td>
</tr>
</tbody>
</table>
<p><br>
</p>
<div class="figure-caption">
<p><strong>Table 2:</strong> An estimate of the time required to train and test the model.</p>
</div>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th>Time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Training (on 48K samples)</td>
<td>16 hours</td>
</tr>
<tr class="even">
<td>Testing (BERT-FAST)</td>
<td>52 hours</td>
</tr>
<tr class="odd">
<td>Testing (BERT-SLOW)</td>
<td>63 days</td>
</tr>
</tbody>
</table>
<p><br>
</p>
</section>
<section id="future-workrefinement" class="level2">
<h2 class="anchored" data-anchor-id="future-workrefinement">Future work/refinement</h2>
<p>In the future, with more time available, we would train on all data, not just our limited dataset of 48,000 pairs, as well as perform evaluation on the held-out test set with the full set of possible EC matches that have one or more words in common with the UPC description. We would compare against baseline word embedding methods such as word2vec <span class="citation" data-cites="DBLP:journals/corr/abs-1712-09405">(Mikolov et al. 2017)</span> and Glove <span class="citation" data-cites="pennington-etal-2014-glove">(Pennington, Socher, and Manning 2014)</span>, and we would explore hierarchical prediction methods for improving efficiency and accuracy. Specifically, we would first train a classifier to predict the generic food category, and then train finer-grained models to predict specific foods within a general food category. Finally, we are exploring multi-modal transformer-based approaches that allow two input modalities (i.e., food images and text descriptions of a meal) for predicting the best UPC match.</p>
</section>
<section id="lessons-learned" class="level2">
<h2 class="anchored" data-anchor-id="lessons-learned">Lessons learned</h2>
<p>We recommend that future challenges provide every team with both a CPU and a GPU in their workspace, to avoid transitioning from one to the other midway through the challenge. In addition, if possible, it would be very helpful to provide a mechanism for running jobs in the background. Finally, it may be useful for teams to submit snippets of code along with library package names, in order for the installations to be tested properly beforehand.</p>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../case-studies/posts/2023/08/21/04-second-place-winners.html">← Part 4: Second place winners</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../case-studies/posts/2023/08/21/06-value-of-competitions.html">Part 6: The value of competitions →</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Yifan (Rosetta) Hu</strong> is an undergraduate student and <strong>Mandy Korpusik</strong> is an assistant professor of computer science at Loyola Marymount University’s Seaver College of Science and Engineering.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Yifan Hu and Mandy Korpusik
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@pvsbond?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Peter Bond</a> on <a href="https://unsplash.com/photos/KfvknMhkmw0?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Hu, Yifan, and Mandy Korpusik. 2023. “Food for Thought: Third place winners – Loyola Marymount.” Real World Data Science, August 21, 2023. <a href="https://realworlddatascience.net/viewpoints/case-studies/posts/2023/08/21/05-third-place-winners.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-DBLP:journals/corr/abs-1810-04805" class="csl-entry">
Devlin, J., M.-W. Chang, K. Lee, and K. Toutanova. 2018. <span>“<span>BERT:</span> Pre-Training of Deep Bidirectional Transformers for Language Understanding.”</span> <em>CoRR</em> abs/1810.04805. <a href="http://arxiv.org/abs/1810.04805">http://arxiv.org/abs/1810.04805</a>.
</div>
<div id="ref-dong_liu" class="csl-entry">
Dong, G., and H. Liu, eds. 2018. <em>Feature Engineering for Machine Learning and Data Analytics</em>. First edition. CRC Press.
</div>
<div id="ref-korpusik17_interspeech" class="csl-entry">
Korpusik, M., Z. Collins, and J. Glass. 2017a. <span>“<span class="nocase">Character-Based Embedding Models and Reranking Strategies for Understanding Natural Language Meal Descriptions</span>.”</span> In <em>Proceedings of Interspeech</em>, 3320–24. <a href="https://doi.org/10.21437/Interspeech.2017-422">https://doi.org/10.21437/Interspeech.2017-422</a>.
</div>
<div id="ref-7953245" class="csl-entry">
———. 2017b. <span>“Semantic Mapping of Natural Language Input to Database Entries via Convolutional Neural Networks.”</span> In <em>2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 5685–89. <a href="https://doi.org/10.1109/ICASSP.2017.7953245">https://doi.org/10.1109/ICASSP.2017.7953245</a>.
</div>
<div id="ref-7902155" class="csl-entry">
Korpusik, M., and J. Glass. 2017. <span>“Spoken Language Understanding for a Nutrition Dialogue System.”</span> <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em> 25 (7): 1450–61. <a href="https://doi.org/10.1109/TASLP.2017.2694699">https://doi.org/10.1109/TASLP.2017.2694699</a>.
</div>
<div id="ref-8461769" class="csl-entry">
———. 2018. <span>“Convolutional Neural Networks and Multitask Strategies for Semantic Mapping of Natural Language Input to a Structured Database.”</span> In <em>2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 6174–78. <a href="https://doi.org/10.1109/ICASSP.2018.8461769">https://doi.org/10.1109/ICASSP.2018.8461769</a>.
</div>
<div id="ref-8721137" class="csl-entry">
———. 2019. <span>“Deep Learning for Database Mapping and Asking Clarification Questions in Dialogue Systems.”</span> <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em> 27 (8): 1321–34. <a href="https://doi.org/10.1109/TASLP.2019.2918618">https://doi.org/10.1109/TASLP.2019.2918618</a>.
</div>
<div id="ref-7472843" class="csl-entry">
Korpusik, M., C. Huang, M. Price, and J. Glass. 2016. <span>“Distributional Semantics for Understanding Spoken Meal Descriptions.”</span> In <em>2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 6070–74. <a href="https://doi.org/10.1109/ICASSP.2016.7472843">https://doi.org/10.1109/ICASSP.2016.7472843</a>.
</div>
<div id="ref-korpusik19_interspeech" class="csl-entry">
Korpusik, M., Z. Liu, and J. Glass. 2019. <span>“<span class="nocase">A Comparison of Deep Learning Methods for Language Understanding</span>.”</span> In <em>Proceedings of Interspeech</em>, 849–53. <a href="https://doi.org/10.21437/Interspeech.2019-1262">https://doi.org/10.21437/Interspeech.2019-1262</a>.
</div>
<div id="ref-7078635" class="csl-entry">
Korpusik, M., N. Schmidt, J. Drexler, S. Cyphers, and J. Glass. 2014. <span>“Data Collection and Language Understanding of Food Descriptions.”</span> In <em>2014 IEEE Spoken Language Technology Workshop (SLT)</em>, 560–65. <a href="https://doi.org/10.1109/SLT.2014.7078635">https://doi.org/10.1109/SLT.2014.7078635</a>.
</div>
<div id="ref-DBLP:journals/corr/abs-1909-11942" class="csl-entry">
Lan, Z., M. Chen, S. Goodman, K. Gimpel, P. Sharma, and R. Soricut. 2019. <span>“<span>ALBERT:</span> <span>A</span> Lite <span>BERT</span> for Self-Supervised Learning of Language Representations.”</span> <em>CoRR</em> abs/1909.11942. <a href="http://arxiv.org/abs/1909.11942">http://arxiv.org/abs/1909.11942</a>.
</div>
<div id="ref-DBLP:journals/corr/abs-1908-03265" class="csl-entry">
Liu, L., H. Jiang, P. He, W. Chen, X. Liu, J. Gao, and J. Han. 2019. <span>“On the Variance of the Adaptive Learning Rate and Beyond.”</span> <em>CoRR</em> abs/1908.03265. <a href="http://arxiv.org/abs/1908.03265">http://arxiv.org/abs/1908.03265</a>.
</div>
<div id="ref-DBLP:journals/corr/abs-1907-11692" class="csl-entry">
Liu, Y., M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov. 2019. <span>“RoBERTa: <span>A</span> Robustly Optimized <span>BERT</span> Pretraining Approach.”</span> <em>CoRR</em> abs/1907.11692. <a href="http://arxiv.org/abs/1907.11692">http://arxiv.org/abs/1907.11692</a>.
</div>
<div id="ref-DBLP:journals/corr/abs-1711-05101" class="csl-entry">
Loshchilov, I., and F. Hutter. 2017. <span>“Fixing Weight Decay Regularization in Adam.”</span> <em>CoRR</em> abs/1711.05101. <a href="http://arxiv.org/abs/1711.05101">http://arxiv.org/abs/1711.05101</a>.
</div>
<div id="ref-DBLP:journals/corr/abs-1712-09405" class="csl-entry">
Mikolov, T., E. Grave, P. Bojanowski, C. Puhrsch, and A. Joulin. 2017. <span>“Advances in Pre-Training Distributed Word Representations.”</span> <em>CoRR</em> abs/1712.09405. <a href="http://arxiv.org/abs/1712.09405">http://arxiv.org/abs/1712.09405</a>.
</div>
<div id="ref-pennington-etal-2014-glove" class="csl-entry">
Pennington, J., R. Socher, and C. Manning. 2014. <span>“<span>G</span>lo<span>V</span>e: Global Vectors for Word Representation.”</span> In <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (<span>EMNLP</span>)</em>, 1532–43. Doha, Qatar: Association for Computational Linguistics. <a href="https://doi.org/10.3115/v1/D14-1162">https://doi.org/10.3115/v1/D14-1162</a>.
</div>
<div id="ref-DBLP:journals/corr/abs-1802-05365" class="csl-entry">
Peters, M. E., M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee, and L. Zettlemoyer. 2018. <span>“Deep Contextualized Word Representations.”</span> <em>CoRR</em> abs/1802.05365. <a href="http://arxiv.org/abs/1802.05365">http://arxiv.org/abs/1802.05365</a>.
</div>
<div id="ref-radford2018improving" class="csl-entry">
Radford, A., K. Narasimhan, T. Salimans, and I. Sutskever. 2018. <span>“Improving Language Understanding by Generative Pre-Training.”</span> <a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf">https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf</a>.
</div>
<div id="ref-NIPS2017_3f5ee243" class="csl-entry">
Vaswani, A., N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin. 2017. <span>“Attention Is All You Need.”</span> In <em>Advances in Neural Information Processing Systems</em>, edited by I. Guyon, U. Von Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett. Vol. 30. Curran Associates, Inc. <a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a>.
</div>
<div id="ref-NEURIPS2019_dc6a7e65" class="csl-entry">
Yang, Z., Z. Dai, Y. Yang, J. Carbonell, R. R. Salakhutdinov, and Q. V. Le. 2019. <span>“XLNet: Generalized Autoregressive Pretraining for Language Understanding.”</span> In <em>Advances in Neural Information Processing Systems</em>, edited by H. Wallach, H. Larochelle, A. Beygelzimer, F. dAlché-Buc, E. Fox, and R. Garnett. Vol. 32. Curran Associates, Inc. <a href="https://proceedings.neurips.cc/paper_files/paper/2019/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf">https://proceedings.neurips.cc/paper_files/paper/2019/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf</a>.
</div>
</div></section></div> ]]></description>
  <category>Machine learning</category>
  <category>Natural language processing</category>
  <category>Public policy</category>
  <category>Health and wellbeing</category>
  <guid>https://realworlddatascience.net/case-studies/posts/2023/08/21/05-third-place-winners.html</guid>
  <pubDate>Mon, 21 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/case-studies/posts/2023/08/21/images/05-lm.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Food for Thought: Competition and challenge design</title>
  <dc:creator>Zheyuan Zhang and Uyen Le</dc:creator>
  <link>https://realworlddatascience.net/case-studies/posts/2023/08/21/02-competition-design.html</link>
  <description><![CDATA[ 




<p>Since 2014, the professional services firm Westat, Inc.&nbsp;has been developing the Purchase to Plate Crosswalk (PPC) for the United States Department of Agriculture (USDA) Economic Research Service (ERS). The PPC links the retail food transactions database from IRI’s InfoScan service and the USDA Food and Nutrient Database for Dietary Studies (FNDDS). However, the current linkage process uses only partly automated data matching, meaning it is resource intensive, time consuming, and requires manual review.</p>
<p>With sponsorship from ERS, Westat partnered with the Coleridge Initiative to host the Food for Thought competition to challenge researchers and data scientists to use machine learning and natural language processing to find accurate and efficient methods for creating the PPC. Figure 1 provides a visual overview of the challenge set by the competition.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pt2-fig1.png"><img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/images/pt2-fig1.png" class="img-fluid figure-img" width="700"></a></p>
</figure>
</div>
<div class="figure-caption">
<p><strong>Figure 1:</strong> Overview of the Food for Thought Competition Challenge.</p>
</div>
<p>The one-to-many matching task that is central to the competition throws up many challenges for researchers to wrestle with. Because IRI data contains food transactions collected from partnered retail establishments for over 350,000 items, the matchings need to be made based on limited data features, including categories, providers, and semantically inconsistent descriptions that consist of short phrases. Consider this hypothetical example: IRI product-related information about a (fictional) “Cheesy Hashbrowns Hamburger Helper, 5.5 Oz Box” needs to be linked to FNDDS nutrition-related information found under “Mixed dishes – meat, poultry, seafood: Mixed meat dishes”. Figure 2 demonstrates how the two databases are linked with each other to create the PPC. As can be seen, there is no common word that easily indicates that “Cheesy Hashbrowns Hamburger Helper…” should be matched with “Mixed dishes…”, and such cases exist in all IRI tables used for the challenge, from 2012 through 2018.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pt2-fig2.png"><img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/images/pt2-fig2.png" class="img-fluid figure-img" width="700"></a></p>
</figure>
</div>
<div class="figure-caption">
<p><strong>Figure 2:</strong> Each universal product code (UPC) from the IRI data could match to only one ensemble code (EC) from the FNDDS data, whereas one EC code could match to multiple UPCs.</p>
</div>
<p>Also, because nutritionists or food scientists will always need to review the matching, regardless of the matching method used, it was important that our evaluation of proposed matching methods focused both on the accuracy of prediction models and also on metrics that would lead participants to develop models that facilitate qualified reviewers to reduce their workloads.</p>
<p>Organising the competition was also a challenge in its own right, for data privacy reasons. IRI scanner data contains sensitive information, such as store name, location, unit price, and weekly quantity sold for each item. This ruled out using existing online platforms like Kaggle, DrivenData or AIcrowd to host the competition, and instead required a private secure data enclave to ensure the safe use of sensitive and confidential data assets. The need for such an environment imposed capacity constraints on the competition, meaning only dozens of teams could be invited to take part, whereas on open platforms it is common to have thousands of teams competing and sharing ideas and code.</p>
<section id="competition-structure" class="level2">
<h2 class="anchored" data-anchor-id="competition-structure">Competition structure</h2>
<p>The competition ran over 10 months and consisted of three separate challenges: two interim, one final. Applications opened in September 2021, and the competition started in January 2022. Submission deadlines for the first and second interim challenges were in July and September 2022, respectively. For these rounds, participants submitted preliminary solutions for evaluation based solely on quantitative metrics, and two awards of $10,000 were given to the highest-scoring teams. The deadline for the final challenge was in October 2022. Here, solutions were evaluated by the scientific review board based on three judging criteria: quantitative metrics, transferability, and innovation. First, second, and third place winners received awards of $30,000, $1,500, and $1,000 respectively. Final presentations were given at the Food for Thought symposium in December 2022.</p>
<p>The competition was run entirely within the Coleridge Initiative’s Administrative Data Research Facility (ADRF), which was established by the United States Census Bureau to inform the decision-making of the Commission on Evidence-Based Policy under the Evidence Act. ADRF follows the Five Safes Framework: safe projects, safe people, safe data, safe settings, and safe outputs.</p>
<p>In keeping with this framework, participants were provided with ADRF login credentials after signing the relevant data use agreements during the onboarding process. All participants were required to agree to the ADRF terms of use, to complete security training, and to pass a security training assessment prior to accessing the challenge data. Participants’ access within ADRF was limited to the challenge environment and data only. There was no internet access, so Coleridge Initiative ensured that any packages requested by teams were available for use within the environment after passing security review. All codes and documentation were only allowed to be exported outside ADRF after export reviews from both Coleridge Initiative and USDA staff. At the end of each challenge, the teams submitted write-ups and supporting files by placing all the necessary submission files in their ADRF team folder. Detailed submission instructions are available via the <a href="https://github.com/realworlddatascience/realworlddatascience.github.io/tree/main/case-studies/posts/2023/08/21/_code">Real World Data Science GitHub repository</a>.</p>
</section>
<section id="metrics" class="level2">
<h2 class="anchored" data-anchor-id="metrics">Metrics</h2>
<p>Submissions were evaluated by Coleridge Initiative and technical review and subject review boards based on the following criteria:</p>
<ul>
<li><strong>Quantitative metrics</strong> were used to measure the predictive accuracy and runtime of the model.<br>
</li>
<li><strong>Transferability</strong> measured the quality of documentation and code, and the ability of individuals who are not involved in model development to replicate and implement the team’s approach.<br>
</li>
<li><strong>Innovation</strong> measured novelty and creativity of the model in addressing the linkage problem.</li>
</ul>
<p>Technical review was overseen by faculty members from computer science and engineering departments of top US universities. Subject review was handled by subject matter experts from USDA and Westat.</p>
<p>From a quantitative perspective, the most common way to evaluate machine learning competition submissions is to use model predictive accuracy. However, single metrics are typically incomplete descriptions of real-world tasks, and they can easily hide significant differences between models which simple predictive accuracy cannot capture. To select the most appropriate official challenge metrics, Coleridge Initiative reviewed the literature on the use of evaluation measures in both classification and ranking task machine learning competitions. Success at 5 (S@5) and Normalized Discounted Cumulative Gain at 5 (NDCG@5) scores were ultimately used as the quantitative metrics.</p>
<p>The metrics were applied as follows: models proposed by each team were tasked with outputting five potential FNDDS matches for each IRI code, with potential FNDDS matches ordered from most likely to least likely. S@5 and NDCG@5 scores are broadly similar – both measure whether a correct match is present in the five proposed matches that participants were asked to identify. However, S@5 does not take rank position into account and only considers whether the five proposed FNDDS matches contain the correct FNDDS response. NDCG@5 does take rank into account and also measures how highly the correct FNDDS response is ranked among the five proposed matches. Both measures range from 0 to 1 (or 0% to 100%). Models get a “full credit” for S@5 as long as they contain the correct FNDDS option. NDCG@5 penalizes models when the correct match is ranked lower on the list of 5 proposed matches.</p>
</section>
<section id="technical-description" class="level2">
<h2 class="anchored" data-anchor-id="technical-description">Technical description</h2>
<section id="environment-setup" class="level5">
<h5 class="anchored" data-anchor-id="environment-setup">Environment setup</h5>
<p>Coleridge Initiative solicited technical requirements from participants at the challenge application stage to prepare the ADRF environment as much as possible before the competition began. Each team was asked to share anticipated workspace specifications and software library requests in their application package. From this we identified, reviewed, and installed the requested Python and R packages, libraries, and library components (e.g., pre-trained models, training data) that were not yet available within ADRF.</p>
<p>The setup of graphics processing units (GPUs) was also a critical part of competition preparation. We created an environment with 16 gibibyte (GiB) of GPU memory for each team. Our technology team met with multiple teams several times to discuss computing environment configurations to ensure the GPU could work properly. None of these efforts was wasted: without GPU access, it would be impossible for teams to use state-of-the-art pre-trained models such as the Bidirectional Encoder Representations from Transformers <span class="citation" data-cites="DBLP:journals/corr/abs-1810-04805">(BERT, Devlin et al. 2018)</span>.</p>
<p>We completed the setup of new team workspaces, each customized to the individual team’s resource and library requirements, including GPU configuration. The isolation and customization of workspaces was vital because teams may request different versions of libraries that potentially have version conflict with other libraries. We ensured the configurations were all set before the challenge began because such data challenges are bursty in nature <span class="citation" data-cites="macavaney_et_al_2021">(Macavaney et al. 2021)</span>, and handling support requests in the private data enclave risked causing delays. We hoped to avoid receiving too many requests in the beginning phase of the competition in order to give participants a better experience, though we did of course provide participants with instructions on how to request additional libraries during the challenge period.</p>
</section>
<section id="supporting-materials" class="level5">
<h5 class="anchored" data-anchor-id="supporting-materials">Supporting materials</h5>
<p>In addition to environment preparation, we made available a list of supporting documentation, including IRI, PPC, and FNDDS codebooks, technical reports, and related publications that could help teams understand the challenge datasets. The FNDDS codebook pooled information on variable availability, coding, and descriptions across dataset files and years. It also included internal Westat food category coding difficulty ratings and notes on created PPC codes and provided UPC code, EC code, and general dataset remarks and observations that may take time for analysts to discover on their own.</p>
<p>We developed a baseline model to demonstrate the challenge task and the expected outputs – both outside of ADRF using FNDDS and fictitious data in place of IRI data, and an analogous model using FNDDS and IRI data within the ADRF secure environment. Moreover, we provided the teams with an evaluation script to read in their submissions and evaluate them for predictive accuracy against the public test set using S@5 and NDCG@5 challenge metrics. Finally, we held multiple webinars during the course of the challenge to explain next steps, address participant questions, solicit feedback, and provide general support. Multiple teams also met with our technology team to clarify ADRF-related questions or troubleshoot technical issues.</p>
<p>(Baseline model, toolkits, and evaluation script are available from the <a href="https://github.com/realworlddatascience/realworlddatascience.github.io/tree/main/case-studies/posts/2023/08/21/_code">Real World Data Science GitHub repository</a>.)</p>
</section>
<section id="data-splitting" class="level5">
<h5 class="anchored" data-anchor-id="data-splitting">Data splitting</h5>
<p>To mimic the real-world scenario, the competition used 2012–2016 IRI data as the training set, and the 2017–2018 IRI data as the test set, since the data change over time and USDA could provide the most recent data available. To make sure that models were generalizable and not just overfit to the test set, we split the test set into private and public test sets. In this way, we guaranteed that the models were evaluated on completely hidden data. In order to keep the similar distribution of the two sets, we first divided the data into five quintiles based on EC code frequencies and then randomly sampled 80% of records in each group without repetition for placement into the private test set. Later in the competition, because of the computation limit, we further shrank the private test set to 40% of its original size using the same data-splitting method.</p>
</section>
<section id="judging" class="level5">
<h5 class="anchored" data-anchor-id="judging">Judging</h5>
<p>In the first two rounds, submissions were evaluated based on the quantitative metrics, as previously mentioned above. Coleridge Initiative was responsible for running the evaluation script, making sure not to re-train the model or modify the configs in any way, and only applying the model to predict the private test set. Prediction results were then compared against ground truth to get the private scores.</p>
<p>The final challenge was reviewed by the scientific review board on all three judging criteria. Submitted models were first evaluated by Coleridge Initiative in the same way as in the first two rounds. The runtime of models was also recorded as an assessment of model cost. The scientific review boards then assessed the models by the quality of documentation, the quality of code, and the ability to replicate and implement the team’s approach, and scored the models for innovation and creativity in addressing the linkage problem. Lastly, scores were summarized and the scientific review board discussed and decided the winners of the competition.</p>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>The next few articles in this collection walk readers through the solutions proposed by competition finalists. Figure 3 provides a brief summary.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pt2-fig3.png"><img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/images/pt2-fig3.png" class="img-fluid figure-img" width="700"></a></p>
</figure>
</div>
<div class="figure-caption">
<p><strong>Figure 3:</strong> Top competitors and their solutions to the Food for Thought challenge.</p>
</div>
</section>
<section id="lessons-learned" class="level2">
<h2 class="anchored" data-anchor-id="lessons-learned">Lessons learned</h2>
<p>It was undoubtedly challenging for teams to work with highly secured data in a private data enclave for this data challenge. We solicited feedback from teams and summarized the issues that we experienced throughout the competitions, together with the solutions to resolve those issues. Below are our main lessons learned and we hope this summary can serve to inform future competitions.</p>
<ul>
<li><p><strong>Environmental factors:</strong> The installation and setup of packages, libraries, and resources, as well as the configuration of GPUs, system dependencies, and workspace design were expected to take a long time as each team had their own needs. To accelerate the process, we requested a list of specific package and environment requirements from the teams in advance. However, due to the complexity of the system configuration required by the teams, environment setup took longer than expected. Thus, the challenge deadlines had to be postponed a few times to accommodate this.</p></li>
<li><p><strong>Time commitment:</strong> Twelve teams were selected to participate in the challenge, but only three teams remained in the final challenge. Other than one team that was disqualified for violating the ADRF terms of use agreement, eight dropped out because of other commitments and insufficient time to meaningfully participate. To ensure security, ADRF does not allow jobs to run in the backend, which also adds to the time commitment of teams. To encourage teams to participate in the final challenge, we gave out additional awards for second and third places.</p></li>
<li><p><strong>Computing resource limit:</strong> One issue encountered in evaluating submitted models was computing environment resource limits due to the secured nature of the data enclave. The original private test dataset is four times larger than the public test dataset, making it unfeasible to evaluate. To overcome this issue, given the fixed resource constraints, we decided to reduce the private test set to 40% of its original size. It would have been helpful, though, if the competition had set a model running time limit at the outset, so that participants could build simpler yet effective models.</p></li>
<li><p><strong>Supporting code:</strong> Although the initial baseline model we provided was extremely simple, we found this helped participants a lot in the initial phase – yet there is space to improve. To be specific, supporting codes should be constructed so that all relevant data tables are used and specify the main function to run the code, especially how the model should be tested. The teams only used the main table, which was the only table that was used in the baseline model, for training and did not touch the other supporting table. If we included the other table in the baseline model, it could help participants to have a better use of this data as well. In addition, a baseline model should be intuitive for the participants to follow, allowing evaluators to easily replace the public test set with the private test set without any programming modifications.</p></li>
</ul>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../case-studies/posts/2023/08/21/01-purchase-to-plate.html">← Part 1: Purchase to Plate</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../case-studies/posts/2023/08/21/03-first-place-winners.html">Part 3: First place winners →</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Zheyuan Zhang</strong> and <strong>Uyen Le</strong> are research scientists at the Coleridge Initiative.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Zheyuan Zhang and Uyen Le
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Zhang, Zheyuan, and Uyen Le. 2023. “Food for Thought: Competition and challenge design.” Real World Data Science, August 21, 2023. <a href="https://realworlddatascience.net/viewpoints/case-studies/posts/2023/08/21/02-competition-design.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-DBLP:journals/corr/abs-1810-04805" class="csl-entry">
Devlin, J., M.-W. Chang, K. Lee, and K. Toutanova. 2018. <span>“<span>BERT:</span> Pre-Training of Deep Bidirectional Transformers for Language Understanding.”</span> <em>CoRR</em> abs/1810.04805. <a href="http://arxiv.org/abs/1810.04805">http://arxiv.org/abs/1810.04805</a>.
</div>
<div id="ref-macavaney_et_al_2021" class="csl-entry">
Macavaney, S., A. Mittu, G. Coppersmith, J. Leintz, and P. Resnik. 2021. <span>“Community-Level Research on Suicidality Prediction in a Secure Environment: Overview of the CLPsych 2021 Shared Task.”</span> In Proceedings of the Seventh Workshop on Computational Linguistics and Clinical Psychology: Improving Access.
</div>
</div></section></div> ]]></description>
  <category>Machine learning</category>
  <category>Natural language processing</category>
  <category>Public policy</category>
  <category>Health and wellbeing</category>
  <guid>https://realworlddatascience.net/case-studies/posts/2023/08/21/02-competition-design.html</guid>
  <pubDate>Mon, 21 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/case-studies/posts/2023/08/21/images/pt2-intro.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Food for Thought: The value of competitions for confidential data</title>
  <dc:creator>Steven Bedrick, Ophir Frieder, Julia Lane, and Philip Resnik</dc:creator>
  <link>https://realworlddatascience.net/case-studies/posts/2023/08/21/06-value-of-competitions.html</link>
  <description><![CDATA[ 




<p>We are witnessing a sea change in data collection practices by both governments and businesses – from purposeful collection (through surveys and censuses, for example) to opportunistic (drawing on web and social media data, and administrative datasets). This shift has made clear the importance of record linkage – a government might, for example, look to link records held by its various departments to understand how citizens make use of the gamut of public services.</p>
<p>However, creating manual linkages between datasets can be prohibitively expensive, time consuming, and subject to human constraints and bias. Machine learning (ML) techniques offer the potential to combine data better, faster, and more cheaply. But, as the recently released <a href="https://www.ai.gov/wp-content/uploads/2023/01/NAIRR-TF-Final-Report-2023.pdf">National AI Research Resources Task Force report</a> highlights, it is important to have an open and transparent approach to ensure that unintended biases do not occur.</p>
<p>In other words, ML tools are not a substitute for thoughtful analysis. Both private and public producers of a linked dataset have to determine the level of linkage quality – such as what precision/recall tradeoff is best for the intended purpose (that is, the balance between false-positive links and failure to cover links that should be there), how much processing time and cost is acceptable, and how to address coverage issues. The challenge is made more difficult by the idiosyncrasies of heterogeneous datasets, and more difficult yet when datasets to be linked include confidential data <span class="citation" data-cites="10.1257/jel.20171350 DBLP:books/sp/ChristenRS20">(Christensen and Miguel 2018; Christen, Ranbaduge, and Schnell 2020)</span>.</p>
<p>And, of course, an ML solution is never the end of the road: many data linkage scenarios are highly dynamic, involving use cases, datasets, and technical ecosystems that change and evolve over time; effective use of ML in practice necessitates an ongoing and continuous investment <span class="citation" data-cites="DBLP:journals/corr/abs-2112-01716">(Koch et al. 2021)</span>. Because techniques are constantly improving, producers need to keep abreast of new approaches. A model that is working well today may no longer work in a year because of changes in the data, or because the organizational needs have changed so that a certain type of error is no longer acceptable. As Sculley et al.&nbsp;point out, “it is remarkably easy to incur massive ongoing maintenance costs at the system level when applying machine learning” <span class="citation" data-cites="43146">(Sculley et al. 2014)</span>.</p>
<p>Also important is that record linkage is not seen as a technical problem relegated to the realm of computer scientists to solve. The full engagement of domain experts in designing the optimization problem, identifying measures of success, and evaluating the quality of the results is absolutely critical, as is building an understanding of the pros and cons of different measures <span class="citation" data-cites="10.1371/journal.pone.0249833 10.1007/s11222-017-9746-6">(Schafer et al. 2021; Hand and Christen 2018)</span>. There will need to be much learning by doing in “sandbox” environments, and back and forth communication across communities to achieve successful outcomes, as noted in the <a href="https://www.bea.gov/system/files/2022-10/acdeb-year-2-report.pdf">recommendations of the Advisory Committee on Data for Evidence Building</a> (a screenshot of which is shown in Figure 1).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pt6-fig1.png"><img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/images/pt6-fig1.png" class="img-fluid figure-img" width="700"></a></p>
</figure>
</div>
<div class="figure-caption">
<p><strong>Figure 1:</strong> A recommendation for building an “innovation sandbox” as part of the creation of a new National Secure Data Service in the United States.</p>
</div>
<p>Despite the importance of trial and error and transparency about linkage quality, there is no handbook that guides domain experts in how to design such sandboxes. There is a very real need for agreed-upon, domain-independent guidelines, or better yet, official standards to evaluate sandboxes. Those standards would define “who” could and would conduct the evaluation, and help guarantee independence and repeatability. And while innovation challenges have been embraced by the federal government, the devil can be very much in the details <span class="citation" data-cites="4138bca6-f7b7-3af8-a96c-5e2544823c5c">(Williams 2012)</span>.</p>
<p>It is for this reason that the approach taken in the Food for Thought linkage competition, and described in this compendium, provides an important first step towards a well specified, replicable framework for achieving high quality outcomes. In that respect it joins other recent efforts to bring together community-level research on shared sensitive data <span class="citation" data-cites="macavaney-etal-2021-community tsakalidis-etal-2022-overview">(MacAvaney et al. 2021; Tsakalidis et al. 2022)</span>. This competition, like those, helped bring to the foreground both the opportunities and challenges of doing research in secure sandboxes with sensitive data. Notably, these exercises highlight a kind of cultural tension between secure, managed environments, on the one hand, and unfettered machine learning research, on the other. The need for flexibility and agility in computational research bumps up against the need for advance planning and careful step-by-step processes in environments with well-defined data governance rules, and one of the key lessons learned is that the tradeoffs here need to be recognized and planned for.</p>
<p>This particular competition was important for a number of other reasons. Thanks to its organization as a competition, complete with prizes and bragging rights for strongly performing teams, it attracted new eyes from computer science and data science to think about how to address a critical real-world linkage problem. It offered the potential to produce approaches that were scalable, transparent, and reproducible. The engagement of domain experts and statisticians meant that it will be possible to conduct an informed error analysis, to explicitly relate the performance metrics in the task to the problem being solved in the real world, and to bring in the expertise of survey methodologists to think about the possible adjustments. And because it identified different approaches of addressing the same problem, it created an environment for new innovative ideas.</p>
<p>More generally, in addition to the excitement of the new approaches, this exercise laid bare the fragility of linkages in general and highlighted the importance of secure sandboxes for confidential data. While the promise of privacy preserving technologies is alluring as <a href="https://www.bea.gov/system/files/2022-10/acdeb-year-2-report.pdf">an alternative to bringing confidential data together in one place</a>, such approaches are likely too immature to deploy ad hoc until a better understanding is established of how to translate real-world problems and their associated data into well-defined tasks, how to measure quality, and particularly how to assess the impact of match quality on different subgroups <span class="citation" data-cites="10.1145/3433638">(Domingo-Ferrer, Sánchez, and Blanco-Justicia 2021)</span>. The scientific profession has gone through too painful a lesson with the premature application of differential privacy techniques to ignore the lessons that can be learned from a careful and systematic analysis of different approaches <span class="citation" data-cites="10.1145/3433638 van_riper 10.1257/pandp.20191107 giles2022faking">(2021; Van Riper et al. 2020; Ruggles et al. 2019; Giles et al. 2022)</span>.</p>
<p>We hope that the articles in this collection provide not only the first steps towards a handbook of best practices, but also an inspiration to share lessons learned, so that success can be emulated, and failures understood and avoided.</p>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../case-studies/posts/2023/08/21/05-third-place-winners.html">← Part 5: Third place winners</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../case-studies/index.html">Find more case studies</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Steven Bedrick</strong> is an associate professor in Oregon Health and Science University’s Department of Medical Informatics and Clinical Epidemiology.
</dd>
<dd>
<p><strong>Ophir Frieder</strong> is a professor in Georgetown University’s Department of Computer Science, and in the Department of Biostatistics, Bioinformatics &amp; Biomathematics at Georgetown University Medical Center.</p>
</dd>
<dd>
<p><strong>Julia Lane</strong> is a professor at the NYU Wagner Graduate School of Public Service and a NYU Provostial Fellow for Innovation Analytics. She co-founded the Coleridge Initiative.</p>
</dd>
</dl>
<p><strong>Philip Resnik</strong> holds a joint appointment as professor in the University of Maryland Institute for Advanced Computer Studies and the Department of Linguistics, and an affiliate professor appointment in computer science.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Steven Bedrick, Ophir Frieder, Julia Lane, and Philip Resnik
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@alexandru_tugui?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Alexandru Tugui</a> on <a href="https://unsplash.com/photos/-inuQpBGbgI?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Bedrick, Steven, Ophir Frieder, Julia Lane, and Philip Resnik. 2023. “Food for Thought: The value of competitions for confidential data.” Real World Data Science, August 21, 2023. <a href="https://realworlddatascience.net/viewpoints/case-studies/posts/2023/08/21/06-value-of-competitions.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>




<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-DBLP:books/sp/ChristenRS20" class="csl-entry">
Christen, P., T. Ranbaduge, and R. Schnell. 2020. <em>Linking Sensitive Data - Methods and Techniques for Practical Privacy-Preserving Information Sharing</em>. Springer. <a href="https://doi.org/10.1007/978-3-030-59706-1">https://doi.org/10.1007/978-3-030-59706-1</a>.
</div>
<div id="ref-10.1257/jel.20171350" class="csl-entry">
Christensen, G., and E. Miguel. 2018. <span>“Transparency, Reproducibility, and the Credibility of Economics Research.”</span> <em>Journal of Economic Literature</em> 56 (3): 920–80. <a href="https://doi.org/10.1257/jel.20171350">https://doi.org/10.1257/jel.20171350</a>.
</div>
<div id="ref-10.1145/3433638" class="csl-entry">
Domingo-Ferrer, J., D. Sánchez, and A. Blanco-Justicia. 2021. <span>“The Limits of Differential Privacy (and Its Misuse in Data Release and Machine Learning).”</span> <em>Communications of the ACM</em> 64 (7): 33–35. <a href="https://doi.org/10.1145/3433638">https://doi.org/10.1145/3433638</a>.
</div>
<div id="ref-giles2022faking" class="csl-entry">
Giles, O., K. Hosseini, G. Mingas, O. Strickson, L. Bowler, C. Rangel Smith, H. Wilde, et al. 2022. <span>“Faking Feature Importance: A Cautionary Tale on the Use of Differentially-Private Synthetic Data.”</span> <a href="https://arxiv.org/abs/2203.01363">https://arxiv.org/abs/2203.01363</a>.
</div>
<div id="ref-10.1007/s11222-017-9746-6" class="csl-entry">
Hand, D., and P. Christen. 2018. <span>“A Note on Using the f-Measure for Evaluating Record Linkage Algorithms.”</span> <em>Statistics and Computing</em> 28 (3): 539–47. <a href="https://doi.org/10.1007/s11222-017-9746-6">https://doi.org/10.1007/s11222-017-9746-6</a>.
</div>
<div id="ref-DBLP:journals/corr/abs-2112-01716" class="csl-entry">
Koch, B., E. Denton, A. Hanna, and J. G. Foster. 2021. <span>“Reduced, Reused and Recycled: The Life of a Dataset in Machine Learning Research.”</span> <em>CoRR</em> abs/2112.01716. <a href="https://arxiv.org/abs/2112.01716">https://arxiv.org/abs/2112.01716</a>.
</div>
<div id="ref-macavaney-etal-2021-community" class="csl-entry">
MacAvaney, S., A. Mittu, G. Coppersmith, J. Leintz, and P. Resnik. 2021. <span>“Community-Level Research on Suicidality Prediction in a Secure Environment: Overview of the <span>CLP</span>sych 2021 Shared Task.”</span> In <em>Proceedings of the Seventh Workshop on Computational Linguistics and Clinical Psychology: Improving Access</em>, 70–80. Online: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/2021.clpsych-1.7">https://doi.org/10.18653/v1/2021.clpsych-1.7</a>.
</div>
<div id="ref-10.1257/pandp.20191107" class="csl-entry">
Ruggles, S., C. Fitch, D. Magnuson, and J. Schroeder. 2019. <span>“Differential Privacy and Census Data: Implications for Social and Economic Research.”</span> <em>AEA Papers and Proceedings</em> 109 (May): 403–8. <a href="https://doi.org/10.1257/pandp.20191107">https://doi.org/10.1257/pandp.20191107</a>.
</div>
<div id="ref-10.1371/journal.pone.0249833" class="csl-entry">
Schafer, K. M., G. Kennedy, A. Gallyer, and P. Resnik. 2021. <span>“A Direct Comparison of Theory-Driven and Machine Learning Prediction of Suicide: A Meta-Analysis.”</span> <em>PLOS ONE</em> 16 (4): 1–23. <a href="https://doi.org/10.1371/journal.pone.0249833">https://doi.org/10.1371/journal.pone.0249833</a>.
</div>
<div id="ref-43146" class="csl-entry">
Sculley, D., G. Holt, D. Golovin, E. Davydov, T. Phillips, D. Ebner, V. Chaudhary, and M. Young. 2014. <span>“Machine Learning: The High Interest Credit Card of Technical Debt.”</span> In <em>SE4ML: Software Engineering for Machine Learning (NIPS 2014 Workshop)</em>.
</div>
<div id="ref-tsakalidis-etal-2022-overview" class="csl-entry">
Tsakalidis, A., J. Chim, I. M. Bilal, A. Zirikly, D. Atzil-Slonim, F. Nanni, P. Resnik, et al. 2022. <span>“Overview of the <span>CLP</span>sych 2022 Shared Task: Capturing Moments of Change in Longitudinal User Posts.”</span> In <em>Proceedings of the Eighth Workshop on Computational Linguistics and Clinical Psychology</em>, 184–98. Seattle, USA: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/2022.clpsych-1.16">https://doi.org/10.18653/v1/2022.clpsych-1.16</a>.
</div>
<div id="ref-van_riper" class="csl-entry">
Van Riper, D., T. Kugler, J. Schroeder, and S. Ruggles. 2020. <span>“Differential Privacy and Racial Residential Segregation.”</span> In <em>2020 APPAM Fall Research Conference</em>.
</div>
<div id="ref-4138bca6-f7b7-3af8-a96c-5e2544823c5c" class="csl-entry">
Williams, H. 2012. <span>“Innovation Inducement Prizes: Connecting Research to Policy.”</span> <em>Journal of Policy Analysis and Management</em> 31 (3): 752–76. <a href="http://www.jstor.org/stable/41653827">http://www.jstor.org/stable/41653827</a>.
</div>
</div></section></div> ]]></description>
  <category>Machine learning</category>
  <category>Natural language processing</category>
  <category>Public policy</category>
  <category>Health and wellbeing</category>
  <guid>https://realworlddatascience.net/case-studies/posts/2023/08/21/06-value-of-competitions.html</guid>
  <pubDate>Mon, 21 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/case-studies/posts/2023/08/21/images/06-value-of-competitions.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Food for Thought: Second place winners – DeepFFTLink</title>
  <dc:creator>Yang Wu, Aishwarya Budhkar, Kai Zhang, Xuhong Zhang, and Xiaozhong Liu</dc:creator>
  <link>https://realworlddatascience.net/case-studies/posts/2023/08/21/04-second-place-winners.html</link>
  <description><![CDATA[ 




<p>DeepFFTLink team members: Yang Wu and Kai Zhang are PhD students at Worcester Polytechnic Institute. Aishwarya Budhkar is a PhD student at Indiana University Bloomington. Xuhong Zhang is an assistant professor at Indiana University Bloomington. Xiaozhong Liu is an associate professor at Worcester Polytechnic Institute.</p>
<section id="perspective-on-the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="perspective-on-the-challenge">Perspective on the challenge</h2>
<p>Text matching is an essential task in natural language processing <span class="citation" data-cites="DBLP:journals/corr/PangLGXWC16">(NLP, Pang et al. 2016)</span>, while record linkage across different sources is an essential task in data science. Machine learning techniques allow people to combine data faster and cheaper than using manual linkage. However, in the context of the Food for Thought challenge, existing methods for matching universal product codes (UPCs) to ensemble codes (ECs) require every UPC to be compared with every EC code (Figure 1a). Such approaches can be computationally expensive in the training process when data is noisy. Here, we propose an ensemble model with a category-based adapter to tackle this problem, drawing on the category information included in UPC and EC data. The category-based adapter allows UPCs to be first matched with only a small and reliable set of ECs (Figure 1b). Then, an ensemble model will be deployed to make predictions for UPC-EC matching. Our proposed approach can achieve competitive performance compared with state-of-the-art models.</p>
<div class="quarto-layout-panel" style="padding-top: 1em; margin-bottom: 0;">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-figure quarto-figure-center" style="flex-basis: 50.0%;justify-content: center;">
<figure class="figure">
<p><a href="images/pt4-fig1a.png"><img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/images/pt4-fig1a.png" class="img-fluid figure-img"></a></p>
<figcaption class="figure-caption">(a)</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center" style="flex-basis: 50.0%;justify-content: center;">
<figure class="figure">
<p><a href="images/pt4-fig1b.png"><img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/images/pt4-fig1b.png" class="img-fluid figure-img"></a></p>
<figcaption class="figure-caption">(b)</figcaption>
</figure>
</div>
</div>
</div>
<div class="figure-caption">
<p><strong>Figure 1:</strong> A toy example of our method. Panel (a) shows the traditional matching method, while (b) is our proposed ensemble model with category-based adapter. With the help of the adapter, UPC 1 only needs to be matched with EC 1 and EC 3.</p>
</div>
</section>
<section id="our-approach" class="level2">
<h2 class="anchored" data-anchor-id="our-approach">Our approach</h2>
<p>We propose a two-step framework to address this problem. To begin with, we use a category-based adapter to get reliable candidate ECs for each UPC. Then, an ensemble model <span class="citation" data-cites="10.1007/3-540-45014-9_1">(Dietterich 2000)</span> is deployed to make a prediction for each UPC-EC pair.</p>
<section id="category-based-adapter" class="level5">
<h5 class="anchored" data-anchor-id="category-based-adapter">Category-based adapter</h5>
<p>By using 2015–2016 UPC-EC data, we created a knowledge base, which is a UPC category–EC pair-wised table for generating candidate ECs. Within this setting, each UPC category is, on average, related to only 32 ECs. This knowledge base is then used as context to further filter the candidate ECs. Note that there are some new ECs generated year by year, which can also be part of the potential ECs in the UPC-EC matching task, since the contextual information of new ECs does not exist in our knowledge base.</p>
</section>
<section id="ensembled-model" class="level5">
<h5 class="anchored" data-anchor-id="ensembled-model">Ensembled model</h5>
<p>We ensemble the base-string match and BERT models. BERT is a deep learning model for natural language processing <span class="citation" data-cites="DBLP:journals/corr/abs-1810-04805">(Devlin et al. 2018)</span>. In the base-string match model, we used the Term Frequency-Inverse Document Frequency (TFIDF) of each UPC and EC description as features to calculate a pairwise cosine similarity, which is a distance between instances. Meanwhile, we used features extracted from UPC and EC descriptions to fine-tune the BERT base model and calculated the cosine similarity of embeddings between each UPC and EC. Then we rank ECs based on their similarity scores with the UPC.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pt4-fig2.png"><img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/images/pt4-fig2.png" class="img-fluid figure-img"></a></p>
</figure>
</div>
<div class="figure-caption">
<p><strong>Figure 2:</strong> The framework of our proposed model. A two-step strategy is used to make the final prediction.</p>
</div>
<div class="callout callout-style-simple callout-note" style="margin-top: 2rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Find the code in the <a href="https://github.com/realworlddatascience/realworlddatascience.github.io/tree/main/case-studies/posts/2023/08/21/_code">Real World Data Science GitHub repository</a>.</p>
</div>
</div>
</div>
</section>
</section>
<section id="our-results" class="level2">
<h2 class="anchored" data-anchor-id="our-results">Our results</h2>
<p>We randomly selected 500 samples from the 2017–2018 UPC-EC data to train the ensembled weight for each model. Two functions were adapted to make a fusion of base-string and BERT models:</p>
<p><span id="eq-first"><img src="https://latex.codecogs.com/png.latex?%0AC%20=%20a%20*%20X%20+%20b%20*%20Y%20%20%0A%5Ctag%7B1%7D"></span></p>
<p><span id="eq-second"><img src="https://latex.codecogs.com/png.latex?%0AC%20=%20%20a%20*%20log(X)%20+%20b%20*%20log(Y)%20%5Ctext%7B.%20%7D%0A%5Ctag%7B2%7D"></span></p>
<p><img src="https://latex.codecogs.com/png.latex?C"> denotes the final confidence score. <img src="https://latex.codecogs.com/png.latex?X"> and <img src="https://latex.codecogs.com/png.latex?Y"> represent <em>base_string_similarity_score</em> and <em>BERT_similarity_score</em>, respectively. <img src="https://latex.codecogs.com/png.latex?a"> and <img src="https://latex.codecogs.com/png.latex?b"> are corresponding model weights for base_string and BERT models.</p>
<p>A better Success@5 is achieved with function (1). The ensembled weights for the base-string model and BERT model are 0.738 and 0.262, respectively. The experiment result indicates that the base_string model contributes more than the BERT model when the ensemble model makes predictions. The prediction result for the 2017–2018 data is:</p>
<ul>
<li>Success@5: 0.727</li>
<li>NDCG@5: 0.528</li>
</ul>
<p>Computation time is 6 hours.</p>
</section>
<section id="future-work" class="level2">
<h2 class="anchored" data-anchor-id="future-work">Future work</h2>
<p>Our next step will focus on adding the newly generated EC data into our knowledge base, which allows the model to be more stable to make predictions for UPC-EC matching. Our model is an unsupervised method, which does not need labels for each instance. We use cosine similarity to rank the matches, so no labels are needed in the training process. However, our future work will try to label some instances to handle the UPC-EC matching task in a supervised manner.</p>
</section>
<section id="lessons-learned" class="level2">
<h2 class="anchored" data-anchor-id="lessons-learned">Lessons learned</h2>
<ol type="1">
<li><p><strong>If the data is not complex, simple models may outperform complex models.</strong> For example, in our experiment, we found that the base-string model outperforms single RoBERTa <span class="citation" data-cites="DBLP:journals/corr/abs-1907-11692">(Liu et al. 2019)</span> or BERT models. However, our ensemble model can outperform each individual model since model fusion allows information aggregation from multiple models.</p></li>
<li><p><strong>Multi-label models may not work well on UPC-EC data.</strong> In our early work, we tried to consider the UPC-EC matching task as a multi-label problem, e.g., we labeled each EC as a binary label which indicated whether the EC was an appropriate match or not. We mapped UPC and EC pairs into a multi-label table. However, we find that the UPC and EC keeps a one-to-one relation for most UPCs. The model performance of a multi-label model, i.e., Label-Specific Attention Network <span class="citation" data-cites="xiao-etal-2019-label">(LSAN, Xiao et al. 2019)</span>, is lower than base-string model on both Success@5 and NDCG@5 metrics.</p></li>
</ol>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../case-studies/posts/2023/08/21/03-first-place-winners.html">← Part 3: First place winners</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../case-studies/posts/2023/08/21/05-third-place-winners.html">Part 5: Third place winners →</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Yang Wu</strong> and <strong>Kai Zhang</strong> are PhD students, and <strong>Xiaozhong Liu</strong> is an associate professor at Worcester Polytechnic Institute. <strong>Aishwarya Budhkar</strong> is a PhD student and <strong>Xuhong Zhang</strong> is an assistant professor at Indiana University Bloomington.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Yang Wu, Aishwarya Budhkar, Kai Zhang, Xuhong Zhang, and Xiaozhong Liu
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@hansonluu?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Hanson Lu</a> on <a href="https://unsplash.com/photos/sq5P00L7lXc?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Wu, Yang, Aishwarya Budhkar, Kai Zhang, Xuhong Zhang, and Xiaozhong Liu. 2023. “Food for Thought: Second place winners – DeepFFTLink.” Real World Data Science, August 21, 2023. <a href="https://realworlddatascience.net/viewpoints/case-studies/posts/2023/08/21/04-second-place-winners.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-DBLP:journals/corr/abs-1810-04805" class="csl-entry">
Devlin, J., M.-W. Chang, K. Lee, and K. Toutanova. 2018. <span>“<span>BERT:</span> Pre-Training of Deep Bidirectional Transformers for Language Understanding.”</span> <em>CoRR</em> abs/1810.04805. <a href="http://arxiv.org/abs/1810.04805">http://arxiv.org/abs/1810.04805</a>.
</div>
<div id="ref-10.1007/3-540-45014-9_1" class="csl-entry">
Dietterich, T. G. 2000. <span>“Ensemble Methods in Machine Learning.”</span> In <em>Multiple Classifier Systems</em>, 1–15. Berlin, Heidelberg: Springer Berlin Heidelberg.
</div>
<div id="ref-DBLP:journals/corr/abs-1907-11692" class="csl-entry">
Liu, Y., M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov. 2019. <span>“RoBERTa: <span>A</span> Robustly Optimized <span>BERT</span> Pretraining Approach.”</span> <em>CoRR</em> abs/1907.11692. <a href="http://arxiv.org/abs/1907.11692">http://arxiv.org/abs/1907.11692</a>.
</div>
<div id="ref-DBLP:journals/corr/PangLGXWC16" class="csl-entry">
Pang, L., Y. Lan, J. Guo, J. Xu, S. Wan, and X. Cheng. 2016. <span>“Text Matching as Image Recognition.”</span> <em>CoRR</em> abs/1602.06359. <a href="http://arxiv.org/abs/1602.06359">http://arxiv.org/abs/1602.06359</a>.
</div>
<div id="ref-xiao-etal-2019-label" class="csl-entry">
Xiao, L., X. Huang, B. Chen, and L. Jing. 2019. <span>“Label-Specific Document Representation for Multi-Label Text Classification.”</span> In <em>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</em>, 466–75. Hong Kong, China: Association for Computational Linguistics. <a href="https://doi.org/10.18653/v1/D19-1044">https://doi.org/10.18653/v1/D19-1044</a>.
</div>
</div></section></div> ]]></description>
  <category>Machine learning</category>
  <category>Natural language processing</category>
  <category>Public policy</category>
  <category>Health and wellbeing</category>
  <guid>https://realworlddatascience.net/case-studies/posts/2023/08/21/04-second-place-winners.html</guid>
  <pubDate>Mon, 21 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/case-studies/posts/2023/08/21/images/04-deepfftlink.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>The Food for Thought Challenge: Using AI to support evidence-based food and nutrition policy</title>
  <dc:creator>Brian Tarran and Julia Lane</dc:creator>
  <link>https://realworlddatascience.net/case-studies/posts/2023/08/21/00-food-for-thought.html</link>
  <description><![CDATA[ 




<p>There’s a saying: “You are what you eat.” Its meaning is somewhat open to interpretation, as with many such sayings, but it is typically used to make the point that if you want to <em>be</em> well, you need to eat well. Nutrition scientists and dieticians spend their careers trying to figure out what “eating well” looks like – the foods the human body needs, in what quantities, and how best to consume them. Their research informs advice and guidance issued by health professionals and governments. Ultimately, though, the choice of what to eat falls to us – individuals and families – and our choices are often determined by our tastes, the availability of foodstuffs in our local stores, their price and affordability.</p>
<p>So, what exactly <em>do</em> we eat? Answers come from a variety of sources. In the United States, there are dietary recall studies such as the <a href="https://www.cdc.gov/nchs/nhanes/index.htm">National Health and Nutrition Examination Survey</a>, which asks a sample of respondents to report their food and beverage consumption over a set period of time. There are also organisations like <a href="https://www.iriworldwide.com/en-gb">IRI</a> that collect point-of-sale data from retail stores on the actual food and drink being sold to consumers. By and large, this information comes from barcodes on product packaging being scanned at checkouts, so it is often referred to as “scanner data”.</p>
<p>This data – from dietary recall studies and retail scanners – is valuable: once we know what people are eating, we can check the nutritional content of those foods and build up a picture of what the diet of a typical individual or family looks like and how it compares to the diet recommended by doctors and policymakers. And, if we know what other foodstuffs are available, how much they cost, and the nutritional value of those items, we can work out how much families need to spend, and on what, in order to eat well and, hopefully, be well.</p>
<p>Figuring all this out is where something called the Purchase to Plate Crosswalk (PPC) comes in. It’s a key tool for understanding the “<a href="https://www.sciencedirect.com/science/article/pii/S0889157521005445">healthfulness of retail food purchases</a>” and it does this by linking IRI scanner data on what people buy with data on the nutritional content of those foods, as recorded in the US Department of Agriculture’s Food and Nutrient Database for Dietary Studies (FNDDS). But there’s a catch: scanner data is collected about hundreds of thousands of food products, whereas the FNDDS has nutritional profile information for only a few thousand items. Linking these two datasets therefore gives rise to a one-to-many matching problem – a problem that takes several hundred person-hours to resolve.</p>
<p>What if machine learning can help? That question inspired a competition, the Food for Thought Challenge, organized by the Coleridge Initiative, a nonprofit organization working with governments to ensure that data are more effectively used for public decision-making. Researchers and data scientists were invited to use machine learning and natural language processing to more efficiently link data on supermarket products to nutrient databases.</p>
<p>This collection of articles tells the story of the <a href="https://coleridgeinitiative.org/projects/food-for-thought">Food for Thought Challenge</a>. We begin by exploring the <a href="../../../../../case-studies/posts/2023/08/21/01-purchase-to-plate.html">policy issues</a> that drive the development of the PPC – the need to understand the national diet, developing healthy diet plans, and costing up those plans – and the issues posed by record linkage. Next, we learn about <a href="../../../../../case-studies/posts/2023/08/21/02-competition-design.html">the nature of the challenge and the structure of the competition in more detail</a>, and then the <a href="../../../../../case-studies/posts/2023/08/21/03-first-place-winners.html">three</a> <a href="../../../../../case-studies/posts/2023/08/21/04-second-place-winners.html">winning</a> <a href="../../../../../case-studies/posts/2023/08/21/05-third-place-winners.html">teams</a> walk us through their solutions. We end the collection with some closing thoughts on <a href="../../../../../case-studies/posts/2023/08/21/06-value-of-competitions.html">the value of competitions for addressing data scientific challenges in the public sector</a>.</p>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../case-studies/index.html">Find more case studies</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../case-studies/posts/2023/08/21/01-purchase-to-plate.html">Part 1: The Purchase to Plate Suite →</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Brian Tarran</strong> is editor of Real World Data Science, and head of data science platform at the Royal Statistical Society.
</dd>
<dd>
<p><strong>Julia Lane</strong> is a professor at the NYU Wagner Graduate School of Public Service and a NYU Provostial Fellow for Innovation Analytics. She co-founded the Coleridge Initiative, whose goal is to use data to transform the way governments access and use data for the social good through training programs, research projects and a secure data facility. She recently served on the Advisory Committee on Data for Evidence Building and the National AI Research Resources Task Force.</p>
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society and Julia Lane
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@melaniesylim?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Melanie Lim</a> on <a href="https://unsplash.com/photos/246b6c6IeC0?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian, and Julia Lane. 2023. “The Food for Thought Challenge: Using AI to support evidence-based food and nutrition policy.” Real World Data Science, August 21, 2023. <a href="https://realworlddatascience.net/viewpoints/case-studies/posts/2023/08/21/00-food-for-thought.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Machine learning</category>
  <category>Natural language processing</category>
  <category>Public policy</category>
  <category>Health and wellbeing</category>
  <guid>https://realworlddatascience.net/case-studies/posts/2023/08/21/00-food-for-thought.html</guid>
  <pubDate>Mon, 21 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/case-studies/posts/2023/08/21/images/00-shopping.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Food for Thought: The importance of the Purchase to Plate Suite</title>
  <dc:creator>Andrea Carlson and Thea Palmer Zimmerman</dc:creator>
  <link>https://realworlddatascience.net/case-studies/posts/2023/08/21/01-purchase-to-plate.html</link>
  <description><![CDATA[ 




<div class="callout callout-style-default callout-important callout-titled" style="margin-top: 0;">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Disclaimer
</div>
</div>
<div class="callout-body-container callout-body">
<p>The findings and conclusions in this publication are those of the authors and should not be construed to represent any official USDA or US Government determination or policy. This research was supported by the US Department of Agriculture’s Economic Research Service and Center for Nutrition, Policy and Promotion. Findings should not be attributed to Circana (formerly IRI).</p>
</div>
</div>
<p>About 600,000 <a href="https://www.cdc.gov/nchs/fastats/leading-causes-of-death.htm">deaths per year in the United States</a> are related to chronic diseases that are linked to poor dietary choices. Many other individuals suffer from diet-related health conditions, which may limit their ability to work, learn, and be physically active <span class="citation" data-cites="usda_2020">(US Department of Agriculture and US Department of Health and Human Services 2020)</span>. In recognition of the link between diet and health, in 1974 the Senate Select Committee on Nutrition and Human Needs, originally formed to eliminate hunger, expanded its focus to improving eating habits, nutrition policy and the national diet. Since 1980, the Dietary Guidelines for Americans have been released every five years by the US Departments of Agriculture (USDA) and Health and Human Services (DHHS). The guidelines present “<a href="https://www.dietaryguidelines.gov/">advice on what to eat and drink to meet nutrient needs, promote health, and prevent disease</a>”.</p>
<p>Because there can be economic and social barriers to maintaining a healthy diet, USDA promotes <a href="https://www.usda.gov/nutrition-security">Food and Nutrition Security</a> so that everyone has consistent and equitable access to healthy, safe, and affordable foods that promote optimal health and well-being. A set of data tools called the <a href="https://www.ers.usda.gov/data-products/purchase-to-plate/">Purchase to Plate Suite</a> (PPS) supports these goals by enabling the update of the <a href="https://www.fns.usda.gov/snap/thriftyfoodplan#:~:text=What%20is%20the%20Thrifty%20Food,lowest%20cost%20of%20the%20four.">Thrifty Food Plan</a> (TFP), which estimates how much a budget-conscious family of four needs to spend on groceries to ensure a healthy diet. The TFP market basket – consisting of the specific amounts of various food categories required by the plan – forms the basis of the maximum allotment for the Supplemental Nutrition Assistance Program (SNAP, formerly known as the “Food Stamps” program), which provided financial support towards the cost of groceries for <a href="https://www.fns.usda.gov/pd/supplemental-nutrition-assistance-program-snap">over 41 million individuals in almost 22 million households in fiscal year 2022</a>.</p>
<p>The 2018 Farm Act (Agriculture Improvement Act of 2018) requires that USDA reevaluate the TFP every five years using current food composition, consumption patterns, dietary guidance, and food prices, and using approved scientific methods. USDA’s Economic Research Service (ERS) was charged with estimating the current food prices using retail food scanner data <span class="citation" data-cites="levin_et_al_2018 muth_et_al_2016">(Levin et al. 2018; Muth et al. 2016)</span> and utilized the PPS for this task. The most recent TFP update was released in August 2021 and the revised cost of the market basket was the first non-inflation adjustment increase in benefits for SNAP in over 40 years <span class="citation" data-cites="thrifty_food_plan_2021">(US Department of Agriculture 2021)</span>.</p>
<p>The PPS combines datasets to enhance research related to the economics of food and nutrition. There are four primary components of the suite:</p>
<ul>
<li>Purchase to Plate Crosswalk (PPC),</li>
<li>Purchase to Plate Price Tool (PPPT),</li>
<li>Purchase to Plate National Average Prices (PP-NAP) for the National Health and Nutrition Examination Survey (NHANES), and</li>
<li>Purchase to Plate Ingredient Tool (PPIT).</li>
</ul>
<p>The PPC allows researchers to measure the healthfulness of store purchases. On average <a href="https://www.ers.usda.gov/data-products/foodaps-national-household-food-acquisition-and-purchase-survey/summary-findings/#calories">US consumers acquire about 75% of their calories from retail stores</a>, and there are a number of studies linking the availability of foods at home to the healthfulness of the overall diet <span class="citation" data-cites="gattshall_et_al_2008 hanson_et_al_2005">(e.g., Gattshall et al. 2008; Hanson et al. 2005)</span>. Thus, understanding the healthfulness of store purchases allows us to understand differences in consumers who purchase healthy versus less healthy foods, and may contribute to better policies that promote healthier food purchases. While healthier diets are linked to a lower risk of disease outcomes <span class="citation" data-cites="REEDY2014881">(Reedy et al. 2014)</span>, other factors such as health care access may also be contributors <span class="citation" data-cites="cleary_et_al_2022">(Cleary, Liu, and Carlson 2022)</span>. The PPC also forms the basis of the price tool, PPPT – which allows researchers to estimate custom prices for dietary recall studies – and a new ERS data product, the <a href="https://www.ers.usda.gov/data-products/purchase-to-plate/">PP-NAP</a>. The national average prices from PP-NAP are used in reevaluating the TFP. By using the PP-NAP with 24-hour dietary recall information from surveys such as What We Eat in America (<a href="https://www.ars.usda.gov/northeast-area/beltsville-md-bhnrc/beltsville-human-nutrition-research-center/food-surveys-research-group/docs/wweianhanes-overview/">WWEIA</a>) – the dietary component of the nationally representative <a href="https://www.cdc.gov/nchs/nhanes/index.htm">National Health and Nutrition Examination Survey</a>(NHANES)<sup>1</sup> – researchers can examine the relationship between the cost of food, dietary intake, and chronic diseases linked to poor diets. The price estimates also allow researchers to develop cost-effective healthy diets such as <a href="https://www.myplate.gov/myplate-kitchen/recipes">MyPlate Kitchen</a>. The final component of the Purchase to Plate Suite, the ingredient tool (PPIT), breaks dietary recall-reported foods back into purchasable ingredients, based on US retail food purchases. The PPIT is also used in the revaluation of the TFP, and by researchers who want to look at the relationship between reported ingestion of grocery items, cost and disease outcomes using WWEIA/NHANES. More information on the development of the PPC is available in two papers by Carlson et al. <span class="citation" data-cites="carlson_et_al_2019 carlson_et_al_2022">(2019, 2022)</span>.</p>
<p>The Food for Thought competition aimed to support the development of the PPC – and thus policy-oriented research – by linking retail food scanner data to the USDA nutrition data used to analyze NHANES dietary recall data, specifically the Food and Nutrient Database for Dietary Studies (FNDDS) <span class="citation" data-cites="fndds_2018 fndds_2020">(2018, 2020)</span>. In particular, the competition set out to use artificial intelligence (AI) to reduce human resources in creating the links for the PPC, while still maintaining the high-quality standards required for reevaluating the TFP and for data published by ERS (which is one of 13 Principle Statistical Agencies in the United States Federal Government).</p>
<section id="methods-used-to-date" class="level2">
<h2 class="anchored" data-anchor-id="methods-used-to-date">Methods used to date</h2>
<p>On the surface, the linking process may appear simple: both the FNDDS and retail food scanner data are databases of food. But the scanner data are produced for market research, and the FNDDS for dietary studies. The scanner data include about 350,000 items with sales each year, while the FNDDS has only 10,000–15,000 items. Scanner data relates to specific products, while FNDDS items are often more general. Both datasets have different hierarchical structures – the FNDDS hierarchy is based around major food groups: dairy; meat, poultry and seafood; eggs; nuts and legumes; grains; fruits; vegetables; fats and oils; and sugars, sweets, and beverages. Items fall into the groups regardless of preparation method or form. That is, broccoli prepared from frozen and from fresh both appear in the vegetable group, and for some fruits and vegetables, the fresh, frozen, canned and dried form are the same FNDDS item. Vegetable-based mixed dishes, such as broccoli and carrot stir-fry or soup, are also classified in the vegetable group. On the other hand, the scanner data classifies foods by grocery aisle. That is, the fresh and frozen broccoli are classified in different areas: produce and frozen vegetables. Similarly, when sold as a prepared food, the broccoli and carrot stir-fry may be found in the frozen entries, as a kit in either the frozen or produce section, refrigerated foods, or all of these.</p>
<p>To allow researchers to import the FNDDS nutrient data into the scanner data, a one-to-many match between FNDDS and scanner data items was needed. The food descriptions in the scanner data include brand names and package sizes and are written as a consumer would pronounce them – e.g., fresh and crisp broccoli florets, ready-cut, 10 oz – versus a more general FNDDS description such as “Broccoli, raw”. (Also linked to the “Broccoli, raw” code would be broccoli sold with stems attached, broccoli spears, and any other way raw broccoli is sold.) In the scanner data, the Universal Product Code (UPC) and the European Article Number (EAN) can link items between tables within the scanner data, as well as between datasets of grocery items, such as the USDA Global Branded Foods Product Database, a component of <a href="https://fdc.nal.usda.gov/index.html">USDA’s Food Data Central</a>. However, these codes are not related to the FNDDS codes, or any other column within the FNDDS. In other words, before development of the PPC, there were no established linking identifiers.</p>
<p>Figure 1 shows the process USDA uses to develop matches between scanner data and FNDDS.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pt1-fig1.png"><img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/images/pt1-fig1.png" class="img-fluid figure-img" width="700"></a></p>
</figure>
</div>
<div class="figure-caption">
<p><strong>Figure 1:</strong> Process currently used to create the matches between the USDA Food and Nutrient Database for Dietary Studies (FNDDS) and the retail scanner data (labelled “IRI” for the IRI InfoScan and Consumer Network) product dictionaries. Source: Author provided.</p>
</div>
<p>We start the linking process by categorizing the scanner data items into homogeneous groups to make the first round of automated matching more efficient. To save time, we use the second lowest hierarchical category in the scanner data which generally divides items within a grocery aisle into homogenous groups such as produce, canned beans, baking mixes, and bread. Once the linking categories for scanner data are established, we select appropriate items from the FNDDS. Since the FNDDS is highly structured, this selection is usually straightforward.</p>
<p>Our next step is to use semantic matching to create a search table that aligns similar terms within the IRI product dictionary and FNDDS. This first requires that we extract attributes from the FNDDS descriptions into fields similar to those in the scanner data product dictionary. The FNDDS descriptions are found across multiple columns because they are added as the need arises to provide examples of brand names or alternative descriptions of foods which help code the foods WWEIA participants report eating. We manually create matching tables that link terms used in FNDDS to those used in the scanner data, organized by the fields defined in the restructured FNDDS. We then use this table as the basis of a probabilistic matching process. For example, when linking the produce group, “fresh” in the scanner data would be aligned with “raw” and “prepared from fresh” and NOT “prepared from frozen” in the FNDDS, and “broccoli florets” would also be aligned with “raw” and “broccoli”. Since the FNDDS is designed to code the foods individuals report eating, many of the foods in the FNDDS are already prepared and result in descriptions such as “broccoli, steamed, prepared from fresh” or “broccoli, boiled, prepared from frozen”.</p>
<p>Once the linking table is established, the probabilistic match process returns the single best possible match for each item in the scanner data. For example, a match between fresh broccoli florets and frozen broccoli would have a lower probability score than “broccoli, raw”. Because these matches form the basis of major USDA policies, we cannot accept an error rate of more than 5 percent, and lower is preferred. To reach that goal, nutritionists review every match to make sure the probabilistic match did not return a match between cauliflower florets and fresh broccoli, say, or that a broccoli and carrot stir-fry is not matched to a dish with broccoli, carrots, and chicken. The correct matches, such as the one between fresh broccoli florets and raw broccoli, are set aside while the items with an incorrect match, such as cauliflower florets and the broccoli and carrot stir-fry, are used to revise the search table. Revisions might include adding (NOT chicken) to the broccoli and carrot stir-fry dish. Mixed dishes — such as the broccoli and carrot stir-fry — pose particular challenges because there are a wide variety of similar products available in the grocery store. After a few rounds of revising the search table and running the probabilistic match process, it is more efficient to use a manual match, established by one nutritionist and reviewed by another, after which the match is assumed to be correct.</p>
<p>The process improved with each new wave of FNDDS and IRI data. Our first creation of the PPC linked the FNDDS 2011/12 to the 2013 IRI retail scanner data. Subsequent waves started with the previous search table and resulting matches were reviewed by nutritionists. We also used more fields in the IRI product dictionary to create the homogeneous linking groups and made modifications to these groups with each wave. During each wave we experimented with the number of rounds of probabilistic matching that was the most cost effective. For some linking groups it took less human time to manually match from the start, while for other groups it was more efficient to do multiple rounds of improvements to the search table. Starting with the most recent wave (matching FNDDS 2017/18 to the 2017 and 2018 retail scanner data), we assumed previous matches appearing in the newer data were correct. Although this assumption was good for most matches, a review demonstrated the need to review previous matches prior to removing the item from the list of scanner data items needing FNDDS matches. In the future we intend to explore methods developed by the participants of the Food for Thought competition.</p>
</section>
<section id="linking-challenges" class="level2">
<h2 class="anchored" data-anchor-id="linking-challenges">Linking challenges</h2>
<p>An ongoing challenge to the linking problem is that both the scanner data and the FNDDS undergo substantive changes each year, meaning that both the previous matches and search tables need to be reviewed and revised with each new effort, as tables that work with one cycle of FNDDS and scanner data will need revisions to use with the next cycle. Changes to the scanner data that impact our current method include dropped and added items, data corrections, and revisions to the categories that form the basis of the homogeneous linking groups. In addition, there are errors such as incorrect food descriptions, conflicting package size information, and changes in the item description from year to year. Since the FNDDS is designed to support dietary recall studies, revisions reflect both changes to available foods and the level of detail respondents can provide. These revisions result in dropped/added food codes, changes to food descriptions that impact which scanner data items match to the FNDDS items, and revisions to recipes used in the nutrient coding which impacts the number of retail ingredients available in the FNDDS.</p>
<p>Of the four parts of the PPS, establishing the matches is the most time-consuming task and constitutes at least 60 percent of the total budget. In the most recent round, we had 168 categories and each one went through 2-3 automated matching rounds; after each round, nutritionists spent an average of two hours reviewing the matches. This adds up to somewhere between 670 and 1,000 hours of review time. After the automated review, manual matching requires an additional 300 hours. Reducing the amount of time required to establish matches and link the FNDDS and retail scanner datasets may lead to significant time savings, resulting in faster data availability. That, in turn, could allow more timely policy-based research, and the mandated revision of the Thrifty Food Plan can continue with the most recent food price data.</p>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../case-studies/posts/2023/08/21/00-food-for-thought.html">← Introduction</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../case-studies/posts/2023/08/21/02-competition-design.html">Part 2: Competition design →</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Andrea Carlson</strong> is an agricultural economist in the Food Markets Branch of the Food Economics Division in USDA’s Economic Research Service. She is the project lead for the Purchase to Plate Suite, which allows users to import USDA nutrient and food composition data into retail food scanner data acquired by USDA and estimate individual food prices for dietary intake data.
</dd>
<dd>
<p><strong>Thea Palmer Zimmerman</strong> is a senior study director and research nutritionist at Westat.</p>
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Image credit</dt>
<dd>
Thumbnail photo by <a href="https://unsplash.com/@neonbrand?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Kenny Eliason</a> on <a href="https://unsplash.com/photos/SvhXD3kPSTY?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Carlson, Andrea, and Thea Palmer Zimmerman. 2023. “Food for Thought: The importance of the Purchase to Plate Suite.” Real World Data Science, August 21, 2023. <a href="https://realworlddatascience.net/viewpoints/case-studies/posts/2023/08/21/01-purchase-to-plate.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>
</section>
<section id="acknowledgements" class="level2">
<h2 class="anchored" data-anchor-id="acknowledgements">Acknowledgements</h2>
<p>The research presented in this compendium supports the Purchase to Plate Suite of data products. Carlson has been privileged to both develop and lead this project over the course of her career, but it is not a solo project. Many thanks to the Linkages Team from USDA’s Economic Research Service (Christopher Lowe, Mark Denbaly Elina Page, and Catherine Cullinane Thomas) the Center for Nutrition Policy and Promotion (Kristin Koegel, Kevin Kuczynski, Kevin Meyers Mathieu, TusaRebecca Pannucci), and our contractor Westat, Inc.&nbsp;(Thea Palmer Zimmerman, Carina E. Tornow, Amber Brown McFadden, Caitlin Carter, Viji Narayanaswamy, Lindsay McDougal, Elisha Lubar, Lynnea Brumby, Raquel Brown, and Maria Tamburri). Many others have supported this project over the years.</p>



</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-carlson_et_al_2019" class="csl-entry">
Carlson, A. C., E. T. Page, T. P. Zimmerman, C. E. Tornow, and S. Hermansen. 2019. <span>“Linking USDA Nutrition Databases to IRI Household-Based and Store-Based Scanner Data.”</span> Technical bulletin 1952. US Department of Agriculture, Economic Research Service.
</div>
<div id="ref-carlson_et_al_2022" class="csl-entry">
Carlson, A. C., C. E. Tornow, E. T. Page, A. Brown McFadden, and T. Palmer Zimmerman. 2022. <span>“Development of the Purchase to Plate Crosswalk and Price Tool: Estimating Prices for the National Health and Nutrition Examination Survey (NHANES) Foods and Measuring the Healthfulness of Retail Food Purchases.”</span> <em>Journal of Food Composition and Analysis</em> 106: 104344. <a href="https://doi.org/10.1016/j.jfca.2021.104344">https://doi.org/10.1016/j.jfca.2021.104344</a>.
</div>
<div id="ref-cleary_et_al_2022" class="csl-entry">
Cleary, R., Y. Liu, and A. Carlson. 2022. <span>“Differences in the Distribution of Nutrition Between Households Above and Below Poverty.”</span> Agricultural and Applied Economic Association Annual Meeting. Anaheim, CA. <a href="https://ageconsearch.umn.edu/record/322267">https://ageconsearch.umn.edu/record/322267</a>.
</div>
<div id="ref-gattshall_et_al_2008" class="csl-entry">
Gattshall, M. L., J. A. Shoup, J. A. Marshall, L. A. Crane, and P. A. Estabrooks. 2008. <span>“Validation of a Survey Instrument to Assess Home Environments for Physical Activity and Healthy Eating in Overweight Children.”</span> <em>International Journal of Behavioral Nutrition and Physical Activity</em> 5 (3). <a href="https://doi.org/10.1186/1479-5868-5-3">https://doi.org/10.1186/1479-5868-5-3</a>.
</div>
<div id="ref-hanson_et_al_2005" class="csl-entry">
Hanson, N. I., D. Neumark-Sztainer, M. E. Eisenberg, M. Story, and M. Wall. 2005. <span>“Associations Between Parental Report of the Home Food Environment and Adolescent Intakes of Fruits, Vegetables and Dairy Foods.”</span> <em>Public Health Nutrition</em> 8 (1). <a href="https://doi.org/10.1079/PHN2005661">https://doi.org/10.1079/PHN2005661</a>.
</div>
<div id="ref-levin_et_al_2018" class="csl-entry">
Levin, D., D. Noriega, C. Dicken, A. Okrent, M. Harding, and M. Lovenheim. 2018. <span>“Examining Store Scanner Data: A Comparison of the IRI Infoscan Data with Other Data Sets, 2008-12.”</span> Technical bulletin 1949. US Department of Agriculture, Economic Research Service.
</div>
<div id="ref-muth_et_al_2016" class="csl-entry">
Muth, M. K., M. Sweitzer, D. Brown, K. Capogrossi, S. Karns, D. Levin, A. Okrent, P. Siegel, and C. Zhen. 2016. <span>“Understanding IRI Household-Based and Store-Based Scanner Data.”</span> Technical bulletin 1942. US Department of Agriculture, Economic Research Service.
</div>
<div id="ref-REEDY2014881" class="csl-entry">
Reedy, J., S. M. Krebs-Smith, P. E. Miller, A. D. Liese, L. L. Kahle, Y. Park, and A. F. Subar. 2014. <span>“Higher Diet Quality Is Associated with Decreased Risk of All-Cause, Cardiovascular Disease, and Cancer Mortality Among Older Adults.”</span> <em>The Journal of Nutrition</em> 144 (6): 881–89. <a href="https://doi.org/10.3945/jn.113.189407">https://doi.org/10.3945/jn.113.189407</a>.
</div>
<div id="ref-thrifty_food_plan_2021" class="csl-entry">
US Department of Agriculture. 2021. <span>“Thrifty Food Plan, 2021.”</span> Food and Nutrition Service 916. US Department of Agriculture. <a href="https://FNS.usda.gov/TFP">https://FNS.usda.gov/TFP</a>.
</div>
<div id="ref-fndds_2018" class="csl-entry">
US Department of Agriculture, Agricultural Research Service. 2018. <span>“USDA Food and Nutrient Database for Dietary Studies 2015-2016.”</span> US Department of Agriculture, Agricultural Research Service. <a href="https://www.ars.usda.gov/nea/bhnrc/fsrg">https://www.ars.usda.gov/nea/bhnrc/fsrg</a>.
</div>
<div id="ref-fndds_2020" class="csl-entry">
———. 2020. <span>“USDA Food and Nutrient Database for Dietary Studies 2017-2018.”</span> US Department of Agriculture, Agricultural Research Service. <a href="https://www.ars.usda.gov/nea/bhnrc/fsrg">https://www.ars.usda.gov/nea/bhnrc/fsrg</a>.
</div>
<div id="ref-usda_2020" class="csl-entry">
US Department of Agriculture and US Department of Health and Human Services. 2020. <span>“Dietary Guidelines for Americans, 2020-2025.”</span> 9th edition. <span>US Department of Agriculture and US Department of Health and Human Services</span>. <a href="https://DietaryGuidelines.gov">https://DietaryGuidelines.gov</a>.
</div>
</div></section><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>NHANES is a multi-module continuous survey conducted by the Centers for Disease Control and Prevention. In addition to the WWEIA, NHANES includes a four-hour complete medical exam including a health history, and a blood and urine analysis.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Machine learning</category>
  <category>Natural language processing</category>
  <category>Public policy</category>
  <category>Health and wellbeing</category>
  <guid>https://realworlddatascience.net/case-studies/posts/2023/08/21/01-purchase-to-plate.html</guid>
  <pubDate>Mon, 21 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/case-studies/posts/2023/08/21/images/01-pps.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Food for Thought: First place winners – Auburn Big Data</title>
  <dc:creator>Alex Knipper, Naman Bansal, Jingyi Zheng, Wenying Li, and Shubhra Kanti Karmaker</dc:creator>
  <link>https://realworlddatascience.net/case-studies/posts/2023/08/21/03-first-place-winners.html</link>
  <description><![CDATA[ 




<p>The Auburn Big Data team from Auburn University consists of five members, including three assistant professors: Dr Wenying Li of the Department of Agricultural Economics and Rural Sociology, Dr Jingyi Zheng of the Department of Mathematics and Statistics, and Dr Shubhra Kanti Karmaker of the Department of Computer Science and Software Engineering. Additionally, the team comprises two PhD students, Naman Bansal and Alex Knipper, who are affiliated with Dr Karmaker’s big data lab at Auburn University.</p>
<p>It is estimated that our team has spent approximately 1,400 hours on this project.</p>
<section id="our-perspective-on-the-challenge" class="level2">
<h2 class="anchored" data-anchor-id="our-perspective-on-the-challenge">Our perspective on the challenge</h2>
<p>At the start of this competition, we decided to test three general approaches, in the order listed:</p>
<ol type="1">
<li><p>A heuristic approach, where we use only the data and a defined similarity metric to predict which FNDDS label a given IRI item should have.</p></li>
<li><p>A simpler modeling approach, where we train a simple statistical classifier, like a random forest <span class="citation" data-cites="10.1007/978-3-030-03146-6_86">(Parmar, Katariya, and Patel 2019)</span>, logistic regression, etc., to predict the FNDDS label for a given IRI item. For this method, we opted to use a random forest as our statistical model, as it was a simpler model to use as a baseline, having shown decent performance in a wide range of classification tasks. As it turned out, this approach was quite robust and accurate, so we kept it as our main model for this approach.</p></li>
<li><p>A large language modeling approach, where we train a model like BERT <span class="citation" data-cites="DBLP:journals/corr/abs-1810-04805">(Devlin et al. 2018)</span> to map the descriptions for given IRI and FNDDS items to the FNDDS category the supplied IRI item belongs to.</p></li>
</ol>
</section>
<section id="our-approach" class="level2">
<h2 class="anchored" data-anchor-id="our-approach">Our approach</h2>
<p>As we explored the data provided, we opted to use the given 2017–2018 PPC dataset as our primary dataset for both training and testing. To ensure a fair evaluation of the model, we randomly split the dataset into 60% training samples and 40% testing samples, making sure our training process never sees the testing dataset. For evaluating our models, we adopted the competition’s metrics: Success@5 and NDCG@5. After months of testing, our statistical classifier (approach #2) proved itself to be the model that both processes the data fastest and achieves the highest performance on our testing metrics.</p>
<p>This approach, at a high level, takes in the provided data (among other configuration parameters), formats the data in a computer-readable format – converting the IRI and FNDDS descriptions to a numerical representation with word embeddings <span class="citation" data-cites="DBLP:journals/corr/abs-1810-04805 mikolov2013efficient pennington-etal-2014-glove">(2018; Mikolov et al. 2013; Pennington, Socher, and Manning 2014)</span> and then using that numerical representation to calculate the distances between each description – and then trains a classification model (random forest <span class="citation" data-cites="10.1007/978-3-030-03146-6_86">(2019)</span>/neural network <span class="citation" data-cites="SCHMIDHUBER201585">(Schmidhuber 2015)</span>) that can predict an FNDDS label for a given IRI item.</p>
<p>In terms of data, our approach uses the FNDDS/IRI descriptions, combining them into a single “description” field, and the IRI item’s categorical items – department, aisle, category, product, brand, manufacturer, and parent company – to further discern between items.</p>
<p>While most industrial methods require use of a graphics processing unit (graphics card, or GPU) to perform this kind of processing, our primary method only requires the computer’s internal processor (CPU) to function properly. With that in mind, to achieve the best possible performance on our test metrics, the most time-consuming operations are run in parallel. The time taken to train our primary model can likely be further improved if we parallelize these operations across a GPU, with the only downside being the imposition of a GPU requirement for systems aiming to run this method.</p>
<p>In addition to our primary method, our team has worked with alternate approaches on the GPU (using BERT <span class="citation" data-cites="DBLP:journals/corr/abs-1810-04805">(2018)</span>, neural networks <span class="citation" data-cites="SCHMIDHUBER201585">(2015)</span>, etc.) to either: 1) speed up the time it takes to process and make inferences for the data, achieving similar performance on our test metrics, or 2) achieve higher performance, likely at a cost to the time it takes to process everything. Our reasoning behind doing so is that if a simple statistical model performs well, then a larger language model should be able to demonstrate a higher performance on our test metrics without much of an increase in training time. At the current time, these methods are still unable to match the performance/efficiency tradeoff of our primary method.</p>
<p>After exploring alternate methods to no avail, our team then decided to focus again on our primary method, the random forest <span class="citation" data-cites="10.1007/978-3-030-03146-6_86">(2019)</span>, and a secondary method, feed-forward neural network mapping our input features (X) to the FNDDS labels (Y) <span class="citation" data-cites="SCHMIDHUBER201585">(2015)</span>, to optimize their training hyperparameters for the dataset. Our aim in this is to see which of our already-implemented, easier-to-run downstream methods would better optimize the performance/efficiency tradeoff after having its training parameters optimized to the fullest. This has resulted in a marginal increase in training time (+20-30 minutes) and a roughly 5% increase in performance for our still-highest performing model, the random forest.</p>
<p>Overall, our primary method – the random forest – gave us an approximate training time (including data pre-processing) of 4 hours 30 minutes for our ~38,000 IRI item training set, and an approximate inference time of 15 minutes on our testing set of ~15,000 IRI items. Furthermore, our method gave us a Success@5 score of .789 and an NDCG@5 score of .705 on our testing set.</p>
<section id="key-features" class="level5">
<h5 class="anchored" data-anchor-id="key-features">Key features</h5>
<p>Here is a list of the key features we utilize, along with what type of data we treat it as.</p>
<ul>
<li>FNDDS
<ul>
<li>food_code – identifier</li>
<li>main_food_description – text</li>
<li>additional_food_description – text</li>
<li>ingredient_description – text</li>
</ul></li>
<li>IRI
<ul>
<li>upc – identifier</li>
<li>upcdesc – text</li>
<li>dept – categorical</li>
<li>aisle – categorical</li>
<li>category – categorical</li>
<li>product – categorical</li>
<li>brand – categorical</li>
<li>manufacturer – categorical</li>
<li>parent – categorical</li>
</ul></li>
</ul>
<p>The intuition behind using these particular features is that the text-based descriptions provide the majority of the “meaning” of the item. By converting each description to a numerical representation <span class="citation" data-cites="mikolov2013efficient pennington-etal-2014-glove">(2013; 2014)</span>, we can then calculate the similarity between each “meaning” to determine which FNDDS label is most similar to the IRI item provided. However, that alone is not enough. The categorical features on the IRI item help to further enhance the model’s classifications using the logic and categories people use in places like grocery stores. For example, if given an item whose aisle was “fruit” and brand was “Dole”, the item could be reasonably expected to be something like “peaches” over something like “broccoli”.</p>
</section>
<section id="feature-selection" class="level5">
<h5 class="anchored" data-anchor-id="feature-selection">Feature selection</h5>
<p>Aforementioned intuition aside, our feature selection was rather naive, in that we manually examined the data and removed any redundant text features before doing anything else. After that, we decided to use description fields as “text” data to comprise the main “meaning” of the item, represented numerically after converting the text using a word embedding <span class="citation" data-cites="mikolov2013efficient pennington-etal-2014-glove">(2013; 2014)</span>. We also decided to use the non-description fields (aisle, category, etc.) as “categorical” data that would be turned into its own numerical representation, allowing our model to more easily discern between items using similar systems to people.</p>
</section>
<section id="feature-transformations" class="level5">
<h5 class="anchored" data-anchor-id="feature-transformations">Feature transformations</h5>
<p>Our feature transformations are also relatively simple. First, we combine all description fields for each item to make one large description, and then use a word embedding method (like GloVe <span class="citation" data-cites="pennington-etal-2014-glove">(2014)</span> or BERT <span class="citation" data-cites="DBLP:journals/corr/abs-1810-04805">(2018)</span>) to convert the description into a numerical representation, resulting in a 300-dimensional GloVe or 768-dimensional BERT vector of numbers for each description. Then, for each IRI item, we calculate the cosine and Euclidean distances from each FNDDS item, resulting in two vectors, both equal in length to the original FNDDS data (in this case, two vectors of length ~7,300). The intuition behind this is that while cosine and Euclidean distances can tell us similar things, providing both of these sets of distances to the model should allow it to pick up on a more nuanced set of relationships between the IRI and FNDDS items.</p>
<p>For categorical data, we take all unique values in each field and assign them an ID number. While that is often not the best practice for making a numerical representation out of categorical data <span class="citation" data-cites="10.5120/ijca2017915495">(Potdar, Pardawala, and Pai 2017)</span>, it seemed to work for the downstream model.</p>
<p>Regardless, the aforementioned feature transformations give us (ad hoc) ~14,900 features if we use GloVe and ~15,300 features if we use BERT. Both feature sets can then be sent to the downstream random forest/neural network to start classifying items.</p>
<p>It should be noted that processing the data is by far the most time-consuming part of our method. The data processing times for each embedding are as follows:</p>
<ul>
<li>GloVe: ~3 hours</li>
<li>BERT: ~6 hours</li>
</ul>
<p>Due to BERT both taking so long to process data and performing lower than our GloVe embeddings on the classification task, we opt to use GloVe embeddings for our primary method. Our only theoretical explanation here is that since BERT is better at context-dependent tasks <span class="citation" data-cites="10.1145/3443279.3443304">(Wang, Nulty, and Lillis 2021)</span>, it likely will expect something similar to well-structured sentences as input, which is not what the IRI/FNDDS descriptions are. Rather, GloVe – being a method that depends less on context <span class="citation" data-cites="mikolov2013efficient pennington-etal-2014-glove">(2013; 2014)</span> – should excel better when the input text is not a well-formed sentence.</p>
</section>
<section id="training-methods" class="level5">
<h5 class="anchored" data-anchor-id="training-methods">Training methods</h5>
<p>Once the data has been processed, we collect the following data for each IRI item:</p>
<ul>
<li>UPC code</li>
<li>Description (converted to numerical representation)</li>
<li>Categorical variables (converted to numerical representation)</li>
<li>Distances to each FNDDS item</li>
</ul>
<p>Once that has been collected for each IRI item, we can finally use our classification model. We initialize our model and begin the training process with the IRI data mentioned above and the target FNDDS labels for each one, so the model knows what the “correct” answer is for the given data. Once the model has trained on our training dataset, we save the model and it is ready for use.</p>
<p>This part of training takes much less time than preparing the data, since calculating the embeddings takes a lot more computation than a random forest model. The training times for each method are as follows:</p>
<ul>
<li>Random Forest: ~1 hour 15 minutes</li>
<li>Neural Network: ~25 minutes</li>
</ul>
<p>Despite the neural network taking far less time to train than the random forest, it still scores lower on the scoring metrics than the random forest, so we opt to continue using the random forest model as our primary method.</p>
</section>
<section id="general-approach-to-developing-the-model" class="level5">
<h5 class="anchored" data-anchor-id="general-approach-to-developing-the-model">General approach to developing the model</h5>
<p>Since the linkage problem involves mapping tens of thousands of items to a smaller category set of a few thousand items, we decided to frame this problem as a multi-class classification problem <span class="citation" data-cites="aly2005survey">(Aly 2005)</span>, where we then rank the top “k” most probable class mappings, as requested by the competition ruleset.</p>
<p>Most of the usable data available to us is text data, so we need a method that can use that text-based information to accurately map classes based on the aforementioned text information. To best accomplish this, we opt to use word embedding techniques to calculate an average numerical representation for each text description (both IRI and FNDDS), so we can calculate distances between each description, giving our model a sense of how similar each description is.</p>
</section>
<section id="the-key-trick-to-the-model" class="level5">
<h5 class="anchored" data-anchor-id="the-key-trick-to-the-model">The key “trick” to the model</h5>
<p>Since text descriptions hold the most information that can be used to link between an IRI item and an FNDDS item, finding a way to calculate the similarity between each description is paramount to making this method work.</p>
<p>Both distance calculation methods used in this work, cosine and Euclidean distance, are very similar in the type of information encoded, the only major difference being that cosine distance is implicitly normalized and Euclidean distance is not <span class="citation" data-cites="10.1145/967900.968151">(Qian et al. 2004)</span>.</p>
</section>
<section id="notable-observations" class="level5">
<h5 class="anchored" data-anchor-id="notable-observations">Notable observations</h5>
<p>Just by building the ranking using the cosine similarities between each IRI item and all FNDDS items, we can achieve a Success@5 performance of 0.234 and an NDCG@5 performance of 0.312. The other features are provided and the random forest classifier is used to add some extra discriminative power to the model.</p>
</section>
<section id="data-disclaimer" class="level5">
<h5 class="anchored" data-anchor-id="data-disclaimer">Data disclaimer</h5>
<p>Our current method only uses the data readily available from the 2017–2018 dataset, which we acknowledge is intended for testing. To remedy this, we further split this dataset into train/test sets and report results on our unseen test subset for our primary performance metrics. This gives a decent look into how the model will perform on unseen data.</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Find the code in the <a href="https://github.com/realworlddatascience/realworlddatascience.github.io/tree/main/case-studies/posts/2023/08/21/_code">Real World Data Science GitHub repository</a>.</p>
</div>
</div>
</div>
</section>
</section>
<section id="our-results" class="level2">
<h2 class="anchored" data-anchor-id="our-results">Our results</h2>
<section id="approximate-training-time" class="level5">
<h5 class="anchored" data-anchor-id="approximate-training-time">Approximate training time</h5>
<p>Overall, our approximate training time for our primary method is 4 hours 30 minutes broken down (approximately) as follows:</p>
<ol type="1">
<li>Reading data from database: 30 seconds</li>
<li>Calculating ~7,300 FNDDS description embeddings: 15 minutes 45 seconds</li>
<li>Calculating ~38,000 IRI description embeddings and similarity scores: 2 hours 20 minutes 45 seconds</li>
<li>Formatting calculated data for the random forest classifier: 35 minutes</li>
<li>Training the random forest classifier: 1 hour 15 minutes</li>
</ol>
</section>
<section id="approximate-inference-time" class="level5">
<h5 class="anchored" data-anchor-id="approximate-inference-time">Approximate inference time</h5>
<p>Our approximate inference time for our primary method is 15 minutes to make inferences for ~15,000 IRI items.</p>
</section>
<section id="s5-ndcg5-performance" class="level5">
<h5 class="anchored" data-anchor-id="s5-ndcg5-performance">S@5 &amp; NDCG@5 performance</h5>
<p>This is how our best-performing model (GloVe + random forest) performs at the current time on the testing set:</p>
<ul>
<li>NDCG@5: 0.705</li>
<li>Success@5: 0.789</li>
</ul>
<p>When we evaluate that same model on the full PPC dataset we were provided (~38,000 items), we get the following scores:</p>
<ul>
<li>NDCG@5: 0.879</li>
<li>Success@5: 0.916</li>
</ul>
<p>(Note: The full PPC dataset contains approximately 15,000 items that we used to train the model, so these scores are not as representative of our method’s performance as the previous scores.)</p>
</section>
</section>
<section id="future-workrefinement" class="level2">
<h2 class="anchored" data-anchor-id="future-workrefinement">Future work/refinement</h2>
<p>As mentioned previously, we only used the given 2017–2018 PPC dataset as our primary dataset for both training and testing. Going forward, we would like to include datasets from previous years as well, which we believe would further increase our model performance. Additionally, the datasets generated from this research have the potential to inform and support additional studies from a variety of perspectives, including nutrition, consumer research, and public health. Further research utilizing these datasets has the potential to make significant contributions to our understanding of consumer behavior and the role of food and nutrient consumption in overall health and well-being.</p>
</section>
<section id="lessons-learned" class="level2">
<h2 class="anchored" data-anchor-id="lessons-learned">Lessons learned</h2>
<p>It was interesting that the random forest model performed better than the vanilla neural network model. This shows that a simple solution can work better, depending on the application. This observation is in line with the well-established principle in machine learning that the choice of model should be guided by the nature of the problem and the characteristics of the data. In this case, the random forest model, being a simpler and more interpretable model, was better suited to the problem at hand and was able to outperform the more complex neural network model. These results underscore the importance of careful model selection and the need to consider both the complexity of the model and the specific requirements of the problem when choosing an algorithm for a particular application.</p>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../case-studies/posts/2023/08/21/02-competition-design.html">← Part 2: Competition design</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../case-studies/posts/2023/08/21/04-second-place-winners.html">Part 4: Second place winners →</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the authors</dt>
<dd>
<strong>Alex Knipper</strong> and <strong>Naman Bansal</strong> are PhD students, and <strong>Jingyi Zheng</strong>, <strong>Wenying Li</strong>, and <strong>Shubhra Kanti Karmaker</strong> are assistant professors at Auburn University.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Alex Knipper, Naman Bansal, Jingyi Zheng, Wenying Li, and Shubhra Kanti Karmaker
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/case-studies/posts/2023/08/21/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@nicotitto?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">nrd</a> on <a href="https://unsplash.com/photos/D6Tu_L3chLE?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Knipper, Alex, Naman Bansal, Jingyi Zheng, Wenying Li, and Shubhra Kanti Karmaker. 2023. “Food for Thought: First place winners – Auburn Big Data.” Real World Data Science, August 21, 2023. <a href="https://realworlddatascience.net/viewpoints/case-studies/posts/2023/08/21/03-first-place-winners.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-aly2005survey" class="csl-entry">
Aly, M. 2005. <span>“Survey on Multiclass Classification Methods, Tech. Rep.”</span> <em>California Institute of Technology</em>.
</div>
<div id="ref-DBLP:journals/corr/abs-1810-04805" class="csl-entry">
Devlin, J., M.-W. Chang, K. Lee, and K. Toutanova. 2018. <span>“<span>BERT:</span> Pre-Training of Deep Bidirectional Transformers for Language Understanding.”</span> <em>CoRR</em> abs/1810.04805. <a href="http://arxiv.org/abs/1810.04805">http://arxiv.org/abs/1810.04805</a>.
</div>
<div id="ref-mikolov2013efficient" class="csl-entry">
Mikolov, Tomas, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. <span>“Efficient Estimation of Word Representations in Vector Space.”</span> <a href="https://arxiv.org/abs/1301.3781">https://arxiv.org/abs/1301.3781</a>.
</div>
<div id="ref-10.1007/978-3-030-03146-6_86" class="csl-entry">
Parmar, A., R. Katariya, and V. Patel. 2019. <span>“A Review on Random Forest: An Ensemble Classifier.”</span> In <em>International Conference on Intelligent Data Communication Technologies and Internet of Things (ICICI) 2018</em>, edited by J. Hemanth, X. Fernando, P. Lafata, and Z. Baig, 758–63. Cham: Springer International Publishing.
</div>
<div id="ref-pennington-etal-2014-glove" class="csl-entry">
Pennington, J., R. Socher, and C. Manning. 2014. <span>“<span>G</span>lo<span>V</span>e: Global Vectors for Word Representation.”</span> In <em>Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (<span>EMNLP</span>)</em>, 1532–43. Doha, Qatar: Association for Computational Linguistics. <a href="https://doi.org/10.3115/v1/D14-1162">https://doi.org/10.3115/v1/D14-1162</a>.
</div>
<div id="ref-10.5120/ijca2017915495" class="csl-entry">
Potdar, K., T. S. Pardawala, and C. D. Pai. 2017. <span>“A Comparative Study of Categorical Variable Encoding Techniques for Neural Network Classifiers.”</span> <em>International Journal of Computer Applications</em> 175 (4): 7–9. <a href="https://doi.org/10.5120/ijca2017915495">https://doi.org/10.5120/ijca2017915495</a>.
</div>
<div id="ref-10.1145/967900.968151" class="csl-entry">
Qian, G., S. Sural, Y. Gu, and S. Pramanik. 2004. <span>“Similarity Between Euclidean and Cosine Angle Distance for Nearest Neighbor Queries.”</span> In <em>Proceedings of the 2004 ACM Symposium on Applied Computing</em>, 1232–37. SAC ’04. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/967900.968151">https://doi.org/10.1145/967900.968151</a>.
</div>
<div id="ref-SCHMIDHUBER201585" class="csl-entry">
Schmidhuber, J. 2015. <span>“Deep Learning in Neural Networks: An Overview.”</span> <em>Neural Networks</em> 61: 85–117. https://doi.org/<a href="https://doi.org/10.1016/j.neunet.2014.09.003">https://doi.org/10.1016/j.neunet.2014.09.003</a>.
</div>
<div id="ref-10.1145/3443279.3443304" class="csl-entry">
Wang, C., P. Nulty, and D. Lillis. 2021. <span>“A Comparative Study on Word Embeddings in Deep Learning for Text Classification.”</span> In <em>Proceedings of the 4th International Conference on Natural Language Processing and Information Retrieval</em>, 37–46. NLPIR ’20. New York, NY, USA: Association for Computing Machinery. <a href="https://doi.org/10.1145/3443279.3443304">https://doi.org/10.1145/3443279.3443304</a>.
</div>
</div></section></div> ]]></description>
  <category>Machine learning</category>
  <category>Natural language processing</category>
  <category>Public policy</category>
  <category>Health and wellbeing</category>
  <guid>https://realworlddatascience.net/case-studies/posts/2023/08/21/03-first-place-winners.html</guid>
  <pubDate>Mon, 21 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/case-studies/posts/2023/08/21/images/03-auburn.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Where do AI, data science, and computer games intersect?</title>
  <dc:creator>Alice-Maria Toader and Liam Brierley</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/08/17/data-science-and-games.html</link>
  <description><![CDATA[ 




<p>Game studios have cemented their place among the fastest-growing media industries. In recognition of this, we hosted an event in June through the <a href="https://rss.org.uk/membership/rss-groups-and-committees/groups/merseyside/">Royal Statistical Society (RSS) Merseyside Local Group</a> to explore AI and data science in computer game development. This was an amazing opportunity to engage with a different, in-vogue domain that has unique ties to data science. We showcased two fantastic presentations covering both academic and industry perspectives.</p>
<p>Stanley Wang, a data scientist at SEGA Europe, opened the event by showing the methods that SEGA uses to collect, process, and apply data on player decisions in-game. It was a revealing glimpse at how smoothly in-game data collection is integrated into SEGA’s digital platforms and the ways these data can be used to engage game-centred communities – for example, running special celebrations once milestones are hit for in-game events (revenue made, goals scored, etc.) or offering real-time integration with streaming platforms so viewers can see detailed statistics on in-game progress. Stanley showed one particular example where data collection fed directly into development decisions for <em>Endless Space</em>, a competitive strategy game where players vie for galactic conquest. During the beta (a period where a game is available to play but still considered in-testing before commercial release), SEGA were able to monitor how well-balanced the playable alien factions were based on real-time win rate data, which led to improvements to game mechanics for the final release.</p>
<p>We also learned how SEGA’s data science teams are using clustering methods to identify different game-playing behaviours in <em>Two Point Hospital</em>, a simulation game where players design, build, and manage a hospital through various scenarios. After compiling high-dimensional in-game data such as objectives achieved, treatment of staff, and even furniture choices, various clustering algorithms (including <a href="https://towardsdatascience.com/a-practical-guide-on-k-means-clustering-ca3bef3c853d">k-means clustering</a>) were used to identify common sets of player behaviour. Stanley highlighted that when using these sorts of <em>unsupervised learning methods</em>, it’s useful to get insights from multiple models to inform methodological decisions like number of clusters chosen or how to treat outliers. SEGA identified four distinct types of player from these analyses, which you can hear more about from Stanley in the video below. The approach allowed the company to better understand gamers’ motivations and experiences with a view to designing future game content.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/KAg3YDHvvqE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Our second speaker, Dr Konstantinos Tsakalidis, a lecturer in the Department of Computer Science at the University of Liverpool, presented exciting new ideas to teach computer games developers of the future. Dr Tsakalidis walked us through the curriculum for a dynamic new undergraduate program that reflects the latest software development technologies and the theory behind them. The course outline was designed around building knowledge and practice from the fundamentals upwards, starting from game physics as a prerequisite for game mechanics, game mechanics being a prerequisite for game content, and game content being a prerequisite for game AI. Combined with the continuous active involvement of students at each stage, this represented a great model of <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8049623/">constructivist teaching</a>. Dr Tsakalidis also proposed that practical game development (and subsequent assessments) should follow the latest <a href="https://www.datacamp.com/podcast/data-science-and-ai-in-the-gaming-industry">research on data science and AI in computer games</a>.</p>
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Alice-Maria Toader</strong> is a PhD student at the University of Liverpool and a committee member of the RSS Merseyside Local Group. <strong>Liam Brierley</strong> is a research fellow in health data science at the University of Liverpool and chair of the RSS Merseyside Local Group.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Alice-Maria Toader and Liam Brierley
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/posts/2023/08/17/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/posts/2023/08/17/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://unsplash.com/@jezar?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jezael Melgoza</a> on <a href="https://unsplash.com/photos/FOx3_4_2O1E?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Toader, Alice-Maria and Liam Brierley. 2023. “Where do AI, data science, and computer games intersect?” Real World Data Science, August 17, 2023. <a href="https://realworlddatascience.net/viewpoints/posts/2023/08/17/data-science-and-games.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Events</category>
  <category>Video games</category>
  <category>Education</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/08/17/data-science-and-games.html</guid>
  <pubDate>Thu, 17 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/08/17/images/sega-store.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Live from Toronto: Real World Data Science at the Joint Statistical Meetings</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html</link>
  <description><![CDATA[ 




<section id="sunday-august-6" class="level2">
<h2 class="anchored" data-anchor-id="sunday-august-6">Sunday, August 6</h2>
<section id="use-of-color-in-statistical-charts" class="level3">
<h3 class="anchored" data-anchor-id="use-of-color-in-statistical-charts">Use of color in statistical charts</h3>
<p><em>Haley Jeppson, Danielle Albers Szafir, and Ian Lyttle</em></p>
<p>JSM 2023 is underway, and the first session I attended today was this panel on the use of colour in statistical charts.</p>
<p>The topic appealed to me for two reasons:</p>
<ul>
<li>Before my trip to Toronto, I interviewed <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html">Alberto Cairo about the many “dialects” of data visualisation</a>.</li>
<li>I’ve recently been working with Andreas Krause and Nicola Rennie to create new guidance for improving statistical graphics, titled “<a href="https://royal-statistical-society.github.io/datavisguide/">Best Practices for Data Visualisation</a>”.</li>
</ul>
<p>The “Best Practices…” guide links to several useful data visualisation tools, and this session today has put a few more on my radar:</p>
<ul>
<li><p><a href="https://cmci.colorado.edu/visualab/ColorCrafting/">Color Crafting</a>, by Stephen Smart, Keke Wu, and Danielle Albers Szafir. The authors write: “Visualizations often encode numeric data using sequential and diverging color ramps. Effective ramps use colors that are sufficiently discriminable, align well with the data, and are aesthetically pleasing. Designers rely on years of experience to create high-quality color ramps. However, it is challenging for novice visualization developers that lack this experience to craft effective ramps as most guidelines for constructing ramps are loosely defined qualitative heuristics that are often difficult to apply. Our goal is to enable visualization developers to readily create effective color encodings using a single seed color.”</p></li>
<li><p><a href="https://observablehq.com/collection/@ijlyttle/color">Computing on color</a>, a collection of Observable notebooks by Ian Lyttle that allow users to see how different colour spaces and colour scales work with different types of colour vision deficiency.</p></li>
</ul>
</section>
</section>
<section id="monday-august-7" class="level2">
<h2 class="anchored" data-anchor-id="monday-august-7">Monday, August 7</h2>
<section id="astronomers-speak-statistics" class="level3">
<h3 class="anchored" data-anchor-id="astronomers-speak-statistics">Astronomers Speak Statistics</h3>
<p>Astrophysicist Joel Leja kicked off his JSM talk with a video of the launch of the James Webb Space Telescope – an inspiring way to start the day, and a prelude to a discussion of the statistical challenges involved in studying the deep universe.</p>
<p>James Webb, since launch, has “completely expanded our point of view”, said Leja, allowing astronomers to explore the first stars and galaxies at greater resolution than ever before.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/james-webb.png" class="img-fluid figure-img" alt="Image from the James Webb telescope showing two galaxies in the process of merging, twisting each other out of shape." width="500"></p>
<figcaption class="figure-caption">Image from the James Webb telescope showing two galaxies in the process of merging, twisting each other out of shape. Credit: ESA/Webb, NASA &amp; CSA, L. Armus, A. Evan, licenced under CC BY 2.0.</figcaption>
</figure>
</div>
<p>Already, after only 13 months of operation, the images and data sent back by the telescope have left observers astounded: for example, finding suspected early galaxies that are bigger than thought possible based on extreme value analysis.</p>
<p>But the big challenge facing those studying the early universe is trying to work out how early galaxies evolved over time. “We can’t watch this happen,” said Leja, joking that this process lasts longer than a typical PhD. So, instead, he said, “We need to use statistics to understand this, to figure out how they grow up.”</p>
</section>
<section id="teaching-statistics-in-higher-education-with-active-learning" class="level3">
<h3 class="anchored" data-anchor-id="teaching-statistics-in-higher-education-with-active-learning">Teaching statistics in higher education with active learning</h3>
<p>Great talk from Nathaniel T. Stevens of the University of Waterloo, explaining how a posting for a Netflix job inspired the creation of a final project for students to learn response surface methodology.</p>
<p>The job ad in question “really opened my eyes” to the use of online controlled experiments by companies, said Stevens. He told delegates how LinkedIn, the business social networking site, runs over 400 experiments per day, trying to optimise user experience and other aspects of site engagement.</p>
<p>Netflix’s job ad highlighted just how sophisticated these experiments are, said Stevens. People might hear companies refer to their use of A/B tests, but the term trivialises what’s involved, Stevens explained.</p>
<p>Having encountered a job ad from Netflix, looking for someone to design, run, and analyse experiments and support internal methodological research, Stevens was inspired to present students with a hypothetical business problem, based on the Netflix homepage. That homepage, for those not familiar, features rows and rows of movies and TV shows sorted by theme, each show presented as a tile that, when hovered over, leads to a pop-up with a video preview and a match score – a prediction of how likely a viewer is to enjoy the show.</p>
<p>Stevens explained the hypothetical goal as trying to minimise “browsing time” – the time it takes a Netflix user to pick something to watch. Browsing time was defined as time spent scrolling and searching, not including time spent watching previews.</p>
<p>Students were given four factors that might influence browsing time – tile size, match score, preview length, and preview type – and through a sequence of experiments based on data generated by a Shiny app, students sought to minimise browsing time.</p>
<p>The response from the students? Two Netflix-style thumbs up. Ta-dum!</p>
</section>
</section>
<section id="tuesday-august-8" class="level2">
<h2 class="anchored" data-anchor-id="tuesday-august-8">Tuesday, August 8</h2>
<section id="the-next-50-years-of-data-science" class="level3">
<h3 class="anchored" data-anchor-id="the-next-50-years-of-data-science">The Next 50 Years of Data Science</h3>
<p>Stanford University’s David Donoho wrestled with the question of whether a singularity is approaching in this post-lunch session on the future of data science.</p>
<p>Taking his cue from the 2005 Ray Kurzweil book, <em>The Singularity is Near</em>, Donoho reviewed recent – and sometimes rapid – advances in data science and artificial intelligence to argue that a singularity may have already arrived, just not in the way Kurzweil supposed.</p>
<p>Kurzweil’s book argues that at some point after the 2030s, machine intelligence will supersede human intelligence, leading to a takeover or disruption of life as we know it.</p>
<p>At JSM, Donoho argued that we have certainly seen a “massive scaling” of compute over the past decade, along with expanded communications infrastructure and the wider spread of information – all of which is having an impact on human behaviour.</p>
<p>That human behaviour can often now be directly measured thanks to the proliferation of digital devices with data collection capabilities, and this in turn is leading to a major scaling in datasets and performance scaling for machine learning models.</p>
<p>But does this mean that an AI singularity is near? Not according to Donoho. The notion of an AI singularity “is a kind of misdirection”, he said. Something very profound is happening, Donoho argued, and it is the culmination of three long-term initiatives in data science that have come together in recent years. “They constitute a singularity on their own.”</p>
<p>These three initiatives, as Donoho described, are: datafication and data sharing; adherence to the “challenge problem” paradigm; and documentation and sharing of code. These are solid achievements that came out of the last decade, said Donoho, and they are “truly revolutionary” when they come together to form what he refers to as “frictionless reproducibility.”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/donoho-talk.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/donoho-talk.png" class="img-fluid figure-img" alt="Slide text reads: Today's data scientists: typical interactions: What's your package name? What's your URL? QR Code? What's your stack? Today's data scientists: implicit demands: Data sharing, Specific numerical performance measures, Code sharing, Single-click access. Frictionless replications." width="500"></a></p>
<figcaption class="figure-caption">Photo of David Donoho’s slide, describing the scientific revolution of the “data science decade”. Photo by Brian Tarran, licenced under CC BY 4.0.</figcaption>
</figure>
</div>
<p>Frictionless reproducibility, when achieved, leads to a “reproducibility singularity” – the moment where it takes almost no time at all for an idea to spread. “If there is an AI singularity,” said Donoho, “it will be because this came first.”</p>
</section>
</section>
<section id="wednesday-august-9" class="level2">
<h2 class="anchored" data-anchor-id="wednesday-august-9">Wednesday, August 9</h2>
<section id="new-frontiers-of-statistics-in-trustworthy-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="new-frontiers-of-statistics-in-trustworthy-machine-learning">New frontiers of statistics in trustworthy machine learning</h3>
<p>Data, data everywhere, but is it safe to “drink”? A presentation this morning from Yaoliang Yu of the University of Waterloo looked at the issue of data poisoning attacks on algorithms and the effectiveness of current approaches.</p>
<p>Yu began by explaining how machine learning algorithms require a lot of data for training, and that large amounts of data can be obtained cheaply by scraping the web.</p>
<p>But, he said, when researchers download this cheap data, they are bound to worry about the quality of it. Drawing an analogy to food poisoning, Yu asked: What if the data we “feed” to algorithms is not clean? What is the impact of that?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/data-hazards.png" class="img-fluid figure-img" alt="A person is illustrated in a warm, cartoon-like style in green. They are looking up thoughtfully from the bottom left at a large hazard symbol in the middle of the image. The hazard symbol is a bright orange square tilted 45 degrees, with a black and white illustration of an exclamation mark in the middle where the exclamation mark shape is made up of tiny 1s and 0s like binary code. To the right-hand side of the image a small character made of lines and circles (like nodes and edges on a graph) is standing with its ‘arms’ and ‘legs’ stretched out, and two antenna sticking up. It faces off to the right-hand side of the image." width="500"></p>
<figcaption class="figure-caption">Illustration by Yasmin Dwiputri &amp; Data Hazards Project / Better Images of AI / Managing Data Hazards / Licenced by CC-BY 4.0.</figcaption>
</figure>
</div>
<p>As a real-world example of a data poisoning attack, Yu pointed to TayTweets, the Microsoft Twitter chatbot that spewed racism within hours of launch <a href="https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist">after Twitter users began engaging with it</a>.</p>
<p>Yu then walked delegates through some experiments showing how, generally, indiscriminate data poisoning attacks are ineffective when the ratio of poisoned data to clean data is small. A poisoning rate of 3%, for example, leads to model accuracy drops of 1.5%–2%, Yu said.</p>
<p>However, he then put forward the idea of “parameter corruption” – an attack that seeks to modify a model directly. Yu showed that this would be more effective in terms of accuracy loss, though – fortunately – perhaps less practical to implement.</p>
</section>
<section id="data-science-and-product-analysis-at-google" class="level3">
<h3 class="anchored" data-anchor-id="data-science-and-product-analysis-at-google">Data Science and Product Analysis at Google</h3>
<p>Our final session at JSM 2023, before heading home, was a whistle-stop tour of various data science projects at Google, covering YouTube, Google Maps, and Google Search.</p>
<p>Jacopo Soriano kicked us off with a brief intro to the role and responsibilities of statisticians and data scientists at Google, and within YouTube specifically – the main task being to make good decisions based on uncertain data.</p>
<p>Soriano also spoke about the key role randomised experiments play in product development – harking back to Nathaniel Stevens’ earlier talk on this subject. YouTube runs hundreds, if not thousands, of concurrent experiments, Soriano said; statisticians can’t, therefore, be involved in each one. As Soriano’s colleague, Angela Schoergendorfer, explained later in the session, the role of the data scientist is to build methodology and metrics that others in the business can use to run their own experiments.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/google-sign.png" class="img-fluid figure-img" alt="Google logo on top of building, against a blue sky." width="500"></p>
<figcaption class="figure-caption">Photo by Pawel Czerwinski on Unsplash.</figcaption>
</figure>
</div>
<p>For every experiment YouTube runs, a portion of its voluminous daily traffic will be assigned to control arms and treatment arms, with traffic able to be diverted to different groups based on user type, creators, videos, advertisers, etc. Once experiments are running, metrics such as search clickthrough rates, watch time using specific devices, or daily active user numbers are monitored. Teams tend to look at percentage change as the scale to measure whether something is working or not, said Soriano, rather than comparing treatment to control group.</p>
<p>Next up was Lee Richardson, who spoke about the use of proxy metrics. Technology companies like Google are often guided by so-called “<a href="https://www.forbes.com/sites/forbesbusinesscouncil/2022/11/11/what-is-your-startups-north-star-metric/">north star metrics</a>”, which executive leadership use to guide the overall strategy and priorities of an organisation. However, Richardson said, these can be hard to design experiments around, and so proxy metrics stand in for the north star metrics. Proxies need to be sensitive, he said, and move in the same direction as, e.g., a long-term positive user experience.</p>
<p>On the subject of user experience, Christopher Haulk then explained how YouTube measures user satisfaction through single-question surveys – typically asking a YouTube user to rate the video they just watched. The company doesn’t send out that many surveys, Haulk said, and response rates are in the single-digit percentage range, so it can be hard to evaluate whether changes YouTube makes to, e.g., its video recommendation algorithm are working to improve user satisfaction. Haulk then went on to explain a modelling approach the company uses to predict how users are likely to respond in order to “fill in” for missing responses.</p>
<p>Over at Google Search, user feedback is also regularly sought to help support the evolution of the product. Angela Schoergendorfer explained how, with so many people already using Google Search, statistically significant changes in top-line metrics like daily active users can take months to see. Decision metics should ideally capture user value quickly, said Schoergendorfer – within days. For this, Google has 10,000 trained “search quality” raters they can call on. Random samples of user search queries and results are sent to these raters, who are asked to evaluate the quality of the search results. Users can also be asked in the moment, or offline through the Google Rewards app.</p>
<p>In 2021, Schoergendorfer said, Google conducted approximately 800,000 experiments and quality tests. But perhaps the most impressive statistic of the day came from Sam Morris, who works on Google Maps. Something, somewhere, is always changing in the world, said Morris – be it a road closure or a change to business hours. The Maps team cannot evaluate every single piece of data – a lot of changes are automated or algorithmic, he explained. “So far this year, we have probably processed 16 billion changes to the map,” said Morris – a staggering figure!</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Live from Toronto: Real World Data Science at the Joint Statistical Meetings.” Real World Data Science, August 6, 2023, updated August 15, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>Conferences</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html</guid>
  <pubDate>Tue, 15 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/google-sign.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>The many ‘dialects’ of data visualization: Alberto Cairo and ‘The Art of Insight’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html</link>
  <description><![CDATA[ 




<p>Alberto Cairo is Knight Chair in Visual Journalism at the School of Communication of the University of Miami (UM). He’s also the director of visualization at UM’s Institute for Data Science and Computing. He joins Real World Data Science to discuss his upcoming book, <em>The Art of Insight: How Great Visualization Designers Think</em>, in which Cairo reflects on his conversations with data artists, data journalists, and information designers.</p>
<p>“If we can conceptualise data visualization as language, this language can have multiple dialects,” says Cairo. “And these dialects – let’s say the statistical dialect, the data journalism dialect, the art dialect – they are not mutually exclusive. They exist, or they should exist, ideally, in constant conversation with each other. So, we can borrow ideas from each other, learn from each other.”</p>
<p>Listen to the full interview below or on <a href="https://www.youtube.com/watch?v=htUWWVzYTUI">YouTube</a>.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/htUWWVzYTUI" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Find out more about Cairo’s work and his upcoming book at <a href="http://www.thefunctionalart.com/">thefunctionalart.com</a>.</p>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to Real World Data Science. I’m Brian Tarran. And today I’m joined by Alberto Cairo, Knight chair in visual journalism at the School of Communication of the University of Miami. He’s also the director of visualization at UM’s Institute for data science and computing. Alberto, welcome. Thanks for joining us.</p>
<p><strong>Alberto Cairo</strong><br>
Hi, Brian. Very nice to be here. Thank you for inviting me.</p>
<p><strong>Brian Tarran</strong><br>
No worries. Well, today we’re excited to be discussing your new book, The Art of Insight: How Great Visualization Designers Think. I think it’s a really– I’ve not read all of it yet. I’ve dipped in and out of some chapters that you kindly sent me ahead of time. I think it’s really interesting and unique. I think the thing that struck me was often when we talk about visualization design, we tend to concentrate on what designers do, not necessarily about how they think about what they do, or how they think generally. And so, that was to be my first question for you is like, what aspects of their thought processes, these experts, what were you really trying to understand and why?</p>
<p><strong>Alberto Cairo</strong><br>
Yeah, yeah, this latest book of mine is very different to the previous one that I– that I wrote. The book is not out yet, by the way, the book will be out in November of 2023. I am in the process of copy editing it, getting rid of typos. But as you said, I mean the book focuses not so much on the– on the work itself, but more on the people who produce the work and the motivations and values that lie behind the work that they do. It is also, in comparison to my previous books, it is also a shift of perspective, I would say because my previous books, particularly The Truthful Art and How Charts Lie which came out in 2019, focus mostly on statistical visualization. Right, so it has a very strong, they both have a very strong statistical focus – how to make sure that your graphs and your data maps don’t deceive people. I teach elementary principles of visualization, of communication through visualization. But visualization is much more than that. And that is what I wanted to convey with this book. More and more throughout the years, I have come to understand data visualization not so much as a representation of data for insight or for communication, but as a language, a language that can be used for many different purposes. And I try to reflect that in the book. Obviously, a great part of the book is devoted to people who come from the same world where I come from, the professional world where I come from, the world of data journalism, so plenty of them are data journalists. Many of them are data analysts and statisticians and researchers. But a good portion of the book is devoted to people who use– who use visualization for other purposes such as self expression, self discovery, art in some cases. I wanted to provide a sort of like a broader understanding of the language of visualization and I also talk about– I also discussed the fact that if we can conceptualize data visualization as language, this language can have multiple dialects. And that is what I wanted to convey in the book. And these are not, these dialects – let’s say the statistical dialect, the data journalism dialect, the art dialect – they are not mutually exclusive. They exist, or they should exist, ideally, in constant conversation with each other. So we can borrow ideas from each other, learn from each other. So I wanted to provide sort of like an overview of the huge diversity that exists in the world of visualization – in terms of people, in terms of race, in terms of gender, but also in terms of the dialects that people use.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, and is that almost pushing back a little bit at this idea that, you know, if visualization is a language in the same way that English is or Spanish is or whatever it might be, that there are– there must be rules that people have to follow?</p>
<p><strong>Alberto Cairo</strong><br>
Yeah, I push back against that a little bit in the book because obviously, I mean, what I have taught and what I continue talking– talking about at the– talking about at the University of Miami, what I teach my classes, is what you could call let’s say standard data visualization, right? Data visualization for communication. I discuss a lot about, you know, cognitive science, you know, perception, you know, how to apply that, colour palettes – I just do standard data visualization. But that is just one of the dialects that data visualization has, right? Data visualization can be used for journalism, for business analytics, for statistics, for art, for expression, for self discovery – some of the people who I interviewed, plot their own data, for example, their own health metrics, as a way to reduce their own anxiety. So I interviewed, for example, a person who has gone through– who in the past went through very serious health problems like cancer, brain cancer and other health problems, and he discovered that the process of designing visualizations based on his own data was similar to– had similar effects as meditating about your own thoughts, right. It was a way to pour your anxiety and your dark feelings onto the graphic, so they will not overburden your mind. I find that absolutely fascinating. And it shows you that, I believe, that’s what I– what I reflect in the book, that there are really no universal rules in data visualization. There are parochial rules that are applicable to different– to the different dialects. But it is it is wrong, it is a mistake, to apply the standards of one of the dialects of data visualization to a completely different dialect of data visualization. Every visualization, I feel or I think, should be judged according to their own terms, to the terms in which they were created.</p>
<p><strong>Brian Tarran</strong><br>
The book is essentially set out as a series of discussions with these visualization designers, right. And then it’s your interspersed reflections on the conversations and things that you’re sort of taking away from them. And when you were saying in the introduction about why you wanted to have these conversations, you say you were kind of looking to, or needing to, rekindle your love for the design of information. So I wanted to ask you, maybe I’ve misjudged that sentence, but you know, had you fallen out of love with the design of information? Or did you just kind of get to that point where you thought, oh, there must be more to it than this, the way I– the way I work. What was the– what was the motivating force driving you down this path?</p>
<p><strong>Alberto Cairo</strong><br>
It’s not that I stopped, you know, being in love with data visualization, or more broadly with information design, because I teach information design – data visualization is one of the branches of information design. So I also teach, you know, illustration driven visual explanations – how an airplane works, and you do a cutaway of the airplane and you show the engines and how they work. I also do that type of information design. So it’s not that I ever stopped being in love with– with the work that I do. As I explain, by the way, in the conclusions of the book, in the epilogue of the book, which circles back to the themes in the prologue, information design and data visualization are a great part of who I am as a person. To me, it’s a way of life. I use visualization not only to communicate with other people, I use visualization also to study. When I am reading a book, I am probably producing a visualization of the book, like some sort of network diagram, in which I plot all the ideas from the book. That’s a technique, a mnemonic technique, that I learned from my– from my father, who is a medical doctor, but also a humanist. He taught me this technique to study: when you’re reading a book, just write down the concepts that you’re learning about, and then connect them with arrows make little comments on the side. Indirectly he was teaching me to make data visualization. So data visualization, information design has permeated my life since I was very, very young – since I– since I didn’t have the language to talk about what I was doing. But at the same time, in the past three or four years, many personal circumstances led me to feel, let’s say, my morale went down quite a lot, the pandemic also and then some personal problems and stuff. And I started feeling a little bit disillusioned with my own– with my own work, like having self doubts, right? Am I doing the right thing? Am I in the right career? Should I be doing something else? Have I written everything that I wanted to write about this field? Have I designed every graphic that was worthy to be designed? And I felt the need to connect with other people. Because something that I discovered throughout the years is that we human beings, we don’t think well when we are alone, we think better when we are in connection with others. So my conversations with the many friends that are showcased in the book, obviously I wanted to give their work and their lives and their values visibility because I believe that they are worthy to be explored and understood by readers. But it was also a way for me to sort of like recover a little bit of the passion that I had about information design in the past – and I was successful. I mean, I went out of– The process of writing a book can be grueling. So, while you’re writing a book, you’re always thinking, you know, this is crap. What is it that I’m doing? I don’t know where I’m going. But in hindsight, now that the book is written, and I am reviewing it, I am thinking, hmm, this is not bad. This is not bad, right? And I discovered that I was– I felt energized, thanks to all these conversations with tons of inspiring people from all over the world.</p>
<p><strong>Brian Tarran</strong><br>
I think I can sort of sympathize with that, you know, the process of creating – I don’t do data visualization myself – but creating content, it can be quite a lonely process sometimes. And you do have that, I always talk about the roller coaster of emotions – of the peaks, were you think you’re doing a great job, and then the troughs where you’re like, Oh, my God, why or I should just throw it all in. So actually being able to sit down and talk to people and share ideas does inspire you, does sort of bring you back up again, doesn’t it? But I was worried, actually, that because the last time we spoke was, I think, around the time that How Charts Lie had come out, and you were interviewed by one of our freelance writers on Significance magazine – where I was at the time – and I thought, oh, no, maybe– maybe all that encountering the dark side of data visualization and all that misinformation that was out there…</p>
<p><strong>Alberto Cairo</strong><br>
That I felt depressed, right, because the book was useless, or not useless. But I mean, it was not read by the people – How Charts Lie, I mean – it was not read by the people who needed to read the book.</p>
<p><strong>Brian Tarran</strong><br>
That is always the case with these books, isn’t it? So they– they’re really valuable, if only you could get them in the hands of the right people. That’s the challenge.</p>
<p><strong>Alberto Cairo</strong><br>
We preach– We preach to the choir a little bit with these type of books, unfortunately, yeah.</p>
<p><strong>Brian Tarran</strong><br>
Well, I still enjoyed it anyway. And it’s always valuable to, to listen to experts like yourself and take learnings from those. So the, the things that– the interviews I’ve read, I’ve not read all of them, but I think the things that jumped out for me – the interviews with people like Ed Hawkins, talking about the Warming Stripes, you know, talking about how their focus is less about – and tell me if I’m mischaracterizing this – it’s less about direct communication of information or data, it’s more about conveying like a feeling or an intuitive understanding of something. And obviously, warming stripes, most people have seen those, you know – the kind of plots of changes in temperature against a baseline over time and the kind of rapid shift to deeper, darker shades of red as we get closer to the present, you know – I think they do create a sense of the urgency of the climate crisis when you just look at them. But what lessons do you as a kind of, you know, as a data visualization designer, a journalistic data visualization designer, what do you take from those sorts of examples, where it isn’t direct communication, of information or data, it’s about feeling? What can you– what can you take from that and bring to your own work?</p>
<p><strong>Alberto Cairo</strong><br>
Well, the fact, as I was saying before, that not all visualizations are alike, as I explained in that chapter. Hawkins got a little bit of pushback, because that visualization broke some rules – and I’m doing sort of like scare quotes with my fingers right now, right? It broke some rules because it doesn’t have axes, it doesn’t have scales. It’s just a beautiful picture. But that is valuable, that is valuable, and it’s proven that it is valuable. It’s one of the most popular data visualizations in history already. And he, it’s a perfect example of a match between purpose and outcomes. And that is what needs to be explored when evaluating a data visualization. So, Hawkins told me when I interviewed him that he didn’t want to create an analytical data visualization. If he wanted to do that, he will do a line chart with like error bars or whatever, right? Something that you could publish in a paper. He has done thousands of those types of graphs. But this graphic was originally designed to bring to a festival, to be displayed in the background while there was a conversation going on about climate change. So it was designed with the specific and explicit purpose not to provide an analytical tool to explore the data but as something that brought attention to the information, something that ignited curiosity in the viewers. And I think that if that is the purpose, the outcomes actually match really well what he had in mind, and therefore the visualization works. That’s a visualization that works. So that’s just one of the many examples that appear in the book, of graphics that somehow defy conventions but at the same time, according to their own predefined purposes, work pretty well. So we have the example, for example, from Jaime Serra, who is a designer from Spain who is a– he’s a data visualization designer, he has worked for many, many years for newspapers. But the type of graphics that he creates blend the artistic with the– with the statistical and the analytical. He uses objects, for example, to create data visualizations to– he comes up with these beautiful pieces that sometimes he has showcased in exhibits all over the– all over the world. But then I also talked to people who produce what we could call more conventional data visualizations, right – people who work in public health, right, people who work in data journalism, people who live in countries where, you know, producing accurate and truthful data visualization can be dangerous to your career, right? I talk, for example, to Attila Bátorfy, who is a data journalist working in Hungary, and obviously Hungary, right now, considering the Viktor Orban regime, it’s not very friendly to journalists who want to be accurate and truthful. And he tries to be, and he’s very successful in Hungary right now, right? He’s a, he’s a voice against authoritarianism in his country. Or Anatoly Bondarenko, who is a data journalist and data visualization designer from Ukraine, who years ago created an organization called Texty, which is an investigative reporting newsroom in Ukraine, a nonprofit in Ukraine, to investigate corruption in the Ukrainian government but also Russian interference in Ukraine prior to the war. And, and that is one of my favorite chapters, because I’m Anatoly is a good friend of mine, and he’s, he’s fighting. He’s part of the Ukrainian army. And I think about him on a regular basis. And I am in touch with him just to make sure that he’s– that he’s safe, that he’s doing good. That chapter begins with a sentence that says that I sometimes wake up in shock thinking about, you know, my friend is at war, right? That’s such a strange thought and his work is so valuable, it’s so impressive. Again, what I find inspiring in all the people I talk to, I talk with, in the book is not just the work itself, it’s the values and the motivations behind the work and sometimes the resilience of the people producing that work. That’s what I find inspiring.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah, I was– when you were talking there about the Hawkins warming stripes examples, the– the idea of evaluating visualizations, you know, on their own terms, on their kind of their stated purposes, I think is quite important. But do you think people creating data visualizations, do they spend enough time thinking through generally – not the experts you’ve talked to, obviously, they’re the maybe the exception – but about what the purpose– what is it that I want to achieve with this data visualization? Is that kind of one of the things that all your interviewees have in common, a very clear sense of purpose?</p>
<p><strong>Alberto Cairo</strong><br>
They do. They do have that sense of purpose. That doesn’t mean that they don’t sometimes create these great visualizations out of a whim – say, I’m gonna just create a pretty graphic based on that, no purpose whatsoever. And that’s perfectly fine. Again, the analogy with writing. Not all writing can be technical writing. That’s just one of the types of writing that we could use. And conventional, traditional visualization is analogous to technical writing – you want to communicate something effectively, clearly, and therefore you try to create something that doesn’t use too many words, or too many, you know, verbal flourishes, you just go directly to the point and try to communicate directly. But that’s not the only way you can use writing. You can write poetry, so why not using data visualization to create visual poetry? That’s perfectly, perfectly fine. Again, every visualization needs to be judged based on their own– on their own stated purposes. As to the question of whether people in general – like, not the people I talked to in the book, for the book – but, you know, people in general think about purpose when designing data visualizations, that’s a question that I cannot answer. But that’s the core of my classes and workshops. It’s like my classes and workshops outline, both at the university but also as a consultant, put a lot of emphasis on the purpose part. I mean, just list what do you want to communicate? What do you want to achieve? Create an actually a bullet point list of what you want to communicate, and based on that list, then you can make choices. The way that I teach data visualization these days is not about teaching rules, right? Like, you know, use a bar graph to compare, use this graphic for that, use a scatterplot to show associations between, you know, continuous variables or whatever. No, that’s not the way I teach visualization. I teach visualization based on a process of reasoning, right? Reason that takes you from the purpose to the outcome. And every decision down the road in between those two points needs to be somehow justified. You need to justify every decision that you make in the visualization in a way that is– that can be persuasive to other people who may be in your team. I use this colour palette because, and what comes after the because is the important part. I use this type of graphic because, and what comes after the because is the important part, and so on and so forth.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, there’s something that struck me. I think it was a podcast producer who came up this idea of the XY story formula – that’s how you assess the value of a kind of an article pitch. Now, I’m writing a story about X, and it is interesting because Y – and it’s the bit that follows after the “because” that determines– you have to work on that and refine that, and that’s what shapes your story and your outputs. I’m glad you brought up teaching as well, because I was reading through the epilogue, and it said about you having “anarchic leanings and sympathies” and I was kind of curious about how those sympathies and leanings manifest in your work or in your teaching. And obviously, you said you don’t teach rules. So maybe that’s part of it. But…</p>
<p><strong>Alberto Cairo</strong><br>
What sympathies are you referring to?</p>
<p><strong>Brian Tarran</strong><br>
I don’t know. It was just that phrase jumped out: I have, I have anarchic– I think it’s “despite my anarchic leanings and sympathies”, and I was kind of curious as to what are those, and how do they– how do they manifest?</p>
<p><strong>Alberto Cairo</strong><br>
Well, one of the points that I make, particularly in the epilogue, which I think that is the most important part of the book, because it’s where I lay out my own thinking – is that, one of the points that I make is that you cannot really separate the work from the people. And I make the analogy with philosophy, I read a lot of philosophy. There is this book that I absolutely love about philosophy, titled “What is Ancient Philosophy?” by Pierre Hadott, who was, I think that he was French – wonderful book, absolutely wonderful book if you’re interested in the ancient history of philosophy, that book is amazing. Talks about the Hellenistic tradition of philosophy. I could go on and on and talk about that book. I absolutely love it. I think that I read it four times, something like that. And the point that Hadott makes in “What is Ancient Philosophy?” is that it takes you a long way to understand the philosophy of the, you know, the classics – Plato, Aristotle, and then the Hellenists like the Epicureans, or the Stoics, or whatever – it takes you a long way if you sort of like understand the temperament of those people, and their lived experiences, what they went through in their lives, right? If you understand, for example, what Plato lived, his times and his temperament, and also the history of the times when he lived, you can understand the Republic better, his best book, right? You, you sort of like guess where it comes from, right, where his thinking comes from. And I think that’s something similar can be said about visualization, right? I have my own temperament. I have a– I have a very driven temperament. So I’m quite a strong will – when I decide that I’m going to do something, I usually put the energy to do it. But at the same time, I’m quite anarchic, not in the sense of being disorganized, but in the sense that I don’t deal with authority well. I just want to be left alone, right? Just leave me alone. I will figure things out on my own. I work well with other people, right. But in horizontal organizations, I enjoy horizontal teams, rather than hierarchical teams, right. I work really well in horizontal teams. And that is somehow reflected, I think, in the way that I think about data visualization. I somehow rebelled against, you know, the 1980s, 1990s tradition of data visualization teaching around what I call the Tuftean – after Edward Tufte – the Tuftean tradition of saying, this is the only way to do visualization well, these are the rules of data visualization. Well, why? Why are those the rules? Tell me what is this based on, or is it just your own opinion? I mean, I enjoy reading Tufte and I enjoy reading, you know, people like Steven Few, who is a friend of mine, etc. But at the same time I rebelled against that tradition, because in many cases, as I explain in The Art of Insight, many of those so called rules are merely the opinions of people. This is just my opinion. I like this stuff. I like this style, and therefore, I’m going to try to pass my own opinion as if it were a rule of design. I think that we need to be a little bit more honest about what we are doing. Many of those rules are not really grounded on any sort of empirical evidence, and therefore they are still valuable – I think that people should keep reading Tufte, they should keep reading [unclear] and many of the, we should keep reading them. But always with a pinch of salt, taking everything that we read with a pinch of salt, and this applies to my own books as well. We need to be a little bit more skeptical, a little bit more flexible in some sense, knowing that we are on these together and what really matters, I think, is the conversation between people in the field. Conversation is a word that appears a lot in The Art of Insight. I see my work, and I see the work of everybody else who writes or thinks or makes data visualizations as part of an ongoing conversation between people in which we can learn from each other, borrow from each other – always understanding that our opinions can be strongly stated, but sometimes they have very, very shaky foundations.</p>
<p><strong>Brian Tarran</strong><br>
What you’re saying about the importance of still reading these kinds of texts, where the rules – again, in inverted commas – are set, the importance of doing that, that kind of reminded me of like in my, in my own world of, you know, the written word, people like James Ellroy, the author of American Tabloid, you know, about understanding the rules of grammar so that you know how to break them for effect and for impact and things like that. So I can see how that applies to data visualization.</p>
<p><strong>Alberto Cairo</strong><br>
It is, yeah, that’s sort of like already has become a cliche, right: learn the rules, so you can break them. I think that that is valuable. But at the same time, I think that we need to go beyond that and say, there are really no rules. I mean, there are a few things that could be considered rules. For example, we know that, you know, if you want to compare numbers, a bar graph is usually superior to a pie chart, for example. We know that, there is empirical evidence behind that, so you can sort of like derive a principle out of that, right? But beyond those very basic things, there are really not many rules. What there are is a lot of conventions, inherited conventions, right, that historically have developed and we have– we have inherited. So we could say, you know, it’s good to learn the conventions. It is still good to learn about perception and cognition to guide your decisions. But after you do that, all that matters is the choices that you make with the knowledge that you have, and with the guesses that you can make. Right? So it’s not that you’re breaking the rules, you’re creating your own path, based on the inherited knowledge that you have under your belt.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. My last question for you – because I don’t want to take up too much of your time, I know you are very busy, Alberto – is, you mentioned, again, going back to the previous question, or two, the people that you work with, and one of those sometime collaborators is Shirley Wu, who you refer to in your introduction, and I was really struck by the description of the installation, the number of COVID deaths each week, and this this dripping valve. I think what struck me most was that, you know, obviously, Shirley had this idea that the drips would represent the number of COVID deaths each week, these drips into a bowl, but that this wasn’t explicitly stated to people viewing the installation, right? She created space for viewers to bring their own interpretations, and they did. And again, it’s one of these things that I think is a beautiful idea – being able to, to withhold some information – but I don’t know, how does that manifest if you’re, you know, a data scientist or whatever, and you’re trying to create visualizations for, you know, an internal client or whatever it might be. How do you kind of bring some of that, that flavor and that interpretation and that space, to a graphic? I think that’s something that I was thinking about when reading that book, that part of the book.</p>
<p><strong>Alberto Cairo</strong><br>
There are many examples like that in the book. For example, in the chapter about Jaime Serra, Jaime created once a graphic in which– he drinks a lot of coffee, and he wanted to – remember that one – he wanted to, he wanted to see how much coffee he was actually drinking throughout a year. And if I have to do that, I will, you know, I will get my mug, the mug that I use every day to drink my coffee, I will draw a scale on top of that, and then I will measure the number of ounces of coffee that I’m drinking. At the end of the year, I will probably design a line graph, a time series line graph, to see whether there is any seasonality in my coffee consumption. I will design an analytical chart or so to speak, right, a graphic to analyze my own data. But he wanted to design something a little bit more fun, a little bit more expressive, a little more artistic and what he did was to create a graphic in which he plotted the amount of coffee that he drinks throughout a year through coffee stains. He got 12 pieces of paper, each one of them corresponding to a month. He folded those pieces of paper to subdivide them into quadrants, each one corresponding to a day. And then whenever he was drinking coffee, he tried to leave a coffee stain on the corresponding quadrant of the corresponding paper. And the result was sort of like it was a physic– it’s a physical data visualization. And it is amazing. Now, does that mean that you can insert that type of graphic, let’s say, in a business dashboard, or on a quarterly report in a company? No, that’s not the purpose of that type of visualization. The way that I usually explain the value of that type of visualization is to create this sort of like hypothetical scenario. And I have used these many times with clients when presenting you know, Shirley’s work or Jaime’s work. I say this is not the type of graphic that you use for analysis, right. For analysis, you need to use line graphs, bar graphs, scatter plots, traditional conventional data visualizations. But let’s suppose that you, for some reason, one year you conduct a survey internally in your company to analyze how much coffee people drink in the company, right? And you do sort of like this beautiful report that you print out as a hardcover book to give to your own clients as a gift when they come to visit you. What do you put inside of the book? The analytical graphics, right? The analytical charts that slice and dice the data by gender, by location, by whatever? You put all the conventional traditional graphics? What do you put on the cover? What you put on the cover is the beautiful artistic data visualization, which is still a data visualization. And same thing with Shirley’s work, right. Shirley’s installation about COVID: true, it’s not a graphic. It’s not a visualization. It’s not really a graphic because it’s physical. It’s a physical installation. But it is not a visualization that is intended to communicate the data in any sort of like, with accuracy or anything, it just tries to create a feeling. So again, imagine that you work for let’s say, a company focusing on public health or whatever. And every day, what you produce will be conventional charts and graphs and maps. That’s what we need to use to analyze data. But let’s suppose that you want to create some sort of like beautiful piece of artwork to display in your headquarters. That will be an amazing piece to display in your headquarters. It will get people– it will get visitors curious about what you do, it may drive– it may lead you to conversations about the data that they deal with everyday, the same way that Ed Hawkins’s warming stripes graphic did. It’s just a different type of data visualization that needs to be judged according to its own purposes, under its own terms.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, fantastic. Well, that’s a really nice idea to end on. Hope some people take it forward, and future visits to offices will be more visually appealing as we get to explore those spaces. So, Alberto, thank you very much. So the book is out in November, yes?</p>
<p><strong>Alberto Cairo</strong><br>
November the 15th. Yeah.</p>
<p><strong>Brian Tarran</strong><br>
Is there a website yet that people can go and find out more details?</p>
<p><strong>Alberto Cairo</strong><br>
No, still working on it. For now, there is some information in my weblog, which is the title of my first book, The Functional Art. So, it’s thefunctionalart.com. That’s my web blog. And there’s some information about The Art of Insight there, including some, you know, some sneak peeks.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Well, we’ll put a link to that in the in the show notes. So, Alberto, thank you for joining us today. Best of luck finishing up the book and the website. And I hope you can join us again soon because there’s so much more that I could discuss about the book with you, but it’s been great talking to you today.</p>
<p><strong>Alberto Cairo</strong><br>
Thank you, Brian.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Images are not covered by this licence. Photo of Alberto Cairo is copyright JCA Photography.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “The many ‘dialects’ of data visualization: Alberto Cairo and ‘The Art of Insight.’” Real World Data Science, August 1, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Data visualisation</category>
  <category>Communication</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html</guid>
  <pubDate>Tue, 01 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/images/alberto-cairo.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘Go out and talk about data science, particularly to schoolchildren’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/schools-outreach.html</link>
  <description><![CDATA[ 




<p>Rachel Hilliam, statistics professor at The Open University, used her inaugural lecture this month to make “a real plea” to the data science community “for outreach into schools”, to help build excitement and awareness of the promise and potential for careers in data science.</p>
<p>“We have a plethora of jobs that we cannot fill in data science at the moment,” said Hilliam. “We’ve had all sorts of initiatives in terms of trying to retrain people, and that’s great, and those are gaps that we need to plug. But unless we get that pipeline coming through, we’re always going to have this problem at the top.”</p>
<p>Hilliam, who is chair of the <a href="https://alliancefordatascienceprofessionals.co.uk">Alliance for Data Science Professionals</a>, wants schoolchildren and teachers to be made more aware of the benefits of, and opportunities for, data science careers. “Let me tell you,” she said, “if you go out into a school and say, ‘Do your kids want to be a data scientist?’, the teachers will look at you and go, ‘A what?’. They have no idea, generally, that data science actually exists, which is a shame.”</p>
<p>But there are plentiful opportunities to introduce data science to children, Hilliam suggests. She began her talk by saying that: “Data is everywhere – in every single thing that we do, in all of our walks of life.” And she concluded by saying: “Whatever it is that these kids are interested in, […] there is lots of data out there, so there is absolutely no reason why we can’t excite children in a career in data science. So, that’s where I’d like to finish. Go out and talk about data science, particularly to schoolchildren!”</p>
<p>Watch the lecture in full below or on YouTube. Skip to <a href="https://www.youtube.com/live/tCQhU4yP0OU?feature=share&amp;t=1024">17:04</a> for the start of the talk.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/tCQhU4yP0OU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@neonbrand?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Kenny Eliason</a> on <a href="https://unsplash.com/photos/zFSo6bnZJTw?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘Go out and talk about data science, particularly to schoolchildren.’” Real World Data Science, July 27, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/schools-outreach.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Education</category>
  <category>Data literacy</category>
  <category>Outreach</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/schools-outreach.html</guid>
  <pubDate>Thu, 27 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/images/kenny-eliason-zFSo6bnZJTw-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
</channel>
</rss>
