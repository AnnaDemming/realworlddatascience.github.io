<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/viewpoints/index.html</link>
<atom:link href="https://realworlddatascience.net/viewpoints/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://realworlddatascience.net/images/rwds-logo-150px.png</url>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/viewpoints/index.html</link>
<height>83</height>
<width>144</width>
</image>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Mon, 14 Aug 2023 10:13:29 GMT</lastBuildDate>
<item>
  <title>Live from Toronto: Real World Data Science at the Joint Statistical Meetings</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html</link>
  <description><![CDATA[ 




<section id="sunday-august-6" class="level2">
<h2 class="anchored" data-anchor-id="sunday-august-6">Sunday, August 6</h2>
<section id="use-of-color-in-statistical-charts" class="level3">
<h3 class="anchored" data-anchor-id="use-of-color-in-statistical-charts">Use of color in statistical charts</h3>
<p><em>Haley Jeppson, Danielle Albers Szafir, and Ian Lyttle</em></p>
<p>JSM 2023 is underway, and the first session I attended today was this panel on the use of colour in statistical charts.</p>
<p>The topic appealed to me for two reasons:</p>
<ul>
<li>Before my trip to Toronto, I interviewed <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html">Alberto Cairo about the many “dialects” of data visualisation</a>.</li>
<li>I’ve recently been working with Andreas Krause and Nicola Rennie to create new guidance for improving statistical graphics, titled “<a href="https://royal-statistical-society.github.io/datavisguide/">Best Practices for Data Visualisation</a>”.</li>
</ul>
<p>The “Best Practices…” guide links to several useful data visualisation tools, and this session today has put a few more on my radar:</p>
<ul>
<li><p><a href="https://cmci.colorado.edu/visualab/ColorCrafting/">Color Crafting</a>, by Stephen Smart, Keke Wu, and Danielle Albers Szafir. The authors write: “Visualizations often encode numeric data using sequential and diverging color ramps. Effective ramps use colors that are sufficiently discriminable, align well with the data, and are aesthetically pleasing. Designers rely on years of experience to create high-quality color ramps. However, it is challenging for novice visualization developers that lack this experience to craft effective ramps as most guidelines for constructing ramps are loosely defined qualitative heuristics that are often difficult to apply. Our goal is to enable visualization developers to readily create effective color encodings using a single seed color.”</p></li>
<li><p><a href="https://observablehq.com/collection/@ijlyttle/color">Computing on color</a>, a collection of Observable notebooks by Ian Lyttle that allow users to see how different colour spaces and colour scales work with different types of colour vision deficiency.</p></li>
</ul>
</section>
</section>
<section id="monday-august-7" class="level2">
<h2 class="anchored" data-anchor-id="monday-august-7">Monday, August 7</h2>
<section id="astronomers-speak-statistics" class="level3">
<h3 class="anchored" data-anchor-id="astronomers-speak-statistics">Astronomers Speak Statistics</h3>
<p>Astrophysicist Joel Leja kicked off his JSM talk with a video of the launch of the James Webb Space Telescope – an inspiring way to start the day, and a prelude to a discussion of the statistical challenges involved in studying the deep universe.</p>
<p>James Webb, since launch, has “completely expanded our point of view”, said Leja, allowing astronomers to explore the first stars and galaxies at greater resolution than ever before.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/james-webb.png" class="img-fluid figure-img" alt="Image from the James Webb telescope showing two galaxies in the process of merging, twisting each other out of shape." width="500"></p>
<figcaption class="figure-caption">Image from the James Webb telescope showing two galaxies in the process of merging, twisting each other out of shape. Credit: ESA/Webb, NASA &amp; CSA, L. Armus, A. Evan, licenced under CC BY 2.0.</figcaption>
</figure>
</div>
<p>Already, after only 13 months of operation, the images and data sent back by the telescope have left observers astounded: for example, finding suspected early galaxies that are bigger than thought possible based on extreme value analysis.</p>
<p>But the big challenge facing those studying the early universe is trying to work out how early galaxies evolved over time. “We can’t watch this happen,” said Leja, joking that this process lasts longer than a typical PhD. So, instead, he said, “We need to use statistics to understand this, to figure out how they grow up.”</p>
</section>
<section id="teaching-statistics-in-higher-education-with-active-learning" class="level3">
<h3 class="anchored" data-anchor-id="teaching-statistics-in-higher-education-with-active-learning">Teaching statistics in higher education with active learning</h3>
<p>Great talk from Nathaniel T. Stevens of the University of Waterloo, explaining how a posting for a Netflix job inspired the creation of a final project for students to learn response surface methodology.</p>
<p>The job ad in question “really opened my eyes” to the use of online controlled experiments by companies, said Stevens. He told delegates how LinkedIn, the business social networking site, runs over 400 experiments per day, trying to optimise user experience and other aspects of site engagement.</p>
<p>Netflix’s job ad highlighted just how sophisticated these experiments are, said Stevens. People might hear companies refer to their use of A/B tests, but the term trivialises what’s involved, Stevens explained.</p>
<p>Having encountered a job ad from Netflix, looking for someone to design, run, and analyse experiments and support internal methodological research, Stevens was inspired to present students with a hypothetical business problem, based on the Netflix homepage. That homepage, for those not familiar, features rows and rows of movies and TV shows sorted by theme, each show presented as a tile that, when hovered over, leads to a pop-up with a video preview and a match score – a prediction of how likely a viewer is to enjoy the show.</p>
<p>Stevens explained the hypothetical goal as trying to minimise “browsing time” – the time it takes a Netflix user to pick something to watch. Browsing time was defined as time spent scrolling and searching, not including time spent watching previews.</p>
<p>Students were given four factors that might influence browsing time – tile size, match score, preview length, and preview type – and through a sequence of experiments based on data generated by a Shiny app, students sought to minimise browsing time.</p>
<p>The response from the students? Two Netflix-style thumbs up. Ta-dum!</p>
</section>
</section>
<section id="tuesday-august-8" class="level2">
<h2 class="anchored" data-anchor-id="tuesday-august-8">Tuesday, August 8</h2>
<section id="the-next-50-years-of-data-science" class="level3">
<h3 class="anchored" data-anchor-id="the-next-50-years-of-data-science">The Next 50 Years of Data Science</h3>
<p>Stanford University’s David Donoho wrestled with the question of whether a singularity is approaching in this post-lunch session on the future of data science.</p>
<p>Taking his cue from the 2005 Ray Kurzweil book, <em>The Singularity is Near</em>, Donoho reviewed recent – and sometimes rapid – advances in data science and artificial intelligence to argue that a singularity may have already arrived, just not in the way Kurzweil supposed.</p>
<p>Kurzweil’s book argues that at some point after the 2030s, machine intelligence will supersede human intelligence, leading to a takeover or disruption of life as we know it.</p>
<p>At JSM, Donoho argued that we have certainly seen a “massive scaling” of compute over the past decade, along with expanded communications infrastructure and the wider spread of information – all of which is having an impact on human behaviour.</p>
<p>That human behaviour can often now be directly measured thanks to the proliferation of digital devices with data collection capabilities, and this in turn is leading to a major scaling in data sets and performance scaling for machine learning models.</p>
<p>But does this mean that an AI singularity is near? Not according to Donoho. The notion of an AI singularity “is a kind of misdirection”, he said. Something very profound is happening, Donoho argued, and it is the culmination of three long-term initiatives in data science that have come together in recent years. “They constitute a singularity on their own.”</p>
<p>These three initiatives, as Donoho described, are: datafication and data sharing; adherence to the “challenge problem” paradigm; and documentation and sharing of code. These are solid achievements that came out of the last decade, said Donoho, and they are “truly revolutionary” when they come together to form what he refers to as “frictionless reproducibility.”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/donoho-talk.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/donoho-talk.png" class="img-fluid figure-img" alt="Slide text reads: Today's data scientists: typical interactions: What's your package name? What's your URL? QR Code? What's your stack? Today's data scientists: implicit demands: Data sharing, Specific numerical performance measures, Code sharing, Single-click access. Frictionless replications." width="500"></a></p>
<figcaption class="figure-caption">Photo of David Donoho’s slide, describing the scientific revolution of the “data science decade”. Photo by Brian Tarran, licenced under CC BY 4.0.</figcaption>
</figure>
</div>
<p>Frictionless reproducibility, when achieved, leads to a “reproducibility singularity” – the moment where it takes almost no time at all for an idea to spread. “If there is an AI singularity,” said Donoho, “it will be because this came first.”</p>
</section>
</section>
<section id="wednesday-august-9" class="level2">
<h2 class="anchored" data-anchor-id="wednesday-august-9">Wednesday, August 9</h2>
<section id="new-frontiers-of-statistics-in-trustworthy-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="new-frontiers-of-statistics-in-trustworthy-machine-learning">New frontiers of statistics in trustworthy machine learning</h3>
<p>Data, data everywhere, but is it safe to “drink”? A presentation this morning from Yaoliang Yu of the University of Waterloo looked at the issue of data poisoning attacks on algorithms and the effectiveness of current approaches.</p>
<p>Yu began by explaining how machine learning algorithms require a lot of data for training, and that large amounts of data can be obtained cheaply by scraping the web.</p>
<p>But, he said, when researchers download this cheap data, they are bound to worry about the quality of it. Drawing an analogy to food poisoning, Yu asked: What if the data we “feed” to algorithms is not clean? What is the impact of that?</p>
<p>As a real-world example of a data poisoning attack, Yu pointed to TayTweets, the Microsoft Twitter chatbot that spewed racism within hours of launch <a href="https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist">after Twitter users began engaging with it</a>.</p>
<p>Yu then walked delegates through some experiments showing how, generally, indiscriminate data poisoning attacks are ineffective when the ratio of poisoned data to clean data is small. A poisoning rate of 3%, for example, leads to model accuracy drops of 1.5%–2%, Yu said.</p>
<p>However, he then put forward the idea of “parameter corruption” – an attack that seeks to modify a model directly. Yu showed that this would be more effective in terms of accuracy loss, though – fortunately – perhaps less practical to implement.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="http://www.yasmindwiputri.com">Yasmin Dwiputri</a> &amp; <a href="https://www.datahazards.com">Data Hazards Project</a> / <a href="https://www.betterimagesofai.org">Better Images of AI</a> / Managing Data Hazards / <a href="https://creativecommons.org/licenses/by/4.0/">Licenced by CC BY 4.0</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Live from Toronto: Real World Data Science at the Joint Statistical Meetings.” Real World Data Science, August 6, 2023, updated August 9, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>Conferences</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html</guid>
  <pubDate>Mon, 14 Aug 2023 10:13:29 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/data-hazards.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>The many ‘dialects’ of data visualization: Alberto Cairo and ‘The Art of Insight’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html</link>
  <description><![CDATA[ 




<p>Alberto Cairo is Knight Chair in Visual Journalism at the School of Communication of the University of Miami (UM). He’s also the director of visualization at UM’s Institute for Data Science and Computing. He joins Real World Data Science to discuss his upcoming book, <em>The Art of Insight: How Great Visualization Designers Think</em>, in which Cairo reflects on his conversations with data artists, data journalists, and information designers.</p>
<p>“If we can conceptualise data visualization as language, this language can have multiple dialects,” says Cairo. “And these dialects – let’s say the statistical dialect, the data journalism dialect, the art dialect – they are not mutually exclusive. They exist, or they should exist, ideally, in constant conversation with each other. So, we can borrow ideas from each other, learn from each other.”</p>
<p>Listen to the full interview below or on <a href="https://www.youtube.com/watch?v=htUWWVzYTUI">YouTube</a>.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/htUWWVzYTUI" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Find out more about Cairo’s work and his upcoming book at <a href="http://www.thefunctionalart.com/">thefunctionalart.com</a>.</p>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to Real World Data Science. I’m Brian Tarran. And today I’m joined by Alberto Cairo, Knight chair in visual journalism at the School of Communication of the University of Miami. He’s also the director of visualization at UM’s Institute for data science and computing. Alberto, welcome. Thanks for joining us.</p>
<p><strong>Alberto Cairo</strong><br>
Hi, Brian. Very nice to be here. Thank you for inviting me.</p>
<p><strong>Brian Tarran</strong><br>
No worries. Well, today we’re excited to be discussing your new book, The Art of Insight: How Great Visualization Designers Think. I think it’s a really– I’ve not read all of it yet. I’ve dipped in and out of some chapters that you kindly sent me ahead of time. I think it’s really interesting and unique. I think the thing that struck me was often when we talk about visualization design, we tend to concentrate on what designers do, not necessarily about how they think about what they do, or how they think generally. And so, that was to be my first question for you is like, what aspects of their thought processes, these experts, what were you really trying to understand and why?</p>
<p><strong>Alberto Cairo</strong><br>
Yeah, yeah, this latest book of mine is very different to the previous one that I– that I wrote. The book is not out yet, by the way, the book will be out in November of 2023. I am in the process of copy editing it, getting rid of typos. But as you said, I mean the book focuses not so much on the– on the work itself, but more on the people who produce the work and the motivations and values that lie behind the work that they do. It is also, in comparison to my previous books, it is also a shift of perspective, I would say because my previous books, particularly The Truthful Art and How Charts Lie which came out in 2019, focus mostly on statistical visualization. Right, so it has a very strong, they both have a very strong statistical focus – how to make sure that your graphs and your data maps don’t deceive people. I teach elementary principles of visualization, of communication through visualization. But visualization is much more than that. And that is what I wanted to convey with this book. More and more throughout the years, I have come to understand data visualization not so much as a representation of data for insight or for communication, but as a language, a language that can be used for many different purposes. And I try to reflect that in the book. Obviously, a great part of the book is devoted to people who come from the same world where I come from, the professional world where I come from, the world of data journalism, so plenty of them are data journalists. Many of them are data analysts and statisticians and researchers. But a good portion of the book is devoted to people who use– who use visualization for other purposes such as self expression, self discovery, art in some cases. I wanted to provide a sort of like a broader understanding of the language of visualization and I also talk about– I also discussed the fact that if we can conceptualize data visualization as language, this language can have multiple dialects. And that is what I wanted to convey in the book. And these are not, these dialects – let’s say the statistical dialect, the data journalism dialect, the art dialect – they are not mutually exclusive. They exist, or they should exist, ideally, in constant conversation with each other. So we can borrow ideas from each other, learn from each other. So I wanted to provide sort of like an overview of the huge diversity that exists in the world of visualization – in terms of people, in terms of race, in terms of gender, but also in terms of the dialects that people use.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, and is that almost pushing back a little bit at this idea that, you know, if visualization is a language in the same way that English is or Spanish is or whatever it might be, that there are– there must be rules that people have to follow?</p>
<p><strong>Alberto Cairo</strong><br>
Yeah, I push back against that a little bit in the book because obviously, I mean, what I have taught and what I continue talking– talking about at the– talking about at the University of Miami, what I teach my classes, is what you could call let’s say standard data visualization, right? Data visualization for communication. I discuss a lot about, you know, cognitive science, you know, perception, you know, how to apply that, colour palettes – I just do standard data visualization. But that is just one of the dialects that data visualization has, right? Data visualization can be used for journalism, for business analytics, for statistics, for art, for expression, for self discovery – some of the people who I interviewed, plot their own data, for example, their own health metrics, as a way to reduce their own anxiety. So I interviewed, for example, a person who has gone through– who in the past went through very serious health problems like cancer, brain cancer and other health problems, and he discovered that the process of designing visualizations based on his own data was similar to– had similar effects as meditating about your own thoughts, right. It was a way to pour your anxiety and your dark feelings onto the graphic, so they will not overburden your mind. I find that absolutely fascinating. And it shows you that, I believe, that’s what I– what I reflect in the book, that there are really no universal rules in data visualization. There are parochial rules that are applicable to different– to the different dialects. But it is it is wrong, it is a mistake, to apply the standards of one of the dialects of data visualization to a completely different dialect of data visualization. Every visualization, I feel or I think, should be judged according to their own terms, to the terms in which they were created.</p>
<p><strong>Brian Tarran</strong><br>
The book is essentially set out as a series of discussions with these visualization designers, right. And then it’s your interspersed reflections on the conversations and things that you’re sort of taking away from them. And when you were saying in the introduction about why you wanted to have these conversations, you say you were kind of looking to, or needing to, rekindle your love for the design of information. So I wanted to ask you, maybe I’ve misjudged that sentence, but you know, had you fallen out of love with the design of information? Or did you just kind of get to that point where you thought, oh, there must be more to it than this, the way I– the way I work. What was the– what was the motivating force driving you down this path?</p>
<p><strong>Alberto Cairo</strong><br>
It’s not that I stopped, you know, being in love with data visualization, or more broadly with information design, because I teach information design – data visualization is one of the branches of information design. So I also teach, you know, illustration driven visual explanations – how an airplane works, and you do a cutaway of the airplane and you show the engines and how they work. I also do that type of information design. So it’s not that I ever stopped being in love with– with the work that I do. As I explain, by the way, in the conclusions of the book, in the epilogue of the book, which circles back to the themes in the prologue, information design and data visualization are a great part of who I am as a person. To me, it’s a way of life. I use visualization not only to communicate with other people, I use visualization also to study. When I am reading a book, I am probably producing a visualization of the book, like some sort of network diagram, in which I plot all the ideas from the book. That’s a technique, a mnemonic technique, that I learned from my– from my father, who is a medical doctor, but also a humanist. He taught me this technique to study: when you’re reading a book, just write down the concepts that you’re learning about, and then connect them with arrows make little comments on the side. Indirectly he was teaching me to make data visualization. So data visualization, information design has permeated my life since I was very, very young – since I– since I didn’t have the language to talk about what I was doing. But at the same time, in the past three or four years, many personal circumstances led me to feel, let’s say, my morale went down quite a lot, the pandemic also and then some personal problems and stuff. And I started feeling a little bit disillusioned with my own– with my own work, like having self doubts, right? Am I doing the right thing? Am I in the right career? Should I be doing something else? Have I written everything that I wanted to write about this field? Have I designed every graphic that was worthy to be designed? And I felt the need to connect with other people. Because something that I discovered throughout the years is that we human beings, we don’t think well when we are alone, we think better when we are in connection with others. So my conversations with the many friends that are showcased in the book, obviously I wanted to give their work and their lives and their values visibility because I believe that they are worthy to be explored and understood by readers. But it was also a way for me to sort of like recover a little bit of the passion that I had about information design in the past – and I was successful. I mean, I went out of– The process of writing a book can be grueling. So, while you’re writing a book, you’re always thinking, you know, this is crap. What is it that I’m doing? I don’t know where I’m going. But in hindsight, now that the book is written, and I am reviewing it, I am thinking, hmm, this is not bad. This is not bad, right? And I discovered that I was– I felt energized, thanks to all these conversations with tons of inspiring people from all over the world.</p>
<p><strong>Brian Tarran</strong><br>
I think I can sort of sympathize with that, you know, the process of creating – I don’t do data visualization myself – but creating content, it can be quite a lonely process sometimes. And you do have that, I always talk about the roller coaster of emotions – of the peaks, were you think you’re doing a great job, and then the troughs where you’re like, Oh, my God, why or I should just throw it all in. So actually being able to sit down and talk to people and share ideas does inspire you, does sort of bring you back up again, doesn’t it? But I was worried, actually, that because the last time we spoke was, I think, around the time that How Charts Lie had come out, and you were interviewed by one of our freelance writers on Significance magazine – where I was at the time – and I thought, oh, no, maybe– maybe all that encountering the dark side of data visualization and all that misinformation that was out there…</p>
<p><strong>Alberto Cairo</strong><br>
That I felt depressed, right, because the book was useless, or not useless. But I mean, it was not read by the people – How Charts Lie, I mean – it was not read by the people who needed to read the book.</p>
<p><strong>Brian Tarran</strong><br>
That is always the case with these books, isn’t it? So they– they’re really valuable, if only you could get them in the hands of the right people. That’s the challenge.</p>
<p><strong>Alberto Cairo</strong><br>
We preach– We preach to the choir a little bit with these type of books, unfortunately, yeah.</p>
<p><strong>Brian Tarran</strong><br>
Well, I still enjoyed it anyway. And it’s always valuable to, to listen to experts like yourself and take learnings from those. So the, the things that– the interviews I’ve read, I’ve not read all of them, but I think the things that jumped out for me – the interviews with people like Ed Hawkins, talking about the Warming Stripes, you know, talking about how their focus is less about – and tell me if I’m mischaracterizing this – it’s less about direct communication of information or data, it’s more about conveying like a feeling or an intuitive understanding of something. And obviously, warming stripes, most people have seen those, you know – the kind of plots of changes in temperature against a baseline over time and the kind of rapid shift to deeper, darker shades of red as we get closer to the present, you know – I think they do create a sense of the urgency of the climate crisis when you just look at them. But what lessons do you as a kind of, you know, as a data visualization designer, a journalistic data visualization designer, what do you take from those sorts of examples, where it isn’t direct communication, of information or data, it’s about feeling? What can you– what can you take from that and bring to your own work?</p>
<p><strong>Alberto Cairo</strong><br>
Well, the fact, as I was saying before, that not all visualizations are alike, as I explained in that chapter. Hawkins got a little bit of pushback, because that visualization broke some rules – and I’m doing sort of like scare quotes with my fingers right now, right? It broke some rules because it doesn’t have axes, it doesn’t have scales. It’s just a beautiful picture. But that is valuable, that is valuable, and it’s proven that it is valuable. It’s one of the most popular data visualizations in history already. And he, it’s a perfect example of a match between purpose and outcomes. And that is what needs to be explored when evaluating a data visualization. So, Hawkins told me when I interviewed him that he didn’t want to create an analytical data visualization. If he wanted to do that, he will do a line chart with like error bars or whatever, right? Something that you could publish in a paper. He has done thousands of those types of graphs. But this graphic was originally designed to bring to a festival, to be displayed in the background while there was a conversation going on about climate change. So it was designed with the specific and explicit purpose not to provide an analytical tool to explore the data but as something that brought attention to the information, something that ignited curiosity in the viewers. And I think that if that is the purpose, the outcomes actually match really well what he had in mind, and therefore the visualization works. That’s a visualization that works. So that’s just one of the many examples that appear in the book, of graphics that somehow defy conventions but at the same time, according to their own predefined purposes, work pretty well. So we have the example, for example, from Jaime Serra, who is a designer from Spain who is a– he’s a data visualization designer, he has worked for many, many years for newspapers. But the type of graphics that he creates blend the artistic with the– with the statistical and the analytical. He uses objects, for example, to create data visualizations to– he comes up with these beautiful pieces that sometimes he has showcased in exhibits all over the– all over the world. But then I also talked to people who produce what we could call more conventional data visualizations, right – people who work in public health, right, people who work in data journalism, people who live in countries where, you know, producing accurate and truthful data visualization can be dangerous to your career, right? I talk, for example, to Attila Bátorfy, who is a data journalist working in Hungary, and obviously Hungary, right now, considering the Viktor Orban regime, it’s not very friendly to journalists who want to be accurate and truthful. And he tries to be, and he’s very successful in Hungary right now, right? He’s a, he’s a voice against authoritarianism in his country. Or Anatoly Bondarenko, who is a data journalist and data visualization designer from Ukraine, who years ago created an organization called Texty, which is an investigative reporting newsroom in Ukraine, a nonprofit in Ukraine, to investigate corruption in the Ukrainian government but also Russian interference in Ukraine prior to the war. And, and that is one of my favorite chapters, because I’m Anatoly is a good friend of mine, and he’s, he’s fighting. He’s part of the Ukrainian army. And I think about him on a regular basis. And I am in touch with him just to make sure that he’s– that he’s safe, that he’s doing good. That chapter begins with a sentence that says that I sometimes wake up in shock thinking about, you know, my friend is at war, right? That’s such a strange thought and his work is so valuable, it’s so impressive. Again, what I find inspiring in all the people I talk to, I talk with, in the book is not just the work itself, it’s the values and the motivations behind the work and sometimes the resilience of the people producing that work. That’s what I find inspiring.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah, I was– when you were talking there about the Hawkins warming stripes examples, the– the idea of evaluating visualizations, you know, on their own terms, on their kind of their stated purposes, I think is quite important. But do you think people creating data visualizations, do they spend enough time thinking through generally – not the experts you’ve talked to, obviously, they’re the maybe the exception – but about what the purpose– what is it that I want to achieve with this data visualization? Is that kind of one of the things that all your interviewees have in common, a very clear sense of purpose?</p>
<p><strong>Alberto Cairo</strong><br>
They do. They do have that sense of purpose. That doesn’t mean that they don’t sometimes create these great visualizations out of a whim – say, I’m gonna just create a pretty graphic based on that, no purpose whatsoever. And that’s perfectly fine. Again, the analogy with writing. Not all writing can be technical writing. That’s just one of the types of writing that we could use. And conventional, traditional visualization is analogous to technical writing – you want to communicate something effectively, clearly, and therefore you try to create something that doesn’t use too many words, or too many, you know, verbal flourishes, you just go directly to the point and try to communicate directly. But that’s not the only way you can use writing. You can write poetry, so why not using data visualization to create visual poetry? That’s perfectly, perfectly fine. Again, every visualization needs to be judged based on their own– on their own stated purposes. As to the question of whether people in general – like, not the people I talked to in the book, for the book – but, you know, people in general think about purpose when designing data visualizations, that’s a question that I cannot answer. But that’s the core of my classes and workshops. It’s like my classes and workshops outline, both at the university but also as a consultant, put a lot of emphasis on the purpose part. I mean, just list what do you want to communicate? What do you want to achieve? Create an actually a bullet point list of what you want to communicate, and based on that list, then you can make choices. The way that I teach data visualization these days is not about teaching rules, right? Like, you know, use a bar graph to compare, use this graphic for that, use a scatterplot to show associations between, you know, continuous variables or whatever. No, that’s not the way I teach visualization. I teach visualization based on a process of reasoning, right? Reason that takes you from the purpose to the outcome. And every decision down the road in between those two points needs to be somehow justified. You need to justify every decision that you make in the visualization in a way that is– that can be persuasive to other people who may be in your team. I use this colour palette because, and what comes after the because is the important part. I use this type of graphic because, and what comes after the because is the important part, and so on and so forth.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, there’s something that struck me. I think it was a podcast producer who came up this idea of the XY story formula – that’s how you assess the value of a kind of an article pitch. Now, I’m writing a story about X, and it is interesting because Y – and it’s the bit that follows after the “because” that determines– you have to work on that and refine that, and that’s what shapes your story and your outputs. I’m glad you brought up teaching as well, because I was reading through the epilogue, and it said about you having “anarchic leanings and sympathies” and I was kind of curious about how those sympathies and leanings manifest in your work or in your teaching. And obviously, you said you don’t teach rules. So maybe that’s part of it. But…</p>
<p><strong>Alberto Cairo</strong><br>
What sympathies are you referring to?</p>
<p><strong>Brian Tarran</strong><br>
I don’t know. It was just that phrase jumped out: I have, I have anarchic– I think it’s “despite my anarchic leanings and sympathies”, and I was kind of curious as to what are those, and how do they– how do they manifest?</p>
<p><strong>Alberto Cairo</strong><br>
Well, one of the points that I make, particularly in the epilogue, which I think that is the most important part of the book, because it’s where I lay out my own thinking – is that, one of the points that I make is that you cannot really separate the work from the people. And I make the analogy with philosophy, I read a lot of philosophy. There is this book that I absolutely love about philosophy, titled “What is Ancient Philosophy?” by Pierre Hadott, who was, I think that he was French – wonderful book, absolutely wonderful book if you’re interested in the ancient history of philosophy, that book is amazing. Talks about the Hellenistic tradition of philosophy. I could go on and on and talk about that book. I absolutely love it. I think that I read it four times, something like that. And the point that Hadott makes in “What is Ancient Philosophy?” is that it takes you a long way to understand the philosophy of the, you know, the classics – Plato, Aristotle, and then the Hellenists like the Epicureans, or the Stoics, or whatever – it takes you a long way if you sort of like understand the temperament of those people, and their lived experiences, what they went through in their lives, right? If you understand, for example, what Plato lived, his times and his temperament, and also the history of the times when he lived, you can understand the Republic better, his best book, right? You, you sort of like guess where it comes from, right, where his thinking comes from. And I think that’s something similar can be said about visualization, right? I have my own temperament. I have a– I have a very driven temperament. So I’m quite a strong will – when I decide that I’m going to do something, I usually put the energy to do it. But at the same time, I’m quite anarchic, not in the sense of being disorganized, but in the sense that I don’t deal with authority well. I just want to be left alone, right? Just leave me alone. I will figure things out on my own. I work well with other people, right. But in horizontal organizations, I enjoy horizontal teams, rather than hierarchical teams, right. I work really well in horizontal teams. And that is somehow reflected, I think, in the way that I think about data visualization. I somehow rebelled against, you know, the 1980s, 1990s tradition of data visualization teaching around what I call the Tuftean – after Edward Tufte – the Tuftean tradition of saying, this is the only way to do visualization well, these are the rules of data visualization. Well, why? Why are those the rules? Tell me what is this based on, or is it just your own opinion? I mean, I enjoy reading Tufte and I enjoy reading, you know, people like Steven Few, who is a friend of mine, etc. But at the same time I rebelled against that tradition, because in many cases, as I explain in The Art of Insight, many of those so called rules are merely the opinions of people. This is just my opinion. I like this stuff. I like this style, and therefore, I’m going to try to pass my own opinion as if it were a rule of design. I think that we need to be a little bit more honest about what we are doing. Many of those rules are not really grounded on any sort of empirical evidence, and therefore they are still valuable – I think that people should keep reading Tufte, they should keep reading [unclear] and many of the, we should keep reading them. But always with a pinch of salt, taking everything that we read with a pinch of salt, and this applies to my own books as well. We need to be a little bit more skeptical, a little bit more flexible in some sense, knowing that we are on these together and what really matters, I think, is the conversation between people in the field. Conversation is a word that appears a lot in The Art of Insight. I see my work, and I see the work of everybody else who writes or thinks or makes data visualizations as part of an ongoing conversation between people in which we can learn from each other, borrow from each other – always understanding that our opinions can be strongly stated, but sometimes they have very, very shaky foundations.</p>
<p><strong>Brian Tarran</strong><br>
What you’re saying about the importance of still reading these kinds of texts, where the rules – again, in inverted commas – are set, the importance of doing that, that kind of reminded me of like in my, in my own world of, you know, the written word, people like James Ellroy, the author of American Tabloid, you know, about understanding the rules of grammar so that you know how to break them for effect and for impact and things like that. So I can see how that applies to data visualization.</p>
<p><strong>Alberto Cairo</strong><br>
It is, yeah, that’s sort of like already has become a cliche, right: learn the rules, so you can break them. I think that that is valuable. But at the same time, I think that we need to go beyond that and say, there are really no rules. I mean, there are a few things that could be considered rules. For example, we know that, you know, if you want to compare numbers, a bar graph is usually superior to a pie chart, for example. We know that, there is empirical evidence behind that, so you can sort of like derive a principle out of that, right? But beyond those very basic things, there are really not many rules. What there are is a lot of conventions, inherited conventions, right, that historically have developed and we have– we have inherited. So we could say, you know, it’s good to learn the conventions. It is still good to learn about perception and cognition to guide your decisions. But after you do that, all that matters is the choices that you make with the knowledge that you have, and with the guesses that you can make. Right? So it’s not that you’re breaking the rules, you’re creating your own path, based on the inherited knowledge that you have under your belt.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. My last question for you – because I don’t want to take up too much of your time, I know you are very busy, Alberto – is, you mentioned, again, going back to the previous question, or two, the people that you work with, and one of those sometime collaborators is Shirley Wu, who you refer to in your introduction, and I was really struck by the description of the installation, the number of COVID deaths each week, and this this dripping valve. I think what struck me most was that, you know, obviously, Shirley had this idea that the drips would represent the number of COVID deaths each week, these drips into a bowl, but that this wasn’t explicitly stated to people viewing the installation, right? She created space for viewers to bring their own interpretations, and they did. And again, it’s one of these things that I think is a beautiful idea – being able to, to withhold some information – but I don’t know, how does that manifest if you’re, you know, a data scientist or whatever, and you’re trying to create visualizations for, you know, an internal client or whatever it might be. How do you kind of bring some of that, that flavor and that interpretation and that space, to a graphic? I think that’s something that I was thinking about when reading that book, that part of the book.</p>
<p><strong>Alberto Cairo</strong><br>
There are many examples like that in the book. For example, in the chapter about Jaime Serra, Jaime created once a graphic in which– he drinks a lot of coffee, and he wanted to – remember that one – he wanted to, he wanted to see how much coffee he was actually drinking throughout a year. And if I have to do that, I will, you know, I will get my mug, the mug that I use every day to drink my coffee, I will draw a scale on top of that, and then I will measure the number of ounces of coffee that I’m drinking. At the end of the year, I will probably design a line graph, a time series line graph, to see whether there is any seasonality in my coffee consumption. I will design an analytical chart or so to speak, right, a graphic to analyze my own data. But he wanted to design something a little bit more fun, a little bit more expressive, a little more artistic and what he did was to create a graphic in which he plotted the amount of coffee that he drinks throughout a year through coffee stains. He got 12 pieces of paper, each one of them corresponding to a month. He folded those pieces of paper to subdivide them into quadrants, each one corresponding to a day. And then whenever he was drinking coffee, he tried to leave a coffee stain on the corresponding quadrant of the corresponding paper. And the result was sort of like it was a physic– it’s a physical data visualization. And it is amazing. Now, does that mean that you can insert that type of graphic, let’s say, in a business dashboard, or on a quarterly report in a company? No, that’s not the purpose of that type of visualization. The way that I usually explain the value of that type of visualization is to create this sort of like hypothetical scenario. And I have used these many times with clients when presenting you know, Shirley’s work or Jaime’s work. I say this is not the type of graphic that you use for analysis, right. For analysis, you need to use line graphs, bar graphs, scatter plots, traditional conventional data visualizations. But let’s suppose that you, for some reason, one year you conduct a survey internally in your company to analyze how much coffee people drink in the company, right? And you do sort of like this beautiful report that you print out as a hardcover book to give to your own clients as a gift when they come to visit you. What do you put inside of the book? The analytical graphics, right? The analytical charts that slice and dice the data by gender, by location, by whatever? You put all the conventional traditional graphics? What do you put on the cover? What you put on the cover is the beautiful artistic data visualization, which is still a data visualization. And same thing with Shirley’s work, right. Shirley’s installation about COVID: true, it’s not a graphic. It’s not a visualization. It’s not really a graphic because it’s physical. It’s a physical installation. But it is not a visualization that is intended to communicate the data in any sort of like, with accuracy or anything, it just tries to create a feeling. So again, imagine that you work for let’s say, a company focusing on public health or whatever. And every day, what you produce will be conventional charts and graphs and maps. That’s what we need to use to analyze data. But let’s suppose that you want to create some sort of like beautiful piece of artwork to display in your headquarters. That will be an amazing piece to display in your headquarters. It will get people– it will get visitors curious about what you do, it may drive– it may lead you to conversations about the data that they deal with everyday, the same way that Ed Hawkins’s warming stripes graphic did. It’s just a different type of data visualization that needs to be judged according to its own purposes, under its own terms.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, fantastic. Well, that’s a really nice idea to end on. Hope some people take it forward, and future visits to offices will be more visually appealing as we get to explore those spaces. So, Alberto, thank you very much. So the book is out in November, yes?</p>
<p><strong>Alberto Cairo</strong><br>
November the 15th. Yeah.</p>
<p><strong>Brian Tarran</strong><br>
Is there a website yet that people can go and find out more details?</p>
<p><strong>Alberto Cairo</strong><br>
No, still working on it. For now, there is some information in my weblog, which is the title of my first book, The Functional Art. So, it’s thefunctionalart.com. That’s my web blog. And there’s some information about The Art of Insight there, including some, you know, some sneak peeks.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Well, we’ll put a link to that in the in the show notes. So, Alberto, thank you for joining us today. Best of luck finishing up the book and the website. And I hope you can join us again soon because there’s so much more that I could discuss about the book with you, but it’s been great talking to you today.</p>
<p><strong>Alberto Cairo</strong><br>
Thank you, Brian.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Images are not covered by this licence. Photo of Alberto Cairo is copyright JCA Photography.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “The many ‘dialects’ of data visualization: Alberto Cairo and ‘The Art of Insight.’” Real World Data Science, August 1, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Data visualisation</category>
  <category>Communication</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html</guid>
  <pubDate>Tue, 01 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/images/alberto-cairo.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘Go out and talk about data science, particularly to schoolchildren’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/schools-outreach.html</link>
  <description><![CDATA[ 




<p>Rachel Hilliam, statistics professor at The Open University, used her inaugural lecture this month to make “a real plea” to the data science community “for outreach into schools”, to help build excitement and awareness of the promise and potential for careers in data science.</p>
<p>“We have a plethora of jobs that we cannot fill in data science at the moment,” said Hilliam. “We’ve had all sorts of initiatives in terms of trying to retrain people, and that’s great, and those are gaps that we need to plug. But unless we get that pipeline coming through, we’re always going to have this problem at the top.”</p>
<p>Hilliam, who is chair of the <a href="https://alliancefordatascienceprofessionals.co.uk">Alliance for Data Science Professionals</a>, wants schoolchildren and teachers to be made more aware of the benefits of, and opportunities for, data science careers. “Let me tell you,” she said, “if you go out into a school and say, ‘Do your kids want to be a data scientist?’, the teachers will look at you and go, ‘A what?’. They have no idea, generally, that data science actually exists, which is a shame.”</p>
<p>But there are plentiful opportunities to introduce data science to children, Hilliam suggests. She began her talk by saying that: “Data is everywhere – in every single thing that we do, in all of our walks of life.” And she concluded by saying: “Whatever it is that these kids are interested in, […] there is lots of data out there, so there is absolutely no reason why we can’t excite children in a career in data science. So, that’s where I’d like to finish. Go out and talk about data science, particularly to schoolchildren!”</p>
<p>Watch the lecture in full below or on YouTube. Skip to <a href="https://www.youtube.com/live/tCQhU4yP0OU?feature=share&amp;t=1024">17:04</a> for the start of the talk.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/tCQhU4yP0OU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@neonbrand?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Kenny Eliason</a> on <a href="https://unsplash.com/photos/zFSo6bnZJTw?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘Go out and talk about data science, particularly to schoolchildren.’” Real World Data Science, July 27, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/schools-outreach.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Education</category>
  <category>Data literacy</category>
  <category>Outreach</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/schools-outreach.html</guid>
  <pubDate>Thu, 27 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/images/kenny-eliason-zFSo6bnZJTw-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Testing out ChatGPT’s new Code Interpreter</title>
  <dc:creator>Lee Clewley</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/code-interpreter.html</link>
  <description><![CDATA[ 




<p>On July 6, 2023, <a href="https://twitter.com/OpenAI/status/1677015057316872192?s=20">OpenAI began rolling out the Code Interpreter plugin</a> to users of its ChatGPT Plus service. But what exactly is this, and what functionality does it offer?</p>
<p>Code Interpreter runs code and allows for uploading data so you can use ChatGPT for data cleaning, preprocessing, analysis, visualisation and predictive modelling tasks, among other things. This tool holds great promise for programmers and analysts alike, with the potential to streamline coding workflows as well as having an automated data analyst at your fingertips.</p>
<p>To use Code Interpreter, you need to enable it in the ChatGPT settings (at time of writing this only works with a paid ChatGPT Plus subscription).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic1.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic1.png" class="img-fluid figure-img" alt="Screenshot of ChatGPT Plus setting, showing Code Interpreter plugin option." width="700"></a></p>
</figure>
</div>
<p>Now, let’s take it for a bit of a spin by uploading the <a href="https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset">stroke prediction dataset from Kaggle</a>.</p>
<section id="the-stroke-prediction-dataset" class="level2">
<h2 class="anchored" data-anchor-id="the-stroke-prediction-dataset">The stroke prediction dataset</h2>
<p>The World Health Organization (WHO) identifies stroke as the second leading cause of death worldwide, accounting for roughly 11% of all fatalities.</p>
<p>Kaggle’s stroke prediction dataset is used to forecast the likelihood of a patient suffering a stroke, taking into account various input parameters such as age, gender, presence of certain diseases, and smoking habits. Each row in the dataset offers pertinent information about an individual patient.</p>
<p>Loading this dataset into ChatGPT Code Interpreter, one is treated with:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic2.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic2.png" class="img-fluid figure-img" alt="Screenshot from ChatGPT, showing Code Interpreter's initial review of an uploaded stroke prediction dataset." width="700"></a></p>
</figure>
</div>
<p>The user is asked: “Please let me know what analysis or operations you’d like to perform on this dataset. For instance, we can perform exploratory data analysis, data cleaning, data visualization, or predictive modelling.”</p>
<p>It seems quite a bold claim. So, I asked it to do all of the above.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic3.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic3.png" class="img-fluid figure-img" alt="Screenshot from ChatGPT, showing Code Interpreter's overview explanation of planned analysis steps." width="700"></a></p>
</figure>
</div>
<section id="exploratory-data-analysis" class="level3">
<h3 class="anchored" data-anchor-id="exploratory-data-analysis">Exploratory Data Analysis</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic4.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic4.png" class="img-fluid figure-img" alt="Screenshot of ChatGPT Code Interpreter's exploratory data analysis outputs." width="700"></a></p>
</figure>
</div>
<p>This is a good, useful summary. The missing values in <code>bmi</code> are set to the median, which the user can later decide to change for themselves as the code is available to do so.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic5.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic5.png" class="img-fluid figure-img" alt="Screenshot of code output from ChatGPT Code Interpreter, showing how to set missing values in dataset to the median value." width="700"></a></p>
</figure>
</div>
</section>
<section id="data-visualisation" class="level3">
<h3 class="anchored" data-anchor-id="data-visualisation">Data visualisation</h3>
<p>Next, the visualisations of the variables are shown along with a correlation heatmap. Users can toggle between the visualisations and the code. The outputs are pretty useful, except for one mistake: <code>id</code> shouldn’t be included as part of the heatmap.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic6.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic6.png" class="img-fluid figure-img" alt="Screenshot of ChatGPT Code Interpreter's description of visualisations it will create, along with partial code for doing so." width="700"></a></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic7.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic7.png" class="img-fluid figure-img" alt="Histograms and bar plots created by ChatGPT Code Interpreter for variables in the Kaggle stroke prediction dataset." width="700"></a></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p>Histograms and bar plots created by ChatGPT Code Interpreter for variables in the Kaggle stroke prediction dataset.</p>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic8.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic8.png" class="img-fluid figure-img" alt="Correlation heatmap for variables in the Kaggle stroke prediction dataset." width="700"></a></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p>Correlation heatmap for variables in the Kaggle stroke prediction dataset.</p>
</div>
<p>Things start to go seriously awry when Code Interpreter tries to create a predictive model.</p>
</section>
<section id="the-predictive-model-is-garbage" class="level3">
<h3 class="anchored" data-anchor-id="the-predictive-model-is-garbage">The predictive model is garbage</h3>
<p>From the screenshot below, you can see that lumping all the data into a predictive model creates some highly spurious results. Age is a factor, as it should be, as is hypertension – indeed, those with hypertension in this dataset are around three times more likely to have a stroke than those without. In reality, there are also significant effects from glucose level and smoking, and also a slight BMI effect in this small, unbalanced dataset. However, <code>work_type_children</code> having a large positive effect is alarming and plainly wrong.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic9.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic9.png" class="img-fluid figure-img" alt="Screenshot showing ChatGPT Code Interpreter's most important features for predicting stroke. The inclusion of 'work_type_children' is wrong: it says that 'individuals who are children are more likely to have a stroke', but goes on to explain that 'this might be the result of an imbalance in the dataset or noise, as in reality, children generally have a lower risk of stroke." width="700"></a></p>
</figure>
</div>
<p>It is very evident from the table below that the positive coefficient on children is spurious.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic10.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic10.png" class="img-fluid figure-img" alt="Screenshot of table from ChatGPT code interpreter, showing 'number of individuals' and 'number of strokes' for each 'work type'. Figures for children are 687 individuals and 2 strokes." width="700"></a></p>
</figure>
</div>
<p>So, where does this leave our thinking about Code Interpreter?</p>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>My test case is possibly an unfair one. The sort of study presented to Code Interpreter is one that requires careful analysis, and it uses a relatively small, tricky dataset whose difficulties are compounded by missing data. It’s therefore not surprising that, in this context, an automated analysis fails to shine in all respects.</p>
<p>To be fair, OpenAI themselves describe the plugin as an “<a href="https://openai.com/blog/chatgpt-plugins">eager junior programmer</a>”. And as would be the case with a real junior programmer or junior data scientist, you’d expect a more experienced hand to be guiding an analysis like the one I asked for – someone who can sense-check results, point out errors, and offer suggestions for fixes and improvements.</p>
<p>Despite some stumbles in this demo, OpenAI’s “junior programmer” presents a real step forward in the ChatGPT offering, and it is particularly impressive that one can toggle between code and charts without having to worry about coding at all.</p>
<p>At this stage, I would argue that Code Interpreter may be useful for quick summaries, visualisations and a little basic data cleaning and some preliminary investigations. However, based on what I’ve seen so far, it is clear to me that highly trained statisticians won’t be replaced anytime soon.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Lee Clewley</strong> is a member of the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/10/18/meet-the-team.html">editorial board of Real World Data Science</a> and head of applied AI in GSK’s AI and Machine Learning Group, R&amp;D.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Lee Clewley
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://unsplash.com/@charlesdeluvio?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">charlesdeluvio</a> on <a href="https://unsplash.com/photos/pjAH2Ax4uWk?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Clewley, Lee. 2023. “Testing out ChatGPT’s new Code Interpreter.” Real World Data Science, July 19, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/code-interpreter.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Coding</category>
  <category>Data analysis</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/code-interpreter.html</guid>
  <pubDate>Wed, 19 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/charlesdeluvio-pjAH2Ax4uWk-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Teaching a chatbot about love, and other adventures from London Data Week</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/LDW.html</link>
  <description><![CDATA[ 




<p><a href="https://www.londondataweek.org/">London Data Week</a> wraps up on Sunday, and what a week it’s been! Kudos to organisers <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/london-data-week.html">Sam Nutt and Jennifer Ding</a> for the huge amount of energy and passion they invested in making this idea a reality, and I’m looking forward to seeing what they have in store for us next year.</p>
<p>My highlights of the week? Well, of course, I really enjoyed being part of the event that was hosted at the Royal Statistical Society on Tuesday. The <a href="https://rss.org.uk/membership/volunteering-and-promoting/statisticians-for-society-initiative/">Statisticians for Society</a> workshop brought together charities and statisticians to explore ways in which data and statistics can support third sector organisations to deliver on their charitable aims as well as demonstrate to communities and funders the impact they are having. There’s a nice selection of <a href="https://rss.org.uk/membership/volunteering-and-promoting/statisticians-for-society-initiative/case-studies/">case studies of successful past projects on the RSS website</a>, and hopefully the London Data Week event will result in several new additions to this collection in due course.</p>
<p>I wasn’t able to attend this event myself, but I’m really looking forward to viewing the outputs of the <a href="https://betterimagesofai.org/images">Better Images of AI</a> workshop, which was also held on Tuesday. Real World Data Science has used several of the group’s images to illustrate past articles (<a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/11/23/LLM-content-warning.html#qa">here</a>, <a href="https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html">here</a> and <a href="https://realworlddatascience.net/ideas/posts/2023/07/03/trusted-AI.html">here</a>), so I’m excited to see what gets added to the image gallery in the coming weeks.</p>
<p>Sticking with the AI theme, I also got to explore the <a href="https://london.sciencegallery.com/ai-season">“AI: Who’s Looking After Me?” exhibition</a> at the Science Gallery, where I found myself unexpectedly moved by one installation in particular – <a href="https://london.sciencegallery.com/ai-artworks/newly-forgotten-technologies">an artificial landfill of broken and discarded tablets and smart speakers</a>, explaining matter-of-factly, but with an unmistakable air of mournfulness, that they had been replaced “by a newer model that is better because it is lighter, or heavier, or bigger, or smaller…”. Fortunately I was able to cheer myself up with another exhibit, which tasks visitors with <a href="https://london.sciencegallery.com/ai-artworks/looking-for-love">helping a chatbot to define and understand love</a>.</p>
<p>Later on in my visit to the Science Gallery (which was actually last Thursday, before London Data Week officially began), I listened to a panel debate on “Building Better AI in the Open”, featuring Margaret Mitchell of HuggingFace, Lara Groves of the Ada Lovelace Institute, and Irini Papadimitriou of FutureEverything, facilitated by artist and machine learning design researcher Caroline Sinders. A recording of the panel is below, and well worth a watch for discussion of:</p>
<ul>
<li>the advantages of open source versus closed source</li>
<li>the role of public participation in AI</li>
<li>what transparency in AI development should look like</li>
<li>issues of accountability in AI applications.</li>
</ul>
<p>Jennifer Ding followed up the panel with <a href="https://loti.london/blog/building-better-ai-in-the-open/">a thoughtful post on the benefits of open source AI</a>, and for more on trustworthy AI – and the need for transparency, explainability, and fairness – check out Maxine Setiawan and Mira Pijselman’s recent Real World Data Science article, <a href="https://realworlddatascience.net/ideas/posts/2023/07/03/trusted-AI.html">“Trusted AI: translating AI ethics from theory into practice”</a>.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/xddQq3opSzU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://unsplash.com/it/@bendavisual?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Benjamin Davies</a> on <a href="https://unsplash.com/photos/Oja2ty_9ZLM?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Teaching a chatbot about love, and other adventures from London Data Week.” Real World Data Science, July 7, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/LDW.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>AI</category>
  <category>Open source</category>
  <category>Accountability</category>
  <category>Public opinion</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/LDW.html</guid>
  <pubDate>Fri, 07 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/images/benjamin-davies-Oja2ty_9ZLM-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>How do people feel about AI? Well, it’s complicated</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/how-do-people-feel-about-ai.html</link>
  <description><![CDATA[ 




<p>How do people feel about AI? That was a question recently explored in a survey of 4,000 British residents. The answer is that, well, it depends.</p>
<p>Researchers at the Ada Lovelace Institute and the Alan Turing Institute designed the survey to ask about specific AI use cases, rather than the concept of AI more broadly. Use cases included face recognition for policing, border control and security, targeted advertising for political campaigns and consumer products, virtual assistants, driverless cars, and so on.</p>
<p>Roshni Modhvadia, a researcher at the Ada Lovelace Institute and member of the survey team, reported that respondents overall were broadly positive towards most of the use cases they were asked about. Healthcare applications (using AI to assess the risk of cancer, for example) or face recognition for border security were seen as very or somewhat beneficial by more than 80% of those surveyed. More than half of respondents thought that other applications, such as virtual reality in education, climate research simulations, and robotic care assistants were very or somewhat beneficial.</p>
<p>Views were less positive towards applications including driverless cars, autonomous weapons and targeted advertising. These were the applications that respondents expressed most concern about, and for each of these use cases perceived risks were felt to outweigh perceived benefits.</p>
<p>And yet, even for applications that were seen as being overwhelmingly beneficial – assessing cancer risk and face recognition for border control – respondents still expressed concern about the potential for overreliance on the technologies, the issue of who is accountable for mistakes, and the impact the technologies might have on jobs and employment opportunities.</p>
<p>Three-fifths (62%) of respondents said laws and regulations would make them more comfortable with AI technologies being used. This is an important finding given where the national AI conversation is at the moment, said Professor Helen Margetts, director of the public policy programme at The Alan Turing Institute.</p>
<p>The current national conversation has been fuelled by the success of ChatGPT and the growing adoption of generative AI tools. The Lovelace/Turing survey, fielded in November 2022, did not ask about ChatGPT <em>et al.</em>, but the results do at least provide a baseline against which to measure any shifts in attitudes brought on by what Professor Shannon Vallor, Baillie Gifford Chair in the Ethics of Data and Artificial Intelligence at the Edinburgh Futures Institute at the University of Edinburgh, described as “this latest round of AI hype and confusion”.</p>
<ul>
<li>For more on that theme, see Michael Timothy Bennett’s recent article, <a href="https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html">“No, AI probably won’t kill us all – and there’s more to this fear campaign than meets the&nbsp;eye”</a>.</li>
</ul>
<p>Modhvadia, Margetts and Vallor were speaking at an online event last week to mark the launch of the survey report. Video of the event is below. The <a href="https://www.adalovelaceinstitute.org/report/public-attitudes-ai/">full report</a> is available from the Ada Lovelace Institute website.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/sUG6y_E2UD4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="how-do-people-feel-about-ai-in-statistics-and-data-science-education" class="level2">
<h2 class="anchored" data-anchor-id="how-do-people-feel-about-ai-in-statistics-and-data-science-education">How do people feel about AI in statistics and data science education?</h2>
<p>A new paper in the <em>Journal of Statistics and Data Science Education</em> considers the potential for using ChatGPT in statistics and data science classrooms. Authors Amanda R. Ellis and Emily Slade of the University of Kentucky give suggestions for using ChatGPT to generate course content: lecture notes and new material such as practice quizzes or exam questions, or pseudocode for introducing students to statistical programming. It could also be used as a code debugging tool and integrated into set tasks – e.g., have students prompt ChatGPT to write code, then run the code themselves and assess whether the code works as intended.</p>
<p>“We recognize that educators have valid concerns regarding the implementation and integration of AI tools in the classroom,” write the authors, later adding that: “We encourage readers to consider other technologies, such as the calculator, WolframAlpha, and Wikipedia, all of which were met with initial wariness but are now commonly used as learning tools. As statistics and data science educators, we can actively shape and guide the incorporation of AI tools within our classrooms.”</p>
<p><strong>Read the paper:</strong> <a href="https://amstat.tandfonline.com/doi/full/10.1080/26939169.2023.2223609">A new era of learning: Considerations for ChatGPT as a tool to enhance statistics and data science education</a></p>
</section>
<section id="ok-but-how-do-people-feel-about-ai-generated-music" class="level2">
<h2 class="anchored" data-anchor-id="ok-but-how-do-people-feel-about-ai-generated-music">OK, but how do people feel about AI-generated music?</h2>
<p>A new demo on Hugging Face allows users to <a href="https://huggingface.co/spaces/facebook/MusicGen">generate short samples of music based on text descriptions</a>. Users can also “condition on a melody” by uploading audio files. The results are… interesting, as I discovered while playing around with the demo yesterday.</p>
<center>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Text-to-music-generation is now a thing (via <a href="https://twitter.com/huggingface?ref_src=twsrc%5Etfw"><span class="citation" data-cites="huggingface">@huggingface</span></a>: <a href="https://t.co/fpBDLuB4yh">https://t.co/fpBDLuB4yh</a>) so I thought I'd try creating some new genre mashups <a href="https://t.co/y93w7x9pNW">pic.twitter.com/y93w7x9pNW</a>
</p>
— Brian Tarran (<span class="citation" data-cites="brtarran">@brtarran</span>) <a href="https://twitter.com/brtarran/status/1668301878751375369?ref_src=twsrc%5Etfw">June 12, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
<p><strong>Read the paper:</strong> <a href="https://huggingface.co/papers/2306.05284">Simple and controllable music generation</a></p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://unsplash.com/@askkell?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Andy Kelly</a> on <a href="https://unsplash.com/photos/0E_vhMVqL9g?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “How do people feel about AI? Well, it’s complicated.” Real World Data Science, June 13, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/how-do-people-feel-about-ai.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Accountability</category>
  <category>Regulation</category>
  <category>Public opinion</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/how-do-people-feel-about-ai.html</guid>
  <pubDate>Tue, 13 Jun 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/images/andy-kelly-0E_vhMVqL9g-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>London Data Week is almost here. What’s it all about?</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/london-data-week.html</link>
  <description><![CDATA[ 




<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/nLzL-swPBgg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to Real World Data Science. I’m Brian Tarran. And today I’m joined by the organisers of the upcoming London Data Week, Sam Nutt and Jennifer Ding. Sam, Jennifer, how are you? Nice to see you here. Thank you for joining us. I wanted to start, maybe you can introduce yourselves to our viewers, tell them a little bit about your background. Sam, I don’t know if you want to go first.</p>
<p><strong>Sam Nutt</strong><br>
So I’m Sam Nutt. I’m the researcher and data ethicist at the London Office of Technology and Innovation, or LOTI. We’re about four years old. We’re an innovation unit that sits across 26 of the boroughs of London, and the Mayor of London, the GLA and we work sort of through collaborative processes to sort of foster innovation within local government, in the public sector in London. And I lead partly on our work on data ethics, as the title suggests, but also I lead our work on innovative public participation, which I guess leads nicely into maybe talking a little bit later about London Data Week. But yeah, that’s kind of my background and where I’m coming from. My interest in data, I guess, more originally came from the governance side, and how we use it properly and best in public sector context.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Thanks, Sam. Jennifer?</p>
<p><strong>Jennifer Ding</strong><br>
Hi, I’m Jennifer. I’m from the Alan Turing Institute, and I– the Turing, I should say is the UK’s national institute for data science and AI. And I sit on a team called Tools, Practices and Systems, or TPS, which we sometimes colloquially call the Turing’s open science team. So we focus on open, reproducible, and ethical data science practices. And at the Turing, I co-lead a team of research application managers, and our focus is making sure that the research that happens at Turing is more usable, and also actually used by more people outside of academia. In a previous life, I was a data scientist at various US tech startups, working on applied machine learning, mostly for local and national government partners. And in New York, where I was for many years, I participated in something called New York Open Data Week, which was a great introduction to the open data world, and also the civic technology world and how vibrant and exciting those communities are.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Okay, so that– so you’ve had the exposure to data weeks before? Tell us how did London Data Week as an idea first germinate?</p>
<p><strong>Sam Nutt</strong><br>
Yeah, well, I mean, maybe I can go because it was it was something LOTI, last year, we had a sort of anniversary event, we sort of tried to bring together our community, across local government, and also partners. And so we invited [the] Alan Turing [Institute], we’ve done some work with them. And Jen came, and it was just something Jen raised to me, with me last July, you know, the idea of maybe doing something a little bit, like, inspired by some of the bits we’ve seen, for example, in New York, but also thinking, you know, what’s, what’s the London version of that? What’s the opportunity we have, given, you know, our different context to New York, and we don’t just mean in terms of, you know, you’ve got a different, like, legal context for how you use data and regulation stuff, but the cultural bits, you know, what is the physical space? How does that make London different? The people who live here, you know, what are the opportunities of London. And I think, you know, partly also inspired at the time by, you know, at least from my perspective, a real want to include, you know, ordinary people, Londoners, the public at large – all of those terms can be broken down – but effectively, to increase participation in how we think about data and how we, you know, think also about the future of the city, in a, you know, a future that we know is going to be defined by how we use data. So it kind of, it was a perfect thing where I was very inspired by, you know, I was thinking about those things, and then Jen came along. I don’t know, maybe Jen, you can talk about why you came along with that idea in the first place.</p>
<p><strong>Jennifer Ding</strong><br>
Yeah, absolutely. Yeah. Sam and I sometimes talk about how funny that chance encounter was really. I think the LOTI event was a really great example of how London’s flavour of data innovation is actually quite unique. Just gathered there with all the local councils and various other data organisations that LOTI works with. It was such a cool display of how much the public sector is involved in defining data innovation in London, and also how much academic and private tech in London is also committed to creating data and tech outputs that are for the public good. And coming from the US, I think it was very inspiring to see that organisations like LOTI, organisations like the Turing Institute, like the Ada Lovelace Institute, the Open Data Institute – there is such a great network of data for public good institutions here that are committed to, you know, centering Londoners in the conversation. And I think something that Sam and I really got to talking about was, you know, was this an opportunity also to clearly articulate what this new thing, this unique thing, is that exists in London, that if you’re here, and you work in the space, you know it, but it hasn’t really been formally articulated in the way that I think many of us know that Silicon Valley is associated with a certain kind of innovation – and may be Europe as well with regulation – but what’s happening in London is really special. And we hope that with all our great partners and our London Data Week team, we can begin to start to articulate what makes data innovation in London so special.</p>
<p><strong>Brian Tarran</strong><br>
Please do, Jen.</p>
<p><strong>Brian Tarran</strong><br>
And before we get carried away, we should probably pin down exactly when London Data Week is taking place. It’s beginning of July, is that correct?</p>
<p><strong>Jennifer Ding</strong><br>
That’s right, first week of July 3rd to 9th July.</p>
<p><strong>Brian Tarran</strong><br>
And so from what you’ve said, my understanding, broadly, maybe the aims of the week are to kind of bring together people who are working in data, who are using data and people who are affected by data, or for whom data helps sort of shape their lives, to kind of have maybe, I don’t know, a broader understanding, a kind of commonality of purpose, whatever it might be, is that is that how you would summarise it or…</p>
<p><strong>Sam Nutt</strong><br>
Very nicely summarised, are you available for comms help?</p>
<p><strong>Brian Tarran</strong><br>
I am. Very expensive, though, I’m afraid.</p>
<p><strong>Sam Nutt</strong><br>
Okay. It’s all pro bono stuff. No, I think, yeah, I think that’s really well put. It’s, yeah, it’s articulating that– coming together to start to actually build that imagination, that vision for what London is, and articulate it more, in more clear terms. But it’s also, you know, actually trying to do some things in line with that as well. Some of the activities and events we have, you know, we’re running, it’s kind of in this distributed format. So different organisations across London, who are sort of value aligned across the sector, who might have their own communities, their own publics, can run things – different types of events, you know, engaging people in different ways. And then, you know, all together, we think, sort of the sum of the parts of doing these things across a week, in this distributed format, testing different engagement methods, you know, not only sort of builds a community of organisations around these, like common values, but also lets us, you know, actually reach out to the public, you know, the public with all the different people in London, from different backgrounds, there are so many different communities, you know, as much as possible, to connect to different communities and make them part of the conversation about how we use data and AI and in ways that they kind of historically haven’t been. Not just for data and AI, for lots of other things. But, you know, we know that these technologies are going to be so important for the future. And it’s, you know, designing events and activities that can try and ensure that they’re sort of have a, you know, a seat at the table, thinking about what that future is.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. And you mentioned there a range of events. Jen, can you give us a flavour of some of the events coming up, the highlights, things that you might personally be most looking forward to?</p>
<p><strong>Jennifer Ding</strong><br>
Yeah, happy to Brian. And maybe something to add to is something Sam and I were really hoping to go for is to not have, you know, maybe the typical talk or panel style format for all of our events that might be really common in a conference, but rather have different kinds of events that can focus on different kinds of activities. So having public conversations and debates, having exhibits and experiences, having resident or citizen science opportunities where people can actually be a part of creating data, and also learning opportunities if people want to upskill or learn about a concept. So to shout out some of the events I’m really excited for, maybe to start with the more wacky ones first. The Turing is hosting a “Cabaret of Dangerous Ideas” which will be a comedy show at the Camden Club where they will dig into topics like technology and data, but over a pint and through humour. So apparently, this is an 18+ show. So that might give you a little bit of a flavour of what’s to come. Another event we’re really excited about is an event called All the Docks, where a team of cyclists attempt this challenge in one day to hit every single Santander bike dock. They’ve done it before, and this year for London Data Week, they’re doing a round to hit, I think, the now over 800 docks that now exist in London. And this time, for London Data Week, what they’re also doing is making it a data collection exercise. So as they cross the streets of London, they’ll collect data on the road conditions, the cycling infrastructure, which can be then an open data set that people can use after the event as well. So those are two that jumped to mind. I don’t know, Sam, if there’s anything you want to highlight, or Brian because I know there’s a really exciting on that the RSS is…</p>
<p><strong>Brian Tarran</strong><br>
Yeah, I’ll put a quick plug in for the, so <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/statisticians-for-society-london-data-week/#fulleventinfo">the Royal Statistical Society are organising an event associated with our Statisticians for Society initiative</a>, which offers pro bono support to charities under a million turnover in the UK. So I can, I’ll post a link in the show notes so that people can find out more about that and sign up if they meet the criteria and are interested in taking part. But Sam, sorry, I, I hijacked there. But go ahead.</p>
<p><strong>Sam Nutt</strong><br>
No, Brian, I was going to only mention your event. But no, a couple of others, I think just to show the like breadth of the types of activities. So you know, for example, it’s also it’s about partnering with organisations who are thinking and you know, already doing things like this, so the Science Gallery, for example, there’s– they’ve got an exhibition called “AI: Who’s looking after me?”, which is, you know, looks at some of the playful ways that AI is already involved in people’s lives and brings sort of people on a critical journey. That’s more of that sort of art exhibition type thing. In local government, where, in LOTI, we’re helping some boroughs with developing basically, a toolkit, a resource to help officers in boroughs in some of the data teams, who maybe haven’t had that history of engaging with residents, as seen as more sort of technical back office staff, actually, you know, give them the confidence to go out and have a conversation with residents about some of their practice and see how they can improve it. So there’s been a lot of interest there, in particular, around having conversations about how we do data linkage better, which, you know, in some ways, feels– it’s quite a straightforward data topic. But actually, the huge thing is that these teams in boroughs have never thought, we need to speak with residents at the design stage of data projects, you know, the public, what might a digitally excluded, relatively low sort of data literacy person be able to tell us about our data work that’s helpful to me as, you know, a data scientist, that was sort of some of the historical thinking, but actually, we’re sort of bringing boroughs on the journey of thinking, actually realising, you know, the value of doing that. So that’s sort of, I guess, the range of types of things as well.</p>
<p><strong>Brian Tarran</strong><br>
Fantastic. So where, if people do want to sign up for any of these events, is there a good way for them to do that? Is it go to the LOTI website– not LOTI website, the London Data Week website, I’m guessing?</p>
<p><strong>Jennifer Ding</strong><br>
There is a good amount of info on both the Turing and the LOTI website, but the best place we’d suggest is <a href="https://www.londondataweek.org/">londondataweek.org</a>. There you’ll find a list of events. And if you click on an event, there’s more information. And also, if you click “Find out more”, you can access a link for more information on how you express interest or sign up.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. And if people– when we’re speaking, we are almost exactly a month away from London Data Week. If someone’s listening to this and they think, Oh, I’ve got a great idea for an event I want to organise, is it too late for them to squeeze onto the programme now? Should they get in touch somehow if, if inspiration strikes?</p>
<p><strong>Sam Nutt</strong><br>
We’ll never say never. Probably there is a very late point in which we would say never. I think realistically, you know, the way it’s being run, it’s being run often with the time of volunteers and this sort of thing. And it is sort of the first year of us running it. So a lot of it’s coming through, through Jen and I. So if you are interested in running something, please do reach out to us. You know, we’ve got very good, Jen and I, at finding creative ways to slot people into programs and this sort of thing. But equally I think at this point, it’s really more about you know, bringing together people and organisations who are interested and actually, you know, I think we’ve got a really good exciting, fun set of events and activities across London that would be great to be part of even if you yourself haven’t been able to organise something, and then maybe it’s something for next year, for London Data Week 2024. Fingers crossed, we might be able to do something there.</p>
<p><strong>Brian Tarran</strong><br>
So the stress of day jobs and organising a week-long event, or week-long collection of activities, hasn’t put you off doing it again? No.&nbsp;</p>
<p><strong>Jennifer Ding</strong><br>
So far, so good, Brian.</p>
<p><strong>Sam Nutt</strong><br>
Yeah, we’ll “no comment” some of that.</p>
<p><strong>Jennifer Ding</strong><br>
We’re definitely really excited though. And if anyone does have an idea or wants to start a conversation, there’s a contact form on our website, drop us an email. <a href="https://twitter.com/londondataweek">We also have a Twitter</a> if you want to send us a message through that. So at the very least, we love, we’d love to chat.</p>
<p><strong>Brian Tarran</strong><br>
Great, well, we’ll put all those contact details, social media accounts, etc., into the show notes so people can find you. But thank you very much for joining us today. I know this must be a very busy time for you. But Sam Nutt, Jennifer Ding, thank you for joining us and talking about the upcoming London Data Week. I’m looking forward to it.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
<p>© 2023 Royal Statistical Society</p>
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Images are not covered by this licence. Thumbnail image by <a href="https://unsplash.com/@fakearthur?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">ARTHUR YAO</a> on <a href="https://unsplash.com/photos/HTicW9-i4xY?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
<p>Tarran, Brian. 2023. “London Data Week is almost here. What’s it all about?” Real World Data Science, June 8, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/london-data-week.html">URL</a></p>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Data</category>
  <category>Innovation</category>
  <category>Events</category>
  <category>Communities</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/london-data-week.html</guid>
  <pubDate>Thu, 08 Jun 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/images/arthur-yao-HTicW9-i4xY-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>No, AI probably won’t kill us all – and there’s more to this fear campaign than meets the eye</title>
  <dc:creator>Michael Timothy Bennett</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html</link>
  <description><![CDATA[ 




<p>Doomsaying is an old occupation. Artificial intelligence (AI) is a complex subject. It’s easy to fear what you don’t understand. These three truths go some way towards explaining the oversimplification and dramatisation plaguing discussions about AI.</p>
<p>Last week, outlets around the world were plastered with news of yet another <a href="https://www.safe.ai/statement-on-ai-risk">open letter claiming</a> AI poses an existential threat to humankind. This letter, published through the nonprofit Center for AI Safety, has been signed by industry figureheads including <a href="https://theconversation.com/ai-pioneer-geoffrey-hinton-says-ai-is-a-new-form-of-intelligence-unlike-our-own-have-we-been-getting-it-wrong-this-whole-time-204911">Geoffrey Hinton</a> and the chief executives of Google DeepMind, Open AI and Anthropic.</p>
<p>However, I’d argue a healthy dose of scepticism is warranted when considering the AI doomsayer narrative. Upon close inspection, we see there are commercial incentives to manufacture fear in the AI space.</p>
<p>And as a researcher of artificial general intelligence (AGI), it seems to me the framing of AI as an existential threat has more in common with 17th-century philosophy than computer science.</p>
<section id="was-chatgpt-a-breakthrough" class="level2">
<h2 class="anchored" data-anchor-id="was-chatgpt-a-breakthrough">Was ChatGPT a ‘breakthrough’?</h2>
<p>When ChatGPT was released late last year, people were delighted, entertained and horrified.</p>
<p>But ChatGPT isn’t a research breakthrough as much as it is a product. The technology it is based on is several years old. An early version of its underlying model, GPT-3, was released in 2020 with many of the same capabilities. It just wasn’t easily accessible online for everyone to play with.</p>
<p>Back in 2020 and 2021, <a href="https://ieeexplore.ieee.org/document/9495946">I</a> and many <a href="https://link.springer.com/article/10.1007/s11023-020-09548-1">others</a> wrote papers discussing the capabilities and shortcomings of GPT-3 and similar models – and the world carried on as always. Forward to today, and ChatGPT has had an incredible impact on society. What changed?</p>
<p>In March, Microsoft researchers <a href="https://futurism.com/gpt-4-sparks-of-agi">published a paper</a> claiming GPT-4 showed “sparks of artificial general intelligence”. AGI is the subject of a variety of competing definitions, but for the sake of simplicity can be understood as AI with human-level intelligence.</p>
<p>Some immediately interpreted the Microsoft research as saying GPT-4 <em>is</em> an AGI. By the definitions of AGI I’m familiar with, this is certainly not true. Nonetheless, it added to the hype and furore, and it was hard not to get caught up in the panic. Scientists are no more immune to <a href="https://link.springer.com/book/10.1007/978-3-030-36822-7">group think</a> than anyone else.</p>
<p>The same day that paper was submitted, The Future of Life Institute <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">published an open letter</a> calling for a six-month pause on training AI models more powerful than GPT-4, to allow everyone to take stock and plan ahead. Some of the AI luminaries who signed it expressed concern that AGI poses an existential threat to humans, and that ChatGPT is too close to AGI for comfort.</p>
<p>Soon after, prominent AI safety researcher Eliezer Yudkowsky – who has been commenting on the dangers of superintelligent AI <a href="https://intelligence.org/files/AIPosNegFactor.pdf">since well before</a> 2020 – took things a step further. <a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/">He claimed</a> we were on a path to building a “superhumanly smart AI”, in which case “the obvious thing that would happen” is “literally everyone on Earth will die”. He even suggested countries need to be willing to risk nuclear war to enforce compliance with AI regulation across borders.</p>
</section>
<section id="i-dont-consider-ai-an-imminent-existential-threat" class="level2">
<h2 class="anchored" data-anchor-id="i-dont-consider-ai-an-imminent-existential-threat">I don’t consider AI an imminent existential threat</h2>
<p>One aspect of AI safety research is to address potential dangers AGI might present. It’s a difficult topic to study because there is little agreement on what intelligence is and how it functions, let alone what a superintelligence might entail. As such, researchers must rely as much on speculation and philosophical argument as on evidence and mathematical proof.</p>
<p>There are two reasons I’m not concerned by ChatGPT and its <a href="https://lablab.ai/blog/what-is-babyagi-and-how-can-i-benefit-from-it">byproducts</a>.</p>
<p>First, it isn’t even close to the sort of artificial superintelligence that might conceivably pose a threat to humankind. The models underpinning it are slow learners that require immense volumes of data to construct anything akin to the versatile concepts humans can concoct from only a few examples. In this sense, it is not “intelligent”.</p>
<p>Second, many of the more catastrophic AGI scenarios depend on premises I find implausible. For instance, there seems to be a prevailing (but unspoken) assumption that sufficient intelligence amounts to limitless real-world power. If this was true, more scientists would be billionaires.</p>
<p>Moreover, cognition as we understand it in humans takes place as part of a physical environment (which includes our bodies), and this environment imposes limitations. The concept of AI as a “software mind” unconstrained by hardware has more in common with 17th-century <a href="https://plato.stanford.edu/entries/dualism/">dualism</a> (the idea that the mind and body are separable) than with contemporary theories of the mind existing as <a href="https://plato.stanford.edu/entries/embodied-cognition/">part of the physical world</a>.</p>
</section>
<section id="why-the-sudden-concern" class="level2">
<h2 class="anchored" data-anchor-id="why-the-sudden-concern">Why the sudden concern?</h2>
<p>Still, doomsaying is old hat, and the events of the last few years probably haven’t helped – but there may be more to this story than meets the eye.</p>
<p>Among the prominent figures calling for AI regulation, many work for or have ties to incumbent AI companies. This technology is useful, and there is money and power at stake – so fearmongering presents an opportunity.</p>
<p>Almost everything involved in building ChatGPT has been published in research anyone can access. OpenAI’s competitors can (and have) replicated the process, and it won’t be long before free and open-source alternatives flood the market.</p>
<p>This point was made clearly in a memo <a href="https://www.semianalysis.com/p/google-we-have-no-moat-and-neither">purportedly leaked</a> from Google entitled “We have no moat, and neither does OpenAI”. A moat is jargon for a way to secure your business against competitors.</p>
<p>Yann LeCun, who leads AI research at Meta, says these models should be open since they will become public infrastructure. He and many others are <a href="https://www.businesstoday.in/technology/news/story/completely-ridiculous-metas-chief-ai-scientist-yann-lecun-dismisses-elon-musks-civilisation-destruction-fear-383371-2023-05-30">unconvinced by the AGI doom</a> narrative.</p>
<center>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
A NYT article on the debate around whether LLM base models should be closed or open.<br><br>Meta argues for openness, starting with the release of LLaMA (for non-commercial use), while OpenAI and Google want to keep things closed and proprietary.<br><br>They argue that openness can be…
</p>
— Yann LeCun (<span class="citation" data-cites="ylecun">@ylecun</span>) <a href="https://twitter.com/ylecun/status/1659172655663030272?ref_src=twsrc%5Etfw">May 18, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
<p>Notably, <a href="https://fortune.com/2023/05/05/meta-mark-zuckerberg-not-invited-ai-meeting-white-house/">Meta wasn’t invited</a> when US President Joe Biden recently met with the leadership of Google DeepMind and OpenAI. That’s despite the fact that Meta is almost certainly a leader in AI research; it produced PyTorch, the machine-learning framework OpenAI used to make GPT-3.</p>
<p>At the White House meetings, OpenAI chief executive Sam Altman suggested the US government should issue licences to those who are trusted to responsibly train AI models. Licences, as Stability AI chief executive Emad Mostaque <a href="https://twitter.com/EMostaque/status/1658653142429450242?s=20">puts it</a>, “are a kinda moat”.</p>
<p>Companies such as Google, OpenAI and Microsoft have everything to lose by allowing small, independent competitors to flourish. Bringing in licensing and regulation would help cement their position as market leaders and hamstring competition before it can emerge.</p>
<p>While regulation is appropriate in some circumstances, regulations that are rushed through will favour incumbents and suffocate small, <a href="https://www.forbes.com/sites/hessiejones/2023/04/19/amid-growing-call-to-pause-ai-research-laion-petitions-governments-to-keep-agi-research-open-active-and-responsible/?sh=1b21161a62e3">free and open-source competition</a>.</p>
<center>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Think Google or Microsoft are encouraging legislation for your safety? But of course! These are honorable companies.<br><br>You might think they'd like less competition too though. Maybe a monopoly? Maybe legal red tape preventing free and open source alternatives? Perhaps other… <a href="https://t.co/Z7vSpMyuHg">https://t.co/Z7vSpMyuHg</a>
</p>
— Michael Timothy Bennett (<span class="citation" data-cites="MiTiBennett">@MiTiBennett</span>) <a href="https://twitter.com/MiTiBennett/status/1654357631514079233?ref_src=twsrc%5Etfw">May 5, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
<!-- Below is The Conversation's page counter tag. Please DO NOT REMOVE. -->
<p><img src="https://realworlddatascience.net/viewpoints/posts/2023/06/05/https:/counter.theconversation.com/content/206614/count.gif?distributor=republish-lightbox-basic" alt="The Conversation" width="1" height="1" style="border: none !important; box-shadow: none !important; margin: 0 !important; max-height: 1px !important; max-width: 1px !important; min-height: 1px !important; min-width: 1px !important; opacity: 0 !important; outline: none !important; padding: 0 !important" referrerpolicy="no-referrer-when-downgrade"></p>
<!-- End of code. If you don't see any code above, please get new code from the Advanced tab after you click the republish button. The page counter does not collect any personal data. More info: https://theconversation.com/republishing-guidelines -->
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<a href="https://theconversation.com/profiles/michael-timothy-bennett-1283108">Michael Timothy Bennett</a> is a PhD student in the School of Computing, <a href="https://theconversation.com/institutions/australian-national-university-877">Australian National University</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-12">
<dl>
<dt>Copyright and licence</dt>
<dd>
This article is republished from <a href="https://theconversation.com">The Conversation</a> under a Creative Commons license. Read the <a href="https://theconversation.com/no-ai-probably-wont-kill-us-all-and-theres-more-to-this-fear-campaign-than-meets-the-eye-206614">original article</a>.
</dd>
<dd>
<p>Thumbnail image by <a href="https://alanwarburton.co.uk/">Alan Warburton</a> / © BBC / <a href="https://www.betterimagesofai.org">Better Images of AI</a> / Social Media / <a href="https://creativecommons.org/licenses/by/4.0/">Licenced by CC-BY 4.0</a>.</p>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Regulation</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html</guid>
  <pubDate>Mon, 05 Jun 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/06/05/images/AlanWarburton-SocialMedia.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>What’s the future of data science and AI in an LLM world?</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/future.html</link>
  <description><![CDATA[ 




<p>The impact ChatGPT and large language models (LLMs) are having on the practice and profession of data science is something <a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">we discussed recently with data scientists from Unilever, BT, Deliveroo, and others</a>. So, it was interesting to hear a perspective this week from Osama Rahman, director of the <a href="https://datasciencecampus.ons.gov.uk/">Data Science Campus</a> at the UK Office for National Statistics.</p>
<p>Speaking Tuesday at <a href="https://rss.org.uk/training-events/events/events-2023/local-groups/what-is-the-future-of-data-science-and-ai-online/">an online event</a>, Rahman mused on how LLMs brought both potential benefits and risks. For example, those who can already code can code more efficiently now with the help of LLM-powered tools. However, those same tools also allow non-coders to code – and inexpert use of tools and code presents risks. How do we guard against this, he was asked. “I don’t know,” came the response, “other than you have to observe and clampdown on it.”</p>
<p>Such problems are by no means new or unique to the post-ChatGPT era, of course. As someone with a background in economics, Rahman said he has, over the years, observed “inexpert uses of economics.” His advice was to “make sure experts are plugged in” – to teams, conversations, decision-making processes, etc. – “and are seen as the experts in the use of these tools.”</p>
<p>The discussion was wide-ranging, and also took in questions on whether data scientists have the right skills at this moment – “Skills evolve, it’s just a natural process… We need to keep a culture of curiosity…” – and whether enough is being done to address ethical issues – “My key issue is that ethical frameworks need a lot more discussion and debate than it takes to put out a new tool… I don’t have much to add, other than that there is a problem.”</p>
<p>However, two questions – and answers – jumped out at me as particularly interesting. Rahman was asked: Have we delivered on the promise of data science from 5 years ago? “No, but that’s because expectations were wrong,” he said. “Data science wasn’t going to completely and utterly transform government. But where it has delivered is in an evolving set of tools, people, and skills coming in and allowing us to do impactful stuff. It hasn’t delivered on the false promise that it would change the world, but it has delivered a lot.”</p>
<p>He was also asked: How will data science and AI have changed the world in 5–10 years? “I’m not sure it will,” he said. “It will do certain things. It will allow us to address certain analytical problems more efficiently.” Rahman then offered a salutary reminder. Email once made life more efficient; now, we’re all at risk of “death by email.”</p>
<p>We’ll be sure to update this post with a link to a video or other recording of the event, if/when it becomes available. For now, be sure to check out our two-part discussion on LLMs and data science:</p>
<ul>
<li><a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">How is ChatGPT changing data science?</a></li>
<li><a href="https://realworlddatascience.net/careers/posts/2023/05/18/chatgpt-data-science-pt2.html">Large language models: Do we need to understand the maths, or simply recognise the limitations?</a></li>
</ul>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “What’s the future of data science and AI in an LLM world?” Real World Data Science, May 26, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/future.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Large language models</category>
  <category>Skills</category>
  <category>Tools</category>
  <category>Ethics</category>
  <category>People</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/future.html</guid>
  <pubDate>Fri, 26 May 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/images/binoculars.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘I’m way more into prevention than cure’: Stephanie Hare on why we need a culture of technology ethics</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/04/28/stephanie-hare.html</link>
  <description><![CDATA[ 




<p>We’re about a year late coming to <a href="https://www.harebrain.co/">Stephanie Hare</a>’s book, <a href="https://londonpublishingpartnership.co.uk/technology-is-not-neutral/"><em>Technology is Not Neutral: A Short Guide to Technology Ethics</em></a>. But, as discussed in our interview below, time has only made the text more relevant. The book was written pre-ChatGPT, but Hare’s explorations of ethical questions in the context of facial recognition technology and Covid-19 exposure tracking apps feel both pointed and urgent at this moment, when researchers, regulators, and regular people are weighing the opportunities and potential harms of large language models and generative AI tools.</p>
<p>“We’re having some sort of moment with technology ethics – AI ethics being just a branch of that,” says Hare. Reflecting on her career, spanning 25 years, she says: “The stuff that we’re talking about today that dominates the headlines – that is dominating the discussion in the tech sector – was not discussed at all at the turn of the century, other than by maybe people in the science and technology studies domain or academics. But it wasn’t filtering into boardrooms. It wasn’t on the front pages of newspapers, and it wasn’t being covered in the national news. So, it’s amazing. A whole field has sprung up.”</p>
<p>However, as Hare makes clear in our interview, we still have a long way to go to build a culture of technology ethics throughout society. Check out the full conversation below or on YouTube.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/INKwSTNFSVY" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="timestamps" class="level2">
<h2 class="anchored" data-anchor-id="timestamps">Timestamps</h2>
<ul>
<li>ChatGPT: just another “flavour of the month” in the tech industry? (<a href="https://youtu.be/INKwSTNFSVY?t=78">1:18</a>)</li>
<li>Has concern about large language models helped put technology ethics on the map? (<a href="https://youtu.be/INKwSTNFSVY?t=197">3:17</a>)</li>
<li>What will it take to build a culture of technology ethics – in society, in academia, in industry? (<a href="https://youtu.be/INKwSTNFSVY?t=556">9:16</a>)</li>
<li>Drawing lessons from history (<a href="https://youtu.be/INKwSTNFSVY?t=735">12:15</a>)</li>
<li>Why technology ethics is a “wicked problem” (<a href="https://youtu.be/INKwSTNFSVY?t=1497">24:57</a>)</li>
<li>Checklists and changing mindsets (<a href="https://youtu.be/INKwSTNFSVY?t=1789">29:49</a>)</li>
</ul>
</section>
<section id="quotes" class="level2">
<h2 class="anchored" data-anchor-id="quotes">Quotes</h2>
<p>“The European Union has the AI Act coming down the pike. It doesn’t cover stuff like ChatGPT specifically, but then I don’t know if you want good regulation to cover the technology itself, or how technology is used. I talked about this in my book: do you want to regulate forks – a tool – or do you want to regulate use cases for forks? We’ve regulated the use case, if you will, of murder, or of injury with a fork – or, frankly, any other tool. So it’s the use case we focus on. We don’t really regulate forks. [But] we do regulate some technologies, like biomedical technologies, human genetic stuff, anything nuclear. So we just need to think about where does AI fit with that?” (<a href="https://youtu.be/INKwSTNFSVY?t=342">5:42</a>)</p>
<p>“Move fast and break things was the mantra for this culture [in the technology industry] for a really long time, at least out of the US. And it made a lot of people a lot of money, and they got worshipped by the media. And, you know, they have a whole audience of ‘bros’ who are fans of them. And they’ve never really, any of them, been held to account for what they’ve built.” (<a href="https://youtu.be/INKwSTNFSVY?t=716">11:56</a>)</p>
<p>“Another generation or two, when we’re older, might look at some of what technology we’ve built or our behaviour on climate change, our track record – did we do what we could have done to slow global warming, to improve biodiversity? – and they might hold us to account, saying, ‘You could have stopped this and you didn’t, right? It’s not just what you did. It’s what you did not do.’ So we have to be super careful when we think about ethics, because ethics change, values change over time. And what seems okay today may not be okay in 10, 20, 30 years time. That is on my mind all the time. It’s not very relaxing.” (<a href="https://youtu.be/INKwSTNFSVY?t=1110">18:30</a>)</p>
<p>“[Laws and regulations] are important, they’re necessary, but they’re insufficient. You can act a lot faster if you can get people preventing stuff from being built in the first place, and that means you need to have a culture of people working in technology, both within the organisations – whether that’s research labs, government, companies, universities, whatever – and on the outside – journalists, academics, thinkers, etc., or just the public, an informed public – who can see something and sound the alarm and go, ‘Wait a minute, hang on. That’s not okay.’” (<a href="https://youtu.be/INKwSTNFSVY?t=1982">33:02</a>)</p>
</section>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to another Real World Data Science interview. I’m Brian Tarran. And today I’m joined by Stephanie Hare, a researcher and broadcaster and author of the book Technology is Not Neutral: A Short Guide to Technology Ethics, which is the focus of our conversation today. Welcome, Stephanie.</p>
<p><strong>Stephanie Hare</strong><br>
Thank you so much for having me here.</p>
<p><strong>Brian Tarran</strong><br>
I feel I’m a bit late to the party with the book. The Financial Times picked it up as one of the best books of summer 2022. But I’ve only just got around to reading it.</p>
<p><strong>Stephanie Hare</strong><br>
I mean, I only just got around to reading War and Peace last year. So there’s no rush with these things.</p>
<p><strong>Brian Tarran</strong><br>
Okay. Well, I mean, I can definitely say it’s one of the best books I’ve read in spring 2023, if that helps, and the only other one I read was Lord of the Rings. So–</p>
<p><strong>Stephanie Hare</strong><br>
Wow. I mean that’s some pretty august company, you couldn’t thrill me more.</p>
<p><strong>Brian Tarran</strong><br>
Excellent, excellent. Well, I actually thought coming late to the book might actually have been of benefit to me as a reader because, you know, you’re talking about technology ethics quite broadly. But then you focus in on a couple of use cases, specifically around facial recognition, technology, Covid-19 exposure tracking apps and things like that. But, you know, obviously, since the book was published, the whole discussion around technology ethics has kind of been dominated maybe or taken on a new dimension following the launch and adoption of ChatGPT. I wonder, you know, when the technology was launched, people started using it, adoption rates, you know, went through, went through the roof, what was your kind of initial reaction to all that and what have you made of the kinds of conversations and criticisms that have followed?</p>
<p><strong>Stephanie Hare<br>
</strong>Well, I mean, like everybody I was curious and fascinated and wanted to play around with it a bit. I don’t think I’m of the school of thought that seems to be circulating that this will either you know, destroy mankind as we know it or take everybody’s jobs or potentially upend civilization. There’s been some quite extreme, some quite extreme views put across in the media in the past few months since this was widely released to the public. I don’t know, for some reason, I didn’t drink the Kool-Aid, when I started working in technology. So I always take these things with a grain of salt. And I guess my, my cautionary note to anybody listening to this is you know, at this time last year, all of my clients were wanting presentations and analysis about web3 and NFTs and cryptocurrency and before that, it was blockchain. There’s like always a sort of flavour of the month. AI, for people who’ve worked in this field, is known to have winters, summers, springs, autumns, you know, these seasons of when it’s like coming on and really exciting or not? I’m more excited by DeepMind’s use of artificial intelligence, I think they’re actually working on interesting problems, right, around like protein discovery, like real science, as opposed to like, oh, look, I can have a new sci fi avatar or do a deep fake, you know, people can do deep fakes already. We’re just doing them now in even more disturbing ways. So I guess, I guess it’s that. I’m intrigued by it. But I don’t I don’t feel the need to sort of freak out. Either way, positively or negatively, I have a much more sort of detached satellite-level view, I think probably just because I’m older, seeing these trends come and go. And it’s like, let’s just let’s just wait this out and see how it goes.</p>
<p><strong>Brian Tarran</strong><br>
From your perspective as someone who’s interested in and researching in the area of technology ethics, right, do you see a kind of almost a benefit that the conversation around this has put technology ethics, the conversation around that, on the map? Or do you worry that we’re kind of obsessing over this one technology and this one application? We’re not looking at the field more broadly?</p>
<p><strong>Stephanie Hare</strong><br>
Well, there’s a few things to say on this. So like, first of all, a couple of weeks ago, a bunch of people working in AI, about 1000-plus people – including some fictitious people, by the way – sign this this letter calling for a moratorium on AI research for six months, which was unenforceable, clearly not going to happen, was signed by Elon Musk, who then very quickly announced he was developing his own rival to OpenAI, the company that invented ChatGPT. So you take all of that with a grain of salt. But again, if you’re, if you’re an historian, or if you just have a long memory, you’ll remember that there have been several letters like this. There’s always somebody, you know, very big-wig people. It’s not that we want to dismiss it. But Stephen Hawking and Elon Musk were warning, you know, over around 10 years ago that AI was going to kill humanity if we didn’t put guardrails on it. Professor Stuart Russell talked about this in his Reith Lectures a couple of years ago, which are still online and you can listen to them. And you know, he’s not an alarmist. He’s a serious person and a serious thinker. So we want to listen to him. But I guess what I’m just saying is, you know, every time some sort of new technology or new use case for technology comes up, there’s a group of people who come out and freak out and they get lots of op-eds.&nbsp;It’s usually men, I must say. There’s a lot of women doing some really interesting scholarship in this area that don’t get the op-eds and quite the publicity. So there’s that. Then it is interesting because it makes people think about technology ethics, usually, again, from a place of either fear, right – Are they going to kill us? Are they going to take our jobs? Are they going to remove human agency? – or money – How are people going to make a huge amount of money? Who’s going to make the money? And by displacing whom, right? So, we have two levers: incredible doom or incredible opportunity. And that leaves the rest of us, I think, probably somewhere in the middle, scratching our heads and going like, is this going to actually change my life? And if so, how, and do I really care, given that I’ve got like, you know, a cost of living crisis, recovering from the Covid pandemic for the past few years? Like, if you’re not in this world, it can seem like a lot of shouting. There’s also the question of, do we need new laws? So we know that the European Union has the AI Act coming down the pike. That’s supposed to be passed this year, and there’ll be a two year implementation grace period. So that’s interesting. It doesn’t cover stuff really, like ChatGPT specifically, but then I don’t know if you want good regulation to cover the technology itself, or how technology is used. And I talked about this in my book, like, do you want to regulate forks – a tool – or do you want to regulate use cases for forks? So if I’m, if I stab you, or kill you with a fork, which is totally possible, that is something that we’ve regulated; we’ve regulated the use case, if you will, of murder, or of injury with a fork or frankly, any other tool. So it’s the use case we focus on. We don’t really regulate forks. We do regulate some technologies like bioethics technologies, or biomedical technologies, excuse me, sort of human genetic stuff, anything nuclear. Those technologies we do specifically regulate. So we just need to think about where does AI fit with that? And also, do we need new regulations for everything, or can we use existing ones? And that’s what’s becoming really interesting is that in the US, where I’m from, the main regulator, the FTC, seems to think that it can use a lot of existing laws already. So they’ve been like, if your AI is claiming to do stuff that it can’t, we’re gonna come after you under, like, kind of sort of false advertising, if you will, misrepresenting yourself. They might come after some of the big AI companies based on anti-competition law, right? So no new laws needed for that. And then with the music industry, they’ve been going after all the people who are like, oh, let’s like remix a Drake song, and saying, well, actually, you can’t do that, because you’re violating copyright law, take it down. Right. So again, I don’t want to be like too, too calm about it. Like, we do need to look at some of the use cases that are really problematic and hurting people. But we might actually have a lot more in our arsenal to combat this than we’re currently using. And I think what’s going to happen is, unfortunately, the pace of crafting legislation, and then regulators never fully enforce regulations– Look at the GDPR: no company’s ever been given the full fine. And here in the UK, the ICO is famous for letting companies off the hook, giving them less than half of the original fine. It’s ridiculous. So if you’re going to pin your hopes on regulation, I’m not sure that’s great. I’m weirdly more optimistic about landmark legal cases. So we’re seeing an Australian mayor who was totally defamed by ChatGPT, in Australia, he’s going to be taking or is taking OpenAI to court. And then we might see some of these copyright issues, that could be taken to court, right. And like, that’s where people I think will get more action and, frankly, more respect, because these companies are really happy to pay a lot of money to lobby our lawmakers, and water stuff down. And they always say, Oh, my God, it’s going to constrain innovation. And if they really get desperate, they’ll be like, China! If we don’t, if we’re not allowed to do everything we want, China will win! That is like a– that is just a game that takes everybody nowhere, whereas in the lawsuit angle, that’s interesting, because you’re demonstrating responsibility, you’re discussing liability, you’re having to demonstrate harm. And in the process of discovery, right, you might be able to actually get some of these companies to open up their datasets, how their algorithms work, like, I’m much more intrigued to see where that’s gonna go.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, but I think I mean, having read your book, I would, I would have thought you might perceive all of this sort of stuff as kind of sticking plasters to put over the the injuries that might be caused by these technologies, right? Your argument seems to be that we have an issue whereby we don’t have a culture of technology ethics. So when we’re thinking about building these tools, or when we’re starting off down the path of creating something like this, we’re not already thinking about, you know, the use cases, the harms that might arise from that and things like that. What does it take to build a culture of technology ethics, do you think, in our society, in our academic institutions in our companies?</p>
<p><strong>Stephanie Hare</strong><br>
Honestly, I think, I think this whole accountability piece is going to be what it takes. Because you see, like Alphabet CEO Sundar Pichai gave an interview recently to CBS 60 Minutes in the US where he was like, yeah, there’s a risk that this technology could get out of control, like dot dot dot, this would be terrible for mankind. And you see him kind of be like, hope somebody does something about that. And it’s like, I know somebody that might do something about that, Mr Pichai – you! But clearly he feels, and you can see his point, he feels that right now, if it’s not illegal, then it’s permissible. And he has to win market share. If he doesn’t do it, he’s going to lose. And companies have this all the time. If they wait too long, they lose their first-mover advantage, and they get destroyed. We can go through like countless examples of that in business, particularly in technology. So I get it. But what he isn’t understanding is that if his company is the one that puts out the technology that leads to terrible harm – you know, physically killing people, harming them, destroying the national security infrastructure, something like that – right now, I don’t think he’s thinking about how that’s going to affect him. And that’s because we don’t really penalise executives very often. The worst that might happen is they might leave with a huge golden parachute, and go off and sort of retire in Hawaii with their millions, right? Like nothing really happens to them. So how do you have a culture of technology ethics, where the people who are creating technology and have the power to stop, right, to maybe like back off on stuff, they aren’t really thinking about how will I personally be held responsible if this goes south? So like, Sam Altman and OpenAI, same thing, he was like, he gave an interview where he’s like, I’m really scared about this technology I’m building. It’s like, okay, you could slow down or back off, you could make your datasets open, you could make your algorithms open. You’re called Open AI, that was supposed to be your whole mission, why you were created was to benefit humanity, like, what are you doing? So it’s weird. And I think it comes from the fact that, you know, move fast and break things was the mantra for this culture for a really long time, at least out of the US. And it made a lot of people a lot of money, and they got worshipped by the media. And you know, they have a whole audience of bros who are fans of them. And they’ve never really, any of them, been held to account for what they’ve built.</p>
<p><strong>Brian Tarran</strong><br>
So your interest in technology ethics clearly predates you know, that all the noise at the moment around large language models and generative AI and things like that. What was it that got you interested in this subject? Was it a particular application, something that caused some concern? Or– How did it come about?</p>
<p><strong>Stephanie Hare</strong><br>
This is gonna sound completely weird, but it didn’t come from my experience in tech, really, at all. I have had two paths in my adult life, one has been working in these technology companies with a brief but happy foray in political risk, which is now sort of part of the skill set for tech. But I trained as an historian, and I interviewed someone who was a French civil servant, who at the end of his life was put on trial for crimes against humanity for his actions as a young civil servant during the Second World War. So he collaborated, as so many French civil servants did. And in the course of that collaboration, over a period of many years, went from just, you know, just signing documents and kind of doing what he was told to do, to deporting people and sending them to Auschwitz. So I was very young when I interviewed him, and that marked me, as I would hope it would mark anybody. I talked with him on and off for about three years, until he died. And that was the subject of my PhD. And then I did a fellowship at St.&nbsp;Anthony’s College, Oxford, and spent years looking at it further. And that’s actually going to be my next book. I needed a long time to sit with that material and to read around it, but I had to get the interview while he was still alive. He was so old, he was 93 when I started talking to him, and so it was important to get that down for posterity’s sake first, and then circle back and do some analysis later when I was a bit older. When you talk to somebody who in his case was, you know, not antisemitic, not of the far right politically, was actually like centre-left, had lots of Jewish friends, etc. Was like top of his class, you know, came from a milieu and a background and a formation that I think many of us would read and be like, Okay, that seems pretty reasonable. You ask yourself, how on earth did that person in his, like, young period of his late 20s, early 30s end up being involved and actively participating in what ends up being mass murder. It’s probably the most extreme case study of ethics, or one of the most extreme case studies of ethics that I could have stumbled upon. And it stayed with me and to be honest, it shapes a lot of my work and how I think about human rights and civil liberties and the freedoms that we so often take for granted because I’ve studied, as an historian looking at France and Germany, how quickly those things can be taken away – very quickly, terrifyingly so, in fact. So that lens is always with me. And when I was then working in technology, and seeing some of the things that could be done with these tools and watching this lack of accountability, down to the point of gross negligence in some cases. And also, as a young technologist, not being given any training – we were given no training at all in ethics, in, like, discussing data protection – it was basically: this is the law, just obey the law, like, that’s the, that’s the box that you have to play in. Other than that, like, go for it. And when I look back on that now it’s like, Oh, my God, that’s the equivalent of putting your family in the car, and everybody goes off without wearing their seatbelts on and, you know, all this sort of safety design that we take for granted in cars now, it’s just mad when you think about it, or the way we used to fly. We’re in this phase, it’s really interesting, just over the course of my career – 25 years – where the stuff that we’re talking about today that dominates the headlines, right, that is dominating the discussion in the tech sector, was not discussed at all at the turn of the century, other than by maybe people in the science and technology studies domain or academics. But it wasn’t filtering into boardrooms. It wasn’t on the front pages of newspapers, and it wasn’t being covered in the national news, whereas like now that is all I’m doing. So it’s amazing. A whole field has sprung up.</p>
<p><strong>Brian Tarran</strong><br>
I think that that kind of origin story, if you like, explains some of your, perhaps, belief in the importance of exploring this accountability question when it comes to technology, ethics?</p>
<p><strong>Stephanie Hare</strong><br>
Yeah, because I watched it, and I think what was so fascinating– So as I say, I was in my early 20s. In fact, I was 20, when this man was put on trial, and I had just moved to France. It was the longest trial in French legal history – it was a big deal, you could not not watch it. So I was reading this and seeing it in the press every day, and I watched the French people discussing it around me, you know, really being divisive, this stuff does not go away. And his view was: I was just following orders, I was doing what I was told to do. Which you know, you hear that a lot from engineers or people who are like, this is the design spec I’ve been given, or this is what my boss has told me to do, or this is what our investors want, etc. Or people feel they don’t have the power to stand up because, you know what, they’ve got a mortgage, they’ve got kids, and employers know that, like, they know that and they use it as leverage against people to silence them. Or they’ve signed an NDA, because we get made to sign these NDAs when we work in tech, and then we get made to sign another NDA when we leave, right, so we can’t disparage our employer, and maybe we’re given some money so we don’t talk about the things we’ve seen. You know, it’s, it’s gross – it’s a gross little world, and like you have to be very, very solid and take good care of yourself to work in it, I reckon. To try and keep your ethical and moral compass. It’s hard. So I think because I saw that. And I saw that someone who – whether we believe him or not, this is what he claimed – in his 30s, he was just doing kind of what everybody around him was doing under a situation of crisis. He was let off the hook. I mean, he wasn’t just not persecuted in 1945, he was actually promoted. And then he became France’s top civil servant, and then he became an MP, and then he became budget minister. I mean, this guy’s career was not hurt in any way by what he did. On the contrary, right, he advanced. And yet, by the end of his life, French values had changed, so a new generation wanted to hold him to account. And I think about that a lot for all of us, right, who are sort of walking around in our 30s or 40s. Another generation or two, when we’re older, might look at some of what technology we’ve built or our behaviour on climate change, our track record – did we do what we could have done to slow global warming, to improve biodiversity? – and they might, they might hold us to account saying, you could have stopped this and you didn’t, right? It’s not just what you did. It’s what you did not do. Right. So we have to be super careful when we think about ethics, because ethics change, values change over time. And what seems okay today may not be okay in 10, 20, 30 years time, and we might be the 80- or 90-year-olds who are put on trial. That is on my mind all the time, right. It’s not very relaxing.</p>
<p><strong>Brian Tarran</strong><br>
No, and I guess it makes me think. Well, I mean, this is getting into the hypotheticals right. But is it– if we can’t necessarily predict or plan out how values might evolve over time, is it enough to be able to, to just say or to document that we asked the right questions at the time, rather than just doing things blindly. Is that where we need to kind of almost formalise our process of writing down, setting out, you know, we want to do this, we’ve considered these potential harms, we’ve considered these potential benefits, and we kind of document that so at least, you know, future generations can say well, “They thought about it. They might have not thought about it in the right way, but they tried”?</p>
<p><strong>Stephanie Hare</strong><br>
Absolutely, I think, you know, show your work and be like, these were our, you know, these were our sort of first principles of where we were starting from, this is the context in which we were making this decision. Because again, I don’t, I don’t necessarily fear the judgement of history in terms of if I get something wrong. People get stuff wrong all the time. That’s just being human. It’s, did I not care? You know, was I like, well, sorry, little little boys and girls who are babies now, like, I need to do my stuff, and like, I don’t care about you, right? That attitude is tough. Or I decided I just really, you know, I really needed to buy a flat. So I decided to work for some dodgy company, or dodgy, dodgy company that’s owned by a foreign government, but I knew it was going to be fine, and they’re offering me a tonne of money, and now I can go on nicer holidays. I’ve had these conversations with people about this literally this past week, like, these are live issues for people. There’s a cost of living crisis, ethics can feel like a luxury for some people rather than a necessity. And human beings are very bad, all of us, at thinking about, you know, future selves, right? Like we kind of, we optimise for how we’re feeling now, and we’ll deal with 20 years from now later if we even get there. So I think there’s that. There’s also– this really inspired the writing of the book, Technology is Not Neutral. I knew, I had this weird sense – I had just gone independent, so I had left working for these companies, I was not under any NDAs anymore, which right there gives you a clue; I could say what I wanted – but I also knew there was a chance that I was going to have to go back either into industry, or maybe work for a government, I don’t know what I’m going to need to do in the future or who I’m going to want to work with or what reasons I might even have for that. But I knew I had this window of being an independent researcher and broadcaster, that I could say whatever I wanted, and I had that thing of like, okay, if you’ve had a window of, say, five years, for example, what would you say if you were not afraid? If you were not scared? If you were like, you know, screw the money, screw the corporate pressure, screw the government, whatever, what do you want to talk to the public about? And my views were, I really wanted to talk to them about facial recognition, because I feel people just fundamentally do not understand how dangerous that technology is and how it can be used. I wanted to talk about the pandemic technologies, because we were, you know, I was writing it during the pandemic, and I thought, well, if a pandemic ever happens again, let’s have a nice little tidy case study for potentially future historians or future medical personnel, public health officials to pull out, because when the pandemic hit, we all had to go back and look at stuff from the Spanish flu. You know, there’s a lot of discussion of like, why has this come as such a surprise? Are we going to use these technologies again or not? Right. Like, you know, is it worth it? Is the return on investment worth it in all senses – ethically, as well as medically, all of those things? So I thought I would lay down a couple of markers that I hoped would stand the test of time. But the big thing I wanted to do, because I was always thinking I might have to go and sign another NDA and go work because I too must earn my living, was I wanted to write something so that anyone who cares about technology, is working in it, is investing in it, right – it’s not just people who code, it’s people who fund the people who code. Buying technology – procurement is massive, you’re a really powerful person if you’re in charge of procurement. But also just consumers, and citizens and parents, and teachers and kids. If I could write up everything that I had learned in my 25 years, and succinctly as possible, right – as short as possible, because people are tired, they’re busy – I could pass that baton on, so that if I ever have to stop going on television and radio, and I’m no longer allowed to write in newspapers and warn people about the stuff I’m seeing and the abuses of power, and showing them examples of history of how this can go so terribly wrong, maybe it will have, like, lit somebody else. And I’m delighted to report – I mean, we’ll see; time will tell, it’s only been out a year – the amount of people who have brought me in to train their staff, to talk to their board. I’ve talked to children. I’ve talked to university students, I’ve taught classes all over the world, because we can now do online teaching. I’ve taken a lot of it on television and radio and in the newspapers. People wanted this, and I’m not the only person working on it, of course – there’s been a whole flowering of people, scholars, etc., working in putting out amazing books and documentaries. It’s really, we’re having some sort of moment with technology ethics – AI ethics being just a branch of that. So that’s really encouraging. So I sort of feel like, you know, again, if I, if I’m gonna have to account for myself at the age of 93, I would like to be able to point to that and go, I tried. I tried. And I have no idea if it will succeed or not, but I stood up to the plate and I swung the bat and, you know, I aimed for the bleachers.</p>
<p><strong>Brian Tarran</strong><br>
One of the things I thought was really interesting about the book, it comes towards the end when you’re kind of talking about, you’re summing up, and you talk about how your thinking about almost like the the approach or solution to the technology ethics issue has changed over the course of the writing of the book. You had, like, a list of potential, like, proposals, proposed actions that you wanted to analyse, but then you realised that actually technology ethics is a “wicked problem”. I wonder if you could explain what that term means for people who might not be familiar with it and and why you think of it that way?</p>
<p><strong>Stephanie Hare</strong><br>
Yeah, I’m so grateful to have learned about the term “wicked problem”. My friend Jason Crabtree, who wrote an amazing book about electricity grids, like smart electricity grids, for Cambridge University Press, had asked me to read his manuscript maybe 10 years ago, and I read it, and one thing I took away that just absolutely blew my mind was this concept. So I shall gift it to you for those of you have not heard it. Because then suddenly, you’re like, God, it makes so much sense. There are certain problems, I would say, like, the climate crisis, and biodiversity loss would be a good example of this. There’s certain problems that have many causes, many causes, so there isn’t going to be one solution to fix them. So people constantly ask me, oh, is this the magic bullet? No, they’re like, there are certain problems that there is no magic bullet – the pandemic is probably another, actually. Then, if you do try to solve these wicked problems, the mere act of solving them can introduce a whole new set of problems to them. So like, it becomes even more of a head– You know, I’m trying not to swear, but a messing with your head moment. And it’s exhausting, you know, and it gives you your forehead wrinkles and makes you just sort of want to bang your forehead onto the nearest wall. And yet, you also can’t opt out and be like, well, it’s just too hard. It’s a wicked problem. There’s no solution, there’s nothing to be done, you know, throw up your hands, because you’re like, Yeah, but the problem is, is if we don’t do anything, like literally people are dying; literally, climates are becoming uninhabitable, we’re going to have massive climate migration, that’s going to cause all sorts of problems, water scarcity, we can have wars over this, like, we have to do something. So like, you have to still act on a wicked problem, all while knowing that it’s not going to be solved in a binary sense of like zero, one, black and white, I can point to it and measure it. And for people who like metrics, that’s a real pain, because they’re like, I want to know what good looks like and I want to know how we’ll know when we get there, you know, what’s the percentage, what’s the number? And you kind of have to be like, Well, with a wicked problem, you might never solve it, or you won’t solve it once. Because again, with something like climate change, or pandemics, these are things you’re probably gonna have to solve again, and again, and again, because it’s dynamic. And it’s constant, you know, we’re always going to be managing our relationship with the climate, with the environment. So, you know, we can pick a certain temperature, or a certain percentage of landmass that, you know, has trees or whatever, and like, come up with a little metric for our metric-oriented friends. But that’s still not very meaningful. So it’s more that when you think of a wicked problem, like facial recognition technologies, like, we need to be able to identify people in certain situations, and like, we want that, right. Like, we want to be able to catch criminals, and we want to be able to catch terrorists when they’ve managed to pull off a terrible act of, of harm to people. But at the same time, do you want to turn your society into a sort of permanent dragnet? Do we not care about privacy? If so, like, when do we care about privacy? And when are we okay with maybe sacrificing that for the greater good and who decides that? It’s really problematic if you live in London as I do, and your police force, which is using this technology, has admitted, they’ve admitted themselves to being misogynist, institutionally misogynist, homophobic, racist, right? And then we’re gonna give them a technology that doesn’t work very well on people with certain skin. It doesn’t identify people of a certain age as well. It’s got all sorts of problems. So you’re kind of like, hmm? Facial recognition is covered a bit under the EU AI Act. But even then there’s like so many loopholes. And the thing is, if you cite national security, it usually gets waved through because no one wants to be the person who said, I said we couldn’t use this technology, and then something bad happened. Right? So you err on the side of, like, the precautionary principle. The default is, let them use it. We must trust them. Except what do you do if your police force has given you quite ample evidence not to trust them? Or companies. You know, this is not to bash on the police, by the way – companies are some of the worst offenders in this area. So that’s what I mean about it being a wicked problem is, it’s out there. It’s installed. It’s all over the UK, it’s definitely all over the US as well. And we don’t really have a good framework for it.</p>
<p><strong>Brian Tarran</strong><br>
But then this is where we loop back around to the kind of culture, right, creating a culture of technology ethics? You know, we can’t just put a checklist in place once, do it, tick it off, yeah, we’ve done that for facial recognition technology, we’re good to go. Because there are always new potential use cases for it, new applications, new integrations with different systems that we always need to be thinking, every time, is this the right thing to do? Or–</p>
<p><strong>Stephanie Hare</strong><br>
I mean, I’m still a big fan of checklists. So it’s not that I’m anti-checklist. And I’m not saying that you said that, by the way, I’m more thinking aloud. Checklists can still be useful, right? Like, whenever I’m in a really bad mood, I’m like, Okay, hang on, have I slept? Do I just need a glass of water? Am I hungry? You know, what I think is angry may just be that I skipped lunch. You can kind of go through those things, and anybody who’s had to like troubleshoot why a baby or a small child is unhappy will also have a checklist and what’s on the thing – ah, they missed naptime, where’s their bear? That sort of thing. Companies need checklists, because you’re trying to get loads of people singing from the same hymn sheet, I get that. But what I wanted to get away from was this idea that, like, one person or one team gets this checklist and maybe does that once a year, once a quarter, pick your cadence – and everybody else gets a pass. Ethics doesn’t work that way, because again, ethics is kind of I think in the wicked problem scenario of, like, how do we decide what our values are and how to live them? And how do we know, where do we draw the line? And then how do you, how do you decide if you’ve gone over the line or not? And all of that, who decides who decides? Those are really complex questions that mean that really you can’t abdicate. This is, in a company’s case, it’s the CEO, it’s the board, all the way on down – it has to be baked in to every single employee, and also investors, mindset. And I was thinking about it in terms of cybersecurity, I once had a colleague who gave me an analogy that I think is helpful, so I’ll share it for what it’s worth: When you go on to, say, an oil rig, in the North Sea – a highly dangerous environment – you might be the most junior person there, and you’re there for your very first day of work. But if you spot something on that rig that is a health and safety risk, you have to speak up. You’re not going to go, like, Oh, my boss might say something, whatever, because, like, everybody’s life on that rig is depending on everyone having that culture of careful, that’s not okay. And that really put me in mind where it was like, Oh, wow, we’re going to have to like inculcate an entire new mindset. And we think about technology ethics a lot because of technology being the word, and we think it must mean like hardware or software, it’s always about coding, and it’s often guys in hoodies coding. But my preferred method of hacking is culture. Right. So like, again, if we tried to just solve everything through regulation and laws, that takes, you know – if you look at the average time it takes to pass a law and then for regulators to enforce it – ages, we’re talking years, like it’s too late. These technologies will have moved on. Ditto, calls for international treaties. Do it, by all means. Have a look at how long it takes most international treaties to get passed and then ratified – and then, P.S. What happens when people break them? Really, right. So like, they’re important, they’re necessary, but they’re insufficient. You can act a lot faster if you can get people preventing stuff from being built in the first place, and that means you need to have a culture of people working in technology, both within the organisations – whether that’s research labs, government, companies, universities, whatever – and on the outside – journalists, academics, thinkers, etc, just the public, an informed public – who can see something and do what I just described on the oil rig, like, sound the alarm and go, Wait a minute, hang on. That’s not okay. That is, that to me feels faster. And I’m way more into prevention than cure, for all sorts of reasons. So I think like, yes, to laws and regulations, yes, to treaties; this will be faster. And I think it will be more resilient.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, I agree. And I have to say, wrapping up, that I think Technology is Not Neutral is a great place to start to inculcate that mind shift, that mindset change. So, Stephanie, thank you very much for joining us today.</p>
<p><strong>Stephanie Hare</strong><br>
Thank you for having me.</p>
<p><strong>Brian Tarran</strong><br>
You said you’re working on a new book. Have you got a timeline for that? Or a title?</p>
<p><strong>Stephanie Hare</strong><br>
No.&nbsp;I am the slowest thinker and writer, I’m like the opposite of move fast and break things, I’m like move slowly and like think it over maybe several times. So I’m just getting started out. I’ll sort of go five years. It’s gonna be, it’s a history book. Alright. So this is, this is different, I’m having to take my classes in French and German right now to get kind of match fit in those languages again, and then you know, I’ll be off and writing. But, yeah, I hope to have another book out, you know, in five years.</p>
<p><strong>Brian Tarran</strong><br>
Well, if the year it took me to read Technology is Not Neutral is any indication, in three, four or five years time it will still be relevant today. So–</p>
<p><strong>Stephanie Hare</strong><br>
That’s the thing with history, it always stands the test of time.</p>
<p><strong>Brian Tarran</strong><br>
Well, thank you, thank you again for joining us on Real World Data Science. It’s been a pleasure talking to you.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
<p>© 2023 Royal Statistical Society</p>
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/04/28/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/04/28/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photo of Stephanie Hare is not covered by this licence. Photo is by Mitzi de Margary, supplied by Stephanie Hare and used with permission.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
<p>Tarran, Brian. 2023. “‘I’m way more into prevention than cure’: Stephanie Hare on why we need a culture of technology ethics.” Real World Data Science, April 28, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/04/28/stephanie-hare.html">URL</a></p>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Technology ethics</category>
  <category>AI ethics</category>
  <category>Culture</category>
  <category>Regulation</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/04/28/stephanie-hare.html</guid>
  <pubDate>Fri, 28 Apr 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/04/28/images/stephanie-hare-bw.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Data science as ‘a rainbow’, and other definitions</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/defining-DS.html</link>
  <description><![CDATA[ 




<p>What does “data science” mean to you? That’s a question we’ve been asking a lot in recent weeks as part of our <a href="https://realworlddatascience.net/careers/career-profiles/">career profiles</a> series of interviews – the first of which, featuring <a href="https://realworlddatascience.net/careers/career-profiles/posts/03/28/tamanna-haque.html">Jaguar Land Rover’s Tamanna Haque</a>, was published yesterday.</p>
<p>It’s also a question that was asked recently of Sylvia Richardson, emeritus director of the Medical Research Council Biostatistics Unit at the University of Cambridge and immediate past president of the Royal Statistical Society (RSS).</p>
<p>Richardson was interviewed by Francesca Dominici, interim co-editor-in-chief of the Harvard Data Science Review. In response to the question “What’s data science for you?”, Richardson said:</p>
<blockquote class="blockquote">
<p>It’s hard to be original, but I was racking my brain for a good metaphor, and came up with the metaphor of a rainbow of interconnected disciplines, sharing the common aim of making the best use of data-rich environments we live in to solve problems in society. So, like in a rainbow, data scientists have to work together to draw out information from data. And the colors must match, [though] they are different. Similarly, there are different but intersecting data science tasks, taking different shapes and forms. As data scientists, we recognize and enjoy diversity, we’re not doing all the same tasks. Nevertheless, there is a backbone, a shape to the rainbow. And for us, this backbone is probability theory, study design, and quantifying uncertainty using statistical thinking. We also know that rainbows change all the time. They don’t last, but they keep reappearing. Data science is also evolving constantly because new questions and new types of data keep arising. In a similar way to the rainbow which is strongly influenced by the atmosphere, one key aspect of data science is that we have a strong link to practice. So, we work together to solve problems from different perspectives, we evolve, we try to be relevant to science and society, and make the best use of the data. [<a href="https://hdsr.mitpress.mit.edu/pub/v27yux58/release/2?from=2089&amp;to=3374">Source</a>]</p>
</blockquote>
<p>Richardson’s view on the meaning and importance of data science has special resonance to me, as editor of Real World Data Science. While president of RSS, Richardson set up the <a href="https://rss.org.uk/policy-campaigns/policy-groups/data-science-task-force/">Data Science Task Force</a> out of which this website emerged. As she explains to Dominici:</p>
<blockquote class="blockquote">
<p>… while I was president, I felt a sense of urgency to encourage the RSS to revisit its engagement with data science, and I created a data science task force right at the beginning of my presidency. It didn’t get going earlier because there was COVID to keep us busy! Nevertheless, the Data Science Task Force got underway in 2021 and came up with two major recommendations. One was to give more resources to the practitioners’ community, which led the RSS to create a Real World Data Science online platform. A second direction was to brainstorm on what is still needed for the discipline to thrive. [<a href="https://hdsr.mitpress.mit.edu/pub/v27yux58/release/2?from=17202&amp;to=17799">Source</a>]</p>
</blockquote>
<p>You can read (or listen) to Richardson and Dominici’s conversation in full on the <a href="https://hdsr.mitpress.mit.edu/pub/v27yux58/release/2">Harvard Data Science Review website</a>.</p>
<p>And we’ll have more <a href="https://realworlddatascience.net/careers/career-profiles/">career profiles</a> – and more personal definitions of data science – to share soon. In the meantime, why not tell us what “data science” means to you?</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Data science as ‘a rainbow’, and other definitions.” Real World Data Science, March 29, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/defining-DS.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Updates</category>
  <category>Themes</category>
  <category>People</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/defining-DS.html</guid>
  <pubDate>Wed, 29 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/images/rainbow.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>OpenAI’s text classifier won’t calm fears about AI-written homework</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/AI-screening.html</link>
  <description><![CDATA[ 




<p>When ChatGPT launched in December 2022, it wasn’t long before users highlighted <a href="https://news.sky.com/story/the-ultimate-homework-cheat-how-teachers-are-facing-up-to-chatgpt-12780601">the tool’s potential as a homework aid</a>. Pop an essay question into ChatGPT’s prompt box or feed your creative writing task to the AI instead, <em>et voila</em> – your work is done!</p>
<p>In reality, of course, things aren’t quite so simple. ChatGPT, like other large language models, has an unfortunate <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/27/talking-chatgpt.html">habit of making stuff up</a> – fine for creative writing, perhaps; not so good for a history essay. Outputs need to be checked and verified if you want to guarantee a good mark on your assignments. But while ChatGPT can’t – and shouldn’t – be trusted completely, many have found that it can help lighten the homework load.</p>
<p>With <a href="https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app">ChatGPT’s user count crossing the 100 million mark</a> last month, it’s understandable that worries about an explosion of AI-written text have proliferated in many professions, including education. <a href="https://www.washingtonpost.com/education/2023/01/05/nyc-schools-ban-chatgpt/">Some education systems</a> have decided to <a href="https://www.smh.com.au/national/nsw/can-you-tell-between-a-year-6-student-and-ai-teachers-say-they-can-20230120-p5ce5s.html">ban the use of ChatGPT</a>. Other educators have adopted a more relaxed approach. Writing in <em>Scientific American</em>, <a href="https://www.scientificamerican.com/article/how-chatgpt-can-improve-education-not-threaten-it/">law professor John Villasenor argued</a>:</p>
<blockquote class="blockquote">
<p>“The time when a person had to be a good writer to produce good writing ended in late 2022, and we need to adapt. Rather than banning students from using labor-saving and time-saving AI writing tools, we should teach students to use them ethically and productively… They need to learn to compose well-organized, coherent essays involving a mix of AI-generated text and traditional writing.”</p>
</blockquote>
<p>Villasenor makes a valid point. But experience tells us that not every student is going to use these tools ethically. Some will pursue the path of least resistance and will attempt to present ChatGPT’s outputs as their own. So, the question becomes: Is it possible to tell the difference between human-generated text and AI-generated text?</p>
<section id="spot-the-difference" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="spot-the-difference">Spot the difference</h2>
<p>One answer to that question comes from OpenAI, makers of ChatGPT. On January 31, they launched a classifier “to distinguish between text written by a human and text written by AIs from a variety of providers”.</p>
<p>OpenAI <a href="https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text">introduces the classifier</a> by saying that reliably detecting <em>all</em> AI-written text is “impossible”. But it goes on to say:</p>
<blockquote class="blockquote">
<p>“… we believe good classifiers can inform mitigations for false claims that AI-generated text was written by a human: for example, running automated misinformation campaigns, using AI tools for academic dishonesty, and positioning an AI chatbot as a human.”</p>
</blockquote>
<p>OpenAI stresses that the current version of the classifier “should not be used as a primary decision-making tool”, and users should take that statement to heart – especially if they are planning to vet student homework with it. In evaluations, OpenAI reports that its classifier correctly identifies AI-written text as “likely AI-written” only 26% of the time, while human written text is incorrectly labelled as AI-written 9% of the time.</p>
<p>These two reported numbers are important. They are, respectively, the classifier’s <strong>true positive rate</strong> and the <strong>false positive rate</strong>. The former is the conditional probability of a positive result given that a piece of text <em>is</em> AI generated; the latter is the conditional probability of a positive result given that a piece of text <em>is not</em> AI generated. However, neither piece of information directly addresses the question that will be of most interest to teachers: “If a piece of homework is flagged as ‘likely AI-written’ by the OpenAI classifier, what is the probability that it actually <em>is</em> AI-written?”</p>
<p>To answer this question, we need to flip the conditional probabilities – from “the probability of positive test given text is AI generated” to “the probability text is AI generated given positive test”. Bayes’ theorem provides a formula for doing just that, as described in <a href="https://www.significancemagazine.com/science/547-a-visual-guide-to-screening-test-results">this 2017 article by Tim Brock, published by Significance magazine</a>.</p>
<p>As Brock’s article demonstrates, versions of this problem are familiar to medical statisticians, who often find themselves having to explain screening test outcomes – specifically, the probability that a person has disease X given that they have tested positive for said disease. This probability depends on the <strong>prevalence</strong> of a disease and the <strong>sensitivity</strong> and <strong>specificity</strong> of the test, and Brock defines these terms as follows:</p>
<ul>
<li><dl>
<dt>Prevalence</dt>
<dd>
The proportion of the population being tested that are affected by a given condition.
</dd>
</dl></li>
<li><dl>
<dt>Sensitivity</dt>
<dd>
The proportion of patients with the condition being screened for that are correctly identified as having the condition.
</dd>
</dl></li>
<li><dl>
<dt>Specificity</dt>
<dd>
The proportion of patients without the condition being screened for that are correctly identified as not having the condition.
</dd>
</dl></li>
</ul>
<p>Sensitivity and specificity are also referred to as, respectively, the true positive rate (mentioned earlier) and the true negative rate.</p>
<p>We know from OpenAI’s own evaluations that out of 100 pieces of AI-written text, only around 26 would be correctly classified as “likely AI-written”, so the classifier’s sensitivity is 26%. And out of 100 pieces of human-written text, around 9 would be incorrectly classified as AI written, meaning 91 would be correctly classified as not AI written, so specificity is 91%. But the big piece of information we don’t have is prevalence: What proportion of homework assignments are written by AI?</p>
<p>This prevalence figure is likely to vary based on where students live, what age they are, their level of interest in AI tools and technologies, and many other factors. <a href="https://stanforddaily.com/2023/01/22/scores-of-stanford-students-used-chatgpt-on-final-exams-survey-suggests/">A poll of Stanford University students by The Stanford Daily</a>, for example, found that 17% of respondents used ChatGPT for final assignments or exams in the fall quarter – though it reports that “only about 5% reported having submitted written material directly from ChatGPT with little to no edits”.</p>
<p>So, let’s assume for the moment that 5% of homework assignments are AI-generated. If you were screening 1,000 pieces of homework with the OpenAI classifier, you’d see something close to the following results:</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 21%">
<col style="width: 22%">
<col style="width: 21%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">True positives</th>
<th style="text-align: right;">False positives</th>
<th style="text-align: right;">True negatives</th>
<th style="text-align: right;">False negatives</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Results</td>
<td style="text-align: right;">13</td>
<td style="text-align: right;">86</td>
<td style="text-align: right;">864</td>
<td style="text-align: right;">37</td>
</tr>
</tbody>
</table>
<p>The figures below show the results graphically as proportions of (a) all tests and (b) all positive tests. (All plots are produced using Python and the <code>matplotlib</code> package; code and functions are available from <a href="https://github.com/brtarran/screening-tests">this GitHub repository</a>.)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig1a.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all tests, assuming 5% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 1a:</strong> Classifier test results as a percentage of all tests, assuming 5% prevalence of AI-written homework.</p>
</div></div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig1b.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all positive tests, assuming 5% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 1b:</strong> Classifier test results as a percentage of all positive tests, assuming 5% prevalence of AI-written homework.</p>
</div></div><p>From Figure 1b, we see that if the classifier delivers a “likely AI-written” result, the chance that the text is AI-written is only about 13%. This is the classifier’s <a href="https://uk.cochrane.org/news/sensitivity-and-specificity-explained-cochrane-uk-trainees-blog">positive predictive value</a> at the assumed 5% prevalence.</p>
<p>If we reproduce our figures using a prevalence rate of 17%, also from the Stanford survey, the chance that a positive result is a true positive is now about 37%.</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 21%">
<col style="width: 22%">
<col style="width: 21%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">True positives</th>
<th style="text-align: right;">False positives</th>
<th style="text-align: right;">True negatives</th>
<th style="text-align: right;">False negatives</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Results</td>
<td style="text-align: right;">44</td>
<td style="text-align: right;">75</td>
<td style="text-align: right;">755</td>
<td style="text-align: right;">126</td>
</tr>
</tbody>
</table>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig2a.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all tests, assuming 17% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 2a:</strong> Classifier test results as a percentage of all tests, assuming 17% prevalence of AI-written homework.</p>
</div></div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig2b.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all positive tests,  assuming 17% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 2b:</strong> Classifier test results as a percentage of all positive tests, assuming 17% prevalence of AI-written homework.</p>
</div></div><p>Yet another survey, <a href="https://www.prweb.com/releases/intelligent_com_survey_finds_30_percent_of_college_students_use_artificial_intelligence_chatbot_chatgpt_for_written_homework/prweb19141759.htm">this one from Intelligent.com</a>, claims that 30% of college students have used ChatGPT for written homework. Plugging this number into our calculations, the chance that a positive test result is a true positive is now slightly better than 50/50.</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 21%">
<col style="width: 22%">
<col style="width: 21%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">True positives</th>
<th style="text-align: right;">False positives</th>
<th style="text-align: right;">True negatives</th>
<th style="text-align: right;">False negatives</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Results</td>
<td style="text-align: right;">78</td>
<td style="text-align: right;">63</td>
<td style="text-align: right;">637</td>
<td style="text-align: right;">222</td>
</tr>
</tbody>
</table>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig3a.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all tests, assuming 30% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 3a:</strong> Classifier test results as a percentage of all tests, assuming 30% prevalence of AI-written homework.</p>
</div></div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig3b.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all positive tests,  assuming 30% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 3b:</strong> Classifier test results as a percentage of all positive tests, assuming 30% prevalence of AI-written homework.</p>
</div></div></section>
<section id="determining-guilt" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="determining-guilt">Determining ‘guilt’</h2>
<p>If a test has a positive predictive value of just over 50% (at an assumed prevalence rate of 30%), does that provide a reasonable basis on which to accuse someone of getting ChatGPT to do their homework? That depends on who you ask. If we look to the legal system for guidance, in civil cases like personal injury claims or contract disputes judges typically make decisions on the so-called “balance of probabilities”. This is generally assumed to mean if we are more than 50% sure of someone’s “guilt” in this context, that might be sufficient to find against them. However, in criminal law, a higher standard applies: “beyond reasonable doubt”. Legal scholars have long wrestled with how to quantify this in probabilistic terms, and surveys of judges put “beyond reasonable doubt” somewhere in the range of being 80% to 99% certain of guilt – see, for example <span class="citation" data-cites="mccauliff1982burdens">McCauliff (1982)</span> and <span class="citation" data-cites="solan1999refocusing">Solan (1999)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-mccauliff1982burdens" class="csl-entry">
McCauliff, Catherine MA. 1982. <span>“Burdens of Proof: Degrees of Belief, Quanta of Evidence, or Constitutional Guarantees.”</span> <em>Vand. L. Rev.</em> 35: 1293.
</div><div id="ref-solan1999refocusing" class="csl-entry">
Solan, Lawrence M. 1999. <span>“Refocusing the Burden of Proof in Criminal Cases: Some Doubt about Resaonable Doubt.”</span> <em>Tex. L. Rev.</em> 78: 105.
</div></div><p>It is at this standard of evidence that OpenAI’s classifier shows its limitations. For example, if we flip Bayes’ theorem around, we find that to achieve a positive predictive value of at least 80%, the prevalence rate needs to be at least 58%. For a positive predictive value of 90%, prevalence needs to be 76%. (Verify these figures for yourself: Python code and functions are available from this <a href="https://github.com/brtarran/screening-tests">GitHub repository</a>).</p>
<p>Thus far in our calculations, we’ve set prevalence according to estimates of the percentage of students who use ChatGPT for their homework. But, according to statistician and science writer Robert Matthews, individual students could justifiably complain about having their guilt decided on this basis. “It’s like deciding someone is guilty of a crime just because they happen to live in an area notorious for criminal gangs,” he says. Instead, the guilt of individual students should be decided using an estimate of the chances that <em>they</em> would use ChatGPT for <em>that particular</em> homework assignment.</p>
<p>Looked at in this way, Matthews says, “You already have to be pretty convinced of a person’s ‘guilt’ even before applying the classifier if you want to put the evidence ‘beyond reasonable doubt’. Bayes’ theorem highlights the need to be really clear about what you mean by the ‘accuracy’ of a test, and about what question you want the test to answer.”</p>
<p>So, here’s a question that teachers will be asking if they are worried about ChatGPT-generated homework: “Has the piece of text I’m marking been written by AI?” If those same teachers use the OpenAI classifier to try to answer that question, they will no doubt expect that something classified as “likely AI-written” is more likely to be AI-written than not. However, as it stands now – and as our examples above have shown – users can’t be confident that’s the case. In education terms, this particular ‘test’ is a long way from scoring top marks.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “OpenAI’s text classifier won’t calm fears about AI-written homework.” Real World Data Science, March 15, 2023. <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/03/15/AI-screening.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Classifiers</category>
  <category>Screening tests</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/AI-screening.html</guid>
  <pubDate>Wed, 15 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/teacher-marking-homework.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>US legislators get their data science act together</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/03/06/data-science-act.html</link>
  <description><![CDATA[ 




<p>On February 14, 2023, a bipartisan group of US legislators introduced the <a href="https://stevens.house.gov/media/press-releases/rep-stevens-leads-bipartisan-legislation-increase-access-data-science-and">Data Science and Literacy Act</a> with the goal of boosting access to data science education and building “America’s 21st century STEM workforce”. We sat down with guests Zarek Drozda, Anna Bargagliotti, Christine Franklin and Steve Pierson to discuss the news and to hear why data science education is “the new apple pie”.</p>
<ul>
<li>Zarek Drozda is director of the <a href="https://www.datascience4everyone.org/about">Data Science 4 Everyone</a> coalition.</li>
<li><a href="https://cse.lmu.edu/faculty/?expert=anna.bargagliotti">Anna Bargagliotti</a> is graduate program director and professor of mathematics at the Seaver College of Science and Engineering, Loyola Marymount University.</li>
<li>Christine Franklin is the American Statistical Association’s <a href="https://www.amstat.org/education/asa-k-12-statistical-ambassador">K-12 statistical ambassador</a>.</li>
<li>Steve Pierson is the <a href="https://twitter.com/asa_scipol?lang=en">ASA’s director of science policy</a>.</li>
</ul>
<p>Check out our full conversation below or on YouTube.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/OaRFFgKb1S0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="timestamps" class="level2">
<h2 class="anchored" data-anchor-id="timestamps">Timestamps</h2>
<ul>
<li>The state of data science education in the United States (<a href="https://youtu.be/OaRFFgKb1S0?t=211">3:31</a>)</li>
<li>What will be the main impacts of the Data Science and Literacy Act? (<a href="https://youtu.be/OaRFFgKb1S0?t=554">9:14</a>)</li>
<li>Professional development support for teachers and teacher-educators (<a href="https://youtu.be/OaRFFgKb1S0?t=786">13:06</a>)</li>
<li>How much money is needed to deliver data science education? (<a href="https://youtu.be/OaRFFgKb1S0?t=1133">18:53</a>)</li>
<li>Developing a data science curriculum (<a href="https://youtu.be/OaRFFgKb1S0?t=1629">27:09</a>)</li>
<li>Building confidence in data, statistics, and technology (<a href="https://youtu.be/OaRFFgKb1S0?t=1914">31:54</a>)</li>
<li>Learning from, and making connections with, international colleagues (<a href="https://youtu.be/OaRFFgKb1S0?t=2223">37:03</a>)</li>
</ul>
</section>
<section id="quotes" class="level2">
<h2 class="anchored" data-anchor-id="quotes">Quotes</h2>
<p>“Most of our teachers in US schools, math teachers, have not had any formal training in statistics. Or if they have, it’s been maybe one course. They’re very uncomfortable with trying to implement these standards [for data science and statistics education]. And it’s just going to require a tremendous amount of professional development. Sounds easy in theory to deliver professional development, but very difficult in practice.” (<a href="https://youtu.be/OaRFFgKb1S0?t=618">10:18</a>)</p>
<p>“We know that in aggregate, between federal, state, private and local funding, we’re going to have to create the necessary resources to make sure that our K-12 public education system can prepare students for a world that’s changing super fast, and the K-12 system moves super slow in how it adapts to new content. And so really it’s both about what can we do to upskill data science, data literacy skills [and] it’s also about how do we help the system adapt faster as new technology comes out and leverage the importance of data in that.” (<a href="https://youtu.be/OaRFFgKb1S0?t=1176">19:36</a>)</p>
<p>“I think we’ve spoken to some 50 or 60 offices, both on the Senate side and the House side. And this [has been] received really well. We don’t get any pushback on that there is a need for greater data literacy. Here stateside, I’ve been saying it’s kind of like advocating for apple pie. People get it and they resonate.” (<a href="https://youtu.be/OaRFFgKb1S0?t=1280">21:20</a>)</p>
<p>“As we introduce this bill, I think we should be messaging [that] there’s a economic competition aspect to this; that it’ll be really important for the US to make investments in this area to, frankly, catch up to where I think other international peers are.” (<a href="https://youtu.be/OaRFFgKb1S0?t=2434">40:34</a>)</p>
<p>“Data tell our stories, and they reflect what’s happening in our world today – much like art around us in some ways. And a way to think about data science education is to think about what we need our data understanding to be at each point in time in our educational career, or in our lives. And it’s not static, it’s an evolving thing. So you have to move with the data that are being collected.” (<a href="https://youtu.be/OaRFFgKb1S0?t=2574">42:54</a>)</p>
</section>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to the Real World Data Science news q&amp;a. I’m Brian Tarran. And I’m joined today by a panel of guests to discuss some promising developments in the United States around data science education. On the show today we have Zarek Drozda, director of the Data Science 4 Everyone coalition, Anna Bargagliotti, Graduate Programme Director and Professor of Mathematics at the Seaver College of Science and Engineering, Loyola Marymount University, Christine Franklin, the American Statistical Association’s K-12 statistical ambassador, and Steve Pearson, who is the ASA’s Director of Science Policy. Welcome all. Thank you for joining us. Steve, I’d like to come to you first, because it was one of your ASA science policy tweets that that first drew my attention to this story. And that specifically was the tweet about the introduction of a new Data Science and Literacy Act in the US House of Representatives. Can you give our viewers an overview of the act and its significance to the data science education landscape, please.</p>
<p><strong>Steve Pierson</strong><br>
Happy to Brian and I also want to credit my colleague, Ed Wu, an ASA science policy fellow who worked a lot on this and championed it. So I see kind of two overarching points here for the bill. One is just to help out those budding efforts around the United States to bring more data science education to students, right, the demand in the jobs is out there. Students should know about these jobs, we want to connect them to the 21st century jobs. So this is a Department of Education programme that helps out those schools, communities that need the help that want the help. We’re not trying to require anything of schools, which already have enough curriculum requirements. So this is a voluntary programme, that I mean, I think it’s developing curriculum, it’s providing professional development. But I think there’s another aspect of this, Brian, which is just kind of the attention that this can bring to these jobs, to the schools to the members of Congress that, you know, data intensive jobs are a great job opportunity in the 21st century, right? You can look at so many places to know that, right? The Bureau of Labor Statistics has both statistician and data scientist as the top 10 jobs in terms of projected growth for the next decade. There’s Glassdoor, there’s many others, so we know that. We want to make sure that today’s students know about those opportunities and are connected to them. But we also want to just kind of diversify the STEM workforce. So there’s components of that in the bill as well. And so we want, we think that, you know, a bill introduced into the US Congress will help bring attention to that, including the members of Congress and others.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. I’ll take a step back briefly to look at the data science education landscape as it is today and Zarek, you helped facilitate a National Academies workshop last September, and one of the aims was indeed to survey that landscape for data science education for the K-12 grades – and for international audiences, correct me if I’m wrong, that’s students aged about five up to 17. Is that correct?</p>
<p><strong>Zarek Drozda</strong><br>
Right, for five to 18 range.</p>
<p><strong>Brian Tarran</strong><br>
So yeah, so how would you summarise that kind of state of data science education in the US right now?</p>
<p><strong>Zarek Drozda</strong><br>
Yeah, well, first focus on the workshop that was facilitated by the National Academies. And that was not the first but definitely the largest to date, in terms of a national convening of the United States for data science and data literacy education. We had 100 plus researchers, programme developers, and higher ed faculty in the room. There were 500 online, it was a big, you know, kind of early stage milestone for billing data science education in the United States. And we had a number of topics ranging from you know, what does this look like a practice? What is the professional development for, for K-12 teachers look like? What are examples both standalone data science courses, and also integration into different existing K-12 subject areas. And it was really a showcase of you know, a lot of the curriculum work that’s been developed over the past 10, 15 years for building your full length data science high school courses, or for building lesson plans or for building, you know, education, classroom specific software for data analysis that students can really get their their head around. And so I think it was a milestone to then this legislation then built off right that Steve was mentioning. I’m glad that you know news of both the National Academies workshop and then the legislation and kind of the growing momentum here in the US generally has made it across the pond. I think, partially our social media game was strong enough, which is exciting to hear. But I think it’s just a testament to you know, the energy for this space is really growing, right? Because it’s, it’s career connected. I think it’s so relevant to so many other emerging technologies, whether it’s artificial intelligence or ChatGPT or cyber. And I think, students, what came through really clearly in the workshop is that students really find this content relevant because of the technology applications. And it seems so, you know, of the moment.</p>
<p><strong>Brian Tarran</strong><br>
Yep. Well, certainly, you talked about jumping across the pond. So two weeks ago now, but it might have been three, I attended a meeting, a discussion around what they refer to as the digital skills gap in the UK. And I left that meeting feeling very much like what they were talking about, defining as digital skills were data science skills. And so when I saw that there was this Data Science and Literacy Act, I thought, well, you know, here’s, here’s something that hopefully, other other places like the UK can learn from. So Anna, you participated didn’t you in the workshop? So do you mind sort of giving us an overview of the data science landscape as it is, as it is now?</p>
<p><strong>Anna Bargagliotti</strong><br>
Absolutely, um, so I think, in the United States, at the moment, I think we’re at a spot where the different states are sort of moving. And in the United States, each state has their own department of education. So they, we are not, they’re not federal standards, they are state standards. And each in a lot of states, those standards are being revised and to include data science standards, and those discussions are moving pretty quickly, with some states already approving, other states implementing this coming fall, for example. And other states that are still in the process of sort of starting that. But it’s, but it’s exciting. The other thing that’s really been happening is trying to understand what the curriculum should what curriculum should look like in K-12, in particular. And the GAISE report, like you mentioned before, has a, lays out a, you know, a nice sort of example of what that should look like at the elementary, middle school and high school levels, and can be used sort of as an anchor point for states looking at what they should be doing. I would say at the university level, at the what we call the 12-16 level in the US, we are pretty good. There are many data science programmes and majors and minors across the United States. And they are quite strong, there’s more and more that pop up. And overall, those majors and minors look pretty similar from university to university, and those students are coming out with very, you know, a good skill set, and they are all finding jobs. As Steve mentioned, the job growth is there. And students are feeling quite prepared when they go to into the job growth. So I think where the university level is, could have been well articulated and well defined at the moment, the K-12 level is still sort of in flux of trying to figure out what should be there. And part of that has to do also with teacher preparation, it’s trying to understand what teachers should have and know in order to teach whatever these data science ideas are that are important for the K-12 level. The GAISE report makes some very, I think, concrete recommendations about what that should be, particularly being anchored in the statistical investigative process or problem solving process and understanding how you can use questioning in that and that being really a skill set that we are trying to promote in K-12 education, that then they use also at the university level if they continue on that way. And then just understanding that there’s different large conceptions of data now. Data are not just numbers, data could be sounds, could be text and whatnot. And these ideas are sort of these data science ideas that we are trying to promote in K-12, as well as at the university level. So I think overall, the landscape is quite good. I mean, we’re moving in these great directions. And I think slowly, we’re getting to some consensus about what that looks like. And we’re seeing that in the states moving forward with different standards.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. And so you mentioned the GAISE report there and that’s the Guidelines for Assessment and Instruction in Statistics Education, and of course that’s something you co-authored with, with Chris Franklin, Chris. Yeah, of course. Yeah. I’d like to bring you into the conversation. Now, Chris. You know, you and I have spoken a number of times over the years about GAISE about statistics, education and statistical literacy and, and the challenges of delivering high quality education in data and statistics at all levels of the curriculum. I wanted to get your impression of what you think the big contributions are that this act will hopefully make towards improvement of the data science education landscape.</p>
<p><strong>Christine Franklin</strong><br>
Well, I was very excited to see this act. And I think one of the big impacts that I see is how it can help our state departments of education actually try to implement standards that we’re seeing put in place right now, in terms of statistics and data science. Teachers, right now, most of our teachers in the US schools, math teachers have not had any formal training in statistics. Or if they have, it’s been maybe one course, they’re very uncomfortable with trying to implement these standards. And it’s just going to require a tremendous amount of professional development. Sounds easy in theory to deliver professional development, but very difficult in practice. And a big part of the difficulty of delivering professional development is funding to, to pay for this. Unfortunately, what I’ve seen is state departments of education will often implement these very nice standards in their curriculum, but then they’ve run out of money, or they don’t have sources of funding to where they can then think about the professional development of the teachers. So it’s not only the professional development of the teachers, but also the curriculum that’s going to support the standards that are put in place. Now, fortunately, ASA, for example, has just a wealth of open source resources that teachers can use. But then how did the teachers know where to get it? How do they know how to implement it in the classroom. So state departments are charged with trying to develop a framework of materials for their teachers. This takes money, this takes expertise. So not only that, but I think this bill can help with funding to allow state departments to do that. But professional development typically has been like week long workshops, day workshops, maybe they go online and do workshops, but really, for professional development to be successful. Teachers need day to day support, which requires funding once again, to provide the resource within schools and school systems to provide more of the day to day support that these teachers need. And I think lastly, one thing that we don’t think a lot about, but I’m hoping this bill will help, is the assessment that goes along with the curriculum that we’re implementing for statistics and data science. Once again, that takes funding that takes manpower support. And I’m really hoping that this bill can be a source that that our state DoE’s can turn to make their standards more successful with implementation.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, Chris, when you were speaking there about providing professional development support for the teachers, it reminded me of when I was a primary school governor here in the UK a few months back, a few years back, sorry. And we would always talk about math education, trying to improve math education, and that I think, the teacher confidence to deliver the math curriculum is always the issue that we run up against. So having support, having resources, having people that can go in and help, that changes the dynamic, I think, for teachers and certainly equips them to, to deliver on, you know, on that vision of, of data science education and statistical literacy for all, which is something that we spoke about before, right?</p>
<p><strong>Christine Franklin</strong><br>
That’s exactly right.</p>
<p><strong>Brian Tarran</strong><br>
That’s, that’s your vision for where we get to as a society?</p>
<p><strong>Christine Franklin</strong><br>
Well, I think one thing, one other thing we need to remember, it’s not just the teachers that need our support. It’s also the teacher educators that are preparing our school level teachers. And we, we need to keep that at the top of the list of priorities because most of our teacher educators recognise that our school level teachers need this support, but they are in a similar situation to where they don’t know exactly what they need to do. And so we’ve got kind of two big spots here that we need to work on for professional development, and it’s gonna take a lot of time and effort.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, well, we’ll come back to that later, if you don’t mind. Zarek, did you want to come in? It looked like you was about to chime in.</p>
<p><strong>Zarek Drozda</strong><br>
Yeah, I was just, I wanted to agree with Chris and second it and expand it because I think it’s professional development for teacher educators and every layer above that, right. It’s every layer above the teachers: teacher educators, it’s the district staff who are implementing and creating these programmes, it’s the state staff we’re creating the standards, it’s state policy makers, it’s federal policymakers – like, you could think about professional development for all those stakeholders. And we know we need to build, you know, better education, right, for every one of those groups that are above the individual educator in a classroom, knowing that the national infrastructure is just supporting the teacher in the individual classroom to do this best at the end of the day. So yeah, we think about that in terms of a, there’s a whole system that needs to move here.</p>
<p><strong>Brian Tarran</strong><br>
I think that’s an important point to note, I think, because I go back to that digital skills workshop I was at and one of the questions that came up from from the chair was, you know, what one thing can I take back to the Secretary of State to say we need to add this to the curriculum, but it’s not one thing is it? It’s, it’s it’s a whole system, as you say, Zarek. I did want to ask you a bit about the organisation that you’re a part of, you have a coalition called Data Science 4 Everyone. To what extent was you involved in the kind of shaping of this, of this bill? And, you know, you obviously, you’ve obviously welcomed it, and you’re excited about the potential, and how much work do you see as being left to do to, to kind of get it over the line and get it into application?</p>
<p><strong>Zarek Drozda</strong><br>
Sure, well, just a very quick background on DS4E. We’re a national initiative and a coalition as you said, based at the University of Chicago here in the States. We’ve been putting together a community of education researchers and K-12, system leaders to advance policy and advance awareness and advance the case making right for why data science and data literacy and statistical acumen is so important in this day and age. And we’re really working across the K-12 system, which is very decentralised in the US, to try to forward those goals. Yeah, as I think about next steps and what’s needed, again, just re-double what Chris said, we need more funding. We did some, to give you an example. So when computer science was being built out as a new school subject in the States, they spent somewhere in the range of three to $4 billion over 15 years to build an entirely new school subject. We’re not necessarily doing that here, right? We’re not necessarily building out a whole new school subject, I think we’re really, at least our group has been much more focused on how can we integrate and upskill teachers in K-12 math, or K-12 science or K-12 social studies, right, and integrate these concepts into the existing K-12 ecosystem, working with the different subject societies. But, you know, this bill is a first really great milestone, but we know now we’re going to have to call on state legislators to pass appropriations at the state level to fund teacher support locally, we’re going to have to, you know, call on schools and districts, right, to help give teachers time to be able to implement these classroom experiences. And we’re going to need more research. Right. So this bill calls for grant programmes to state and local partners to create. But I think we also need more funding for NSF and IES, the two kind of education research bodies in the US at the national level, to fund things like student assessments, or to fund accommodations for students with disabilities to be able access to technology for data science software. There’s a lot more R&amp;D work that also has to happen to bring down the adoption costs over time for doing this type of work and making sure that every student regardless of their background, can benefit from the skill areas, and you know, upskilling in this space. And I think the last thing I would say is that we know we also need to work on teacher confidence, right? I think it’s both teacher confidence with statistics, right, and probabilistic thinking. And it’s also the the confidence of the technology, which is brand new, right? Most classrooms in the US have not been using spreadsheets, even though most workplaces do, let alone, you know, R, Python, SQL, any of the more kind of modern computational tools that are used in modern day statistics. And so we have a lot of work on that front to do as well.</p>
<p><strong>Brian Tarran</strong><br>
Okay. And so, if I’ve understood it correctly, there’s about $50 million over five years that is being asked for in this bill. But that’s, from what you’re saying, am I correct in thinking that’s just a kind of a small part of what’s needed to completely deliver on your goals?</p>
<p><strong>Zarek Drozda</strong><br>
It is a first step. An important one, but a first step.</p>
<p><strong>Brian Tarran</strong><br>
So, longer term, is it– Do you head towards the billions territory, like in the computer science space? Or is it a little less demanding of finances and resources and that, do you think? I know it’s hard to say, to pin these things down, but–</p>
<p><strong>Zarek Drozda</strong><br>
At least from my angle, I’d love the group to jump in here, it’s probably a little bit less demanding. But we know that in aggregate between federal, state, private and local funding, we’re going to have to create the necessary resources to make sure that our K-12 public education system can prepare students for a world that’s changing super fast, and the K-12 system moves super slow, right, in how it adapts to new content. And so really it’s both about, you know, what can we do to upskill data science, data literacy skills. It’s also about how do we help the system just adapt faster as new technology comes out and, you know, leverage the importance of data in that.</p>
<p><strong>Steve Pierson</strong><br>
And Brian, I can jump in a little bit on the price tag, which, when we were shopping around this bill, we didn’t actually include like a cost per year for this, because we know that that can be a very sensitive topic, and we were, we really wanted to have bipartisan introduction. So, and we were fortunate to get it right. But it was the offices who have agreed to kind of consider us that came up with the $10 million. And I’m, you know, I know for a fact that, you know, a few of the offices, at least one of the offices did want significantly more, but this was how we were gonna get bipartisan introduction.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. Okay. And on that point, that bipartisan nature of the bill’s introduction, does that give you as a group hope that it will eventually make it through Congress and become a law, and that there’ll be these resources made available?</p>
<p><strong>Steve Pierson</strong><br>
Yeah, absolutely. And I’ll also just say, Brian, that I think we’ve spoken to some 50 or 60 offices, both on the Senate side and the House side. And this is, it’s received really well, we don’t get any pushback on that, you know, yes, there is a need for greater data literacy. Here stateside, I’ve been saying it’s kind of like advocating for apple pie. Right. This is, people get it and they resonate. And to that point, we only brought this to Representative Stevens, I think it was maybe late October. But they really wanted to move on this, they wanted to wait for the new Congress for bandwidth issues. But, significantly, we’re told that the representative wanted this to be her first bill introduced of the new Congress, and she had many to choose from. So I think that’s really positive. The other thing is, I’ve heard from email, we haven’t had a chance to debrief with the staff yet, because they’re swamped with all kinds of things, but they’re getting a lot of positive feedback from people about this bill. So it really seems to be kind of tapping a nerve. A recognition.</p>
<p><strong>Zarek Drozda</strong><br>
I was just going to add to Steve that when we went– So in advance of that legislation being introduced, we had 15 of the largest math and science and technology education associations supporting the legislation, which was a huge win. It showed, I think, that this data science, data literacy, education is really a collaborative multi-subject effort in the States, which does not happen often, it’s usually very siloed. And I think the other thing I’d say is, in the first 24 hours since the bill was introduced, we had 150-160 additional education leaders and organisations sign on to the letter of support that we were helping circulate between Data Science 4 Everyone and the American Statistical Association. And just to re-emphasise that we saw a lot of energy around this, and bipartisan, right. We’re building support on both sides of the aisle, because it’s, you know, this is apple pie, it’s so evident that every student’s going to need this for the next decade.</p>
<p><strong>Brian Tarran</strong> I like this. So data was once the new oil, but now data science education is the new apple pie. I think this is this is great. Anna, you know, assuming that the Data Science and Literacy Act goes through, funds are made available, this work starts in earnest, what sort of timescales are we looking at, do you think, before we start to see the real world impact, you know, in terms of teacher training, student outcomes, and then eventually, obviously, building this workforce, that is so needed, that is equipped with data literacy and data science skills?</p>
<p><strong>Anna Bargagliotti</strong><br>
Yeah, I think I kind of want to say two things to this point. I think post K-12, the college level, we are seeing those outcomes, and they are great. And I think we are really, that is, it feels very good. It feels like we’ve targeted the right things. It feels that students report back that they’re excelling in their jobs and doing great things. So I think that part is sort of, is taken care of. I think at the K-12 level, what’s harder is we’re less nimble. Like Zarek mentioned, K-12 is just a beast to move. It’s very difficult. And we’re in a situation where the target of data science changes every day, truly every day, for two real reasons. One is because the conceptualization of data changes every day. We can imagine today we think of data as text, but in probably a month, there’s some other type of data that we haven’t thought of that will emerge. And so now all of a sudden, you’ve got, you’re trying to teach pillars or concepts in K-12 that are actually a moving target. And then the other big thing that changes pretty much every day is our capabilities for wrangling, visualising access to data, all that stuff is changing. And so at the university level, you’re much more nimble because you’re in these courseworks, and your students are very advanced, and you can kind of move within those, those spaces, and you can change a course at a time. At the K-12 level we’re much more prescribed and harder to move. So I think in terms of timeframe, I think if we focus on the sort of large concepts and the baseline skill sets that we want to graduate students from K-12, I think we can move much quicker than getting into sort of the nitty gritty of a student needs to be able to programme per se, or something like that, like I think more that statistical investigative process, and those questioning, those types of ideas are really the crux of what K-12 looks like that then allows the university level to be more nimble. So for me, the timeframe is I think we have to, we have to think about it differently as we’re never going to arrive. It’s not going to be like, Oh, in five years, this is completed. It’s a, are we reacting in the right way? Or are we sort of ahead of the game. And I think we can get ahead of the game if we go to the concepts and that idea instead of thinking of topics that we’re teaching. And I hope that with this, I have great hope for this bill. I think it’s like everybody said that this is just such a great first drop in the bucket with the apple pie that I think hopefully in the next few years, the states are going to have been moved and then everybody will be doing some type of data science at the state level. And then it’s like Chris mentioned, before moving the professional development, which is a big challenge.</p>
<p><strong>Brian Tarran</strong><br>
When you were speaking, just there, Anna, and you were you were talking about the difference between you what you’re achieving at the college level versus the younger level, it made me think that, you know, this isn’t just about providing a next generation of data science workers, right, it’s about equipping everyone with the skills to be able to exist in a data science world. And this goes to the point that I think Chris and I have spoke about before, right, about being able to be, when you’re confronted with data, being able to ask the right questions about that data. And so I think obviously, that’s, to me, that’s where I think maybe the Guidelines for Assessment and Instruction in Statistics Education seems a promising first step in the development of a data science, data literacy, statistics curricula, do you see that that needing to be – obviously these things are always needing to be revised, right – but do you see that, Chris, as a kind of foundation on which the states can start to build and to move towards this vision that’s laid down in the act?</p>
<p><strong>Christine Franklin</strong><br>
Well, most definitely. And we’ve been real fortunate in the US here that our states right now that are trying to implement more statistics and data science standards, are going to the GAISE II document to use as a guiding document. And ASA has been very fortunate also to where these states, many of them have reached out to us to actually help advise them as they go through the process. I wanted to come in on a follow up with something Anna said in terms of the timeline. As she was speaking, I thought about how when we were sending out our document for review with the GAISE II, the updates, and we sent it out to probably about 20 to 25 different reviewers, we received more feedback than we knew what to do with. But many of the reviewers, very well respected people in the field, came back to us and said, we were being way too ambitious with the GAISE II document that, in fact, so many states here in the US we’re still back trying to implement the recommendations we made in the 2005 GAISE document. And our response was, we can’t be writing for today. What our goal is, is to try to write a document to where 5, 10 years from now, this is where we hope that our K through 12 system will be. And I’ve noticed this in working with other national documents, that I think the tendency oftentimes is to try to write a document for where we are now. And I think that we always need to, in terms of a timeline, think about 10 years down the road when we wrote the document. And it’s hard to be visionary. But as Anna was saying, things are changing so quickly. I mean, the GAISE II document, I think the writers are all saying, oh, we should have included this, we should have included that. Because since its publication in 2020, we’re already seeing needed changes. So I think we’re always going to be catching up to some degree. But as Anna said, I think the goal of these documents needs to be conceptual understanding, it needs to be that role of questioning. I like to say, I just want people to be healthy sceptics to where when they see statistical information, they see data, they immediately start asking questions. They may not know the answers, or know what the answers aresupposed to be, but at least they’re questioning.</p>
<p><strong>Anna Bargagliotti</strong><br>
And I’ll just add one really quick thing, Brian, if that’s okay. Chris and I are about to embark on another ASA initiative, which is the revision of the SET report, which is the Statistics Education for Teachers report that the last publication was, oh my gosh, Chris, I can’t remember even the date–</p>
<p><strong>Christine Franklin</strong><br>
2015.</p>
<p><strong>Anna Bargagliotti</strong><br>
2015. And the the idea of the new report that we will be starting to write this year, along with some wonderful colleagues, is going to be to talk about the teacher preparation aspect of that in light of everything that’s happened with statistics and data science in particular, what should that look like? And how, how could that be? So I just wanted to add that.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. I also wanted to ask, again, maybe this is a question for Zarek. If we’re talking about data science for everyone, what about people like me, who have already already finished their education? I mean, I know you can always learn; every day is an opportunity to learn new things. But, you know, from your coalition’s perspectives, Zarek, what do you want to see happen so that, you know, that we’re not leaving behind big chunks of the population, you know, the older chunks of the population who haven’t had the benefit of going through this education system as it is now, let alone what it might be in five years time, right?</p>
<p><strong>Zarek Drozda</strong><br>
Yeah, Brian, it’s a great question. And I, I just came off a year of serving as a fellow in the US Department of Education. And I had a lot of conversations with the programme officer who is responsible for research, education research and adult education, about that subject. Right. And I think one of the themes that I learned from that work and from that, from those conversations was this idea around fear of technology, as it accelerates. It’s really hard for people to deal with, you know, ChatGPT, DALL-E, AI, neural networks, you know, the list goes like on and on, and it changes every month, as as we’ve discussed here. And I think a big goal from our side is both to build confidence when people are dealing with a deluge of data and a increasing amount of information, right, which we talked about, and it’s also the confidence in the technology tools that are constantly changing. So I think as we think about, you know, a student K-12, we want to get them on a tool, so they can be confident and switch to the next one when it comes out. Because we know that technology integration is just is really critical. And the same thing is true for the adult learners, right, or for the for the folks that are older, there is a wealth of online digital learning, online courses, asynchronous experiences, to learn any coding languages, any programming language, any just software – doesn’t even have to be computation or coding intensive, right, it can just be spreadsheets or, or Tableau or some of the not-too-syntax heavy tools, and there’s so much digital and elearning opportunities for that. If we can build formal exposure into the classroom pathway, and build student confidence to then jump on to those later on. That is really critical. Because if you don’t get an exposure, it’s so hard to take the first step to jump in to the digital training or to you know, go to your employer and say, I want this, you know, this professional development programme, because it’s hard to know where to start. And we also worked on a data literacy training programme for Department of Ed employees while I was there and helping design that experience. You know, for professional or mid career, folks, I think the most important thing was you build confidence and create bitesize first steps to try to like tone down the fear, so people can approach the new world with confidence rather than just responding to it.</p>
<p><strong>Brian Tarran</strong><br>
So I just want to wrap up now, last question for you all, really, maybe if we start with Steve. From a policy perspective, Steve, you know, are there other initiatives on the horizon and things in the pipeline that, you know, people should be watching for in terms of trying to improve data science education across the board in the US, and maybe specifically for the ASA are their areas you’re going to be focusing your efforts and support on.</p>
<p><strong>Steve Pierson</strong><br>
We certainly do want to expand this effort. And we’re trying– In a way, this bill is serving as a way for us to gather that information, because people then know that we’re doing this and they might well hopefully suggest items to, to us. We’ve gotten some I know that, you know, Zarek has a file, I have my own file of what we might want to, how we might want to extend it just with this bill. But yes, we certainly do want to do that. And so for listeners out there that have ideas, please please send them to us. I won’t offer specifics at this point. And I’d love to hear what my colleagues have to say, as well.</p>
<p><strong>Brian Tarran</strong><br>
Does anybody want to jump in on that? Zarek, what’s on your list?</p>
<p><strong>Zarek Drozda</strong><br>
Very short term is just building a Senate version of the legislation, I think, right? We’re going to be working with with the ASA on that, to find champions in that chamber. But then I think I would go back to my call for you know, state legislators need to be thinking about this as well, right, because we know that every state is going to look a little different. We’re in a context right now where locally driven education solutions are going to be really important. And so we’re going to have to build different slightly different flavours of this all around the country. And we’re going to need a lot of work from, I think, state and local champions to fund and help support and build these experiences that are so critical for students across the country.</p>
<p><strong>Brian Tarran</strong><br>
And are there, you know, on the point you mentioned earlier, Zarek, about this news,crossing the pond and reaching me over here in the UK, do you look elsewhere, you know, outside the US and the UK for other good examples of where education systems are starting to integrate data science into the teaching at, you know, the earlier parts of the school curriculum and the school levels.</p>
<p><strong>Anna Bargagliotti</strong><br>
I think Chris can probably jump in even more than me on this one. But definitely in New Zealand. Our colleagues in New Zealand are fantastic. And they’ve been doing K-12 data science and statistics very well for many, many years. And Chris has some very close collaborators. So I’ll hand it over to her to on that. But I thought I’d mention it.</p>
<p><strong>Christine Franklin</strong><br>
Yes, I I think that that’s when you know, when Steve says how can we reach out, I think even beyond policy, a collaboration with international colleagues that have advanced their work in K through 12. I mean, I had the good fortune of having a Fulbright to New Zealand back in 2015. And just the inspiration, the wealth of knowledge that I obtained from there, to bring back to the US with our work here was phenomenal. Plus, we built up collaborations that we are continuing today. We have collaborations with people in the UK, for example, in other countries. I think the other thing I wanted to say besides reaching out internationally is that we as statisticians in the US need to be doing more to help K through 12. And I think about my, you know, my colleagues at the university in the statistics department which I was part of, my colleagues, some of them actually worked with me to reach out to the math educators so that they could try to help with what needed to be done with the preparation of teachers. So I think statisticians need to become more involved, both practising statisticians and academic statisticians, with helping educators at K through 12. And that includes trying to become involved with state departments of education as well, because that’s really where things filter down to the local level in our school districts. So I would like to see somehow a structure put in place to make that happen more. And I’m hoping things such as this bill will bring that awareness to practising statisticians, that this is really important, and you need to become more aware of what’s happening at K through 12, and become involved.</p>
<p><strong>Zarek Drozda</strong><br>
To just add to what Chris is saying, I think it is so important for investment in the K-12. space. And, Brian, I’ll give you a sneak preview of a report that we were collating on international examples of data science and statistics education in K-12, and really serious investments that we’ve seen, I think, and Chris already mentioned, some really great ones that have been long running champions at this internationally. Our recent scan: Israel, their ministry of education is doing a tonne of work for data science, data literacy education. I’ve had so many conversations with them over Zoom. China added a standard semester for big data statistics coding and modelling. And it’s now also in their college entrance exam. There’s examples in Germany, New Zealand, South Korea, Scotland, we’ve we’re continuing to build the list. Frankly, in the UK, right, with core maths, you’re seeing more integration of data and computational thinking into the curricula pathways there. I think in many ways the US is behind, and as we introduce this bill, I think we should be messaging, there’s a economic competition aspect to this, right; that it’ll be really important for the US to make investments in this area to, frankly, catch up to where I think other international peers are.</p>
<p><strong>Brian Tarran</strong><br>
Steve, you wanted to come in on that?</p>
<p><strong>Steve Pierson</strong><br>
I mean, you mentioned like someone coming in mid career, right. And I think that that is really important. But we’ve also kind of been talking about the other ways you can access this, right, in any part of your career, but you can also access data jobs, rural and urban. So we’ve been kind of selling that dimension. But also, you know, just access in terms of diversifying the STEM workforce, we think that’s really important. But it’s also about degree level, right? We did a search for one member of Congress that had a major, I think it was a pharmaceutical in their district. And if you put in data, right, and thousands of jobs pop up for that company. And it’s not just the PhDs, right, it’s more entry level, the people who are what Zarek mentioned in terms of just accreditation, that you can enter a lot of points. But I also want to just make a– point out one part of the bill, which really singles out two-year colleges, which can help the mid career people, the early career people or others, and they face a lot of the same challenges as K through 12. Right, making sure that the instructors are upskilled, that they have a curriculum, but they also need the time to coordinate with their other disciplines that are involved here. They need time to go to that local workforce, what do you need in terms of data science? And for those students that want to go on to a four-year degree, they need to make sure that there’s a smooth pathway for those students. So there are provisions in the bill also for for two year colleges. And those would be my closing comments, Brian.</p>
<p><strong>Brian Tarran</strong><br>
Okay. Anybody else for some closing words? Or should we wrap up on reminding everyone that data science education is the new apple pie?</p>
<p><strong>Anna Bargagliotti</strong><br>
I can close this with something more philosophical, maybe. To me, I think a nice way to think about it or sort of a romantic way to think about it is it’s just data tell our stories, and they reflect what’s happening in our world today, much like art around us in some ways. And a way to think about just data science education is just to think about what we need, what we need our data understanding to be at each point in time in our educational career, or in our lives. And it’s not static, it’s an evolving thing. So you have to move sort of with the data that are being collected.</p>
<p><strong>Brian Tarran</strong><br>
Very good point. Thank you very much, Anna, Steve, Zarek, and Chris, for joining us to talk about the Data Science and Literacy Act. I’m sure there’ll be much more to to follow and update on as this act or bill winds its way through through Congress. So we’ll look forward to hearing more about that in due course. So thank you for joining us today. Thank you to those of you who are watching for joining us. Stay tuned at realworlddatascience.net for more news Q&amp;As.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/03/06/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/03/06/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “US legislators get their data science act together.” Real World Data Science, March 6, 2023. <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/03/06/data-science-act.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Data science education</category>
  <category>Data literacy</category>
  <category>Policy</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/03/06/data-science-act.html</guid>
  <pubDate>Mon, 06 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/03/06/images/andy-feliciotti-isg8AL7-6uk-unsplash.png" medium="image" type="image/png" height="93" width="144"/>
</item>
<item>
  <title>Data science can help close the ‘digital skills’ gap, or so it seems</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/digital-skills.html</link>
  <description><![CDATA[ 




<p>Digital skills. We all need them. Employers say they want them, but there aren’t enough to go around. Supply can’t meet demand, so we’re left with a gap – a digital skills gap. But what are <em>digital skills</em> exactly?</p>
<p>This is a question that was asked repeatedly, in various different constructions, by <a href="https://members.parliament.uk/member/4092/career">Stephen Metcalfe MP</a>, chairing a meeting of the <a href="https://www.scienceinparliament.org.uk/information/about/">Parliamentary and Scientific Committee</a> on Tuesday, February 7. I went along to the meeting as an observer, hoping to hear an answer to that very question.</p>
<p>What I got was several different answers – no single solid definition, but a reasonable sense that boosting data science skills would go a long way towards closing the digital skills gap.</p>
<section id="survey-says" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="survey-says">Survey says…</h2>
<p>The committee meeting was sponsored by the Institution of Engineering and Technology (IET), and the main focus of discussion was the results of IET’s <a href="https://www.theiet.org/impact-society/factfiles/innovation-and-skills-factfiles/iet-skills-survey/skills-for-a-digital-future-survey/">skills for a digital future survey</a>, based on a YouGov poll of 1,235 respondents drawn from engineering employers (defined as “employers who employ at least one engineering and technology employee in the UK”).</p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/images/billetto-editorial-YvLd3xbo0ac-unsplash.jpg" class="img-fluid figure-img" alt="Woman painting while wearing virtual reality headset. Photo by Billetto Editorial on Unsplash." width="500"></p>
<figcaption class="figure-caption">Digital skills, including AI skills, are not only required of engineers, says the IET’s Graham Herries. Generative AI tools like Stable Diffusion threaten to shake-up the creative industries. (Photo by <a href="https://unsplash.com/@billetto?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Billetto Editorial</a> on <a href="https://unsplash.com/photos/YvLd3xbo0ac?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>)</figcaption>
</figure>
</div>
</div></div><p>Kicking off the discussion was Graham Herries, an engineering director and chair of the IET’s Innovation and Skills Panel, who drew attention to the harms that the digital skills gap is reportedly having. Of those respondents who identified skills gaps in their own organisations, 49% pointed to a reduction in productivity, while 35% said skills shortages were restricting company growth.</p>
<p>As the hot topic of the day, <a href="../../../../../../news-and-views/editors-blog/posts/2023/01/27/talking-chatgpt.html">ChatGPT inevitably came up during the discussion</a>. Herries sees it as a disruptive force, and 36% of all respondents believe artificial intelligence (AI) skills will be important for their engineers to have within five years (24% say they are important <em>now</em>). But AI skills are important for non-engineers too, argued Herries, as he pointed to stirrings in the creative industries caused by generative art tools such as <a href="https://stability.ai/blog/stable-diffusion-public-release">Stable Diffusion</a>.</p>
<p>Herries therefore puts AI skills under the broad umbrella of “digital skills”. But, to him, it’s not enough to simply be able to use AI technology; rather, users should know enough to be able to ask the right questions about the provenance of the data used to train the AI, its quality and biases, etc. This was a point developed further by Yvonne Baker, an engineer and the CEO of STEM Learning. Baker talked about digital skills as being both the ability to use digital technology and also to understand its limitations. Yet another perspective was offered by Rab Scott, director of industrial digitalisation at the University of Sheffield’s Advanced Manufacturing Research Centre. Scott defined digital skills in the context of <a href="https://rss.onlinelibrary.wiley.com/doi/10.1111/1740-9713.01523">quality control systems in industry 4.0</a>: it’s about knowing how and where to place a sensor to collect data about the manufacturing process, to feed that data into a data collection system, analyse the data for insights, and use those insights to inform decision-making.</p>
</section>
<section id="closing-the-gap" class="level2">
<h2 class="anchored" data-anchor-id="closing-the-gap">Closing the gap</h2>
<p>Further definitions of “digital skills” are to be found in the <a href="https://www.theiet.org/impact-society/factfiles/innovation-and-skills-factfiles/iet-skills-survey/skills-for-a-digital-future-survey/">IET’s published report</a>. Survey respondents were encouraged to describe the term in their own words, so we see things like:</p>
<ul>
<li><p>“the ability to understand, process and analyse data.”</p></li>
<li><p>“Coding, programming, software design, use of social media for marketing and communicating with stakeholders, data visualisation, work that relies solely on the use [of] online systems.”</p></li>
</ul>
<p>When respondents were asked what skills were lacking in both the external labour market and their internal workforce, around a fifth cited “more complex numerical/statistical skills and understanding”. And when looking to the future and to the skills anticipated to be important areas for growth in the next five years, 39% of respondents picked “data analytics” while 31% said “artificial intelligence and machine learning”.</p>
<p>So, perhaps you now understand why I left the meeting with the feeling that more data science skills, more data science training, could help address the shortfall in “digital skills”.</p>
<p>But how exactly can we equip more people with the right skills? At one point during the discussion, Metcalfe told the meeting that he was still looking for a key takeaway, something he could take to the Secretary of State and say, ‘This is what we need to embed in the curriculum’. What was offered instead was a range of possible solutions.</p>
<p>The IET survey found broad backing for government support for reskilling: 40% of respondents favoured grants or loans for training (and retraining) programmes, 39% would like more funding for apprenticeships, while 33% think there should be better carers advice and guidance in schools and colleges.</p>
<p>Baker also made the case for digital skills to be taught in schools as part of every subject, not just in computer science lessons, and that teachers would need to be supported to deliver this.</p>
<p>But how would <em>you</em> close the “digital skills” gap, if given the chance?</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Have you got news for us?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Is there a recent data science story you’d like our team to discuss? Do you have your own thoughts to share on a hot topic, or a burning question to put to the community? If so, either comment below or <a href="../../../../../../contact.html">contact us</a>.</p>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Data science can help close the ‘digital skills’ gap, or so it seems.” Real World Data Science, February 14, 2023. <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/02/14/digital-skills.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Skills</category>
  <category>Training</category>
  <category>AI</category>
  <category>Machine learning</category>
  <category>Data analytics</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/digital-skills.html</guid>
  <pubDate>Tue, 14 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/images/billetto-editorial-YvLd3xbo0ac-unsplash.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Why open science is ‘just good science in a digital era’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/02/03/heidi-seibold.html</link>
  <description><![CDATA[ 




<p>Years are often dedicated to different causes and aims by different organisations. The United Nations, for example, has designated 2023 the <a href="https://www.undocs.org/en/A/RES/77/32">International Year of Dialogue as a Guarantee of Peace</a>, while for the European Commission it is the <a href="https://ec.europa.eu/commission/presscorner/detail/en/ip_22_6086">European Year of Skills</a>. But over at the White House Office of Science and Technology Policy, 2023 has been declared the <a href="https://www.whitehouse.gov/ostp/news-updates/2023/01/11/fact-sheet-biden-harris-administration-announces-new-actions-to-advance-open-and-equitable-research/">Year of Open Science</a>.</p>
<p>To discuss what this means for science generally and data science in particular, Real World Data Science invited <a href="https://heidiseibold.com/">Heidi Seibold</a> for an interview. Seibold is a statistician and data scientist, and also an open science trainer and consultant, and we talked about how she became involved in open science, what it means to her, the benefits of it, and how academic and industry researchers can move towards it.</p>
<p>Check out our full conversation below or on <a href="https://youtu.be/GD2g7cJ_yE4">YouTube</a>.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/GD2g7cJ_yE4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="timestamps" class="level2">
<h2 class="anchored" data-anchor-id="timestamps">Timestamps</h2>
<ul>
<li>How did Heidi become interested in open science? (<a href="https://youtu.be/GD2g7cJ_yE4?t=106">1:46</a>)</li>
<li>What does open data science mean to Heidi? (<a href="https://youtu.be/GD2g7cJ_yE4?t=470">7:50</a>)</li>
<li>Working with PhD students on open science (<a href="https://youtu.be/GD2g7cJ_yE4?t=720">12:00</a>)</li>
<li>How do open data science principles fit into an industry environment? (<a href="https://youtu.be/GD2g7cJ_yE4?t=850">14:10</a>)</li>
<li>Knowledge transfer and public science (<a href="https://youtu.be/GD2g7cJ_yE4?t=1049">17:29</a>)</li>
<li>Year of Open Science initiatives and lasting impacts (<a href="https://youtu.be/GD2g7cJ_yE4?t=1268">21:08</a>)</li>
</ul>
</section>
<section id="quotes" class="level2">
<h2 class="anchored" data-anchor-id="quotes">Quotes</h2>
<p>“Reproducibility [is] just like this minimum standard in research quality, where we say, ‘When we have the same data and the same analysis, we also want to see the same results’, and being able to check that from others is really, really important.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=165">2:45</a>)</p>
<p>“On the back of my wall here in my office I have written, ‘Open science is just good science in a digital era’… Before, we only had the printing press, and we had to print journals in order to distribute the knowledge that we have.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=323">5:23</a>)</p>
<p>“For me, open data science entails the part of the scientific process that focuses on everything that happens on the computer: the data processing and the data analysis, and then getting from the data analysis – getting the results and the knowledge, really – in sort of a pipeline where you go from one step to the next. And so the image that I have in my head, when I think about open data science, is of a pipeline.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=616">10:16</a>)</p>
<p>“Nobody’s perfect from the beginning. And open science and reproducible research is really hard, and it requires a lot of technical knowledge. And I always feel like people are so scared, because on one hand, they don’t know how to do it yet, and the goal is so far away. And so I always like [to say], you don’t have to be perfect right away; going one step into the right direction is super important.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=754">12:34</a>)</p>
<p>“If we think of companies, for example, like Microsoft – they put a lot of money right now into open source: they bought GitHub, they publish open source software, they put money into open source software projects like R, for example. So, somehow, this must be a good way of making profits.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=909">15:09</a>)</p>
<p>“[Open science for the public has value because] we don’t know what ideas people will have. There’s so many skilled people out there that probably will do amazing things… We have this with the software Stable Diffusion right now. That’s an AI that generates images from text, and it runs on my computer here. And I don’t need AI skills to be able to do that. And people are building such incredible images out of this, and it’s really fun to see.” (<a href="https://youtu.be/GD2g7cJ_yE4?t=1130">18:50</a>)</p>
</section>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to another Real World Data Science interview. I’m Brian Tarran. And today I’m joined by Heidi Seibold, a statistician and data scientist. I invited Heidi along to speak about open science, what it means, the benefits of it, and how to move towards it. So welcome, Heidi, how are you?</p>
<p><strong>Heidi Seibold</strong><br>
Hello, thanks for having me. I’m good.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Excellent. Well, Heidi, I contacted you because, you know, I know you have a real deep interest in open science. And the conversation I think was really motivated by the White House Office of Science and Technology Policy declaring 2023 to be the year of open science. So first off, I wanted to get your reaction to that announcement.</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, I think in general, that’s a really cool thing for open science to happen. Right? We, there’s this movement that’s been going on for a while, and people have been doing these grassroots communities and growing open science from the bottom up. And now we see more and more also top down decisions, which I think is a very good sign for, yeah, quality of science, really.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, definitely. So I mean, we’ll get into some of the details of the initiatives a little later, maybe, but I thought that maybe we could kick off by asking you what you thought of the official definition of open science that the US government has come up with, and, and for the benefit of people watching that’s, in quotes, the principle and practice of making research products and processes available to all while respecting diverse cultures, maintaining security and privacy and fostering collaborations, reproducibility and equity. So as definitions go, does that, you know, does that hit the mark, for you, do you think?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, I think given that this is a federal definition, right, from the US. And they have to like, yeah, take so many opinions into account, I think it’s a great definition. I also asked like on social media, what people thought about it, and I think the response generally was pretty good. What I liked especially is that they focus on collaboration, reproducibility, and equity, which aligns very much with how I personally see open science. So collaboration means like, I always think of the term like building on the shoulders of giants, right. So this is what we want to do in research, we want to build on the work of others. They might be like famous people, but they might also be our colleagues next door. And it’s so important to take that into focus. And also reproducibility, just like this minimum standard in research quality, where we say, when we have the same data and the same analysis, we also want to see the same results, and being able to check that from others is really, really important. And so I think, this focus, I personally like it a lot.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Excellent. So can you tell me a little bit about your background and how you became interested, and I think committed to open science would be a great way of describing it, right?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, so I’m a trained statistician, I studied statistics. And then how did I get into this whole open science thing was, for me, really through reproducible research. So my first research project was during my master’s programme, and we wrote a paper and it was a very computationally complex project, and we had lots of files and folders, and, you know, scripts and stuff like this. And then, at some point, it just all got so messy. And I felt like, oh, no, I’m the worst scientist in the world. And then I told my colleague who I was working with on this project. And he was like, No, this is normal. And I was like, No, this can’t be normal. I want to be on top of things when I do research. And I want to be sure that, like, the code that I’m using for this is the correct code that I actually wanted to use, right. So that must be like a minimum standard that we have. And so through that, I learned about reproducible research and good coding practices. And then I also thought more and more about like, well, if I do all this, I should also publish it so that others can actually check that I’m good doing good work here. Right. And so through that I got more and more into open science and really always felt like that’s the right thing to do, especially if you’re funded through public money.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah. Can I ask you what you think is kind of driving the shift to open science because the way you’ve described open science to me just there, you know, that sounds like to me like, just good scientific practice, and the fact that it’s not something that’s been done before, I wonder whether is it a cultural change, a philosophical change, a technological development, that’s kind of spurring this shift?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah. So that’s a really, really good and deep question. So on the back of my wall here in my office, I have written open science is just good science in a digital era. And I think that describes the answer to your question pretty well. So there was a technological change, right? Before, we only had the printing press. And we had to print journals in order to distribute the knowledge that we have. And of course, that costs money. So journals cost money historically. But now, journal costs are really super low, because nobody needs them printed anyhow. And you only ever want to read like one or two articles out of one issue. So it doesn’t really make sense anymore, right. And also publishing data and code. It’s just like, the cost is so so low, that now in this digital age of the internet, really, we have such a low burden of, of doing the right thing. But on the other hand, we need to make this social shift, because we’ve been always, like, researchers have always done it a certain way. And there are especially certain fields that are really into, like, they feel like this is my data. This is my code. This is my research. Why should I share it? But I feel like the young generation of researchers are like, well, because it’s the right thing to do. And the reason why we’re in research is because we want to have scientific progress and scientific progress comes when we can build upon each other’s work.</p>
<p><strong>Brian Tarran</strong><br>
Of course, and you mentioned, obviously, journal publications, but I wonder to what extent is it that the scale of science has almost kind of outgrown the ability to kind of condense it all down into a, even if it’s a 20 or 30 page, academic paper, right? Because it’s not just about, you know, setting out the research question describing the methods, you know, presenting a table of the data, all that stuff can’t be published now, or it can be, but it can’t be fit within the framework of an academic paper, it has to be on a GitHub repository or in a Jupyter notebook or something like that. So kind of open science encourages us to, to think about distributing that knowledge in different ways.</p>
<p><strong>Heidi Seibold</strong><br>
I think that’s completely true. So, research now is so much more complex than it used to be right. There used to be single researchers who did like, yeah, such breakthroughs within one paper. And now, we already have so much knowledge, and the questions are so much more detailed and complicated. And also the data is so much more and the things that we can do is so much more complex. And so I feel like one paper doesn’t– isn’t enough to describe the research that we’re doing. And we did this one project with, with a group of students, actually, where we took 11 papers that were related to the topic that we were teaching about. And we took these 11 papers and data was available for the papers. And so we thought, well, we try to reproduce the results that they have there. And we found that it is really hard if we don’t have the code, because the method section in papers is really super short, right? It’s a super short section, if it’s not like a statistics paper. And it’s impossible to describe all the intricate steps that you took from the data to the complex model and analysis that you did. It’s just not enough space within the paper. And the code is the perfect description of what you did, right? So why not publish it with it, and especially in cases where data privacy is not an issue, then, and you already publish the data, then it just makes so much sense to also publish the code, because the code is not like there’s no privacy issues to that – usually at least.</p>
<p><strong>Brian Tarran</strong><br>
So is there a kind of you know– when we say open data science, you know, what does that look like? And do you have a kind of example or simplified example of what that would look like, right? And how it’s more than just, you know, the finished paper, the product of the science scientific process?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, so for me, open data science entails the process of– the part of the scientific process that focuses on everything that happens on the computer. So the data processing and the data analysis, and then getting from the data analysis, getting the results and the knowledge really, in sort of, yeah, in sort of a pipeline where you go from one step to the next. And so what the image that I have, in my head, when I think about open data science, I really think of a of a pipeline where you stick the different parts of the pipeline together, in a consecutive order. But of course, research projects are really complicated. And the pipeline just looks really messy, in some ways, but if you still manage to organise it in a way that the different bits all fit together, then you can make it so that in the end, you can imagine something that goes from the start to the finish. And you really understand every step of this pipeline every step of the way, from the raw data to the paper.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. So the idea would be that people provide almost like a framework for you to recreate that yourself if you want to either check the results or yeah, replicate, just replicate the process generally. Right? So is your– so your job now is, I guess, as an open science trainer and consultant, so are you the person that goes into organisations and kind of shows them how to build that pipeline? Or how to, you know, map it out and to present that to people?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, so what I do a lot is do workshops and trainings with PhD students. So graduate programmes will ask me to come in for a day, or, also, we do longer trainings, which are often more useful, because people can in between take the steps that I recommend. And then we just, like, work together on ideas and steps that they can actually take. And I think what’s always important there is to know that nobody’s perfect from the beginning. And open science and reproducible research is really hard. And it requires a lot of technical knowledge. And I always feel like people are so scared, because on one hand, they don’t know how to do it yet. And the goal is so far away. And so I always like, you don’t have to be perfect right away, going one step into the right direction is super important. And that also helps with like the social change, because then the question is, well, I do want to do this, but my supervisor doesn’t know the technology, what do I do? And then we always try to find like one step that they can take, rather than trying to be perfect right away.</p>
<p><strong>Brian Tarran</strong><br>
And it’s, I guess, it’s encouraging to see people like you being brought in to work with people on graduate programmes. So you’re, we’re trying to almost train the next generation of scientists to be thinking, open science first, rather than, you know, falling into bad habits or old habits that, you know, we are trying to do away with.</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, and really, the young researchers, my feeling so far has been that the only pushback I get for my work is from established researchers who feel like well, this is the way I did it, and so it has to be the right way. But the younger generation for them, it’s super obvious that this is the way we should go in order to achieve scientific progress and good scientific practice.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah. A lot of data science now is obviously now done within industry. I wondered how open data science or open science principles fit in an environment you know, where competitive advantages is linked to keeping things in house and confidential and not wanting to share too much. Do you see a conflict there or can the two work together?</p>
<p><strong>Heidi Seibold</strong><br>
So I think there’s– first of all, I think, if we, if we get it done in academia, I’d be already super happy, right? If we get it done in the space where we have public funded projects that then are available for the public, I’d be already like super stoked. But in industry, it’s really interesting because a lot of the work that is done in industry is already done pretty well. So we if we think of, for example, companies, for example, like Microsoft, right, they put a lot of money right now into open source, they bought GitHub, they publish open source software, they put money into open source software projects like R, for example, right. So somehow, this must be a good way of making profits as well. And we see lots of companies investing in open source. So why not think about other research products, like data, and so on, also in the same line as we do of open source, because software is just a similar product. And I don’t think that there’s, I mean, there is some software, or some products, where it makes sense to have a patent or a trade secret or something. But sometimes it’s just more profitable, to have something where people can look into it and trust it. And I’d also helps like finding the next coders, and the next researchers to work on these projects, because, well, we like looking into what we’re going to do next. Right. And also, if we look, for example, into pharma industry, there, we see that a lot of the work they’re doing is already pretty good. For example, if we look at clinical trial transparency, pharma is doing better than academia there. And also, they’re pretty good on reproducible research, because they have to stick to certain rules. And when we look on the other side, so industry also benefits from open science, right? Because if we do open science, in academia, and publicly funded projects, then this will help companies make more money, because they have access to more knowledge and maybe interesting ideas as well, that they don’t have right now. So I think this is a win-win situation for companies as well. And I feel like if academia gives more to the industry, then eventually there will be like a mindset change. And industry will also give more back as well.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, I see– I can see that and I guess it’s, you know, knowledge transfer is a big objective of a lot of academic institutions, right, we want our outputs to be of use to wider society, and that includes business and industry, right. So if people can pick those things up, you know, download it off of the web without having to, you know, make one-to-one links with the researchers who’ve done that project, it just it smooths that transition, and that that knowledge transfer becomes a lot more straightforward. You did, you mentioned about, you know, open science is about public science, essentially putting these, when it’s publicly funded research, this data and this work goes into the public space. You know, I’m guessing that, to a large extent, a lot of, you know, regular members of the public aren’t going to be interacting with open science. They’re not going to be downloading the datasets, they’re not going to be rebuilding the pipelines and rerunning the analysis. But do you still see that there’s a value there for the public in that information being there should they need it? And where are the kind of areas of value that you think the public will exploit?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, I think that’s an interesting question. And I think the biggest answer to that is that we don’t, we don’t know what ideas people will have, right? There’s so many skilled people out there, that probably will do amazing things. And we see that over and over again, when we put stuff out there, that people just get the super cool ideas. So we have this with the software Stable Diffusion right now, right? So that’s an AI that generates images from text, and it runs on my computer here. And I don’t need AI skills to be able to do that. And people are building such incredible images out of this. And it’s really fun to see. So I think, yeah, we just don’t know what’s going to happen. And on the other hand, I think, well, I am a researcher, but I’m also the public, right? And so if I have a question about something that concerns my private life or my friends’ private life, then I can also– I do have the skills to go into this and look at some research for example, I don’t know, how to best raise children or whatever. Um, that’s– so I have a friend, she’s an epidemiologist, and she always goes and looks at research on like, how to feed her child best and what to do. There’s, there’s all kinds of questions you have as a mother. And she, as a researcher can just go into the research and figure out, like, what is the best path for me to take. And I think the more we do open science, the more we can also do, like science communication, that adds on to that as well. Right? So if we have her now, she could now help other mothers make the same good decisions as well. And she would be sort of a science communicator for research that isn’t even hers. Um, so that is pretty cool, I think.</p>
<p><strong>Brian Tarran</strong><br>
I think so, and it’s speaks to me of breaking down silos that, and I guess, blurring the lines between our roles, our professional roles and our personal lives, right. It’s about bringing science into that kind of public sphere, so I can see why the benefits would accrue from doing so. Just to wrap up, let’s go back to that year of open science, that was announced by the White House, are there any other specific initiatives in that big long list that constituted the announcement that you’re excited about?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, there is. I think, especially what I really liked was that, yeah, federally funded research, um, needs to be accessible, including the data when possible. So again, there’s open when possible, closed when necessary. But I think this is a very good first step, to say, okay, it depends on the funding, if it’s publicly funded, then it should also be publicly available. And I think that’s a really good sign. And then also, these, the statement had like, mentioned all these open science initiatives in different fields, which I really liked. So for example, from NASA, they have this transform to open science programme, and they’re already super active. And it’s really cool to see what comes out of that. For medicine, they have requirements for data management plans, which I think is a very solid step towards open science in medicine, because they are we have the issue of data privacy. And we really have to think from the get-go of a project about what should we do in terms of best practices of data management and having a requirement on that is, I think, a really, really solid step. And also, I’m thinking about open science in the field of like federal government even, because open data and federal government is a huge topic, right. And it, that’s definitely something that a lot of people will be interested in as well.</p>
<p><strong>Brian Tarran</strong><br>
Last question for you, then Heidi, you know, what would you want the lasting impact of an initiative like this to be? And you know, would you like to see this sort of thing replicated in other countries around the world? If indeed, you know, other countries may already be doing this and have already done this?</p>
<p><strong>Heidi Seibold</strong><br>
I think in general, it’s a very, very good sign that we’re seeing right now. We’ve seen lots of movement, for example, in the Netherlands – Netherlands is really big on open science – and seeing such a big country [the US] that also plays such an important role in the world, doing– taking this step, is a great sign for the entire, like all of research, really. And yeah, I think it’s also nice to see that we’re going from like, Oh, this is a niche topic that only experts are interested in, and people that are like advocates and nerds focus on, to something that really governments are thinking about.</p>
<p><strong>Brian Tarran</strong><br>
So, open science is going mainstream, I think is the message. And let’s hope that it continues to do so. So Heidi, thank you very much for your time today. Where can people find you online, if f they want to find out more about you and your work and your thoughts on open science?</p>
<p><strong>Heidi Seibold</strong><br>
Yeah, thank you so much for having me. It was wonderful. And I always like talking about open science, so people can find me on my website, heidiseibold.com. And I’m also on Mastodon, Twitter, LinkedIn, YouTube, wherever your search for Heidi Seibold, you’ll find me.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Excellent. Well, thank you again. And thank you to those of you who are tuning in today. Make sure to check realworlddatascience.net for more interviews. Take care.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/02/03/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/02/03/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Why open science is ‘just good science in a digital era’.” Real World Data Science, February 3, 2023. <a href="https://realworlddatascience.net/news-and-views/interviews/posts/02/03/heidi-seibold.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Open science</category>
  <category>Reproducible research</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/02/03/heidi-seibold.html</guid>
  <pubDate>Fri, 03 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/02/03/images/heidi-seibold.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>ChatGPT can hold a conversation, but lacks knowledge representation and original sources for verification</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/27/talking-chatgpt.html</link>
  <description><![CDATA[ 




<p>ChatGPT is, right now, the world’s most popular - and controversial - chatbot. Users have been both wowed by its capabilities<sup>1</sup> and concerned by the confident-sounding nonsense it can produce.</p>
<p>But perhaps what impresses most is the way it is able to sustain a conversation. <a href="../../../../../../news-and-views/editors-blog/posts/2022-11-23-LLMs-content-warning/LLM-content-warning.html">When I interviewed our editorial board member Detlef Nauck about large language models (LLMs)</a>, back in November, he said:</p>
<blockquote class="blockquote">
<p>… if you use these systems for dialogues, then you have to script the dialogue. They don’t sustain a dialogue by themselves. You create a dialogue tree, and what they do is they parse the text that comes from the user and then generate a response to it. And the response is then guided by the dialogue tree. But this is quite brittle; it can break. If you run out of dialogue tree, you need to pass the conversation over to a person. Systems like Siri and Alexa are like that, right? They break very quickly. So, you want these systems to be able to sustain conversations based on the correct context.</p>
</blockquote>
<p>Fast-forward a couple of months and, as discussed in our follow-up interview below, OpenAI, the makers of ChatGPT, have succeeded in building a question answering system that can sustain a dialogue. As Nauck says: “I have not yet seen an example where [ChatGPT] lost track of the conversation… It seems to have quite a long memory, and doing quite well in this.”</p>
<p>There are still major challenges to overcome, says Nauck - not least the fact that ChatGPT has no way to verify the accuracy or correctness of its outputs. But, if it <em>can</em> be linked to original sources, new types of search engines could follow.</p>
<p>Check out the full conversation below or on <a href="https://www.youtube.com/watch?v=AWxfSmcgPbo">YouTube</a>.</p>
<p>Detlef Nauck is a member of the <a href="../../../../../../news-and-views/editors-blog/posts/2022-10-18-meet-the-team/meet-the-team.html">Real World Data Science editorial board</a> and head of AI and data science research for BT’s Applied Research Division.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/AWxfSmcgPbo" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="timestamps" class="level2">
<h2 class="anchored" data-anchor-id="timestamps">Timestamps</h2>
<ul>
<li>How ChatGPT was built and trained (<a href="https://youtu.be/AWxfSmcgPbo?t=41">0:41</a>)</li>
<li>ChatGPT’s major advance (<a href="https://youtu.be/AWxfSmcgPbo?t=185">3:05</a>)</li>
<li>The big problems with large language models (<a href="https://youtu.be/AWxfSmcgPbo?t=276">4:36</a>)</li>
<li>Search engines and chatbots (<a href="https://youtu.be/AWxfSmcgPbo?t=575">9:35</a>)</li>
<li>Questions for OpenAI and other model builders (<a href="https://youtu.be/AWxfSmcgPbo?t=689">11:29</a>)</li>
</ul>
</section>
<section id="quotes" class="level2">
<h2 class="anchored" data-anchor-id="quotes">Quotes</h2>
<p>“[OpenAI] have achieved quite remarkable capabilities in terms of sustaining conversations, and producing very realistic sounding responses… But sometimes [ChatGPT] makes silly mistakes. Sometimes the mistakes are not that obvious. It can hallucinate content… And it still doesn’t know what it’s talking about. It has no knowledge representation, doesn’t have a word model. And it’s just a statistical language model.” (<a href="https://youtu.be/AWxfSmcgPbo?t=124">2:04</a>)</p>
<p>“These models, they produce an answer, which is based on the kind of texts that they have been trained on. And that can be quite effective. But it cannot yet link back to an original source. So what’s still missing is the step where it says, ‘Okay, this my answer to your question, and here’s some evidence.’ As soon as they have done this, then these kinds of systems will probably replace the search engines that we’re used to.” (<a href="https://youtu.be/AWxfSmcgPbo?t=247">4:07</a>)</p>
<p>“[These large language models are] still too big and too expensive to run… For [use in a] contact centre or similar, what you need is a much smaller model that is restricted in terms of what it can say. It should have knowledge representation, so it gives correct answers. And it doesn’t need to speak 48 languages and be able to produce programming code. It only needs to be able to talk about a singular domain, where the information, the knowledge about the domain, has been carefully curated and prepared. And that’s what we’re not seeing yet. Can we build something like this, much smaller, much more restricted, and provably correct, so we can actually use the output?” (<a href="https://youtu.be/AWxfSmcgPbo?t=469">7:49</a>)</p>
<p>“We are seeing communities who don’t necessarily have the technical background to judge the capabilities of these models, but see the opportunities for their own domain and might be acting too fast in adopting them. So the producer of these models has a certain responsibility to make sure that this doesn’t happen.” (<a href="https://youtu.be/AWxfSmcgPbo?t=746">12:26</a>)</p>
</section>
<section id="further-reading" class="level2">
<h2 class="anchored" data-anchor-id="further-reading">Further reading</h2>
<ul>
<li><a href="https://philadelphiaphysicist.wordpress.com/2023/01/13/chatgpt-the-robot-the-myth-the-legend/">ChatGPT: The Robot, the Myth, the Legend</a> - Philadelphia Physicist blog, January 13, 2023</li>
<li><a href="https://twitter.com/sama/status/1599671496636780546?s=20&amp;t=TbscFaGtn5JFu_dfZDczVg">Cost to run ChatGPT</a> - tweet by OpenAI CEO Sam Altman, December 5, 2022</li>
<li><a href="https://www.cnbc.com/2022/12/13/google-execs-warn-of-reputational-risk-with-chatgbt-like-tool.html">Google execs warn company’s reputation could suffer if it moves too fast on AI-chat technology</a> - CNBC, December 13, 2022</li>
<li><a href="https://www.theguardian.com/technology/2023/jan/05/microsoft-chatgpt-bing-search-engine">Microsoft reportedly to add ChatGPT to Bing search engine</a> - <em>The Guardian</em>, January 5, 2023</li>
<li><a href="https://www.theverge.com/2023/1/17/23558516/ai-art-copyright-stable-diffusion-getty-images-lawsuit">Getty Images is suing the creators of AI art tool Stable Diffusion for scraping its content</a> - The Verge, January 17, 2023</li>
</ul>
</section>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
We’re following up today Detlef on the, I guess, one of the biggest stories in artificial intelligence and data science at the moment, ChatGPT, the chat bot that’s driven by a large language model and is proving endless amounts of– providing endless amounts of either entertainment or concern, depending on what you ask it, and what outputs you get. So, but you’ve been looking at it in some detail, right, ChatGPT. And that’s why I thought we would follow up and have a conversation to see, get your view on it, get your take on it. What’s going on?</p>
<p><strong>Detlef Nauck</strong><br>
Yeah. So, what they have done is, OpenAI have used their large language model GPT-3 and they have trained an instance to basically answer questions and have conversations, where the model remembers what has been said in the conversation. And they have done this by using curated data of question and answers, where they basically have posed a question and said, This is what the answer should be. They trained the system on doing this, then, in the next step, they began use questions, potentially different ones, the system came up with a variety of answers, and then again, human curators would mark which is the best answer. And they would use this data to train what’s called a reward model - so, a separate deep network that learns what kind of answer for a particular question is a good one - and then they would use this reward model to do additional reinforcement learning on the ChatGPT that they had built so far, basically using dialogues and the reward model would then either reward or penalise the response that comes out of the system. And by doing that they have achieved quite remarkable capabilities in terms of sustaining conversations, and producing kind of very realistic sounding kind of responses. Sounds all very convincing. The model presents its responses quite confidently. But sometimes it makes silly mistakes. Sometimes the mistakes are not that obvious. It can hallucinate content. So let’s say you ask it to write you scientific text about whatever topic and put some references in and these references are typically completely fabricated and not real. And it still doesn’t know what it’s talking about. It has no knowledge representation, doesn’t have a word model. And it’s just a statistical language model. So it’s what we would call a sequence to sequence model. It uses an input sequence, which are words, and then guesses what’s the next most likely word in the sequence. And then it continues building these sequences.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. But, do you think the big advance as you see it is the way it’s able to remember or store some knowledge, if you like, of the conversation, because that was something that came out of our first conversation that we had, where you were saying that, you know, if you’re looking at these as a potential chatbots for customer service lines, or whatever it might be, actually, the trees, the conversation trees break down after a while, and they don’t, you know, these models get lost, but actually, they’re able to maintain it a little longer, are they, or– ?</p>
<p><strong>Detlef Nauck</strong><br>
Yeah, I have not yet seen an example where they lost track of the conversation they seem to have, it seems to have quite a long memory, and doing quite well in this. So the main capability here is they have built a question answering system. And that’s kind of the ultimate goal for search engines. So if you put something into Google, essentially, you have a question, show me something that answered this, answers this particular question. Of course, what you want this kind of an original source. And these models, they produce an answer, which is based on the kind of texts that they have been trained on. And that can be quite effective. But it cannot yet link back to an original source. So what’s still missing is the step where it says, Okay, this my answer to your question, and here’s some evidence. Then if, as soon as they have done this, then these kinds of systems will probably replace the search engines that we’re used to.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. The other thing that struck me with them was that the, if you’re asking somebody a question - a human, you know, for instance - you expect a response that and you would hope you will be able to trust that response, especially if it’s someone in an expert position or someone you’re calling, you know, on behalf of a company or something. The fact that - and I asked this question of ChatGPT itself - and the response was, again, you should consult external sources to verify the information that’s been provided by the chatbot. So it’s like, I guess that leaves a question as to what the utility of it is, if you if you’re always having to go elsewhere to verify that information.</p>
<p><strong>Detlef Nauck</strong><br>
Yeah, I mean, that’s the main problem with these models, because they don’t have a knowledge representation. They don’t have a word model, they can’t fall back on facts that are represented as being true and present those. They come up with an answer. But I mean, there has been a lot of kind of pre-prompting going in to ChatGPT. So when you start writing something, the session has already been prompted with a lot of text, telling the model how to behave, what not to say, to avoid certain topics. There are additional moderation APIs running that make sure that you can’t create certain type of responses, which are based on classical text filtering, and topic filtering. So they try to kind of restrict what the model can do to make sure it’s not offensive or inappropriate. But that is limited. So through crafting your requests, intelligently, you can convince it to ignore all of these things and go past it in some instances. So the, it’s not yet perfect, and certainly it’s not authoritative. So you can’t trust the information if you’re not an expert yourself. So at the moment, I’d say these kind of models are really useful for experts who can judge the correctness of the answer. And then what you get this kind of maybe a helpful kind of text representation of something that you would have to write yourself otherwise.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, and certainly conversations I’ve had with people, those who kind of work, maybe in creative industries, are finding them quite intriguing, in terms of things like, you know, maybe trying to come up with some clever tweets or something for a particular purpose, or something I want to try out is getting ChatGPT to write headlines for me, because it’s always my least favourite part of the editing job. So that sort of works. But you know, for you, in your position in the industry, has ChatGPT changed your mind at all about, you know, the way you’re perceiving these models and how they might be used? Or is it is it just kind of a next step along in the process of what you’d expect to see before these can become tools that we use?</p>
<p><strong>Detlef Nauck</strong><br>
Yeah, it’s the next step in the evolution of these models. They’re still too big and too expensive to run, right. So now, it is not quite clear how much it costs OpenAI to run the service that they’re currently running. So you see estimates around millions of dollars per day that they have to spend on running the compute infrastructure to serve all of these questions. And this is not quite clear, the only official piece of information that I’ve seen is in a tweet, where the CEO said, a single question costs in the order of single digit cents, but we have no idea how many questions they serve per day, and therefore how much money they are spending. If you want to run a contact centre, or something like this, it all depends on how much compute need to stand up to be able to respond to hundreds or thousands of questions in parallel. And then obviously, if you can’t trust that the answer is correct, it is of no use. So for making use in the service industry for contact centre or similar, what you need is a much smaller model that is restricted in terms of what it can say, it should have knowledge representation, so it gives correct answers. And it doesn’t need to speak 48 languages and be able to produce programming code, it only needs to be able to talk about a singular domain, where it kind of the information, the knowledge about the domain has been carefully curated and prepared. And that’s what we’re not seeing yet. Can we build something like this, much smaller, much more restricted, and kind of provably correct, so we can actually use the output?</p>
<p><strong>Brian Tarran</strong><br>
Yeah. Can we go back just to the point you mentioned earlier about, you know, the, the potential of like linking these sorts of chatbots up with search engines, you know, like Google? There’s been some conversations and reporting around, you know, what breakthroughs or not Google might have made in this regard. I mean, have you got any perspective on that area of work and how far along that is maybe and what the challenges are to get to that point?</p>
<p><strong>Detlef Nauck</strong><br>
Well, Google has its own large language model, LaMDA. And we have seen an announcement that Microsoft wants to integrate ChatGPT into Bing, their search engine. And, but as I said before, what’s missing is the link to original sources. So you, coming up with a response is nice. But you need to be able to back it up, you need to say, Okay, this is my response, and I’m confident that this is correct, because here are some references. If I compare my response to these references, then they essentially mean the same thing. This is kind of what you need to be able to do. And we haven’t seen this step yet. But I’m certain that the search engine providers are hard at work at doing this because that’s essentially what they want. If you do a search in Google, in some instances, you’ll see a side panel where you get detailed information. Let’s say you ask about what’s the capital of Canada, you get a response, you get the information in more detail, you get links to Wikipedia, where they retrieve content from and present this as the response. And this is done through knowledge graphs. And so if these kinds of knowledge graphs grow together with these kind of large language models, then we will see new types of search engines.</p>
<p><strong>Brian Tarran</strong><br>
Okay. I guess final, my final question for you, Detlef, and there might be other angles that you want to explore. But it’s like, are there questions that, you know, if you if you could sit down with OpenAI to talk about ChatGPT and what they’ve done, and what they plan to do next with it, what are the kinds of things that are bubbling away at the top of your mind?</p>
<p><strong>Detlef Nauck</strong><br>
Well, one thing is controlling the use of these models, right? If you let them loose on the public, with an open API that anybody can use, you will see a proliferation of applications on top of it. If you go on YouTube, and you Google ChatGPT and health, you’ll already find discussions where GPs discuss, Oh, that is the next step of automated doctors that we can use. So they believe that the responses from these systems can be used for genuine medical advice. And that’s clearly a step too far. So we are seeing communities who don’t necessarily have the technical background to judge the capabilities of these models, but see the opportunities for their own domain and might be acting too fast in adopting them. So the producer of these models has a certain responsibility to make sure that this doesn’t happen. And I don’t know how they want to control this. And, so my question at the developers of these models would be how do you handle sustainability, because the trend goes to ever bigger models. So there’s, in some parts of the industry, there’s the belief, if you make them big enough you get artificial general intelligence, which I don’t believe is possible with these models. But this is definitely a trend that pushes the size of the models. The kind of, the idea of having just one model that can speak all the languages, can produce questions, answers, programming code, is obviously appealing. So you don’t want to build many models. Ideally, you have only one. But how is that supposed to work? And how do you embed actual word knowledge and word models into these systems so that you can verify what comes out?</p>
<p><strong>Brian Tarran</strong><br>
Yeah. I mean, the ethical dimension that you mentioned in the first part of your response is an important one, I think, in the sense that– but I guess maybe almost redundant in the sense that it’s already out there; you can’t put ChatGPT back in the box, can we, essentially?</p>
<p><strong>Detlef Nauck</strong><br>
Well, it’s expensive to run so charging enough for access will put a lid on some frivolous use cases, but still, it needs to be controlled better. And you can make a jump to an AI regulation. So far, we only thought about regulating automated decision making, or automated classification. We also have to think about the automatic creation of digital content or automatic creation of software, which is possible through these models or the other generative AI models like diffusers. So how do we handle the creation of artificial content that looks like real content?</p>
<p><strong>Brian Tarran</strong><br>
Yeah. And there’s also I think, something I picked up yesterday, there was reports of a case being filed by, I think, Getty Images against the creators of one of these generative art models because they’re saying, you know, that you’ve used our data or you’ve used our image repositories essentially to train this model and it is now producing, you know, it’s producing its own outputs that’s based on this, and I guess there’s an argument of it being a copyright infringement case. And I think that’ll be quite interesting to watch to see how that does change the conversation around - yeah - fair use of that data that is available. You can find these images publicly, but you have to pay to use them for purposes other than just browsing, I guess. Yeah, it’ll be interesting to watch.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Have you got news for us?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Is there a recent data science story you’d like our team to discuss? Do you have your own thoughts to share on a hot topic, or a burning question to put to the community? If so, either comment below or <a href="../../../../../../contact.html">contact us</a>.</p>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/27/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/27/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “ChatGPT can hold a conversation, but lacks knowledge representation and original sources for verification.” Real World Data Science, January, 27 2023. <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/27/talking-chatgpt.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>I asked ChatGPT to write this article’s headline, for example. I typed in “Can you write a headline for this text:” and then copy/pasted the interview transcript into the dialogue box. It first came up with, “AI Chatbot ChatGPT Proves Capable in Sustaining Conversations but Lacks Knowledge Representation and Original Sources for Verification”. I then asked it to shorten the headline to 10 words. It followed up with, “ChatGPT: Large Language Model-Driven Chatbot Proves Capable But Limited”.↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Machine learning</category>
  <category>Large language models</category>
  <category>AI</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/27/talking-chatgpt.html</guid>
  <pubDate>Fri, 27 Jan 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/27/images/Detlef.png" medium="image" type="image/png" height="156" width="144"/>
</item>
<item>
  <title>How to ‘Escape from Model Land’: an interview with Erica Thompson</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/01/25/erica-thompson.html</link>
  <description><![CDATA[ 




<p>Erica Thompson’s new book, <a href="http://www.ericathompson.co.uk/books/"><em>Escape from Model Land</em></a>, offers a fascinating and important perspective on mathematical models as being not just models of the real world, or real processes or systems, but also “subjective versions of reality” that encode all sorts of assumptions and value judgements.</p>
<p>In this interview with Brian Tarran, editor of Real World Data Science, Thompson talks about the “social element of modelling” and how it manifests, how to counter the subjectivity of individual models with a diversity of models, and whether human-made models are held to the same standards of transparency that are expected of AI-“created” models.</p>
<p>Erica Thompson is a senior policy fellow in the ethics of modelling and simulation at the London School of Economics Data Science Institute.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/RB5CQW8lbEo" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="timestamps" class="level2">
<h2 class="anchored" data-anchor-id="timestamps">Timestamps</h2>
<ul>
<li>What led Erica to write the book, and why now? (<a href="https://youtu.be/RB5CQW8lbEo?t=147">2:27</a>)</li>
<li>Critiquing climate models (<a href="https://youtu.be/RB5CQW8lbEo?t=450">7:30</a>)</li>
<li>Exploring the “social element” of modelling (<a href="https://youtu.be/RB5CQW8lbEo?t=696">11:36</a>)</li>
<li>Countering subjectivity with a diversity of perspectives (<a href="https://youtu.be/RB5CQW8lbEo?t=1211">20:11</a>)</li>
<li>AI models, human-made models, and questions of transparency (<a href="https://youtu.be/RB5CQW8lbEo?t=1554">25:54</a>)</li>
<li>Why write a popular science book about these issues? (<a href="https://youtu.be/RB5CQW8lbEo?t=1811">30:11</a>)</li>
<li>Will the UK Prime Minister’s “maths to 18” proposal help or hinder our <em>Escape from Model Land</em>? (<a href="https://youtu.be/RB5CQW8lbEo?t=2041">34:01</a>)</li>
</ul>
</section>
<section id="quotes" class="level2">
<h2 class="anchored" data-anchor-id="quotes">Quotes</h2>
<p>“Putting things in a mathematical language does tend to make people think that it is truth from on high. And so my book, in some way, goes towards saying actually, these models, obviously we hope that they’re based on facts and they’re based on data that we gather, but they also do have this value judgement content as well” (<a href="https://youtu.be/RB5CQW8lbEo?t=111">1:51</a>)</p>
<p>“It is arbitrary how we choose to model a situation. There are infinitely many different ways that you could choose to simplify reality - this huge, messy, complex thing in front of us, with physical laws that we don’t fully understand and things going on that we can only measure by proxy.” (<a href="https://youtu.be/RB5CQW8lbEo?t=729">12:09</a>)</p>
<p>“The choice of assumption has a very direct result in the model output and in the information and advice that you’re giving to policymakers… [In climate models] maybe we have a cost of however many dollars per tonne of carbon dioxide for nuclear electricity or for renewables. But what kind of price would you put on behaviour change? How many dollars per tonne of CO<sub>2</sub> avoided does it cost to change the behaviour of a population such that they use less energy? If you put it in at $2 per tonne of CO<sub>2</sub>, it would be heavily relied on [as a policy response]; if you put it in at $2,000 per tonne of CO<sub>2</sub>, it’ll never happen.” (<a href="https://youtu.be/RB5CQW8lbEo?t=1002">16:42</a>)</p>
<p>“There needs to be more frank discussion of values and value judgments, and politics and social assumptions within models. And I think we are starting to see that with the pandemic models, particularly because it’s been so high profile. [But] it’s really hard to unpick your own value judgments. It’s easier for somebody with a different perspective to come in and say, ‘Oh, actually, you know, you’ve assumed that. Why did you assume that?’ When we are embedded in a particular culture of modelling, it’s particularly hard to imagine that anything could possibly be done differently.” (<a href="https://youtu.be/RB5CQW8lbEo?t=1640">27:20</a>)</p>
<p>“I think some people maybe read the book and think, ‘Oh, this is just a sort of woke advertisement for diversity’. Well, it’s not; it’s a way of doing the maths better. The whole point is to do the maths better, make better forecasts, understand the future more effectively, and be able to make better decisions based on that information.” (<a href="https://youtu.be/RB5CQW8lbEo?t=2021">33:41</a>)</p>
</section>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using speech-to-text transcription software. It has been only lightly edited to correct mistranscriptions and remove repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to the very first instalment of the Real World Data Science interview series. I’m Brian Tarran, the editor of Real World Data Science, and I’m very pleased to be joined today by Erica Thompson, a senior policy fellow in ethics of modelling and simulation at the London School of Economics Data Science Institute, and the author of a fantastic new book - which I have a copy of here - Escape from Model Land, which is subtitled, How mathematical models can lead us astray and what we can do about it. So hello, Erica, thank you for joining us. I hope 2023 got off to a positive start for you.</p>
<p><strong>Erica Thompson</strong><br>
Yes, it has so far.</p>
<p><strong>Brian Tarran</strong><br>
Good, good. Because the book came out, is it just before Christmas or just after?</p>
<p><strong>Erica Thompson</strong><br>
Yeah, just before Christmas. So I’ve had all sorts of things flooding in saying, Oh, I liked your book, or I hated this bit or no, it’s exciting.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, no, well, it’s, I have to say, I think, I thought it was a genuine– I finished reading it over, over Christmas. And I think it offers a genuinely fascinating and important perspective on mathematical models as being not just I guess, models of the real world, or, you know, real processes or systems, but subjective versions of reality, you know, encoding all sorts of assumptions and value judgments of the people who, who create the models. And I mean, I guess that shouldn’t really come as a surprise, right? But, but is it a point that is often lost in the discussion around models, particularly where decisions might be, like, informed or driven by model outputs?</p>
<p><strong>Erica Thompson</strong><br>
I think it is something that’s easy to miss. I mean, especially because we’re sort of, maybe as mathematicians were used to living in model land and doing things which, which we see as being logical consequences of previous things. And then more generally, the public look to science and mathematics and statistics as being objective arbiters, perhaps, of how things are and how things ought to be. And so, so yes, that that kind of putting things in a mathematical language does tend to make people think that it is truth from on high. And so my book, in some way goes towards saying actually, these models, they are, obviously we hope that they’re based on facts, and they’re based on data that we gather, but they also do have this value, judgement content, as well. And so we need to think about what that is and how we deal with it, and how we sort of express it and how we understand it.</p>
<p><strong>Brian Tarran</strong><br>
Right, yeah.</p>
<p><strong>Erica Thompson</strong><br>
Especially where we’re using those models to inform decision making or public policy, then it becomes particularly important.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah, no, and obviously, your book draws up quite a bit on the Covid-19 pandemic, and how models were used there. But I thought it was interesting, actually, that, you know, in reading the acknowledgments that you– that while the pandemic lent the topic, additional relevance, right, you actually started writing the book before that. So what led you to think now’s the time? What was the tipping point, if you like, of thinking, I want to write this book now?</p>
<p><strong>Erica Thompson</strong><br>
Yeah, okay. Well, that’s an interesting question. I mean, because it builds on the last sort of 10 or 15 years of my work. So I started out doing a PhD in climate physics. And my background before that was maths and physics. And so I was doing a PhD on the physics of North Atlantic storms, looking at how they would change given climate change. And so, obviously, the first thing you do is a literature review. And I started looking at different models and what the what they were saying about what would happen to North Atlantic storms. And what I found there was that there were models saying that the storm tracks would go north, they’d go south, they get stronger, they get weaker, they’d, you know, anything you name it. And interesting, particularly, interestingly, was that they, they had relatively small uncertainty ranges. So they they didn’t agree within their own uncertainty ranges. And that made me think, well, we this isn’t telling me very much about North Atlantic storms. But it’s telling me a great deal about modelling and the way that we do modelling and perhaps we need to start thinking more about how these uncertainty ranges are calculated, what does it mean? What, how can we end up in a situation where we have this level of disagreement between models. And so since then, I’ve been looking at, you know, those kinds of concepts in different areas I’ve been looking at sort of insurance and finance and weather and climate and humanitarian forecasting as well. And, and so in all of those application areas, I found the same questions about uncertainty and how we make inferences from model output to be particularly interesting and how common problems may be solved in different ways as well. So it’s interesting to do the compare and contrast. And so, yeah, then I guess I, I’d been on all these sorts of bitty little projects and thought actually, I’d really like to bring this together into something more coherent, you know, to actually say, look, there’s a, there is a common theme here and we need to be putting it together and drawing conclusions. And we can, we can learn a lot from doing that. And we can share the best practice throughout the sector.</p>
<p><strong>Brian Tarran</strong><br>
When you’re starting down this path of, I guess, looking into the, I guess, the ethics and process of modelling, did it, was there a lot of other work that you identify that you could kind of draw on a lot of other thinking around this area? Or was it kind of under studied, under researched sort of aspect of the literature?</p>
<p><strong>Erica Thompson</strong><br>
I think it’s under studied, I mean, of course, everybody who does some modelling, you know, you, you do your modelling, and then somebody says, Okay, we need to put some error bars on the outputs, and you go back and, and think about how we’re going to put the error bars on the outputs. And probably, I would say, most people doing that realise that it’s much more difficult than they have the time to do or the ability within the scope of whatever project they’re doing. But the aerobars, the uncertainties always ended up being tacked on at the end, you do it after you’ve done all the modelling, there’s less incentive to do it. And there’s less resource to do it than to make the model itself better. And I think that’s a very common story, that people realise that they ought to be doing more, but they just don’t have the time the resource, the ability to go and do that. So then yes, there are there are people, and there are particular areas that I think have taken more time to investigate this. So in physical science hydrology, I’d say in particular, has a very well developed history of thinking about the uncertainties in models, maybe because, you know, they are constantly being challenged by events happening, which were not within the models, you know, you’ve got your flood forecast model, and then something happens, and it goes way beyond what you were expecting. And you you have to go back and say, What does this mean for our modelling process. And other areas have much less well developed considerations of uncertainty. And so that’s where I think actually, we could we could really benefit by sharing good practice across these different application areas, because people have looked in different ways. And, you know, with with different levels of statistical interest, you know, some areas go into the stats, much more, some areas are very philosophical about sort of the conceptual foundations of how we should think about models and how we should think about the range of outputs that we get from models. And so what I’m trying to do is bring those together a bit. Yeah.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, I think you certainly achieve that. It is really interesting, the different, the variety of examples that you present, and the ways you talk around these issues. I did want to focus in particular on climate models, though, because, you know, I was looking around your website, finding a bit more about about you, and I noticed on there that you talk about, you no longer fly to conferences, and that’s in order to kind of reduce your own ecological footprint. So I guess I wanted to ask, you know, when you set about writing a book, and it’s going to be a book that’s kind of critiquing models and the ways that they don’t often agree? Did you have like a nagging concern that, you know, the points you wanted to make about models in general, but climate models in particular, that that would kind of lend fodder to the kind of groups that might want to discredit climate models or downplay the risks? Or, indeed, the reality of climate change?</p>
<p><strong>Erica Thompson</strong><br>
I mean, yes, I did have that worry, I still have that worry. And I, but I hope that my book is clear throughout that, you know, that models are not irrelevant, you know, the answer is not to throw them away. If you come to it from this sort of sceptical position, saying, you know, we need to think more carefully about how we make inferences from models, you could go all the way down the rabbit hole and say, Oh, they’re all terrible, let’s just throw them away. But I think that would be completely unjustified. We have good evidence, sort of from from one end of the spectrum of relatively simple linear models, which are incredibly, wildly successful and form the foundation of modern life and modern technology. And, you know, with that, as a basis, we hope that we can, you know, work from there to find the limit of the knowledge that we can get from these more complex models, which are looking at making predictive statements in more extrapolatory domains where the underlying conditions are changing, and we therefore have less ability to rely on what I call the quantitative route of escape from model land, by challenging with relevant past data. You know, we’re looking at extrapolatory conditions like climate change, or social and economic systems, and therefore, we think that the data that we have, while they may be useful and indicative, are not, we can’t just calibrate with respect to past data and expect that to be enough to warrant performance in the future. And so, so I think that sort of one answer is that we shouldn’t be throwing away the models completely because they are demonstrable useful, and the question is to quantify the limits of what we can say, rather than just get rid of them. And then maybe the slightly more nuanced answer is that actually, if we have less confidence in the models, and our uncertainty ranges are wider, then because in many of these application areas and climate change, in particular, the damage function is convex, you know, we are expecting that as we go further from today’s climate, the consequence will be not just linearly worse, but sort of increasingly worse. And therefore, if you have, if you’re considering, you know, just to have a sketch of a kind of cost benefit analysis on some sort of expected utility from taking action to mitigate carbon emissions, for example, if you have more uncertainty, then your range is wider. And so the, the lack of quantification of the top tail becomes dominant in in the expected utility of the outcome. And therefore, you should be choosing to mitigate more, not less, because of that uncertainty. So, you know, the sceptics, I suppose the climate sceptics would say, oh, there’s a possibility that climate change might not be as bad as we expect, and therefore we shouldn’t bother doing anything. But I would say actually, that argument should be turned on its head, if we have greater uncertainty, that should be a bigger motivating factor to reduce carbon emissions rather than the opposite.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, and I think you make that point quite clearly in the book. And the other point you make is that, I guess, building trust in models is about understanding their limitations. And the quote that I thought was really interesting was about acknowledging the social element of modelling. And I wonder, do you mind explaining what that social element is for people who are watching or listening? And how will that kind of manifests itself in models? Maybe you’ve got like a simple example that you might want to talk to? I don’t know.</p>
<p><strong>Erica Thompson</strong><br>
Yeah, okay. So, I mean, the social element of models is, because it is arbitrary how we choose to model a situation, there are infinitely many different ways that you could choose to simplify reality, this, you know, huge, messy, complex thing in front of us with physical laws that we don’t fully understand and things going on that we can only measure, sort of by proxy, with, you know, with models themselves to make many of our measurements of the system. And so, so you might choose to simplify a system in one way to model it. And I might choose to simplify it in a different way. And you might choose one programming language, and I might choose another and they would implement functions in different ways. And so all of our choices change the way that the model will then look at the end of the day. Now, then you say, okay, but supposing I’m modelling you know, what will happen to a ball when I throw it up in the air? Surely, that’s not a, you know, that has no social content, does it? And I’d say basically, no, it doesn’t really have any social content. It has some social content insofar as you’re deciding that this is what we want to make a model of. But ultimately, you and I would probably come up with very similar models, regardless of our background or our perspective, or our interests, or even our education to a large extent. And so, so those relatively simple linear situations, which I refer to as interpolatory models don’t have very much social content. Now, the ones that I’m particularly interested in and that I talk about in the book are things that are extrapolatory, where we’re interested in situations where we are trying to predict into the future a system where we expect the underlying conditions to be non-stationary, to be changing. So climate change is one example. Social and economic systems would be another example. And when we’re modelling systems like that, we have to be much more careful because we could choose to model them in radically different ways. We could, if you want to model an economic system, you might choose to disaggregate with respect to the social class of different households. And I might choose to make a sort of bulk model of the whole system with a representative household. And you could imagine hundreds of different ways to do these sorts of things. So maybe you think about pandemic models and how you could simplify it into individuals or you could make an agent-based model with, you know, actual agents walking around and infecting each other. Or you could just write some differential equations for how the transfer happens. So you could do it in, again, in many different ways. And the choice of simplification is then much more important, and it will have much larger first order effects on the outputs, and then on the framing of the question, you know. So you decide to model it in a certain way, with a certain kind of mathematics, and that changes the way that you might think about intervening in the system. If you’re presenting your model to a policymaker with the intent of informing them about their policy options, you might, if you have a model which can represent the effects of say, closing schools, or universities on pandemic transmission, then then that becomes a policy option. If you have a model which can’t represent those kinds of interventions, then it’s not a policy option. And similarly, with climate change, one of the examples that I talk about in the book is integrated assessment models of energy and climate. And so these are models which consider the energy system out to say 2100, and they put a price on nuclear electricity and renewables and all the other things that go into the energy system and basically say, how can we achieve our carbon targets at the lowest cost? Now, if you put in, if you choose to put in a certain price for a certain technology or assumptions about how that technology will develop in future, then you get a particular answer. And you put emphasis on certain kinds of policy options. And so that has, the choice of assumption has a very direct result in the model output and in the information and advice that you’re giving to policymakers. And of course, you might choose to put in something like behaviour change. So maybe we have a cost of however many dollars per tonne of carbon dioxide, for nuclear electricity or for renewables. But how much, what kind of price would you put on behaviour change? How many dollars per tonne of CO<sub>2</sub> avoided does it cost to change the behaviour of a population such that they use less energy? Well, that’s not really in the models. And if it was, it would, again, it would be first order because that would be you know, if you put it in at $2 per tonne of CO<sub>2</sub>, it would be heavily relied on, if you put it in at $2,000 per tonne of CO<sub>2</sub>, it’ll never happen. And where you choose to put that in between influences how it looks, and then that influences the pathway that’s projected, and it influences the advice that you give to policymakers.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. You mentioned the example of school closures and stuff when you’re talking about Covid-19. I actually thought that, that one really helped me understand, I guess, and made it clear to me was that, there’s often been that argument about whether the lockdown was the right thing to do given the other impacts, but you actually say that if different types of people were doing the modelling, maybe if it was school aged people, and I guess encoding the impact that that would have had on them, and how much they value say not being able to go out and see their friends, the impacts potentially on mental health and things like that, it does change, I guess, the calculation of what the right intervention is or the right response is.</p>
<p><strong>Erica Thompson</strong><br>
Yeah, exactly. And I think I think we haven’t anywhere near bottomed out all of these impacts of the pandemic, you know, both the health impacts, and also, mental health and economic impacts will be rippling on for a very long time to come. So we, you know, we can’t even now retrospectively look back and say what was the right decision? It’s really not clear, depends how you value the different outputs, the different outcomes of a decision. And yes, we didn’t have economic models of what the impact of lockdown would be. And if we, if those had been available and developed the same kind of mathematical complexity and credibility as the models of infection and transmission we had in those early stages of the pandemic, which had essentially morbidity, mortality, and the, you know, the impact on the NHS, you know, number of hospital beds occupied. Those were the bottom lines, and there was nothing else. And so that was given as an input to the policymakers. Now, that’s, of course not everything that the policymakers rely on, they have to, their role is to weigh up everything else as well. But if we’d had models which contained more information about all of those other impacts, I think it’s quite plausible that we would have seen different kinds of decision making. And then there’s also the communication aspect, that these models were used to communicate and justify and persuade the public of the importance of the actions that were taken. And, you know, I think it’d be hard to disagree that the actions that were taken immediately where necessary, we certainly did need some kind of lockdown straight away. But then the question of exactly what you do thereafter is much more difficult.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah. So in the book, you kind of make the point that it’s somewhat of a fool’s errand to try and make models objective, and they can’t ever really achieve this, you know, principle of scientific objectivity. But that we instead should look to counter subjectivity of individual models with a diversity of models that do encode these different perspectives, like we’ve just been talking about. I wonder, you know, how would you see this working in practice? Or how would you like to see this working in practice?</p>
<p><strong>Erica Thompson</strong><br>
I mean, that’s a difficult question. So it’s, it’s nice to think that, you know, we have these models, and they are unavoidably subjective. Essentially, my view is that the model encapsulates the expert opinion of a particular expert, and it comes laden with their own perspectives, and biases and preconceptions, as well as their expertise and their education and their experience of a subject, you know, which shouldn’t be set aside. So if we are trying to understand a situation, then we want to get as many perspectives as possible. And so in theory, incorporating the widest possible diversity of different backgrounds into modelling and making a multiplicity of different models and trying to see the problem from these different perspectives will help us to understand it better. Now, then the statistician will jump in and say, Aha, can we, you know, can we in some way average those models or use some sort of statistical inference to take those models and put them together and come up with an even better answer? And I would, I would sort of counter that by saying that there’s no reason to believe that our, that a set of models generated as essentially just one set of opinions will be an independent and identically distributed sample from some distribution, underneath which will be an estimator of, of the truth, if that even exists. And so many of the formal statistical methods that we would quite like to apply to an ensemble of models, a large group of models put together aren’t really conceptually valid at all. I mean, that doesn’t stop people doing it. And maybe you get some interesting information from it, but you certainly can’t rely on it as an estimator. So there’s a sort of statistical problem there. And then the other question is your reference class. So, to what extent do you believe that these models are all equally valid or equally plausible? So that then brings the social question back to the forefront. Because then you say, you know, if I believe that, you know, somebody from Imperial College, say, who is the head of an institute for epidemiology, and has many, many years of experience making this kind of model, you know, is an expert and is qualified to create a model and for that to be recognised as a valid expert opinion, who else has got the credibility to do that? How do we define that? You know, what do you call a plausible model? So then it’s a question of the sort of scientific gatekeeping. What kind of qualifications do you expect from somebody or from an institution? What kind of expertise counts as being relevant and valid expertise? Does it have to be mathematical expertise? Can it be lived experience? Can it be, does the model have to be a mathematical model? What kinds of mathematics are appropriate for the situation? If we disagree about assumptions, does that mean that we can’t consider the the two sets of models in the same sort of class of plausible models? Or are we going to start pruning it by saying, I believe your assumptions, and I don’t believe your assumptions? And if so, who gets to do that? Who gets to decide what is plausible and what is not plausible? And what is allowed to enter into this set? Because as soon as we start pruning it, then we make the statistical inference more difficult. You know, if you want to say, if you want to start applying your methods that assume that the models are on, you know, that the models are independent, then you can’t start pruning because then that introduces huge dependencies on your own expert judgement. So it just becomes extremely difficult. And this is where all of then the social questions about expertise and credibility and sort of scientific gatekeeping and how we assign that credibility and trust, trust in science, you know, who has trust in which kinds of models? This is something, this is a theme that we see coming out of climate science and, you know, hopefully less now than maybe 10 years ago. But in the pandemic, of course, we’ve seen it coming right up again with questions about lockdowns, and about vaccination strategies, and all of that sort of thing. Trust in science is really important. And maybe one of my themes is that trust in science actually is first order in the modelling process itself. It’s not something that is sort of added on afterwards, I’m going to go away and make my model and then the question is whether or not you trust it. Actually, trust and expertise and credibility are in the modelling process directly.</p>
<p><strong>Brian Tarran</strong><br>
Do you mind if we segue to talking about artificial intelligence models, or models made by artificial intelligence? Because that’s, I think that touches on a lot of the same issues, right? And I wanted to think about, well, first of all, you say that, obviously, artificial intelligence models made by AI, they’re not objective, even though there’s like, they’re kind of building the models, if you like, those AIs have still been trained by people, been coded by individuals and those personal judgments and assumptions and all that get embedded into the artificial intelligence. But I think, I guess my question for you is, we’re starting, I think, to have a very frank and public debate about AI ethics, and to demand transparency and explainability of things like automated decision making systems. But do you think we’re kind of, are we falling short of holding ourselves as people to the same standards of transparency and being clear about the choices and decisions we make? And also documenting that subjectivity when we’re preparing these sorts of models and these sorts of decision making systems for policymakers to use?</p>
<p><strong>Erica Thompson</strong><br>
Yeah, so I mean, I suppose there are two questions there. And one’s about what we do and one’s about the AI. So for the humans, maybe, yes, I think that there needs to be more frank discussion of values and value judgments and politics and social assumptions within models. And I think we are starting to see that with the pandemic models, particularly because it’s been so high profile. I mean, remembering that actually, it’s really hard to unpick your own value judgments. And it’s easier for somebody with a different perspective to come in and say, Oh, actually, you know, you’ve assumed that, why did you assume that? And, you know, when we are embedded in a particular culture of modelling, it’s particularly hard to imagine that anything could possibly be done differently. And so I think that’s, again, where diversity is really important, because introducing those perspectives will help to challenge dominant strains of thinking which can end up in sort of accidentally, and not deliberately at all, in a form of groupthink. So that’s the humans and then the, with the AI, yes, you know, they inherit their value judgments from their creators. And so, for example, on the statistical side, one might think about the kinds of loss functions that are used to calibrate machine learning programmes, you know, how does the machine decide what is better and what is worse? You know, it is learning to model a situation, but there will be some kind of loss function in there, which it is minimising in order to decide what is the best model. And so, being explicit about that loss function, I think, actually is really interesting, you know, the fact that the model has got written down an explicit loss function which it is minimising means that we can then analyse that and think about what are the value judgments inherent in that choice of loss function, which is something that we don’t have when humans are calibrating a model and they’re twiddling a knob here and a knob there and saying, Oh, does it look realistic? Am I getting the right kind of behaviours, you know, does it match up with the map I have from observations or whatever. And so, having that I think we can then say, what are the implications of writing a loss function in this way? And what are the values that are implied? I mean, even just modelling itself, you know, like choosing to solve a problem with recourse to mathematical modelling is a value judgement and implies a certain kind of solution, doesn’t it? So if we say that we even can come to a decision, that the models input will be relevant and interesting and help us, that is a value judgement.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, and perhaps we could return to that point a bit later, because there was a line again that jumped out in the book about decision makers needing to maybe curb some over enthusiasm for mathematical solutions. You do talk about documenting value judgments as being kind of one of five principles that you set out for mathematical modellers to adopt to support responsible modelling. I think it’s fascinating to me that you’ve used the vehicle of a popular science textbook to speak to this community, and to sort of set out these principles rather than, say, a journal paper or conference presentation. So I wanted to ask, is there a particular strategy to that decision? I mean, I have my own theory on that, but maybe I’ll let you go first.</p>
<p><strong>Erica Thompson</strong><br>
I’d love to hear your theory. I mean, I guess partly because I suppose I’m very interdisciplinary. And I’m, I’m hopping between these different areas, as we were discussing before, so I have sort of a climate science community and statistics and data science and other application areas in humanitarian forecasting, sort of hydrology, geophysics, weather and climate and all the rest of it. And actually, I find it really hard to get these thoughts published in journal form, because I suppose partly because it feels too general for any specific journal. And perhaps it feels too simplistic that, that the reviews I get tend to be either Oh, we’ve heard this all before it’s not new, or this is too radical and this isn’t an appropriate journal for it, you know, that sort of thing. And actually, I kind of got to the point of thinking, Well, you know, do people even read these journals anyway? Actually, maybe really what I need to be doing is trying to provoke a wider discussion about models. And I do tend to get a, you know, a really good response, when I speak at conferences or talk to people about these things. People go yes, yes, you know, this is really important. Actually, this is something I’ve really struggled with, we don’t know how to do it, the uncertainty is always just an add on at the end that doesn’t have enough time allocated for it. But I don’t have the resource to do it, I’m not able to grapple with these questions, because they’re so fundamental and so wide ranging, and it would be really helpful to have more of a sort of walkthrough of how people tackle these questions in different fields. And so, so I’ve been trying to do that. And I felt that the book was a good way to sort of spark the conversation and maybe also get it to some different audiences. So I’ve had people contacting me since the book came out saying, oh, you know, I’m working in, like, asset valuation for disputes between states, really random things, quite different. And they say, actually, your book really struck a chord, and we have difficulties with this in this particular area. And so I’m really hoping that, you know, the book will help me then to find, to bring together people working on these sorts of issues with common themes from really different application areas and try to make some headway on how we can actually go about practically changing modelling practice to make it to make it work better, and assess uncertainty better. So it’s not just– I think some people maybe read the book and think, Oh, this is just a sort of woke advertisement for diversity. Well, it’s not; it’s a way of doing the maths better. The whole point is to do the maths better, make better forecasts, understand the future more effectively, and be able to make better decisions based on that information.</p>
<p><strong>Brian Tarran</strong><br>
Yep, well, that’s not too far away from my theory on why you did it. I thought it was that it’s a great way of getting– if you can get policymakers and the public to read this, right, you can get them to hold modellers to these principles, rather than having it just be something that you kind of talk about within the community and it doesn’t really go outside that, right? It’s a way of people, you know, the next pandemic or whatever it might be, the next time a model is the focus of a debate, the public are equipped to ask the right sort of questions about the process. Okay, I’ve got one more question to you because we’re running out of time. And it’s back to that over enthusiasm for mathematical solutions point. I thought was somewhat serendipitous to read about, read that quote, in the same week that the UK Prime Minister Rishi Sunak announced a plan for all pupils in England to study maths to the age of 18. So, I wanted to ask you what you make of that plan, first of all, but also, I think, more importantly, does a more mathematically minded populace, are they better equipped to understand the mathematical descriptions of the world and that they are incomplete descriptions? Or is there kind of maybe some other curriculum that we need to tack on to this maths to 18, in order that people are able to better differentiate between model land and the real world?</p>
<p><strong>Erica Thompson</strong><br>
Yeah, so I mean, I’m not a fan of– I mean, I like the idea of people studying maths to 18. I think more maths is a good thing. I loved maths, I still love maths, I think if more people were more generally numerate then society would be better and life would be better. But if you haven’t enthused people about the value and the interest of maths by 16, forcing them to study it for another two years is absolutely not the answer. It will just put people off staying in school past 16. So I, you know, I think that we need better teaching of maths before 16, rather than forcing people to study maths post 16. And part of that is helping people to understand how mathematics is relevant to the real world that they live in and teaching them the kind of things that they will use in their adult life. You know, people, most people don’t use Pythagoras theorem, but most people do need to fill in a tax return, you know, these sorts of things. Understanding orders of magnitude, and the difference between millions and billions, would be incredibly helpful, wouldn’t it? So, yeah, I think there are more basic questions there that need to be answered before we go into the details of sort of complex maths. And then, so what was the next question?</p>
<p><strong>Brian Tarran</strong><br>
It was about whether whether you think, the more mathematically equipped we are, does that make us better able to understand the limitations of models? Or do we need something else to kind of train us or encourage us to think about these two separate realities, model land and the real world? And I say realities in inverted commas.</p>
<p><strong>Erica Thompson</strong><br>
Yeah, I mean, I think the general public has a good understanding that the model land and the real world are not the same. There is actually a healthy scepticism of models out there. And I think that’s probably a good thing. I give a couple of funny anecdotes in the book about that. So I mean, one was a, I think, a YouGov poll about people going to the moon and saying, you know, would you go to the moon if you could be guaranteed a safe return, blah, blah, blah, and like, a large percentage of those said, Well, no, I just don’t think you could give me a safe return, they reject the model land. And then there was another example about intelligence analysts being asked to sort of calibrate a probability language scale. So they say, like, likely, however many percent and very likely however many percent and unlikely however many percent. And so the study was looking at different ways of doing that. And one way was to accompany the word likely, or unlikely, or whatever, with a written number of what the probability it referred to was. So it would say, like, likely, I can’t remember the number, but sat it was, like 50 to 70%, written down in the question, and then the question was, what is the probability of an event, which is deemed to be likely brackets 50 to 70%? And what people write down was not 50 to 70%. You know, as a mathematician, that’s completely ridiculous. Because the answer was in the question, why wouldn’t you write that down? But of course, what you’re seeing there is the rejection of model land. Somebody has assessed it as 50-70%. The question is, do you believe it? Well, no, actually, you might write something like 40 to 80%, because you expect there to be, you know, the model to be generically overconfident. And so this is sort of what I mean, by curbing over enthusiasm for mathematical solutions is that, you know, we have to understand that the mathematical solutions are living in model land, and that we can, in order to get out of model land, we have to say, do we actually expect this result to refer to the real world? Or is it only saying what the next model run is going to tell us? And so the act of doing that is difficult, and it’s more difficult for mathematicians than for the general public because as mathematicians, we sort of are used to living within model land and noticing when the answer is in the question and then writing it down. And we’re not very good at saying, Well, what’s my subjective estimate of the probability of this model being inadequate in some way? That’s not something that you can necessarily do with respect to data and so it’s a tricky one. So in terms of the over enthusiasm, you know, it’s curbing over enthusiasm, not curbing enthusiasm, because as I said at the beginning, and I returned to a lot in the book, actually, mathematical models are incredibly valuable. And they contain a huge amount of information and insight that we’re, we would be fools to throw away. But we need to understand it, you know, in a more nuanced way and be clear about what it’s telling us and what it’s not telling us. And that answers in model land aren’t necessarily the answers that we need in reality, though they may be informative about them.</p>
<p><strong>Erica Thompson</strong><br>
Well, Erica, thank you very much for your time today, for talking through the book, which is out now. Do you have some some links or information about where people can find out more about the book?</p>
<p><strong>Erica Thompson</strong><br>
Yep, look on my on my website, ericathompson.co.uk. And it’s available through all the usual booksellers.</p>
<p><strong>Brian Tarran</strong><br>
Excellent, excellent. Well, I wish you the best of luck with the book. As I say, I think it’s fantastic. And well, I hope we get to talk again, maybe a bit further down the road and see whether some of these principles and this ethical framework that you talk about for mathematical modelling, whether that kind of comes to fruition because I think we need to watch that closely. So, Erica, thank you.</p>
<p><strong>Erica Thompson</strong><br>
Thank you very much. Thanks for having me.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/01/25/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/01/25/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “How to ‘Escape from Model Land’: an interview with Erica Thompson.” Real World Data Science, January 25, 2023. <a href="https://realworlddatascience.net/news-and-views/interviews/posts/01/25/erica-thompson.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Modelling</category>
  <category>Ethics</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/01/25/erica-thompson.html</guid>
  <pubDate>Wed, 25 Jan 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/01/25/images/erica-thompson.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>We’re taking Real World Data Science on the road</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/18/rwds-at-rss-conference.html</link>
  <description><![CDATA[ 




<p>Real World Data Science has booked its first conference appearance! This September, we’ll be part of the data science stream of the <a href="https://rss.org.uk/training-events/conference-2023/">RSS International Conference</a>.</p>
<p>Our session, “Real World Data Science Live”, will feature talks and discussions based on content published on this site. In particular, we’re looking to share compelling examples of how data science is being used to solve real-world problems.</p>
<p>If you’re thinking about <a href="https://realworlddatascience.net/contributor-docs/call-for-contributions.html">contributing to Real World Data Science</a>, or have already made a submission, do let us know whether you’d be interested in taking part in this in-person event. There are only a handful of speaker slots available, so please get in touch ASAP!</p>
<p>The conference takes place 4-7 September 2023, in Harrogate, Yorkshire. <a href="https://rss.org.uk/news-publication/news-publications/2023/general-news/first-keynote-speaker-announced-for-rss-2023-confe/">Keynote speakers include Anuj Srivastava</a>, a Florida State University professor with research interests in statistical computer vision, functional data analysis, and shape analysis, and other <a href="https://rss.org.uk/training-events/conference-2023/invited-session-topics/">invited topic sessions</a> in the data science stream are:</p>
<ul>
<li>GitHub: Version control for research, teaching and industry</li>
<li>Surrogate-assisted uncertainty quantification of complex computer models</li>
<li>Getting your work to work</li>
<li>Best practices for the analysis and visualisation of Google Trends data</li>
</ul>
<p>See the <a href="https://rss.org.uk/training-events/conference-2023/">RSS International Conference 2023 website</a> for more details.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/18/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/18/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “We’re taking Real World Data Science on the road.” Real World Data Science, January, 18 2023. <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/18/rwds-at-rss-conference.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Updates</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/18/rwds-at-rss-conference.html</guid>
  <pubDate>Wed, 18 Jan 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/18/images/rss-conf23.png" medium="image" type="image/png" height="94" width="144"/>
</item>
<item>
  <title>Explore the RSS Data Science &amp; AI Section newsletter, right here!</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/05/newsletter.html</link>
  <description><![CDATA[ 




<p>Happy New Year from all of us at Real World Data Science. We hope you had a relaxing break over the holidays and are now refreshed and excited to see what 2023 has in store. We’re starting the year with a new addition to the site: a page dedicated to the excellent <a href="https://realworlddatascience.net/news-and-views/newsletter/">RSS Data Science &amp; AI Section newsletter</a>.</p>
<p>This monthly newsletter has been running since February 2020 and is well worth subscribing to as it features roundups of news, new developments, big picture ideas and practical tips.</p>
<p>You’ll find the full list of past newsletters in our <a href="https://realworlddatascience.net/news-and-views/"><strong>News and views</strong></a> section (click the “Newsletter” heading in the section menu). If you want to subscribe to the newsletter, head over to <a href="https://datasciencesection.org/about/">datasciencesection.org</a>. The Data Science &amp; AI Section also has a page on the <a href="https://rss.org.uk/membership/rss-groups-and-committees/sections/data-science-section/">RSS website</a>.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/05/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/05/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Explore the RSS Data Science &amp; AI Section newsletter, right here!” Real World Data Science, January, 5 2023. <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/05/newsletter.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Updates</category>
  <category>Newsletters</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/05/newsletter.html</guid>
  <pubDate>Thu, 05 Jan 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/01/05/images/brett-jordan-LPZy4da9aRo-unsplash.jpg" medium="image" type="image/jpeg"/>
</item>
<item>
  <title>Sink your teeth into some data science papers with our brand new blog</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/12/13/dsb-launch.html</link>
  <description><![CDATA[ 




<p>I’m absolutely thrilled today to announce the launch of our new blog, <a href="../../../../../../ideas/datasciencebites/index.html">DataScienceBites</a>. The blog is not only a new addition to Real World Data Science, but also the latest proud member of the ScienceBites family of sites.</p>
<p><a href="https://sciencebites.org/sciencebites-sites-galaxy/">ScienceBites sites</a> all share the same <a href="https://sciencebites.org/about/">concept</a>: we publish “short digestible <em>bites posts</em> about individual research papers” in an effort to make cutting-edge science accessible to a wide audience, and our posts are written by graduate students and early career researchers.</p>
<p>For <a href="../../../../../../ideas/datasciencebites/index.html">DataScienceBites</a>, our focus will of course be on new publications in the data science space. Contributors are invited to write about papers that are of particular interest to them and to pitch their summaries at an undergraduate level. For an example of what we’re looking for, see our first post on <a href="../../../../../../news-and-views/datasciencebites/posts/2022/12/13/ridesharing.html">“Determining the best way to route drivers for ridesharing via reinforcement learning”</a>.</p>
<p>This launch post is written by Brian King and is republished with permission from <a href="https://mathstatbites.org">MathStatBites</a>, so I want to say a big thank you to Brian and editors Sadie Witkowski and Sara Stoudt for allowing us to repost it. Sadie and Sara have been fantastically supportive of the DataScienceBites idea, and I am grateful for all their behind-the-scenes efforts.</p>
<p>Brian’s post is a great demonstration of the Bites concept, and we hope that it will inspire others to follow suit. If you are a graduate student or early career researcher in data science (or related subjects) with a passion for science communication and an interest in writing about new data science research, please do <a href="../../../../../../contact.html">get in touch</a>. See our <a href="../../../../../../contributor-docs/datasciencebites.html">notes for contributors</a> for further details.</p>
<p>To everyone else, we do hope you enjoy sinking your teeth into the data science literature with <a href="../../../../../../ideas/datasciencebites/index.html">DataScienceBites</a>. Happy reading!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/12/13/images/datasciencebites-logo.png" class="img-fluid figure-img" alt="DataScienceBites logo. A dark grey circle with bite marks cut out. Overlaid text says, Import grad_students as writers, import new_research_papers as nrp, print(writers + nrp) and the title DataScienceBites." width="500"></p>
</figure>
</div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2022 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/12/13/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/12/13/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2022. “Sink your teeth into some data science papers with our brand new blog.” Real World Data Science, December, 13 2022. <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2022-12-13-dsb-launch/dsb-launch.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Updates</category>
  <category>Content ideas</category>
  <category>Call for contributions</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/12/13/dsb-launch.html</guid>
  <pubDate>Tue, 13 Dec 2022 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/12/13/images/datasciencebites-logo.png" medium="image" type="image/png" height="144" width="144"/>
</item>
</channel>
</rss>
