<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/viewpoints/index.html</link>
<atom:link href="https://realworlddatascience.net/viewpoints/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://realworlddatascience.net/images/rwds-logo-150px.png</url>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/viewpoints/index.html</link>
<height>83</height>
<width>144</width>
</image>
<generator>quarto-1.3.450</generator>
<lastBuildDate>Wed, 20 Sep 2023 19:35:32 GMT</lastBuildDate>
<item>
  <title>Live from Chicago: Real World Data Science at posit::conf(2023)</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.html</link>
  <description><![CDATA[ 




<section id="tuesday-september-19" class="level2">
<h2 class="anchored" data-anchor-id="tuesday-september-19">Tuesday, September 19</h2>
<section id="from-data-confusion-to-data-intelligence" class="level3">
<h3 class="anchored" data-anchor-id="from-data-confusion-to-data-intelligence">From data confusion to data intelligence</h3>
<p>An inspiring start to posit::conf(2023) this morning, with keynote talks from Elaine McVey, senior director of analytics at Chief, and David Meza, head of analytics for human capital at NASA, sharing stories and insights on how to build strong data science foundations in organisations.</p>
<p>McVey spoke about the frequent mismatch between high levels of hope for what data science can achieve within organisations, and low levels of understanding about how to set up data science teams for success. The best chance for success, she said, is if data scientists take the lead in helping organisations learn how to make best use of data science expertise.</p>
<p>From there, McVey went on to present a set of “guerilla data science tactics” that data scientists can use to get around any obstacles they may encounter, as illustrated in the slide below:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/images/mcvey-slide.png" class="img-fluid figure-img" alt="Elaine McVey's 'guerilla data science tactics' for building successful data science teams. Start by 'scanning for opportunities', then 'show, don't tell', 'take the data and run', 'nail the landing', and 'up the ante'."></p>
<figcaption class="figure-caption">Elaine McVey’s “guerilla data science tactics” for building successful data science teams.</figcaption>
</figure>
</div>
<p>Data scientists should start by scanning for opportunities to help the organisation, before building a small-scale version of what it is they propose to do. Once buy-in is achieved, and data is made available, it’s time to run with the project. Once complete, you need to “nail the landing”, McVey said, and make sure to communicate results broadly – not just to primary stakeholders, but across the organisation. Then comes time to “up the ante”: if your first project has built some organisational goodwill, leverage that and look for something higher risk, with higher potential reward for the organisation.</p>
<p>Throughout this process, McVey said, data scientists should be building foundations for future projects – creating data pipelines, R packages, etc., that can be reused later. This was a point picked up and developed upon by Meza, who walked through in detail the steps required to establish “data foundations” within organisations, drawing on his own past experiences. Typically, he said, organisations seem to collect data just to store it – but always data should be collected, stored, and managed with analysis in mind.</p>
</section>
<section id="a-hackers-guide-to-open-source-llms" class="level3">
<h3 class="anchored" data-anchor-id="a-hackers-guide-to-open-source-llms">A hacker’s guide to open source LLMs</h3>
<p>Fast.ai’s Jeremy Howard lifted the hood on large language models (LLMs) in the second of two keynotes this morning.</p>
<p>Beginning with an accessible overview of what LLMs are, how they work, and how they are trained, Howard then addressed some of the criticisms made of LLMs – that they “can’t reason” or give correct answers.</p>
<p>As Howard explained, a model like OpenAI’s GPT-4 is not trained at any point to give correct answers to prompts – only to predict the most likely next word, or word token, in a sequence.</p>
<p>The pre-training step, for example, does not involve only feeding the model with “correct answers”, instead relying on a corpus of text from the internet – some (or, maybe, much) of which may consist of factual inaccuracies, errors, falsehoods, etc. And in the fine-tuning stage, when human feedback is used to either reward or penalise model outputs, Howard said there is a preference for confident-sounding responses – and so, again, this doesn’t necessarily reward the model for giving correct answers.</p>
<p>Howard made the case that users have to help language models to give good answers, and that custom instructions can be used to change the way models respond. He then walked delegates through a series of demos using open-source LLMs, to show how outputs can be refined and improved.</p>
<p>“My view is that if you are going to be good at language modelling in any way,” said Howard, “you have to be good at using language models.”</p>
</section>
<section id="documenting-things-openly-for-future-us" class="level3">
<h3 class="anchored" data-anchor-id="documenting-things-openly-for-future-us">Documenting Things: Openly for Future Us</h3>
<p>Julia Stewart Lowndes, founding director of <a href="https://openscapes.org/">Openscapes</a>, gave a compelling talk advocating for the importance of documentation for data science projects.</p>
<p>Documenting things, Lowndes said, should be done for the benefit of “Future Us”: not only ourselves but our teams and our communities who may be contributing to or revisiting the project in the next hours, days, weeks, months and years.</p>
<p>Documenting things does not have to be painful, Lowndes said. In fact, it’s supposed to be helpful. It does, however, take time and intention. And it means slowing down briefly to write things down now, in order that work speeds up in the longer term.</p>
<p>Lowndes then shared some pointers to help people get started with documentation:</p>
<ol type="1">
<li>Have a place to write things down – Google Docs, GitHub, wherever – ideally a place where people can work collaboratively.
<ol type="i">
<li>Develop the habit of writing things down as you go.</li>
<li>Write in a modular way – small bits of text are less daunting and easier to maintain collaboratively.</li>
</ol></li>
<li>Have an audience in mind – you are writing this for someone, so make it engaging for them.
<ol type="i">
<li>write in an inclusive tone.</li>
<li>Narrate code in small chunks, and in a way that you’d say out loud if teaching.</li>
<li>Share, and share early – you want to be able to iterate on your documentation and receive feedback. Also, sharing openly does not always mean publicly – manage permissions as necessary.</li>
</ol></li>
<li>Design for readability and accessibility.
<ol type="i">
<li>Use section headers – particularly important for screen readers, but this also helps generally to describe the flow of a document. Plus, you can link readers directly to specific parts of a document.</li>
<li>Use text formatting.</li>
<li>Use alt-text for images, describing the take-home message of the image.</li>
</ol></li>
</ol>
</section>
<section id="teaching-data-science-in-adverse-circumstances-posit-cloud-and-quarto-to-the-rescue" class="level3">
<h3 class="anchored" data-anchor-id="teaching-data-science-in-adverse-circumstances-posit-cloud-and-quarto-to-the-rescue">Teaching Data Science in Adverse Circumstances: Posit Cloud and Quarto to the Rescue</h3>
<p>Professor Aleksander Dietrichson of the Universidad de San Martin brought a valuable perspective to posit::conf(2023) on the challenges of teaching data science in the face of technology and language barriers.</p>
<p>At the public, state-funded university in Argentina where Dietrichson works, more than half of students do not have access to laptops or computers at home, and those who do have access – whether at home or at school – may not have access to the latest kit. But “<a href="https://posit.cloud/">Posit Cloud</a> solves the resource issue”, Dietrichson said. The free-to-use, online browser-based version of Posit’s tools runs on anything; Dietrichson said he’s tested it successfully on both decade-old computers and cellphones – though he doesn’t recommend using it on a cellphone!</p>
<p>On language barriers, he pointed out that learning to code in R and Python can be challenging when English isn’t your first language – if you don’t have semantic access to function names, for example, there will be a steeper learning curve for students.</p>
<p>Dietrichson also has to deal with the problem of “arithmaphobia” among some of the liberal arts students he teaches. This has necessitated a reshuffling of the typical statistics curriculum, he said, in order to make it easier for students to access. But the work is worth it, Dietrichson explained: many of his students want to work in careers like journalism, and he believes that “journalists should be statistically literate”.</p>
<!-- ### Talk title
Add write-up here

*Add your name and affiliation here* -->
</section>
</section>
<section id="wednesday-september-20" class="level2">
<h2 class="anchored" data-anchor-id="wednesday-september-20">Wednesday, September 20</h2>
<section id="r-not-only-in-production" class="level3">
<h3 class="anchored" data-anchor-id="r-not-only-in-production">R Not Only In Production</h3>
<p>Kara Woo, senior data science engineer at InsightRX, began her Wednesday morning keynote with a rousing description of posit::conf(2023) being like a “great community garden” where things are being cultivated and shared for the benefit of all. This is an important feeling, Woo said, because it doesn’t always feel like that in our day jobs. Data scientists can feel siloed, not able to share ideas with like-minded people, and facing resistance from people who say “R can’t do that, R isn’t a real programming language” – a comment that elicited a groan of weary familiarity from sections of the crowd.</p>
<p>But as Woo went on to explain, “it is possible to build quality software in R” and “it is possible to have an organisation where the strengths of R and the people who use it influence the organisation as a whole”.</p>
<p>Woo was speaking from her experience at InsightRX, a precision medicine company, which makes software for clinicians to inform individualised dosing decisions for patients. Through a tool called Nova, clinicians feed in data about a patient’s unique characteristics, which is then passed to R for analysis, which then returns dosage recommendations to Nova.</p>
<p>In InsightRX, R has also been used to solve problems that are not strictly data science problems. Woo gave the example of working with a colleague to write an R package to identify data labels that have been changed and rollout translations for those labels in multiple languages for software users in different parts of the world.</p>
<p>“Our mindset of R being a first-class language empowers us to solve problems,” said Woo.</p>
<!-- ### Talk title
Add write-up here

*Add your name and affiliation here* -->
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Want to contribute to this blog? Fork <a href="https://github.com/realworlddatascience/realworlddatascience.github.io">our repo</a>, update <a href="https://github.com/realworlddatascience/realworlddatascience.github.io/blob/positconf-blog/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.qmd">this file</a> in the <code>positconf-blog</code> branch, and make a pull request!</p>
</div>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Live from Chicago: Real World Data Science at posit::conf(2023).” Real World Data Science, September 19, 2023, updated September 20, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>Conferences</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/positconf-blog.html</guid>
  <pubDate>Wed, 20 Sep 2023 19:35:32 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/19/images/chicago-theatre.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘Pseudo data science’ and other pitfalls: lessons from the UK’s stats regulator on how not to be misleading</title>
  <dc:creator>Ed Humpherson</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/09/18/pseudo-data-science.html</link>
  <description><![CDATA[ 




<p>A typical article on data science hails new data sources, new tools, and new visualisations, and thereby supports the case for the value of data science.</p>
<p>But this article takes a different angle: it talks about potential pitfalls that can face data scientists. It is based on our work as the Office for Statistics Regulation (OSR), the UK’s regulator for official statistics. We see lots of great work done by statisticians in government. But we also see some of the challenges they face – and data scientists are also likely to encounter the same challenges.</p>
<p>The problems arise from the fact that neither statisticians nor data scientists do their work in isolation. The work usually takes places within organisations – businesses, government bodies, think tanks, academic institutions – and as a result, the statisticians and/or data scientists are not the only players who get to influence how data science is presented and used.</p>
<p>What are the pitfalls we see in our work as regulator?</p>
<section id="pseudo-data-science" class="level2">
<h2 class="anchored" data-anchor-id="pseudo-data-science">Pseudo data science</h2>
<p>The first type of pitfall is pseudo data science.</p>
<p>Pseudo data science is a term we use to describe attempts to pass off crude work as being more data science-y than it really is. That reflects a sense in public life that data science is new, innovative, somehow the Future. In this context, people who are not data scientists can be tempted to dress themselves up in the clothes of data science to enhance their credibility. This dressing up is usually well-intentioned – communications professionals who want to illuminate and explain complex issues in an engaging way.</p>
<p>The trouble is, it can sometimes backfire. In our work at OSR, we have over the last year seen several examples where organisations have sought to publish visualisations that look like they are the product of in-depth data analysis – when in fact they have been drawn by communications staff using graphic design packages. Examples include <a href="https://osr.statisticsauthority.gov.uk/correspondence/ed-humpherson-to-david-pares-treasury-inflation-infographic/">inflation</a>, <a href="https://uksa.statisticsauthority.gov.uk/correspondence/response-from-sir-robert-chote-to-andrew-gwynne-mp-dhsc-chart-on-nurses-pay/">nurses pay</a>, and <a href="https://uksa.statisticsauthority.gov.uk/correspondence/letter-to-rachel-reeves-mp-gdp-growth-chart/">comparisons of UK economic performance with other countries</a>. To be fair, whenever we have pointed out issues like this, organisations have responded well, putting in place new procedures to ensure that analysts sign off on this kind of visualisations. Nevertheless, we suspect that the temptations to indulge in pseudo data science will remain strong – and we may need to intervene on similar cases in future.</p>
</section>
<section id="unintelligent-transparency" class="level2">
<h2 class="anchored" data-anchor-id="unintelligent-transparency">Unintelligent transparency</h2>
<p>The second pitfall is a failure of <a href="https://osr.statisticsauthority.gov.uk/publication/regulatory-guidance-on-intelligent-transparency/">intelligent transparency</a>.</p>
<p>There is a raw form of transparency – quoting a single number (a naked number we call it); or dumping data out into the public domain with no explanation. This is not intelligent transparency. The latter involves being clear where data come from, what their source is, and making underlying data available so that others can understand and verify the statements that are being made. Raw transparency and naked numbers treat an audience with little respect; intelligent transparency helps the audience understand and appreciate what sits behind high level claims.</p>
<p>Data science outputs can sometimes seem to communications teams easy to cherry pick for the most attractive number. Again, like pseudo data science, this reflects largely good intentions – to communicate complex things through ideas. But it becomes easy for a single, unsupported number to be used and reused until it loses most of its meaning. We call this weaponization of data, and it is the antithesis of intelligent transparency. And there is a lot of it about – for example the way in which the former Prime Minister of the UK talked repeatedly about <a href="https://uksa.statisticsauthority.gov.uk/correspondence/sir-david-norgrove-to-prime-minister-employment-statistics/">employment</a>; or <a href="https://uksa.statisticsauthority.gov.uk/correspondence/response-from-sir-robert-chote-to-alex-cole-hamilton-msp-scottish-renewable-energy-statistics/">claims</a> about Scotland’s capacity for <a href="https://uksa.statisticsauthority.gov.uk/correspondence/sir-robert-chote-to-stephen-kerr-msp-renewable-energy/">renewable energy</a>. These examples indicate the pathology of weaponization that can impact data science outputs. They also act as a reminder that data scientists can counter weaponization of their own outputs by delivering engaging and insightful communication.</p>
</section>
<section id="context-collapse" class="level2">
<h2 class="anchored" data-anchor-id="context-collapse">Context collapse</h2>
<p>The third type of pitfall surrounds context collapse.</p>
<p>This idea comes from the work of the philosopher <a href="http://lucymcdonald.co.uk/wp-content/uploads/2023/02/Context-Collapse-Online-LMcDonald.pdf">Lucy McDonald</a> (who in turn has built on the ideas of <a href="https://www.danah.org/">danah boyd</a>). What is context collapse? Imagine a swimming pool – with neat divisions of the pool into different lanes. All is clearly labelled – fast, medium, slow – for lane swimmers, who are in turn separated from the splash area for families and the deep end for divers. Removing the lanes, and thus taking away any signposting, increases the likelihood for things to go wrong. The fast swimmers doing front crawl clash with the slower breaststroke swimmers; both are constantly having to avoid the families with young children; and all need to watch for the periodic big splashes created by the divers. This is the online communication environment, in which formerly private and casual statements can go viral; in which a brief statement in a media environment can be picked up on and circulated many times; and in which some bad actors (the divers) may wish to disrupt deliberately the debate by breaking all the rules.</p>
<p>How can this affect data science? It happens when individual bits of data are taken from their context, and used in service of a different, and bigger, argument. A good example is data on Covid vaccinations. Here, UK organisations like the Office for National Statistics and the UK Health Security Agency published comprehensive data in good faith about vaccinations and their impact. Some of the underlying data, however, was taken out of the broader context and used in isolation to support criticisms of vaccines – criticisms that the wider evidence base did not support.</p>
<p>The challenge then became how the organisations should respond. At an organisational level, they did not wish to withdraw the data – because that would reduce transparency. Instead they sought to both caveat their data more clearly; and directly rebut the more egregious misuses of the data. In a sense, then, what began as an individual analytical output became part of a broader organisational judgement on positioning in the face of misinformation.</p>
<p>It is fair to say that, against this third pitfall, there is not yet a clear consensus on how to address it. Practice is emerging all the time and we at OSR continue to support producers of data as they grapple with it.</p>
<p>There are other potential pitfalls to using data science. But what unites these three – pseudo data science; unintelligent transparency; and context collapse – is that they relate to situations where data science rubs up against broader organisational dynamics, around communications, presentation and organisational strategy.</p>
<p>And the meta-message is this: for data scientists to thrive in organisations, they need to be good at more than data science. They need to be skilled at working alongside and influencing colleagues from other functions. Only through this form of <a href="https://osr.statisticsauthority.gov.uk/analytical-leadership/">data leadership</a> can the pitfalls be dealt with effectively.</p>
<div class="callout callout-style-simple callout-note">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This article is based on a presentation at the <a href="https://www.datascienceforhealthequity.com/">Data Science for Health Equity</a> group in May 2023.</p>
</div>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Ed Humpherson</strong> is head of the Office for Statistics Regulation, which provides independent regulation of all official statistics in the UK. The aim of OSR is to enhance public confidence in the trustworthiness, quality and value of statistics produced by government.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Ed Humpherson
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/posts/2023/09/18/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/posts/2023/09/18/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Humpherson, Ed. 2023. “‘Pseudo data science’ and other pitfalls: lessons from the UK’s stats regulator on how not to be misleading.” Real World Data Science, September 18, 2023. <a href="https://realworlddatascience.net/viewpoints/posts/2023/09/18/pseudo-data-science.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Communication</category>
  <category>Leadership</category>
  <category>Transparency</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/09/18/pseudo-data-science.html</guid>
  <pubDate>Mon, 18 Sep 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/09/18/images/distorted-data.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Contributors: check out the new Real World Data Science template repo on GitHub</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/template.html</link>
  <description><![CDATA[ 




<p>Thinking of contributing to Real World Data Science but not sure how to get started? Help is at hand, thanks to <a href="https://github.com/finnoh">Finn-Ole Höner</a>. The Amsterdam-based business data science student has created <a href="https://github.com/finnoh/RWDS_post_template">a template repository on GitHub</a> that allows anyone to create Real World Data Science content in our house style and format.</p>
<p>In this repository you’ll find two example Quarto (.qmd) documents, which is the main file type we use for generating site content. The “content-brief.qmd” file is a template for developing article ideas to discuss with our site editors, and the “report.qmd” file is a standard article template. Within that article template you’ll find examples of the range of Quarto features that we use, as well as the code you need to make use of them yourself.</p>
<p>These documents can be edited using tools including Visual Studio Code and R Studio. For details on how to work with Quarto documents, see the <a href="https://quarto.org/">Quarto website</a>. Once article drafts are finished they can be rendered into HTML format, and the output files will be displayed in the Real World Data Science style, thanks to the inclusion of our stylesheets in the template repository. This is a great way for contributors to see what their content will look like on Real World Data Science before anything is published.</p>
<p>To get started, head on over to the <a href="https://github.com/finnoh/RWDS_post_template">RWDS_post_template repository</a> and click the “Use this template” button. Also, be sure to <a href="https://realworlddatascience.net/contributor-docs/contributor-guidelines.html">review our contributor guidelines</a> for advice on how to integrate the .qmd templates into the content development and submission workflow.</p>
<p>Huge thanks to Finn-Ole Höner for building this valuable resource for Real World Data Science contributors.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@synkevych?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Roman Synkevych</a> on <a href="https://unsplash.com/photos/UT8LMo-wlyk?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Contributors: check out the new Real World Data Science template repository on GitHub.” Real World Data Science, September 12, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/template.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Call for contributions</category>
  <category>Tools</category>
  <category>Updates</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/template.html</guid>
  <pubDate>Tue, 12 Sep 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/09/12/images/roman-synkevych-UT8LMo-wlyk-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>For minorities, biased AI algorithms can damage almost every part of life</title>
  <dc:creator>Arshin Adib-Moghaddam</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/09/06/biased-algorithms.html</link>
  <description><![CDATA[ 




<p>Bad data does not only produce bad outcomes. It can also help to suppress sections of society, for instance vulnerable women and minorities.</p>
<p>This is the argument of <a href="https://www.bloomsbury.com/us/is-artificial-intelligence-racist-9781350374423/">my new book</a> on the relationship between various forms of racism and sexism and artificial intelligence (AI). The problem is acute. Algorithms generally need to be exposed to data – often taken from the internet – in order to improve at whatever they do, such as <a href="https://www.theguardian.com/us-news/2022/may/11/artitifical-intelligence-job-applications-screen-robot-recruiters">screening job applications</a>, or underwriting mortgages.</p>
<p>But the training data often contains many of the biases that exist in the real world. For example, algorithms could learn that most people in a particular job role are male and therefore favour men in job applications. Our data is polluted by a set of myths from the age of <a href="https://en.wikipedia.org/wiki/Age_of_Enlightenment#:%7E:text=The%20Enlightenment%20included%20a%20range,separation%20of%20church%20and%20state.">“enlightenment”</a>, including biases that lead to <a href="https://www.gaytascience.com/transphobic-algorithms/">discrimination based on gender and sexual identity</a>.</p>
<p>Judging from the history in societies where racism has played a role in <a href="https://sk.sagepub.com/books/racism-from-slavery-to-advanced-capitalism">establishing the social and political order</a>, extending privileges to white males –- in Europe, North America and Australia, for instance –- it is simple science to assume that residues of racist discrimination feed into our technology.</p>
<p>In my research for the book, I have documented some prominent examples. Face recognition software <a href="https://www.washingtonpost.com/technology/2019/12/19/federal-study-confirms-racial-bias-many-facial-recognition-systems-casts-doubt-their-expanding-use/">more commonly misidentified black and Asian minorities</a>, leading to false arrests in the US and elsewhere.</p>
<p>Software used in the criminal justice system has predicted that black offenders would have <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">higher recidivism rates</a> than they did. There have been false healthcare decisions. <a href="https://www.science.org/doi/10.1126/science.aax2342">A study found that</a> of the black and white patients assigned the same health risk score by an algorithm used in US health management, the black patients were often sicker than their white counterparts.</p>
<p>This reduced the number of black patients identified for extra care by more than half. Because less money was spent on black patients who have the same level of need as white ones, the algorithm falsely concluded that black patients were healthier than equally sick white patients. Denial of mortgages for minority populations is facilitated by biased data sets. The list goes on.</p>
<section id="machines-dont-lie" class="level2">
<h2 class="anchored" data-anchor-id="machines-dont-lie">Machines don’t lie?</h2>
<p>Such oppressive algorithms intrude on almost every <a href="https://www.newscientist.com/article/mg25033390-200-the-essential-guide-to-the-algorithms-that-run-your-life/">area of our lives</a>. AI is making matters worse, as it is sold to us as essentially unbiased. We are told that machines don’t lie. Therefore, the logic goes, no one is to blame.</p>
<p>This pseudo-objectiveness is central to the AI-hype created by the Silicon Valley tech giants. It is easily discernible from the speeches of Elon Musk, Mark Zuckerberg and Bill Gates, even if now and then they <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">warn us about the projects</a> that they themselves are responsible for.</p>
<p>There are various unaddressed legal and ethical issues at stake. Who is accountable for the mistakes? Could someone claim compensation for an algorithm denying them parole based on their ethnic background in the same way that one might for a toaster that exploded in a kitchen?</p>
<p>The <a href="https://umdearborn.edu/news/ais-mysterious-black-box-problem-explained#:%7E:text=This%20inability%20for%20us%20to,when%20they%20produce%20unwanted%20outcomes.">opaque nature of AI technology</a> poses serious challenges to legal systems which have been built around individual or human accountability. On a more fundamental level, basic human rights are threatened, as legal accountability is blurred by the maze of technology placed between perpetrators and the various forms of discrimination that can be conveniently blamed on the machine.</p>
<p>Racism has always been a systematic strategy to order society. It builds, legitimises and enforces hierarchies between the haves and have nots.</p>
</section>
<section id="ethical-and-legal-vacuum" class="level2">
<h2 class="anchored" data-anchor-id="ethical-and-legal-vacuum">Ethical and legal vacuum</h2>
<p>In such a world, where it’s difficult to disentangle truth and reality from untruth, our privacy needs to be legally protected. The right to privacy and the concomitant ownership of our virtual and real-life data needs to be codified as a human right, not least in order to harvest the real opportunities that good AI harbours for human security.</p>
<p>But as it stands, the innovators are far ahead of us. Technology has outpaced legislation. The ethical and legal vacuum thus created is readily exploited by criminals, as this brave new AI world is largely anarchic.</p>
<p>Blindfolded by the mistakes of the past, we have entered a wild west without any sheriffs to police the violence of the digital world that’s enveloping our everyday lives. The tragedies are already happening on a daily basis.</p>
<p>It is time to counter the ethical, political and social costs with a concerted social movement in support of legislation. The first step is to educate ourselves about what is happening right now, as our lives will never be the same. It is our responsibility to plan the course of action for this new AI future. Only in this way can a good use of AI be codified in local, national and global institutions.</p>
<!-- Below is The Conversation's page counter tag. Please DO NOT REMOVE. -->
<p><img src="https://realworlddatascience.net/viewpoints/posts/2023/09/06/https:/counter.theconversation.com/content/211778/count.gif?distributor=republish-lightbox-basic" alt="The Conversation" width="1" height="1" style="border: none !important; box-shadow: none !important; margin: 0 !important; max-height: 1px !important; max-width: 1px !important; min-height: 1px !important; min-width: 1px !important; opacity: 0 !important; outline: none !important; padding: 0 !important" referrerpolicy="no-referrer-when-downgrade"></p>
<!-- End of code. If you don't see any code above, please get new code from the Advanced tab after you click the republish button. The page counter does not collect any personal data. More info: https://theconversation.com/republishing-guidelines -->
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<a href="https://theconversation.com/profiles/arshin-adib-moghaddam-211780">Arshin Adib-Moghaddam</a> is professor in global thought and comparative philosophies, <a href="https://theconversation.com/institutions/soas-university-of-london-975">SOAS, University of London</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-12">
<dl>
<dt>Copyright and licence</dt>
<dd>
This article is republished from <a href="https://theconversation.com">The Conversation</a> under a Creative Commons license. Read the <a href="https://theconversation.com/for-minorities-biased-ai-algorithms-can-damage-almost-every-part-of-life-211778">original article</a>.
</dd>
<dd>
<p>Image by <a href="http://alanwarburton.co.uk/">Alan Warburton</a> / © BBC / <a href="https://www.betterimagesofai.org">Better Images of AI</a> / Quantified Human / <a href="https://creativecommons.org/licenses/by/4.0/">Licenced by CC-BY 4.0</a>.</p>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>AI ethics</category>
  <category>Bias</category>
  <category>Ethics</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/09/06/biased-algorithms.html</guid>
  <pubDate>Wed, 06 Sep 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/09/06/images/AlanWarburton-QuantifiedHuman-991x724.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>RSS Conference preview: Evaluating AI, machine learning, and data visualisation</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/rss-conference.html</link>
  <description><![CDATA[ 




<p>The Royal Statistical Society International Conference takes place in Harrogate, England, this September (Monday 4 to Thursday 7). Real World Data Science will be in attendance, and we’ve helped organise a couple of sessions we’d like to tell you about.</p>
<section id="evaluating-ai-how-data-science-and-statistics-can-shape-the-uks-ai-strategy" class="level3">
<h3 class="anchored" data-anchor-id="evaluating-ai-how-data-science-and-statistics-can-shape-the-uks-ai-strategy">Evaluating AI: How data science and statistics can shape the UK’s AI strategy</h3>
<p><strong>Date:</strong> 6 September <strong>Time:</strong> 9:00 am - 10:20 am <strong>Room:</strong> Auditorium (moved from Queens Suite 8)</p>
<p>The launch of ChatGPT less than a year ago is a milestone moment in the story of artificial intelligence. Overnight, large language models were transformed from research projects into consumer products, now used by millions each month. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/code-interpreter.html">The capabilities are impressive</a>, <a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">the productivity gains undeniable</a>. But, what of the downsides? These are issues <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/04/28/stephanie-hare.html">societies, governments, and individuals are now starting to reckon with</a>.</p>
<p>In March 2023, <a href="https://www.gov.uk/government/publications/ai-regulation-a-pro-innovation-approach/white-paper">the UK government published a white paper promising a “pro-innovation approach” to AI regulation</a>, while also acknowledging the risks AI poses to “people’s privacy, their human rights or their safety” and “concerns about the fairness of using AI tools to make decisions which impact people’s lives”. <a href="https://rss.org.uk/RSS/media/File-library/Policy/2023/RSS-AI-white-paper-response-v2-2.pdf">The Royal Statistical Society, in response, has called for investment in a centre for AI evaluation methodology</a>, arguing that users of AI systems should be able to judge the trustworthiness of claims made by AI companies as well as the outputs of their systems.</p>
<p>What should AI evaluation look like? How will it work in practice? What metrics are most important, and – crucially – who gets to decide this? Join us for <a href="https://virtual.oxfordabstracts.com/#/event/4019/program?session=66677&amp;s=700">a special panel debate at the RSS International Conference</a>, where these questions, and more, will be discussed.</p>
</section>
<section id="best-practices-for-data-visualisation-how-to-make-data-outputs-more-readable-accessible-and-impactful" class="level3">
<h3 class="anchored" data-anchor-id="best-practices-for-data-visualisation-how-to-make-data-outputs-more-readable-accessible-and-impactful">Best Practices for Data Visualisation: How to make data outputs more readable, accessible, and impactful</h3>
<p><strong>Date:</strong> 5 September <strong>Time:</strong> 11:40 am - 1:00 pm <strong>Room:</strong> Auditorium</p>
<p>The Royal Statistical Society (RSS) has published a new guide, “<a href="https://royal-statistical-society.github.io/datavisguide/">Best Practices for Data Visualisation</a>”, containing insights, advice, and examples (with code) to make data outputs more readable, accessible, and impactful. The guide is written primarily for contributors to Royal Statistical Society publications – including <em>Significance</em> magazine, the <em>Journal of the Royal Statistical Society Series A</em>, and Real World Data Science – but the information and advice within is also of broad relevance and use for any data visualisation task.</p>
<p>In the first half of this conference session, authors Andreas Krause, <a href="https://nrennie.rbind.io/">Nicola Rennie</a>, and Brian Tarran will introduce the guide and its key recommendations, and there will be a short demo of how to use the new <a href="https://github.com/nrennie/RSSthemes">{RSSthemes} R package</a>. For the second half of the session, attendees will be invited to share feedback with the authors, propose ideas, and start developing new and expanded sections of the guide. Attendees will be shown how to work with the guide’s source files and collaborate via GitHub, so feel free to bring along a laptop and become a contributor!</p>
<p>For more information, see <a href="https://royal-statistical-society.github.io/datavisguide/">rss.org.uk/datavisguide</a> and the <a href="https://virtual.oxfordabstracts.com/#/event/4019/program?session=65937&amp;s=0">RSS Conference website</a>.</p>
</section>
<section id="discussion-meeting-probabilistic-and-statistical-aspects-of-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="discussion-meeting-probabilistic-and-statistical-aspects-of-machine-learning">Discussion Meeting: Probabilistic and statistical aspects of machine learning</h3>
<p><strong>Date:</strong> 6 September <strong>Time:</strong> 5:00pm - 7:00 pm <strong>Room:</strong> Auditorium</p>
<p>We haven’t helped organise this session, but we are interested to see it. Two papers will be presented for discussion and debate. Paper 1 is “Automatic Change-Point Detection in Time Series via Deep Learning” by Jie Li, Paul Fearnhead, Piotr Fryzlewicz, and Tengyao Wang, while Paper 2 is “From Denoising Diffusions to Denoising Markov Models” by Joe Benton, Yuyang Shi, Valentin De Bortoli, George Deligiannidis, and Arnaud Doucet. Preprints of both papers are available now via the <a href="https://rss.org.uk/training-events/events/discussion-papers/">RSS Discussion Meetings webpage</a>, and you can also hear more about the session in this interview with Adam Sykulski, RSS Discussion Papers editor.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/1UL1H21v-Q0?si=WPftzqltawRknPPM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://flic.kr/p/YzNWJw">jcw1967</a>, licenced under a Creative Commons Attribution 2.0 Generic (CC BY 2.0) <a href="https://creativecommons.org/licenses/by/2.0/">licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “RSS Conference preview: Evaluating AI, machine learning, and data visualisation.” Real World Data Science, August 24, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/rss-conference.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Machine learning</category>
  <category>Data visualisation</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/rss-conference.html</guid>
  <pubDate>Thu, 24 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/24/images/harrogate-conference-centre.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Where do AI, data science, and computer games intersect?</title>
  <dc:creator>Alice-Maria Toader and Liam Brierley</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/08/17/data-science-and-games.html</link>
  <description><![CDATA[ 




<p>Game studios have cemented their place among the fastest-growing media industries. In recognition of this, we hosted an event in June through the <a href="https://rss.org.uk/membership/rss-groups-and-committees/groups/merseyside/">Royal Statistical Society (RSS) Merseyside Local Group</a> to explore AI and data science in computer game development. This was an amazing opportunity to engage with a different, in-vogue domain that has unique ties to data science. We showcased two fantastic presentations covering both academic and industry perspectives.</p>
<p>Stanley Wang, a data scientist at SEGA Europe, opened the event by showing the methods that SEGA uses to collect, process, and apply data on player decisions in-game. It was a revealing glimpse at how smoothly in-game data collection is integrated into SEGA’s digital platforms and the ways these data can be used to engage game-centred communities – for example, running special celebrations once milestones are hit for in-game events (revenue made, goals scored, etc.) or offering real-time integration with streaming platforms so viewers can see detailed statistics on in-game progress. Stanley showed one particular example where data collection fed directly into development decisions for <em>Endless Space</em>, a competitive strategy game where players vie for galactic conquest. During the beta (a period where a game is available to play but still considered in-testing before commercial release), SEGA were able to monitor how well-balanced the playable alien factions were based on real-time win rate data, which led to improvements to game mechanics for the final release.</p>
<p>We also learned how SEGA’s data science teams are using clustering methods to identify different game-playing behaviours in <em>Two Point Hospital</em>, a simulation game where players design, build, and manage a hospital through various scenarios. After compiling high-dimensional in-game data such as objectives achieved, treatment of staff, and even furniture choices, various clustering algorithms (including <a href="https://towardsdatascience.com/a-practical-guide-on-k-means-clustering-ca3bef3c853d">k-means clustering</a>) were used to identify common sets of player behaviour. Stanley highlighted that when using these sorts of <em>unsupervised learning methods</em>, it’s useful to get insights from multiple models to inform methodological decisions like number of clusters chosen or how to treat outliers. SEGA identified four distinct types of player from these analyses, which you can hear more about from Stanley in the video below. The approach allowed the company to better understand gamers’ motivations and experiences with a view to designing future game content.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/KAg3YDHvvqE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Our second speaker, Dr Konstantinos Tsakalidis, a lecturer in the Department of Computer Science at the University of Liverpool, presented exciting new ideas to teach computer games developers of the future. Dr Tsakalidis walked us through the curriculum for a dynamic new undergraduate program that reflects the latest software development technologies and the theory behind them. The course outline was designed around building knowledge and practice from the fundamentals upwards, starting from game physics as a prerequisite for game mechanics, game mechanics being a prerequisite for game content, and game content being a prerequisite for game AI. Combined with the continuous active involvement of students at each stage, this represented a great model of <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8049623/">constructivist teaching</a>. Dr Tsakalidis also proposed that practical game development (and subsequent assessments) should follow the latest <a href="https://www.datacamp.com/podcast/data-science-and-ai-in-the-gaming-industry">research on data science and AI in computer games</a>.</p>
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Alice-Maria Toader</strong> is a PhD student at the University of Liverpool and a committee member of the RSS Merseyside Local Group. <strong>Liam Brierley</strong> is a research fellow in health data science at the University of Liverpool and chair of the RSS Merseyside Local Group.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Alice-Maria Toader and Liam Brierley
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/posts/2023/08/17/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/posts/2023/08/17/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://unsplash.com/@jezar?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Jezael Melgoza</a> on <a href="https://unsplash.com/photos/FOx3_4_2O1E?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Toader, Alice-Maria and Liam Brierley. 2023. “Where do AI, data science, and computer games intersect?” Real World Data Science, August 17, 2023. <a href="https://realworlddatascience.net/viewpoints/posts/2023/08/17/data-science-and-games.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Events</category>
  <category>Video games</category>
  <category>Education</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/08/17/data-science-and-games.html</guid>
  <pubDate>Thu, 17 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/08/17/images/sega-store.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Live from Toronto: Real World Data Science at the Joint Statistical Meetings</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html</link>
  <description><![CDATA[ 




<section id="sunday-august-6" class="level2">
<h2 class="anchored" data-anchor-id="sunday-august-6">Sunday, August 6</h2>
<section id="use-of-color-in-statistical-charts" class="level3">
<h3 class="anchored" data-anchor-id="use-of-color-in-statistical-charts">Use of color in statistical charts</h3>
<p><em>Haley Jeppson, Danielle Albers Szafir, and Ian Lyttle</em></p>
<p>JSM 2023 is underway, and the first session I attended today was this panel on the use of colour in statistical charts.</p>
<p>The topic appealed to me for two reasons:</p>
<ul>
<li>Before my trip to Toronto, I interviewed <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html">Alberto Cairo about the many “dialects” of data visualisation</a>.</li>
<li>I’ve recently been working with Andreas Krause and Nicola Rennie to create new guidance for improving statistical graphics, titled “<a href="https://royal-statistical-society.github.io/datavisguide/">Best Practices for Data Visualisation</a>”.</li>
</ul>
<p>The “Best Practices…” guide links to several useful data visualisation tools, and this session today has put a few more on my radar:</p>
<ul>
<li><p><a href="https://cmci.colorado.edu/visualab/ColorCrafting/">Color Crafting</a>, by Stephen Smart, Keke Wu, and Danielle Albers Szafir. The authors write: “Visualizations often encode numeric data using sequential and diverging color ramps. Effective ramps use colors that are sufficiently discriminable, align well with the data, and are aesthetically pleasing. Designers rely on years of experience to create high-quality color ramps. However, it is challenging for novice visualization developers that lack this experience to craft effective ramps as most guidelines for constructing ramps are loosely defined qualitative heuristics that are often difficult to apply. Our goal is to enable visualization developers to readily create effective color encodings using a single seed color.”</p></li>
<li><p><a href="https://observablehq.com/collection/@ijlyttle/color">Computing on color</a>, a collection of Observable notebooks by Ian Lyttle that allow users to see how different colour spaces and colour scales work with different types of colour vision deficiency.</p></li>
</ul>
</section>
</section>
<section id="monday-august-7" class="level2">
<h2 class="anchored" data-anchor-id="monday-august-7">Monday, August 7</h2>
<section id="astronomers-speak-statistics" class="level3">
<h3 class="anchored" data-anchor-id="astronomers-speak-statistics">Astronomers Speak Statistics</h3>
<p>Astrophysicist Joel Leja kicked off his JSM talk with a video of the launch of the James Webb Space Telescope – an inspiring way to start the day, and a prelude to a discussion of the statistical challenges involved in studying the deep universe.</p>
<p>James Webb, since launch, has “completely expanded our point of view”, said Leja, allowing astronomers to explore the first stars and galaxies at greater resolution than ever before.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/james-webb.png" class="img-fluid figure-img" alt="Image from the James Webb telescope showing two galaxies in the process of merging, twisting each other out of shape." width="500"></p>
<figcaption class="figure-caption">Image from the James Webb telescope showing two galaxies in the process of merging, twisting each other out of shape. Credit: ESA/Webb, NASA &amp; CSA, L. Armus, A. Evan, licenced under CC BY 2.0.</figcaption>
</figure>
</div>
<p>Already, after only 13 months of operation, the images and data sent back by the telescope have left observers astounded: for example, finding suspected early galaxies that are bigger than thought possible based on extreme value analysis.</p>
<p>But the big challenge facing those studying the early universe is trying to work out how early galaxies evolved over time. “We can’t watch this happen,” said Leja, joking that this process lasts longer than a typical PhD. So, instead, he said, “We need to use statistics to understand this, to figure out how they grow up.”</p>
</section>
<section id="teaching-statistics-in-higher-education-with-active-learning" class="level3">
<h3 class="anchored" data-anchor-id="teaching-statistics-in-higher-education-with-active-learning">Teaching statistics in higher education with active learning</h3>
<p>Great talk from Nathaniel T. Stevens of the University of Waterloo, explaining how a posting for a Netflix job inspired the creation of a final project for students to learn response surface methodology.</p>
<p>The job ad in question “really opened my eyes” to the use of online controlled experiments by companies, said Stevens. He told delegates how LinkedIn, the business social networking site, runs over 400 experiments per day, trying to optimise user experience and other aspects of site engagement.</p>
<p>Netflix’s job ad highlighted just how sophisticated these experiments are, said Stevens. People might hear companies refer to their use of A/B tests, but the term trivialises what’s involved, Stevens explained.</p>
<p>Having encountered a job ad from Netflix, looking for someone to design, run, and analyse experiments and support internal methodological research, Stevens was inspired to present students with a hypothetical business problem, based on the Netflix homepage. That homepage, for those not familiar, features rows and rows of movies and TV shows sorted by theme, each show presented as a tile that, when hovered over, leads to a pop-up with a video preview and a match score – a prediction of how likely a viewer is to enjoy the show.</p>
<p>Stevens explained the hypothetical goal as trying to minimise “browsing time” – the time it takes a Netflix user to pick something to watch. Browsing time was defined as time spent scrolling and searching, not including time spent watching previews.</p>
<p>Students were given four factors that might influence browsing time – tile size, match score, preview length, and preview type – and through a sequence of experiments based on data generated by a Shiny app, students sought to minimise browsing time.</p>
<p>The response from the students? Two Netflix-style thumbs up. Ta-dum!</p>
</section>
</section>
<section id="tuesday-august-8" class="level2">
<h2 class="anchored" data-anchor-id="tuesday-august-8">Tuesday, August 8</h2>
<section id="the-next-50-years-of-data-science" class="level3">
<h3 class="anchored" data-anchor-id="the-next-50-years-of-data-science">The Next 50 Years of Data Science</h3>
<p>Stanford University’s David Donoho wrestled with the question of whether a singularity is approaching in this post-lunch session on the future of data science.</p>
<p>Taking his cue from the 2005 Ray Kurzweil book, <em>The Singularity is Near</em>, Donoho reviewed recent – and sometimes rapid – advances in data science and artificial intelligence to argue that a singularity may have already arrived, just not in the way Kurzweil supposed.</p>
<p>Kurzweil’s book argues that at some point after the 2030s, machine intelligence will supersede human intelligence, leading to a takeover or disruption of life as we know it.</p>
<p>At JSM, Donoho argued that we have certainly seen a “massive scaling” of compute over the past decade, along with expanded communications infrastructure and the wider spread of information – all of which is having an impact on human behaviour.</p>
<p>That human behaviour can often now be directly measured thanks to the proliferation of digital devices with data collection capabilities, and this in turn is leading to a major scaling in datasets and performance scaling for machine learning models.</p>
<p>But does this mean that an AI singularity is near? Not according to Donoho. The notion of an AI singularity “is a kind of misdirection”, he said. Something very profound is happening, Donoho argued, and it is the culmination of three long-term initiatives in data science that have come together in recent years. “They constitute a singularity on their own.”</p>
<p>These three initiatives, as Donoho described, are: datafication and data sharing; adherence to the “challenge problem” paradigm; and documentation and sharing of code. These are solid achievements that came out of the last decade, said Donoho, and they are “truly revolutionary” when they come together to form what he refers to as “frictionless reproducibility.”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/donoho-talk.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/donoho-talk.png" class="img-fluid figure-img" alt="Slide text reads: Today's data scientists: typical interactions: What's your package name? What's your URL? QR Code? What's your stack? Today's data scientists: implicit demands: Data sharing, Specific numerical performance measures, Code sharing, Single-click access. Frictionless replications." width="500"></a></p>
<figcaption class="figure-caption">Photo of David Donoho’s slide, describing the scientific revolution of the “data science decade”. Photo by Brian Tarran, licenced under CC BY 4.0.</figcaption>
</figure>
</div>
<p>Frictionless reproducibility, when achieved, leads to a “reproducibility singularity” – the moment where it takes almost no time at all for an idea to spread. “If there is an AI singularity,” said Donoho, “it will be because this came first.”</p>
</section>
</section>
<section id="wednesday-august-9" class="level2">
<h2 class="anchored" data-anchor-id="wednesday-august-9">Wednesday, August 9</h2>
<section id="new-frontiers-of-statistics-in-trustworthy-machine-learning" class="level3">
<h3 class="anchored" data-anchor-id="new-frontiers-of-statistics-in-trustworthy-machine-learning">New frontiers of statistics in trustworthy machine learning</h3>
<p>Data, data everywhere, but is it safe to “drink”? A presentation this morning from Yaoliang Yu of the University of Waterloo looked at the issue of data poisoning attacks on algorithms and the effectiveness of current approaches.</p>
<p>Yu began by explaining how machine learning algorithms require a lot of data for training, and that large amounts of data can be obtained cheaply by scraping the web.</p>
<p>But, he said, when researchers download this cheap data, they are bound to worry about the quality of it. Drawing an analogy to food poisoning, Yu asked: What if the data we “feed” to algorithms is not clean? What is the impact of that?</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/data-hazards.png" class="img-fluid figure-img" alt="A person is illustrated in a warm, cartoon-like style in green. They are looking up thoughtfully from the bottom left at a large hazard symbol in the middle of the image. The hazard symbol is a bright orange square tilted 45 degrees, with a black and white illustration of an exclamation mark in the middle where the exclamation mark shape is made up of tiny 1s and 0s like binary code. To the right-hand side of the image a small character made of lines and circles (like nodes and edges on a graph) is standing with its ‘arms’ and ‘legs’ stretched out, and two antenna sticking up. It faces off to the right-hand side of the image." width="500"></p>
<figcaption class="figure-caption">Illustration by Yasmin Dwiputri &amp; Data Hazards Project / Better Images of AI / Managing Data Hazards / Licenced by CC-BY 4.0.</figcaption>
</figure>
</div>
<p>As a real-world example of a data poisoning attack, Yu pointed to TayTweets, the Microsoft Twitter chatbot that spewed racism within hours of launch <a href="https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist">after Twitter users began engaging with it</a>.</p>
<p>Yu then walked delegates through some experiments showing how, generally, indiscriminate data poisoning attacks are ineffective when the ratio of poisoned data to clean data is small. A poisoning rate of 3%, for example, leads to model accuracy drops of 1.5%–2%, Yu said.</p>
<p>However, he then put forward the idea of “parameter corruption” – an attack that seeks to modify a model directly. Yu showed that this would be more effective in terms of accuracy loss, though – fortunately – perhaps less practical to implement.</p>
</section>
<section id="data-science-and-product-analysis-at-google" class="level3">
<h3 class="anchored" data-anchor-id="data-science-and-product-analysis-at-google">Data Science and Product Analysis at Google</h3>
<p>Our final session at JSM 2023, before heading home, was a whistle-stop tour of various data science projects at Google, covering YouTube, Google Maps, and Google Search.</p>
<p>Jacopo Soriano kicked us off with a brief intro to the role and responsibilities of statisticians and data scientists at Google, and within YouTube specifically – the main task being to make good decisions based on uncertain data.</p>
<p>Soriano also spoke about the key role randomised experiments play in product development – harking back to Nathaniel Stevens’ earlier talk on this subject. YouTube runs hundreds, if not thousands, of concurrent experiments, Soriano said; statisticians can’t, therefore, be involved in each one. As Soriano’s colleague, Angela Schoergendorfer, explained later in the session, the role of the data scientist is to build methodology and metrics that others in the business can use to run their own experiments.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/google-sign.png" class="img-fluid figure-img" alt="Google logo on top of building, against a blue sky." width="500"></p>
<figcaption class="figure-caption">Photo by Pawel Czerwinski on Unsplash.</figcaption>
</figure>
</div>
<p>For every experiment YouTube runs, a portion of its voluminous daily traffic will be assigned to control arms and treatment arms, with traffic able to be diverted to different groups based on user type, creators, videos, advertisers, etc. Once experiments are running, metrics such as search clickthrough rates, watch time using specific devices, or daily active user numbers are monitored. Teams tend to look at percentage change as the scale to measure whether something is working or not, said Soriano, rather than comparing treatment to control group.</p>
<p>Next up was Lee Richardson, who spoke about the use of proxy metrics. Technology companies like Google are often guided by so-called “<a href="https://www.forbes.com/sites/forbesbusinesscouncil/2022/11/11/what-is-your-startups-north-star-metric/">north star metrics</a>”, which executive leadership use to guide the overall strategy and priorities of an organisation. However, Richardson said, these can be hard to design experiments around, and so proxy metrics stand in for the north star metrics. Proxies need to be sensitive, he said, and move in the same direction as, e.g., a long-term positive user experience.</p>
<p>On the subject of user experience, Christopher Haulk then explained how YouTube measures user satisfaction through single-question surveys – typically asking a YouTube user to rate the video they just watched. The company doesn’t send out that many surveys, Haulk said, and response rates are in the single-digit percentage range, so it can be hard to evaluate whether changes YouTube makes to, e.g., its video recommendation algorithm are working to improve user satisfaction. Haulk then went on to explain a modelling approach the company uses to predict how users are likely to respond in order to “fill in” for missing responses.</p>
<p>Over at Google Search, user feedback is also regularly sought to help support the evolution of the product. Angela Schoergendorfer explained how, with so many people already using Google Search, statistically significant changes in top-line metrics like daily active users can take months to see. Decision metics should ideally capture user value quickly, said Schoergendorfer – within days. For this, Google has 10,000 trained “search quality” raters they can call on. Random samples of user search queries and results are sent to these raters, who are asked to evaluate the quality of the search results. Users can also be asked in the moment, or offline through the Google Rewards app.</p>
<p>In 2021, Schoergendorfer said, Google conducted approximately 800,000 experiments and quality tests. But perhaps the most impressive statistic of the day came from Sam Morris, who works on Google Maps. Something, somewhere, is always changing in the world, said Morris – be it a road closure or a change to business hours. The Maps team cannot evaluate every single piece of data – a lot of changes are automated or algorithmic, he explained. “So far this year, we have probably processed 16 billion changes to the map,” said Morris – a staggering figure!</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Live from Toronto: Real World Data Science at the Joint Statistical Meetings.” Real World Data Science, August 6, 2023, updated August 15, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>Conferences</category>
  <category>Events</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/jsm-blog.html</guid>
  <pubDate>Tue, 15 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/08/06/images/google-sign.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>The many ‘dialects’ of data visualization: Alberto Cairo and ‘The Art of Insight’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html</link>
  <description><![CDATA[ 




<p>Alberto Cairo is Knight Chair in Visual Journalism at the School of Communication of the University of Miami (UM). He’s also the director of visualization at UM’s Institute for Data Science and Computing. He joins Real World Data Science to discuss his upcoming book, <em>The Art of Insight: How Great Visualization Designers Think</em>, in which Cairo reflects on his conversations with data artists, data journalists, and information designers.</p>
<p>“If we can conceptualise data visualization as language, this language can have multiple dialects,” says Cairo. “And these dialects – let’s say the statistical dialect, the data journalism dialect, the art dialect – they are not mutually exclusive. They exist, or they should exist, ideally, in constant conversation with each other. So, we can borrow ideas from each other, learn from each other.”</p>
<p>Listen to the full interview below or on <a href="https://www.youtube.com/watch?v=htUWWVzYTUI">YouTube</a>.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/htUWWVzYTUI" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Find out more about Cairo’s work and his upcoming book at <a href="http://www.thefunctionalart.com/">thefunctionalart.com</a>.</p>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to Real World Data Science. I’m Brian Tarran. And today I’m joined by Alberto Cairo, Knight chair in visual journalism at the School of Communication of the University of Miami. He’s also the director of visualization at UM’s Institute for data science and computing. Alberto, welcome. Thanks for joining us.</p>
<p><strong>Alberto Cairo</strong><br>
Hi, Brian. Very nice to be here. Thank you for inviting me.</p>
<p><strong>Brian Tarran</strong><br>
No worries. Well, today we’re excited to be discussing your new book, The Art of Insight: How Great Visualization Designers Think. I think it’s a really– I’ve not read all of it yet. I’ve dipped in and out of some chapters that you kindly sent me ahead of time. I think it’s really interesting and unique. I think the thing that struck me was often when we talk about visualization design, we tend to concentrate on what designers do, not necessarily about how they think about what they do, or how they think generally. And so, that was to be my first question for you is like, what aspects of their thought processes, these experts, what were you really trying to understand and why?</p>
<p><strong>Alberto Cairo</strong><br>
Yeah, yeah, this latest book of mine is very different to the previous one that I– that I wrote. The book is not out yet, by the way, the book will be out in November of 2023. I am in the process of copy editing it, getting rid of typos. But as you said, I mean the book focuses not so much on the– on the work itself, but more on the people who produce the work and the motivations and values that lie behind the work that they do. It is also, in comparison to my previous books, it is also a shift of perspective, I would say because my previous books, particularly The Truthful Art and How Charts Lie which came out in 2019, focus mostly on statistical visualization. Right, so it has a very strong, they both have a very strong statistical focus – how to make sure that your graphs and your data maps don’t deceive people. I teach elementary principles of visualization, of communication through visualization. But visualization is much more than that. And that is what I wanted to convey with this book. More and more throughout the years, I have come to understand data visualization not so much as a representation of data for insight or for communication, but as a language, a language that can be used for many different purposes. And I try to reflect that in the book. Obviously, a great part of the book is devoted to people who come from the same world where I come from, the professional world where I come from, the world of data journalism, so plenty of them are data journalists. Many of them are data analysts and statisticians and researchers. But a good portion of the book is devoted to people who use– who use visualization for other purposes such as self expression, self discovery, art in some cases. I wanted to provide a sort of like a broader understanding of the language of visualization and I also talk about– I also discussed the fact that if we can conceptualize data visualization as language, this language can have multiple dialects. And that is what I wanted to convey in the book. And these are not, these dialects – let’s say the statistical dialect, the data journalism dialect, the art dialect – they are not mutually exclusive. They exist, or they should exist, ideally, in constant conversation with each other. So we can borrow ideas from each other, learn from each other. So I wanted to provide sort of like an overview of the huge diversity that exists in the world of visualization – in terms of people, in terms of race, in terms of gender, but also in terms of the dialects that people use.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, and is that almost pushing back a little bit at this idea that, you know, if visualization is a language in the same way that English is or Spanish is or whatever it might be, that there are– there must be rules that people have to follow?</p>
<p><strong>Alberto Cairo</strong><br>
Yeah, I push back against that a little bit in the book because obviously, I mean, what I have taught and what I continue talking– talking about at the– talking about at the University of Miami, what I teach my classes, is what you could call let’s say standard data visualization, right? Data visualization for communication. I discuss a lot about, you know, cognitive science, you know, perception, you know, how to apply that, colour palettes – I just do standard data visualization. But that is just one of the dialects that data visualization has, right? Data visualization can be used for journalism, for business analytics, for statistics, for art, for expression, for self discovery – some of the people who I interviewed, plot their own data, for example, their own health metrics, as a way to reduce their own anxiety. So I interviewed, for example, a person who has gone through– who in the past went through very serious health problems like cancer, brain cancer and other health problems, and he discovered that the process of designing visualizations based on his own data was similar to– had similar effects as meditating about your own thoughts, right. It was a way to pour your anxiety and your dark feelings onto the graphic, so they will not overburden your mind. I find that absolutely fascinating. And it shows you that, I believe, that’s what I– what I reflect in the book, that there are really no universal rules in data visualization. There are parochial rules that are applicable to different– to the different dialects. But it is it is wrong, it is a mistake, to apply the standards of one of the dialects of data visualization to a completely different dialect of data visualization. Every visualization, I feel or I think, should be judged according to their own terms, to the terms in which they were created.</p>
<p><strong>Brian Tarran</strong><br>
The book is essentially set out as a series of discussions with these visualization designers, right. And then it’s your interspersed reflections on the conversations and things that you’re sort of taking away from them. And when you were saying in the introduction about why you wanted to have these conversations, you say you were kind of looking to, or needing to, rekindle your love for the design of information. So I wanted to ask you, maybe I’ve misjudged that sentence, but you know, had you fallen out of love with the design of information? Or did you just kind of get to that point where you thought, oh, there must be more to it than this, the way I– the way I work. What was the– what was the motivating force driving you down this path?</p>
<p><strong>Alberto Cairo</strong><br>
It’s not that I stopped, you know, being in love with data visualization, or more broadly with information design, because I teach information design – data visualization is one of the branches of information design. So I also teach, you know, illustration driven visual explanations – how an airplane works, and you do a cutaway of the airplane and you show the engines and how they work. I also do that type of information design. So it’s not that I ever stopped being in love with– with the work that I do. As I explain, by the way, in the conclusions of the book, in the epilogue of the book, which circles back to the themes in the prologue, information design and data visualization are a great part of who I am as a person. To me, it’s a way of life. I use visualization not only to communicate with other people, I use visualization also to study. When I am reading a book, I am probably producing a visualization of the book, like some sort of network diagram, in which I plot all the ideas from the book. That’s a technique, a mnemonic technique, that I learned from my– from my father, who is a medical doctor, but also a humanist. He taught me this technique to study: when you’re reading a book, just write down the concepts that you’re learning about, and then connect them with arrows make little comments on the side. Indirectly he was teaching me to make data visualization. So data visualization, information design has permeated my life since I was very, very young – since I– since I didn’t have the language to talk about what I was doing. But at the same time, in the past three or four years, many personal circumstances led me to feel, let’s say, my morale went down quite a lot, the pandemic also and then some personal problems and stuff. And I started feeling a little bit disillusioned with my own– with my own work, like having self doubts, right? Am I doing the right thing? Am I in the right career? Should I be doing something else? Have I written everything that I wanted to write about this field? Have I designed every graphic that was worthy to be designed? And I felt the need to connect with other people. Because something that I discovered throughout the years is that we human beings, we don’t think well when we are alone, we think better when we are in connection with others. So my conversations with the many friends that are showcased in the book, obviously I wanted to give their work and their lives and their values visibility because I believe that they are worthy to be explored and understood by readers. But it was also a way for me to sort of like recover a little bit of the passion that I had about information design in the past – and I was successful. I mean, I went out of– The process of writing a book can be grueling. So, while you’re writing a book, you’re always thinking, you know, this is crap. What is it that I’m doing? I don’t know where I’m going. But in hindsight, now that the book is written, and I am reviewing it, I am thinking, hmm, this is not bad. This is not bad, right? And I discovered that I was– I felt energized, thanks to all these conversations with tons of inspiring people from all over the world.</p>
<p><strong>Brian Tarran</strong><br>
I think I can sort of sympathize with that, you know, the process of creating – I don’t do data visualization myself – but creating content, it can be quite a lonely process sometimes. And you do have that, I always talk about the roller coaster of emotions – of the peaks, were you think you’re doing a great job, and then the troughs where you’re like, Oh, my God, why or I should just throw it all in. So actually being able to sit down and talk to people and share ideas does inspire you, does sort of bring you back up again, doesn’t it? But I was worried, actually, that because the last time we spoke was, I think, around the time that How Charts Lie had come out, and you were interviewed by one of our freelance writers on Significance magazine – where I was at the time – and I thought, oh, no, maybe– maybe all that encountering the dark side of data visualization and all that misinformation that was out there…</p>
<p><strong>Alberto Cairo</strong><br>
That I felt depressed, right, because the book was useless, or not useless. But I mean, it was not read by the people – How Charts Lie, I mean – it was not read by the people who needed to read the book.</p>
<p><strong>Brian Tarran</strong><br>
That is always the case with these books, isn’t it? So they– they’re really valuable, if only you could get them in the hands of the right people. That’s the challenge.</p>
<p><strong>Alberto Cairo</strong><br>
We preach– We preach to the choir a little bit with these type of books, unfortunately, yeah.</p>
<p><strong>Brian Tarran</strong><br>
Well, I still enjoyed it anyway. And it’s always valuable to, to listen to experts like yourself and take learnings from those. So the, the things that– the interviews I’ve read, I’ve not read all of them, but I think the things that jumped out for me – the interviews with people like Ed Hawkins, talking about the Warming Stripes, you know, talking about how their focus is less about – and tell me if I’m mischaracterizing this – it’s less about direct communication of information or data, it’s more about conveying like a feeling or an intuitive understanding of something. And obviously, warming stripes, most people have seen those, you know – the kind of plots of changes in temperature against a baseline over time and the kind of rapid shift to deeper, darker shades of red as we get closer to the present, you know – I think they do create a sense of the urgency of the climate crisis when you just look at them. But what lessons do you as a kind of, you know, as a data visualization designer, a journalistic data visualization designer, what do you take from those sorts of examples, where it isn’t direct communication, of information or data, it’s about feeling? What can you– what can you take from that and bring to your own work?</p>
<p><strong>Alberto Cairo</strong><br>
Well, the fact, as I was saying before, that not all visualizations are alike, as I explained in that chapter. Hawkins got a little bit of pushback, because that visualization broke some rules – and I’m doing sort of like scare quotes with my fingers right now, right? It broke some rules because it doesn’t have axes, it doesn’t have scales. It’s just a beautiful picture. But that is valuable, that is valuable, and it’s proven that it is valuable. It’s one of the most popular data visualizations in history already. And he, it’s a perfect example of a match between purpose and outcomes. And that is what needs to be explored when evaluating a data visualization. So, Hawkins told me when I interviewed him that he didn’t want to create an analytical data visualization. If he wanted to do that, he will do a line chart with like error bars or whatever, right? Something that you could publish in a paper. He has done thousands of those types of graphs. But this graphic was originally designed to bring to a festival, to be displayed in the background while there was a conversation going on about climate change. So it was designed with the specific and explicit purpose not to provide an analytical tool to explore the data but as something that brought attention to the information, something that ignited curiosity in the viewers. And I think that if that is the purpose, the outcomes actually match really well what he had in mind, and therefore the visualization works. That’s a visualization that works. So that’s just one of the many examples that appear in the book, of graphics that somehow defy conventions but at the same time, according to their own predefined purposes, work pretty well. So we have the example, for example, from Jaime Serra, who is a designer from Spain who is a– he’s a data visualization designer, he has worked for many, many years for newspapers. But the type of graphics that he creates blend the artistic with the– with the statistical and the analytical. He uses objects, for example, to create data visualizations to– he comes up with these beautiful pieces that sometimes he has showcased in exhibits all over the– all over the world. But then I also talked to people who produce what we could call more conventional data visualizations, right – people who work in public health, right, people who work in data journalism, people who live in countries where, you know, producing accurate and truthful data visualization can be dangerous to your career, right? I talk, for example, to Attila Bátorfy, who is a data journalist working in Hungary, and obviously Hungary, right now, considering the Viktor Orban regime, it’s not very friendly to journalists who want to be accurate and truthful. And he tries to be, and he’s very successful in Hungary right now, right? He’s a, he’s a voice against authoritarianism in his country. Or Anatoly Bondarenko, who is a data journalist and data visualization designer from Ukraine, who years ago created an organization called Texty, which is an investigative reporting newsroom in Ukraine, a nonprofit in Ukraine, to investigate corruption in the Ukrainian government but also Russian interference in Ukraine prior to the war. And, and that is one of my favorite chapters, because I’m Anatoly is a good friend of mine, and he’s, he’s fighting. He’s part of the Ukrainian army. And I think about him on a regular basis. And I am in touch with him just to make sure that he’s– that he’s safe, that he’s doing good. That chapter begins with a sentence that says that I sometimes wake up in shock thinking about, you know, my friend is at war, right? That’s such a strange thought and his work is so valuable, it’s so impressive. Again, what I find inspiring in all the people I talk to, I talk with, in the book is not just the work itself, it’s the values and the motivations behind the work and sometimes the resilience of the people producing that work. That’s what I find inspiring.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, yeah, I was– when you were talking there about the Hawkins warming stripes examples, the– the idea of evaluating visualizations, you know, on their own terms, on their kind of their stated purposes, I think is quite important. But do you think people creating data visualizations, do they spend enough time thinking through generally – not the experts you’ve talked to, obviously, they’re the maybe the exception – but about what the purpose– what is it that I want to achieve with this data visualization? Is that kind of one of the things that all your interviewees have in common, a very clear sense of purpose?</p>
<p><strong>Alberto Cairo</strong><br>
They do. They do have that sense of purpose. That doesn’t mean that they don’t sometimes create these great visualizations out of a whim – say, I’m gonna just create a pretty graphic based on that, no purpose whatsoever. And that’s perfectly fine. Again, the analogy with writing. Not all writing can be technical writing. That’s just one of the types of writing that we could use. And conventional, traditional visualization is analogous to technical writing – you want to communicate something effectively, clearly, and therefore you try to create something that doesn’t use too many words, or too many, you know, verbal flourishes, you just go directly to the point and try to communicate directly. But that’s not the only way you can use writing. You can write poetry, so why not using data visualization to create visual poetry? That’s perfectly, perfectly fine. Again, every visualization needs to be judged based on their own– on their own stated purposes. As to the question of whether people in general – like, not the people I talked to in the book, for the book – but, you know, people in general think about purpose when designing data visualizations, that’s a question that I cannot answer. But that’s the core of my classes and workshops. It’s like my classes and workshops outline, both at the university but also as a consultant, put a lot of emphasis on the purpose part. I mean, just list what do you want to communicate? What do you want to achieve? Create an actually a bullet point list of what you want to communicate, and based on that list, then you can make choices. The way that I teach data visualization these days is not about teaching rules, right? Like, you know, use a bar graph to compare, use this graphic for that, use a scatterplot to show associations between, you know, continuous variables or whatever. No, that’s not the way I teach visualization. I teach visualization based on a process of reasoning, right? Reason that takes you from the purpose to the outcome. And every decision down the road in between those two points needs to be somehow justified. You need to justify every decision that you make in the visualization in a way that is– that can be persuasive to other people who may be in your team. I use this colour palette because, and what comes after the because is the important part. I use this type of graphic because, and what comes after the because is the important part, and so on and so forth.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, there’s something that struck me. I think it was a podcast producer who came up this idea of the XY story formula – that’s how you assess the value of a kind of an article pitch. Now, I’m writing a story about X, and it is interesting because Y – and it’s the bit that follows after the “because” that determines– you have to work on that and refine that, and that’s what shapes your story and your outputs. I’m glad you brought up teaching as well, because I was reading through the epilogue, and it said about you having “anarchic leanings and sympathies” and I was kind of curious about how those sympathies and leanings manifest in your work or in your teaching. And obviously, you said you don’t teach rules. So maybe that’s part of it. But…</p>
<p><strong>Alberto Cairo</strong><br>
What sympathies are you referring to?</p>
<p><strong>Brian Tarran</strong><br>
I don’t know. It was just that phrase jumped out: I have, I have anarchic– I think it’s “despite my anarchic leanings and sympathies”, and I was kind of curious as to what are those, and how do they– how do they manifest?</p>
<p><strong>Alberto Cairo</strong><br>
Well, one of the points that I make, particularly in the epilogue, which I think that is the most important part of the book, because it’s where I lay out my own thinking – is that, one of the points that I make is that you cannot really separate the work from the people. And I make the analogy with philosophy, I read a lot of philosophy. There is this book that I absolutely love about philosophy, titled “What is Ancient Philosophy?” by Pierre Hadott, who was, I think that he was French – wonderful book, absolutely wonderful book if you’re interested in the ancient history of philosophy, that book is amazing. Talks about the Hellenistic tradition of philosophy. I could go on and on and talk about that book. I absolutely love it. I think that I read it four times, something like that. And the point that Hadott makes in “What is Ancient Philosophy?” is that it takes you a long way to understand the philosophy of the, you know, the classics – Plato, Aristotle, and then the Hellenists like the Epicureans, or the Stoics, or whatever – it takes you a long way if you sort of like understand the temperament of those people, and their lived experiences, what they went through in their lives, right? If you understand, for example, what Plato lived, his times and his temperament, and also the history of the times when he lived, you can understand the Republic better, his best book, right? You, you sort of like guess where it comes from, right, where his thinking comes from. And I think that’s something similar can be said about visualization, right? I have my own temperament. I have a– I have a very driven temperament. So I’m quite a strong will – when I decide that I’m going to do something, I usually put the energy to do it. But at the same time, I’m quite anarchic, not in the sense of being disorganized, but in the sense that I don’t deal with authority well. I just want to be left alone, right? Just leave me alone. I will figure things out on my own. I work well with other people, right. But in horizontal organizations, I enjoy horizontal teams, rather than hierarchical teams, right. I work really well in horizontal teams. And that is somehow reflected, I think, in the way that I think about data visualization. I somehow rebelled against, you know, the 1980s, 1990s tradition of data visualization teaching around what I call the Tuftean – after Edward Tufte – the Tuftean tradition of saying, this is the only way to do visualization well, these are the rules of data visualization. Well, why? Why are those the rules? Tell me what is this based on, or is it just your own opinion? I mean, I enjoy reading Tufte and I enjoy reading, you know, people like Steven Few, who is a friend of mine, etc. But at the same time I rebelled against that tradition, because in many cases, as I explain in The Art of Insight, many of those so called rules are merely the opinions of people. This is just my opinion. I like this stuff. I like this style, and therefore, I’m going to try to pass my own opinion as if it were a rule of design. I think that we need to be a little bit more honest about what we are doing. Many of those rules are not really grounded on any sort of empirical evidence, and therefore they are still valuable – I think that people should keep reading Tufte, they should keep reading [unclear] and many of the, we should keep reading them. But always with a pinch of salt, taking everything that we read with a pinch of salt, and this applies to my own books as well. We need to be a little bit more skeptical, a little bit more flexible in some sense, knowing that we are on these together and what really matters, I think, is the conversation between people in the field. Conversation is a word that appears a lot in The Art of Insight. I see my work, and I see the work of everybody else who writes or thinks or makes data visualizations as part of an ongoing conversation between people in which we can learn from each other, borrow from each other – always understanding that our opinions can be strongly stated, but sometimes they have very, very shaky foundations.</p>
<p><strong>Brian Tarran</strong><br>
What you’re saying about the importance of still reading these kinds of texts, where the rules – again, in inverted commas – are set, the importance of doing that, that kind of reminded me of like in my, in my own world of, you know, the written word, people like James Ellroy, the author of American Tabloid, you know, about understanding the rules of grammar so that you know how to break them for effect and for impact and things like that. So I can see how that applies to data visualization.</p>
<p><strong>Alberto Cairo</strong><br>
It is, yeah, that’s sort of like already has become a cliche, right: learn the rules, so you can break them. I think that that is valuable. But at the same time, I think that we need to go beyond that and say, there are really no rules. I mean, there are a few things that could be considered rules. For example, we know that, you know, if you want to compare numbers, a bar graph is usually superior to a pie chart, for example. We know that, there is empirical evidence behind that, so you can sort of like derive a principle out of that, right? But beyond those very basic things, there are really not many rules. What there are is a lot of conventions, inherited conventions, right, that historically have developed and we have– we have inherited. So we could say, you know, it’s good to learn the conventions. It is still good to learn about perception and cognition to guide your decisions. But after you do that, all that matters is the choices that you make with the knowledge that you have, and with the guesses that you can make. Right? So it’s not that you’re breaking the rules, you’re creating your own path, based on the inherited knowledge that you have under your belt.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. My last question for you – because I don’t want to take up too much of your time, I know you are very busy, Alberto – is, you mentioned, again, going back to the previous question, or two, the people that you work with, and one of those sometime collaborators is Shirley Wu, who you refer to in your introduction, and I was really struck by the description of the installation, the number of COVID deaths each week, and this this dripping valve. I think what struck me most was that, you know, obviously, Shirley had this idea that the drips would represent the number of COVID deaths each week, these drips into a bowl, but that this wasn’t explicitly stated to people viewing the installation, right? She created space for viewers to bring their own interpretations, and they did. And again, it’s one of these things that I think is a beautiful idea – being able to, to withhold some information – but I don’t know, how does that manifest if you’re, you know, a data scientist or whatever, and you’re trying to create visualizations for, you know, an internal client or whatever it might be. How do you kind of bring some of that, that flavor and that interpretation and that space, to a graphic? I think that’s something that I was thinking about when reading that book, that part of the book.</p>
<p><strong>Alberto Cairo</strong><br>
There are many examples like that in the book. For example, in the chapter about Jaime Serra, Jaime created once a graphic in which– he drinks a lot of coffee, and he wanted to – remember that one – he wanted to, he wanted to see how much coffee he was actually drinking throughout a year. And if I have to do that, I will, you know, I will get my mug, the mug that I use every day to drink my coffee, I will draw a scale on top of that, and then I will measure the number of ounces of coffee that I’m drinking. At the end of the year, I will probably design a line graph, a time series line graph, to see whether there is any seasonality in my coffee consumption. I will design an analytical chart or so to speak, right, a graphic to analyze my own data. But he wanted to design something a little bit more fun, a little bit more expressive, a little more artistic and what he did was to create a graphic in which he plotted the amount of coffee that he drinks throughout a year through coffee stains. He got 12 pieces of paper, each one of them corresponding to a month. He folded those pieces of paper to subdivide them into quadrants, each one corresponding to a day. And then whenever he was drinking coffee, he tried to leave a coffee stain on the corresponding quadrant of the corresponding paper. And the result was sort of like it was a physic– it’s a physical data visualization. And it is amazing. Now, does that mean that you can insert that type of graphic, let’s say, in a business dashboard, or on a quarterly report in a company? No, that’s not the purpose of that type of visualization. The way that I usually explain the value of that type of visualization is to create this sort of like hypothetical scenario. And I have used these many times with clients when presenting you know, Shirley’s work or Jaime’s work. I say this is not the type of graphic that you use for analysis, right. For analysis, you need to use line graphs, bar graphs, scatter plots, traditional conventional data visualizations. But let’s suppose that you, for some reason, one year you conduct a survey internally in your company to analyze how much coffee people drink in the company, right? And you do sort of like this beautiful report that you print out as a hardcover book to give to your own clients as a gift when they come to visit you. What do you put inside of the book? The analytical graphics, right? The analytical charts that slice and dice the data by gender, by location, by whatever? You put all the conventional traditional graphics? What do you put on the cover? What you put on the cover is the beautiful artistic data visualization, which is still a data visualization. And same thing with Shirley’s work, right. Shirley’s installation about COVID: true, it’s not a graphic. It’s not a visualization. It’s not really a graphic because it’s physical. It’s a physical installation. But it is not a visualization that is intended to communicate the data in any sort of like, with accuracy or anything, it just tries to create a feeling. So again, imagine that you work for let’s say, a company focusing on public health or whatever. And every day, what you produce will be conventional charts and graphs and maps. That’s what we need to use to analyze data. But let’s suppose that you want to create some sort of like beautiful piece of artwork to display in your headquarters. That will be an amazing piece to display in your headquarters. It will get people– it will get visitors curious about what you do, it may drive– it may lead you to conversations about the data that they deal with everyday, the same way that Ed Hawkins’s warming stripes graphic did. It’s just a different type of data visualization that needs to be judged according to its own purposes, under its own terms.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, fantastic. Well, that’s a really nice idea to end on. Hope some people take it forward, and future visits to offices will be more visually appealing as we get to explore those spaces. So, Alberto, thank you very much. So the book is out in November, yes?</p>
<p><strong>Alberto Cairo</strong><br>
November the 15th. Yeah.</p>
<p><strong>Brian Tarran</strong><br>
Is there a website yet that people can go and find out more details?</p>
<p><strong>Alberto Cairo</strong><br>
No, still working on it. For now, there is some information in my weblog, which is the title of my first book, The Functional Art. So, it’s thefunctionalart.com. That’s my web blog. And there’s some information about The Art of Insight there, including some, you know, some sneak peeks.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Well, we’ll put a link to that in the in the show notes. So, Alberto, thank you for joining us today. Best of luck finishing up the book and the website. And I hope you can join us again soon because there’s so much more that I could discuss about the book with you, but it’s been great talking to you today.</p>
<p><strong>Alberto Cairo</strong><br>
Thank you, Brian.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Images are not covered by this licence. Photo of Alberto Cairo is copyright JCA Photography.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “The many ‘dialects’ of data visualization: Alberto Cairo and ‘The Art of Insight.’” Real World Data Science, August 1, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Data visualisation</category>
  <category>Communication</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/alberto-cairo.html</guid>
  <pubDate>Tue, 01 Aug 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/08/01/images/alberto-cairo.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘Go out and talk about data science, particularly to schoolchildren’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/schools-outreach.html</link>
  <description><![CDATA[ 




<p>Rachel Hilliam, statistics professor at The Open University, used her inaugural lecture this month to make “a real plea” to the data science community “for outreach into schools”, to help build excitement and awareness of the promise and potential for careers in data science.</p>
<p>“We have a plethora of jobs that we cannot fill in data science at the moment,” said Hilliam. “We’ve had all sorts of initiatives in terms of trying to retrain people, and that’s great, and those are gaps that we need to plug. But unless we get that pipeline coming through, we’re always going to have this problem at the top.”</p>
<p>Hilliam, who is chair of the <a href="https://alliancefordatascienceprofessionals.co.uk">Alliance for Data Science Professionals</a>, wants schoolchildren and teachers to be made more aware of the benefits of, and opportunities for, data science careers. “Let me tell you,” she said, “if you go out into a school and say, ‘Do your kids want to be a data scientist?’, the teachers will look at you and go, ‘A what?’. They have no idea, generally, that data science actually exists, which is a shame.”</p>
<p>But there are plentiful opportunities to introduce data science to children, Hilliam suggests. She began her talk by saying that: “Data is everywhere – in every single thing that we do, in all of our walks of life.” And she concluded by saying: “Whatever it is that these kids are interested in, […] there is lots of data out there, so there is absolutely no reason why we can’t excite children in a career in data science. So, that’s where I’d like to finish. Go out and talk about data science, particularly to schoolchildren!”</p>
<p>Watch the lecture in full below or on YouTube. Skip to <a href="https://www.youtube.com/live/tCQhU4yP0OU?feature=share&amp;t=1024">17:04</a> for the start of the talk.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/tCQhU4yP0OU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail photo by <a href="https://unsplash.com/@neonbrand?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Kenny Eliason</a> on <a href="https://unsplash.com/photos/zFSo6bnZJTw?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘Go out and talk about data science, particularly to schoolchildren.’” Real World Data Science, July 27, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/schools-outreach.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Education</category>
  <category>Data literacy</category>
  <category>Outreach</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/schools-outreach.html</guid>
  <pubDate>Thu, 27 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/27/images/kenny-eliason-zFSo6bnZJTw-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Testing out ChatGPT’s new Code Interpreter</title>
  <dc:creator>Lee Clewley</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/code-interpreter.html</link>
  <description><![CDATA[ 




<p>On July 6, 2023, <a href="https://twitter.com/OpenAI/status/1677015057316872192?s=20">OpenAI began rolling out the Code Interpreter plugin</a> to users of its ChatGPT Plus service. But what exactly is this, and what functionality does it offer?</p>
<p>Code Interpreter runs code and allows for uploading data so you can use ChatGPT for data cleaning, preprocessing, analysis, visualisation and predictive modelling tasks, among other things. This tool holds great promise for programmers and analysts alike, with the potential to streamline coding workflows as well as having an automated data analyst at your fingertips.</p>
<p>To use Code Interpreter, you need to enable it in the ChatGPT settings (at time of writing this only works with a paid ChatGPT Plus subscription).</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic1.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic1.png" class="img-fluid figure-img" alt="Screenshot of ChatGPT Plus setting, showing Code Interpreter plugin option." width="700"></a></p>
</figure>
</div>
<p>Now, let’s take it for a bit of a spin by uploading the <a href="https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset">stroke prediction dataset from Kaggle</a>.</p>
<section id="the-stroke-prediction-dataset" class="level2">
<h2 class="anchored" data-anchor-id="the-stroke-prediction-dataset">The stroke prediction dataset</h2>
<p>The World Health Organization (WHO) identifies stroke as the second leading cause of death worldwide, accounting for roughly 11% of all fatalities.</p>
<p>Kaggle’s stroke prediction dataset is used to forecast the likelihood of a patient suffering a stroke, taking into account various input parameters such as age, gender, presence of certain diseases, and smoking habits. Each row in the dataset offers pertinent information about an individual patient.</p>
<p>Loading this dataset into ChatGPT Code Interpreter, one is treated with:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic2.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic2.png" class="img-fluid figure-img" alt="Screenshot from ChatGPT, showing Code Interpreter's initial review of an uploaded stroke prediction dataset." width="700"></a></p>
</figure>
</div>
<p>The user is asked: “Please let me know what analysis or operations you’d like to perform on this dataset. For instance, we can perform exploratory data analysis, data cleaning, data visualization, or predictive modelling.”</p>
<p>It seems quite a bold claim. So, I asked it to do all of the above.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic3.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic3.png" class="img-fluid figure-img" alt="Screenshot from ChatGPT, showing Code Interpreter's overview explanation of planned analysis steps." width="700"></a></p>
</figure>
</div>
<section id="exploratory-data-analysis" class="level3">
<h3 class="anchored" data-anchor-id="exploratory-data-analysis">Exploratory Data Analysis</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic4.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic4.png" class="img-fluid figure-img" alt="Screenshot of ChatGPT Code Interpreter's exploratory data analysis outputs." width="700"></a></p>
</figure>
</div>
<p>This is a good, useful summary. The missing values in <code>bmi</code> are set to the median, which the user can later decide to change for themselves as the code is available to do so.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic5.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic5.png" class="img-fluid figure-img" alt="Screenshot of code output from ChatGPT Code Interpreter, showing how to set missing values in dataset to the median value." width="700"></a></p>
</figure>
</div>
</section>
<section id="data-visualisation" class="level3">
<h3 class="anchored" data-anchor-id="data-visualisation">Data visualisation</h3>
<p>Next, the visualisations of the variables are shown along with a correlation heatmap. Users can toggle between the visualisations and the code. The outputs are pretty useful, except for one mistake: <code>id</code> shouldn’t be included as part of the heatmap.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic6.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic6.png" class="img-fluid figure-img" alt="Screenshot of ChatGPT Code Interpreter's description of visualisations it will create, along with partial code for doing so." width="700"></a></p>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic7.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic7.png" class="img-fluid figure-img" alt="Histograms and bar plots created by ChatGPT Code Interpreter for variables in the Kaggle stroke prediction dataset." width="700"></a></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p>Histograms and bar plots created by ChatGPT Code Interpreter for variables in the Kaggle stroke prediction dataset.</p>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic8.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic8.png" class="img-fluid figure-img" alt="Correlation heatmap for variables in the Kaggle stroke prediction dataset." width="700"></a></p>
</figure>
</div>
<div class="figure-caption" style="text-align: center;">
<p>Correlation heatmap for variables in the Kaggle stroke prediction dataset.</p>
</div>
<p>Things start to go seriously awry when Code Interpreter tries to create a predictive model.</p>
</section>
<section id="the-predictive-model-is-garbage" class="level3">
<h3 class="anchored" data-anchor-id="the-predictive-model-is-garbage">The predictive model is garbage</h3>
<p>From the screenshot below, you can see that lumping all the data into a predictive model creates some highly spurious results. Age is a factor, as it should be, as is hypertension – indeed, those with hypertension in this dataset are around three times more likely to have a stroke than those without. In reality, there are also significant effects from glucose level and smoking, and also a slight BMI effect in this small, unbalanced dataset. However, <code>work_type_children</code> having a large positive effect is alarming and plainly wrong.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic9.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic9.png" class="img-fluid figure-img" alt="Screenshot showing ChatGPT Code Interpreter's most important features for predicting stroke. The inclusion of 'work_type_children' is wrong: it says that 'individuals who are children are more likely to have a stroke', but goes on to explain that 'this might be the result of an imbalance in the dataset or noise, as in reality, children generally have a lower risk of stroke." width="700"></a></p>
</figure>
</div>
<p>It is very evident from the table below that the positive coefficient on children is spurious.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><a href="images/pic10.png"><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/pic10.png" class="img-fluid figure-img" alt="Screenshot of table from ChatGPT code interpreter, showing 'number of individuals' and 'number of strokes' for each 'work type'. Figures for children are 687 individuals and 2 strokes." width="700"></a></p>
</figure>
</div>
<p>So, where does this leave our thinking about Code Interpreter?</p>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">Discussion</h2>
<p>My test case is possibly an unfair one. The sort of study presented to Code Interpreter is one that requires careful analysis, and it uses a relatively small, tricky dataset whose difficulties are compounded by missing data. It’s therefore not surprising that, in this context, an automated analysis fails to shine in all respects.</p>
<p>To be fair, OpenAI themselves describe the plugin as an “<a href="https://openai.com/blog/chatgpt-plugins">eager junior programmer</a>”. And as would be the case with a real junior programmer or junior data scientist, you’d expect a more experienced hand to be guiding an analysis like the one I asked for – someone who can sense-check results, point out errors, and offer suggestions for fixes and improvements.</p>
<p>Despite some stumbles in this demo, OpenAI’s “junior programmer” presents a real step forward in the ChatGPT offering, and it is particularly impressive that one can toggle between code and charts without having to worry about coding at all.</p>
<p>At this stage, I would argue that Code Interpreter may be useful for quick summaries, visualisations and a little basic data cleaning and some preliminary investigations. However, based on what I’ve seen so far, it is clear to me that highly trained statisticians won’t be replaced anytime soon.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Lee Clewley</strong> is a member of the <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/10/18/meet-the-team.html">editorial board of Real World Data Science</a> and head of applied AI in GSK’s AI and Machine Learning Group, R&amp;D.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Lee Clewley
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://unsplash.com/@charlesdeluvio?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">charlesdeluvio</a> on <a href="https://unsplash.com/photos/pjAH2Ax4uWk?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Clewley, Lee. 2023. “Testing out ChatGPT’s new Code Interpreter.” Real World Data Science, July 19, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/code-interpreter.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Coding</category>
  <category>Data analysis</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/code-interpreter.html</guid>
  <pubDate>Wed, 19 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/19/images/charlesdeluvio-pjAH2Ax4uWk-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Teaching a chatbot about love, and other adventures from London Data Week</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/LDW.html</link>
  <description><![CDATA[ 




<p><a href="https://www.londondataweek.org/">London Data Week</a> wraps up on Sunday, and what a week it’s been! Kudos to organisers <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/london-data-week.html">Sam Nutt and Jennifer Ding</a> for the huge amount of energy and passion they invested in making this idea a reality, and I’m looking forward to seeing what they have in store for us next year.</p>
<p>My highlights of the week? Well, of course, I really enjoyed being part of the event that was hosted at the Royal Statistical Society on Tuesday. The <a href="https://rss.org.uk/membership/volunteering-and-promoting/statisticians-for-society-initiative/">Statisticians for Society</a> workshop brought together charities and statisticians to explore ways in which data and statistics can support third sector organisations to deliver on their charitable aims as well as demonstrate to communities and funders the impact they are having. There’s a nice selection of <a href="https://rss.org.uk/membership/volunteering-and-promoting/statisticians-for-society-initiative/case-studies/">case studies of successful past projects on the RSS website</a>, and hopefully the London Data Week event will result in several new additions to this collection in due course.</p>
<p>I wasn’t able to attend this event myself, but I’m really looking forward to viewing the outputs of the <a href="https://betterimagesofai.org/images">Better Images of AI</a> workshop, which was also held on Tuesday. Real World Data Science has used several of the group’s images to illustrate past articles (<a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/11/23/LLM-content-warning.html#qa">here</a>, <a href="https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html">here</a> and <a href="https://realworlddatascience.net/ideas/posts/2023/07/03/trusted-AI.html">here</a>), so I’m excited to see what gets added to the image gallery in the coming weeks.</p>
<p>Sticking with the AI theme, I also got to explore the <a href="https://london.sciencegallery.com/ai-season">“AI: Who’s Looking After Me?” exhibition</a> at the Science Gallery, where I found myself unexpectedly moved by one installation in particular – <a href="https://london.sciencegallery.com/ai-artworks/newly-forgotten-technologies">an artificial landfill of broken and discarded tablets and smart speakers</a>, explaining matter-of-factly, but with an unmistakable air of mournfulness, that they had been replaced “by a newer model that is better because it is lighter, or heavier, or bigger, or smaller…”. Fortunately I was able to cheer myself up with another exhibit, which tasks visitors with <a href="https://london.sciencegallery.com/ai-artworks/looking-for-love">helping a chatbot to define and understand love</a>.</p>
<p>Later on in my visit to the Science Gallery (which was actually last Thursday, before London Data Week officially began), I listened to a panel debate on “Building Better AI in the Open”, featuring Margaret Mitchell of HuggingFace, Lara Groves of the Ada Lovelace Institute, and Irini Papadimitriou of FutureEverything, facilitated by artist and machine learning design researcher Caroline Sinders. A recording of the panel is below, and well worth a watch for discussion of:</p>
<ul>
<li>the advantages of open source versus closed source</li>
<li>the role of public participation in AI</li>
<li>what transparency in AI development should look like</li>
<li>issues of accountability in AI applications.</li>
</ul>
<p>Jennifer Ding followed up the panel with <a href="https://loti.london/blog/building-better-ai-in-the-open/">a thoughtful post on the benefits of open source AI</a>, and for more on trustworthy AI – and the need for transparency, explainability, and fairness – check out Maxine Setiawan and Mira Pijselman’s recent Real World Data Science article, <a href="https://realworlddatascience.net/ideas/posts/2023/07/03/trusted-AI.html">“Trusted AI: translating AI ethics from theory into practice”</a>.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/xddQq3opSzU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://unsplash.com/it/@bendavisual?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Benjamin Davies</a> on <a href="https://unsplash.com/photos/Oja2ty_9ZLM?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Teaching a chatbot about love, and other adventures from London Data Week.” Real World Data Science, July 7, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/LDW.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>AI</category>
  <category>Open source</category>
  <category>Accountability</category>
  <category>Public opinion</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/LDW.html</guid>
  <pubDate>Fri, 07 Jul 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/07/07/images/benjamin-davies-Oja2ty_9ZLM-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>How do people feel about AI? Well, it’s complicated</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/how-do-people-feel-about-ai.html</link>
  <description><![CDATA[ 




<p>How do people feel about AI? That was a question recently explored in a survey of 4,000 British residents. The answer is that, well, it depends.</p>
<p>Researchers at the Ada Lovelace Institute and the Alan Turing Institute designed the survey to ask about specific AI use cases, rather than the concept of AI more broadly. Use cases included face recognition for policing, border control and security, targeted advertising for political campaigns and consumer products, virtual assistants, driverless cars, and so on.</p>
<p>Roshni Modhvadia, a researcher at the Ada Lovelace Institute and member of the survey team, reported that respondents overall were broadly positive towards most of the use cases they were asked about. Healthcare applications (using AI to assess the risk of cancer, for example) or face recognition for border security were seen as very or somewhat beneficial by more than 80% of those surveyed. More than half of respondents thought that other applications, such as virtual reality in education, climate research simulations, and robotic care assistants were very or somewhat beneficial.</p>
<p>Views were less positive towards applications including driverless cars, autonomous weapons and targeted advertising. These were the applications that respondents expressed most concern about, and for each of these use cases perceived risks were felt to outweigh perceived benefits.</p>
<p>And yet, even for applications that were seen as being overwhelmingly beneficial – assessing cancer risk and face recognition for border control – respondents still expressed concern about the potential for overreliance on the technologies, the issue of who is accountable for mistakes, and the impact the technologies might have on jobs and employment opportunities.</p>
<p>Three-fifths (62%) of respondents said laws and regulations would make them more comfortable with AI technologies being used. This is an important finding given where the national AI conversation is at the moment, said Professor Helen Margetts, director of the public policy programme at The Alan Turing Institute.</p>
<p>The current national conversation has been fuelled by the success of ChatGPT and the growing adoption of generative AI tools. The Lovelace/Turing survey, fielded in November 2022, did not ask about ChatGPT <em>et al.</em>, but the results do at least provide a baseline against which to measure any shifts in attitudes brought on by what Professor Shannon Vallor, Baillie Gifford Chair in the Ethics of Data and Artificial Intelligence at the Edinburgh Futures Institute at the University of Edinburgh, described as “this latest round of AI hype and confusion”.</p>
<ul>
<li>For more on that theme, see Michael Timothy Bennett’s recent article, <a href="https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html">“No, AI probably won’t kill us all – and there’s more to this fear campaign than meets the&nbsp;eye”</a>.</li>
</ul>
<p>Modhvadia, Margetts and Vallor were speaking at an online event last week to mark the launch of the survey report. Video of the event is below. The <a href="https://www.adalovelaceinstitute.org/report/public-attitudes-ai/">full report</a> is available from the Ada Lovelace Institute website.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/sUG6y_E2UD4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="how-do-people-feel-about-ai-in-statistics-and-data-science-education" class="level2">
<h2 class="anchored" data-anchor-id="how-do-people-feel-about-ai-in-statistics-and-data-science-education">How do people feel about AI in statistics and data science education?</h2>
<p>A new paper in the <em>Journal of Statistics and Data Science Education</em> considers the potential for using ChatGPT in statistics and data science classrooms. Authors Amanda R. Ellis and Emily Slade of the University of Kentucky give suggestions for using ChatGPT to generate course content: lecture notes and new material such as practice quizzes or exam questions, or pseudocode for introducing students to statistical programming. It could also be used as a code debugging tool and integrated into set tasks – e.g., have students prompt ChatGPT to write code, then run the code themselves and assess whether the code works as intended.</p>
<p>“We recognize that educators have valid concerns regarding the implementation and integration of AI tools in the classroom,” write the authors, later adding that: “We encourage readers to consider other technologies, such as the calculator, WolframAlpha, and Wikipedia, all of which were met with initial wariness but are now commonly used as learning tools. As statistics and data science educators, we can actively shape and guide the incorporation of AI tools within our classrooms.”</p>
<p><strong>Read the paper:</strong> <a href="https://amstat.tandfonline.com/doi/full/10.1080/26939169.2023.2223609">A new era of learning: Considerations for ChatGPT as a tool to enhance statistics and data science education</a></p>
</section>
<section id="ok-but-how-do-people-feel-about-ai-generated-music" class="level2">
<h2 class="anchored" data-anchor-id="ok-but-how-do-people-feel-about-ai-generated-music">OK, but how do people feel about AI-generated music?</h2>
<p>A new demo on Hugging Face allows users to <a href="https://huggingface.co/spaces/facebook/MusicGen">generate short samples of music based on text descriptions</a>. Users can also “condition on a melody” by uploading audio files. The results are… interesting, as I discovered while playing around with the demo yesterday.</p>
<center>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Text-to-music-generation is now a thing (via <a href="https://twitter.com/huggingface?ref_src=twsrc%5Etfw"><span class="citation" data-cites="huggingface">@huggingface</span></a>: <a href="https://t.co/fpBDLuB4yh">https://t.co/fpBDLuB4yh</a>) so I thought I'd try creating some new genre mashups <a href="https://t.co/y93w7x9pNW">pic.twitter.com/y93w7x9pNW</a>
</p>
— Brian Tarran (<span class="citation" data-cites="brtarran">@brtarran</span>) <a href="https://twitter.com/brtarran/status/1668301878751375369?ref_src=twsrc%5Etfw">June 12, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
<p><strong>Read the paper:</strong> <a href="https://huggingface.co/papers/2306.05284">Simple and controllable music generation</a></p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Thumbnail image by <a href="https://unsplash.com/@askkell?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Andy Kelly</a> on <a href="https://unsplash.com/photos/0E_vhMVqL9g?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “How do people feel about AI? Well, it’s complicated.” Real World Data Science, June 13, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/how-do-people-feel-about-ai.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Accountability</category>
  <category>Regulation</category>
  <category>Public opinion</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/how-do-people-feel-about-ai.html</guid>
  <pubDate>Tue, 13 Jun 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/06/13/images/andy-kelly-0E_vhMVqL9g-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>London Data Week is almost here. What’s it all about?</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/london-data-week.html</link>
  <description><![CDATA[ 




<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/nLzL-swPBgg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to Real World Data Science. I’m Brian Tarran. And today I’m joined by the organisers of the upcoming London Data Week, Sam Nutt and Jennifer Ding. Sam, Jennifer, how are you? Nice to see you here. Thank you for joining us. I wanted to start, maybe you can introduce yourselves to our viewers, tell them a little bit about your background. Sam, I don’t know if you want to go first.</p>
<p><strong>Sam Nutt</strong><br>
So I’m Sam Nutt. I’m the researcher and data ethicist at the London Office of Technology and Innovation, or LOTI. We’re about four years old. We’re an innovation unit that sits across 26 of the boroughs of London, and the Mayor of London, the GLA and we work sort of through collaborative processes to sort of foster innovation within local government, in the public sector in London. And I lead partly on our work on data ethics, as the title suggests, but also I lead our work on innovative public participation, which I guess leads nicely into maybe talking a little bit later about London Data Week. But yeah, that’s kind of my background and where I’m coming from. My interest in data, I guess, more originally came from the governance side, and how we use it properly and best in public sector context.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Thanks, Sam. Jennifer?</p>
<p><strong>Jennifer Ding</strong><br>
Hi, I’m Jennifer. I’m from the Alan Turing Institute, and I– the Turing, I should say is the UK’s national institute for data science and AI. And I sit on a team called Tools, Practices and Systems, or TPS, which we sometimes colloquially call the Turing’s open science team. So we focus on open, reproducible, and ethical data science practices. And at the Turing, I co-lead a team of research application managers, and our focus is making sure that the research that happens at Turing is more usable, and also actually used by more people outside of academia. In a previous life, I was a data scientist at various US tech startups, working on applied machine learning, mostly for local and national government partners. And in New York, where I was for many years, I participated in something called New York Open Data Week, which was a great introduction to the open data world, and also the civic technology world and how vibrant and exciting those communities are.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. Okay, so that– so you’ve had the exposure to data weeks before? Tell us how did London Data Week as an idea first germinate?</p>
<p><strong>Sam Nutt</strong><br>
Yeah, well, I mean, maybe I can go because it was it was something LOTI, last year, we had a sort of anniversary event, we sort of tried to bring together our community, across local government, and also partners. And so we invited [the] Alan Turing [Institute], we’ve done some work with them. And Jen came, and it was just something Jen raised to me, with me last July, you know, the idea of maybe doing something a little bit, like, inspired by some of the bits we’ve seen, for example, in New York, but also thinking, you know, what’s, what’s the London version of that? What’s the opportunity we have, given, you know, our different context to New York, and we don’t just mean in terms of, you know, you’ve got a different, like, legal context for how you use data and regulation stuff, but the cultural bits, you know, what is the physical space? How does that make London different? The people who live here, you know, what are the opportunities of London. And I think, you know, partly also inspired at the time by, you know, at least from my perspective, a real want to include, you know, ordinary people, Londoners, the public at large – all of those terms can be broken down – but effectively, to increase participation in how we think about data and how we, you know, think also about the future of the city, in a, you know, a future that we know is going to be defined by how we use data. So it kind of, it was a perfect thing where I was very inspired by, you know, I was thinking about those things, and then Jen came along. I don’t know, maybe Jen, you can talk about why you came along with that idea in the first place.</p>
<p><strong>Jennifer Ding</strong><br>
Yeah, absolutely. Yeah. Sam and I sometimes talk about how funny that chance encounter was really. I think the LOTI event was a really great example of how London’s flavour of data innovation is actually quite unique. Just gathered there with all the local councils and various other data organisations that LOTI works with. It was such a cool display of how much the public sector is involved in defining data innovation in London, and also how much academic and private tech in London is also committed to creating data and tech outputs that are for the public good. And coming from the US, I think it was very inspiring to see that organisations like LOTI, organisations like the Turing Institute, like the Ada Lovelace Institute, the Open Data Institute – there is such a great network of data for public good institutions here that are committed to, you know, centering Londoners in the conversation. And I think something that Sam and I really got to talking about was, you know, was this an opportunity also to clearly articulate what this new thing, this unique thing, is that exists in London, that if you’re here, and you work in the space, you know it, but it hasn’t really been formally articulated in the way that I think many of us know that Silicon Valley is associated with a certain kind of innovation – and may be Europe as well with regulation – but what’s happening in London is really special. And we hope that with all our great partners and our London Data Week team, we can begin to start to articulate what makes data innovation in London so special.</p>
<p><strong>Brian Tarran</strong><br>
Please do, Jen.</p>
<p><strong>Brian Tarran</strong><br>
And before we get carried away, we should probably pin down exactly when London Data Week is taking place. It’s beginning of July, is that correct?</p>
<p><strong>Jennifer Ding</strong><br>
That’s right, first week of July 3rd to 9th July.</p>
<p><strong>Brian Tarran</strong><br>
And so from what you’ve said, my understanding, broadly, maybe the aims of the week are to kind of bring together people who are working in data, who are using data and people who are affected by data, or for whom data helps sort of shape their lives, to kind of have maybe, I don’t know, a broader understanding, a kind of commonality of purpose, whatever it might be, is that is that how you would summarise it or…</p>
<p><strong>Sam Nutt</strong><br>
Very nicely summarised, are you available for comms help?</p>
<p><strong>Brian Tarran</strong><br>
I am. Very expensive, though, I’m afraid.</p>
<p><strong>Sam Nutt</strong><br>
Okay. It’s all pro bono stuff. No, I think, yeah, I think that’s really well put. It’s, yeah, it’s articulating that– coming together to start to actually build that imagination, that vision for what London is, and articulate it more, in more clear terms. But it’s also, you know, actually trying to do some things in line with that as well. Some of the activities and events we have, you know, we’re running, it’s kind of in this distributed format. So different organisations across London, who are sort of value aligned across the sector, who might have their own communities, their own publics, can run things – different types of events, you know, engaging people in different ways. And then, you know, all together, we think, sort of the sum of the parts of doing these things across a week, in this distributed format, testing different engagement methods, you know, not only sort of builds a community of organisations around these, like common values, but also lets us, you know, actually reach out to the public, you know, the public with all the different people in London, from different backgrounds, there are so many different communities, you know, as much as possible, to connect to different communities and make them part of the conversation about how we use data and AI and in ways that they kind of historically haven’t been. Not just for data and AI, for lots of other things. But, you know, we know that these technologies are going to be so important for the future. And it’s, you know, designing events and activities that can try and ensure that they’re sort of have a, you know, a seat at the table, thinking about what that future is.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. And you mentioned there a range of events. Jen, can you give us a flavour of some of the events coming up, the highlights, things that you might personally be most looking forward to?</p>
<p><strong>Jennifer Ding</strong><br>
Yeah, happy to Brian. And maybe something to add to is something Sam and I were really hoping to go for is to not have, you know, maybe the typical talk or panel style format for all of our events that might be really common in a conference, but rather have different kinds of events that can focus on different kinds of activities. So having public conversations and debates, having exhibits and experiences, having resident or citizen science opportunities where people can actually be a part of creating data, and also learning opportunities if people want to upskill or learn about a concept. So to shout out some of the events I’m really excited for, maybe to start with the more wacky ones first. The Turing is hosting a “Cabaret of Dangerous Ideas” which will be a comedy show at the Camden Club where they will dig into topics like technology and data, but over a pint and through humour. So apparently, this is an 18+ show. So that might give you a little bit of a flavour of what’s to come. Another event we’re really excited about is an event called All the Docks, where a team of cyclists attempt this challenge in one day to hit every single Santander bike dock. They’ve done it before, and this year for London Data Week, they’re doing a round to hit, I think, the now over 800 docks that now exist in London. And this time, for London Data Week, what they’re also doing is making it a data collection exercise. So as they cross the streets of London, they’ll collect data on the road conditions, the cycling infrastructure, which can be then an open dataset that people can use after the event as well. So those are two that jumped to mind. I don’t know, Sam, if there’s anything you want to highlight, or Brian because I know there’s a really exciting on that the RSS is…</p>
<p><strong>Brian Tarran</strong><br>
Yeah, I’ll put a quick plug in for the, so <a href="https://rss.org.uk/training-events/events/events-2023/rss-events/statisticians-for-society-london-data-week/#fulleventinfo">the Royal Statistical Society are organising an event associated with our Statisticians for Society initiative</a>, which offers pro bono support to charities under a million turnover in the UK. So I can, I’ll post a link in the show notes so that people can find out more about that and sign up if they meet the criteria and are interested in taking part. But Sam, sorry, I, I hijacked there. But go ahead.</p>
<p><strong>Sam Nutt</strong><br>
No, Brian, I was going to only mention your event. But no, a couple of others, I think just to show the like breadth of the types of activities. So you know, for example, it’s also it’s about partnering with organisations who are thinking and you know, already doing things like this, so the Science Gallery, for example, there’s– they’ve got an exhibition called “AI: Who’s looking after me?”, which is, you know, looks at some of the playful ways that AI is already involved in people’s lives and brings sort of people on a critical journey. That’s more of that sort of art exhibition type thing. In local government, where, in LOTI, we’re helping some boroughs with developing basically, a toolkit, a resource to help officers in boroughs in some of the data teams, who maybe haven’t had that history of engaging with residents, as seen as more sort of technical back office staff, actually, you know, give them the confidence to go out and have a conversation with residents about some of their practice and see how they can improve it. So there’s been a lot of interest there, in particular, around having conversations about how we do data linkage better, which, you know, in some ways, feels– it’s quite a straightforward data topic. But actually, the huge thing is that these teams in boroughs have never thought, we need to speak with residents at the design stage of data projects, you know, the public, what might a digitally excluded, relatively low sort of data literacy person be able to tell us about our data work that’s helpful to me as, you know, a data scientist, that was sort of some of the historical thinking, but actually, we’re sort of bringing boroughs on the journey of thinking, actually realising, you know, the value of doing that. So that’s sort of, I guess, the range of types of things as well.</p>
<p><strong>Brian Tarran</strong><br>
Fantastic. So where, if people do want to sign up for any of these events, is there a good way for them to do that? Is it go to the LOTI website– not LOTI website, the London Data Week website, I’m guessing?</p>
<p><strong>Jennifer Ding</strong><br>
There is a good amount of info on both the Turing and the LOTI website, but the best place we’d suggest is <a href="https://www.londondataweek.org/">londondataweek.org</a>. There you’ll find a list of events. And if you click on an event, there’s more information. And also, if you click “Find out more”, you can access a link for more information on how you express interest or sign up.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. And if people– when we’re speaking, we are almost exactly a month away from London Data Week. If someone’s listening to this and they think, Oh, I’ve got a great idea for an event I want to organise, is it too late for them to squeeze onto the programme now? Should they get in touch somehow if, if inspiration strikes?</p>
<p><strong>Sam Nutt</strong><br>
We’ll never say never. Probably there is a very late point in which we would say never. I think realistically, you know, the way it’s being run, it’s being run often with the time of volunteers and this sort of thing. And it is sort of the first year of us running it. So a lot of it’s coming through, through Jen and I. So if you are interested in running something, please do reach out to us. You know, we’ve got very good, Jen and I, at finding creative ways to slot people into programs and this sort of thing. But equally I think at this point, it’s really more about you know, bringing together people and organisations who are interested and actually, you know, I think we’ve got a really good exciting, fun set of events and activities across London that would be great to be part of even if you yourself haven’t been able to organise something, and then maybe it’s something for next year, for London Data Week 2024. Fingers crossed, we might be able to do something there.</p>
<p><strong>Brian Tarran</strong><br>
So the stress of day jobs and organising a week-long event, or week-long collection of activities, hasn’t put you off doing it again? No.&nbsp;</p>
<p><strong>Jennifer Ding</strong><br>
So far, so good, Brian.</p>
<p><strong>Sam Nutt</strong><br>
Yeah, we’ll “no comment” some of that.</p>
<p><strong>Jennifer Ding</strong><br>
We’re definitely really excited though. And if anyone does have an idea or wants to start a conversation, there’s a contact form on our website, drop us an email. <a href="https://twitter.com/londondataweek">We also have a Twitter</a> if you want to send us a message through that. So at the very least, we love, we’d love to chat.</p>
<p><strong>Brian Tarran</strong><br>
Great, well, we’ll put all those contact details, social media accounts, etc., into the show notes so people can find you. But thank you very much for joining us today. I know this must be a very busy time for you. But Sam Nutt, Jennifer Ding, thank you for joining us and talking about the upcoming London Data Week. I’m looking forward to it.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
<p>© 2023 Royal Statistical Society</p>
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Images are not covered by this licence. Thumbnail image by <a href="https://unsplash.com/@fakearthur?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">ARTHUR YAO</a> on <a href="https://unsplash.com/photos/HTicW9-i4xY?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
<p>Tarran, Brian. 2023. “London Data Week is almost here. What’s it all about?” Real World Data Science, June 8, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/london-data-week.html">URL</a></p>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Data</category>
  <category>Innovation</category>
  <category>Events</category>
  <category>Communities</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/london-data-week.html</guid>
  <pubDate>Thu, 08 Jun 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/06/08/images/arthur-yao-HTicW9-i4xY-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>No, AI probably won’t kill us all – and there’s more to this fear campaign than meets the eye</title>
  <dc:creator>Michael Timothy Bennett</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html</link>
  <description><![CDATA[ 




<p>Doomsaying is an old occupation. Artificial intelligence (AI) is a complex subject. It’s easy to fear what you don’t understand. These three truths go some way towards explaining the oversimplification and dramatisation plaguing discussions about AI.</p>
<p>Last week, outlets around the world were plastered with news of yet another <a href="https://www.safe.ai/statement-on-ai-risk">open letter claiming</a> AI poses an existential threat to humankind. This letter, published through the nonprofit Center for AI Safety, has been signed by industry figureheads including <a href="https://theconversation.com/ai-pioneer-geoffrey-hinton-says-ai-is-a-new-form-of-intelligence-unlike-our-own-have-we-been-getting-it-wrong-this-whole-time-204911">Geoffrey Hinton</a> and the chief executives of Google DeepMind, Open AI and Anthropic.</p>
<p>However, I’d argue a healthy dose of scepticism is warranted when considering the AI doomsayer narrative. Upon close inspection, we see there are commercial incentives to manufacture fear in the AI space.</p>
<p>And as a researcher of artificial general intelligence (AGI), it seems to me the framing of AI as an existential threat has more in common with 17th-century philosophy than computer science.</p>
<section id="was-chatgpt-a-breakthrough" class="level2">
<h2 class="anchored" data-anchor-id="was-chatgpt-a-breakthrough">Was ChatGPT a ‘breakthrough’?</h2>
<p>When ChatGPT was released late last year, people were delighted, entertained and horrified.</p>
<p>But ChatGPT isn’t a research breakthrough as much as it is a product. The technology it is based on is several years old. An early version of its underlying model, GPT-3, was released in 2020 with many of the same capabilities. It just wasn’t easily accessible online for everyone to play with.</p>
<p>Back in 2020 and 2021, <a href="https://ieeexplore.ieee.org/document/9495946">I</a> and many <a href="https://link.springer.com/article/10.1007/s11023-020-09548-1">others</a> wrote papers discussing the capabilities and shortcomings of GPT-3 and similar models – and the world carried on as always. Forward to today, and ChatGPT has had an incredible impact on society. What changed?</p>
<p>In March, Microsoft researchers <a href="https://futurism.com/gpt-4-sparks-of-agi">published a paper</a> claiming GPT-4 showed “sparks of artificial general intelligence”. AGI is the subject of a variety of competing definitions, but for the sake of simplicity can be understood as AI with human-level intelligence.</p>
<p>Some immediately interpreted the Microsoft research as saying GPT-4 <em>is</em> an AGI. By the definitions of AGI I’m familiar with, this is certainly not true. Nonetheless, it added to the hype and furore, and it was hard not to get caught up in the panic. Scientists are no more immune to <a href="https://link.springer.com/book/10.1007/978-3-030-36822-7">group think</a> than anyone else.</p>
<p>The same day that paper was submitted, The Future of Life Institute <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">published an open letter</a> calling for a six-month pause on training AI models more powerful than GPT-4, to allow everyone to take stock and plan ahead. Some of the AI luminaries who signed it expressed concern that AGI poses an existential threat to humans, and that ChatGPT is too close to AGI for comfort.</p>
<p>Soon after, prominent AI safety researcher Eliezer Yudkowsky – who has been commenting on the dangers of superintelligent AI <a href="https://intelligence.org/files/AIPosNegFactor.pdf">since well before</a> 2020 – took things a step further. <a href="https://time.com/6266923/ai-eliezer-yudkowsky-open-letter-not-enough/">He claimed</a> we were on a path to building a “superhumanly smart AI”, in which case “the obvious thing that would happen” is “literally everyone on Earth will die”. He even suggested countries need to be willing to risk nuclear war to enforce compliance with AI regulation across borders.</p>
</section>
<section id="i-dont-consider-ai-an-imminent-existential-threat" class="level2">
<h2 class="anchored" data-anchor-id="i-dont-consider-ai-an-imminent-existential-threat">I don’t consider AI an imminent existential threat</h2>
<p>One aspect of AI safety research is to address potential dangers AGI might present. It’s a difficult topic to study because there is little agreement on what intelligence is and how it functions, let alone what a superintelligence might entail. As such, researchers must rely as much on speculation and philosophical argument as on evidence and mathematical proof.</p>
<p>There are two reasons I’m not concerned by ChatGPT and its <a href="https://lablab.ai/blog/what-is-babyagi-and-how-can-i-benefit-from-it">byproducts</a>.</p>
<p>First, it isn’t even close to the sort of artificial superintelligence that might conceivably pose a threat to humankind. The models underpinning it are slow learners that require immense volumes of data to construct anything akin to the versatile concepts humans can concoct from only a few examples. In this sense, it is not “intelligent”.</p>
<p>Second, many of the more catastrophic AGI scenarios depend on premises I find implausible. For instance, there seems to be a prevailing (but unspoken) assumption that sufficient intelligence amounts to limitless real-world power. If this was true, more scientists would be billionaires.</p>
<p>Moreover, cognition as we understand it in humans takes place as part of a physical environment (which includes our bodies), and this environment imposes limitations. The concept of AI as a “software mind” unconstrained by hardware has more in common with 17th-century <a href="https://plato.stanford.edu/entries/dualism/">dualism</a> (the idea that the mind and body are separable) than with contemporary theories of the mind existing as <a href="https://plato.stanford.edu/entries/embodied-cognition/">part of the physical world</a>.</p>
</section>
<section id="why-the-sudden-concern" class="level2">
<h2 class="anchored" data-anchor-id="why-the-sudden-concern">Why the sudden concern?</h2>
<p>Still, doomsaying is old hat, and the events of the last few years probably haven’t helped – but there may be more to this story than meets the eye.</p>
<p>Among the prominent figures calling for AI regulation, many work for or have ties to incumbent AI companies. This technology is useful, and there is money and power at stake – so fearmongering presents an opportunity.</p>
<p>Almost everything involved in building ChatGPT has been published in research anyone can access. OpenAI’s competitors can (and have) replicated the process, and it won’t be long before free and open-source alternatives flood the market.</p>
<p>This point was made clearly in a memo <a href="https://www.semianalysis.com/p/google-we-have-no-moat-and-neither">purportedly leaked</a> from Google entitled “We have no moat, and neither does OpenAI”. A moat is jargon for a way to secure your business against competitors.</p>
<p>Yann LeCun, who leads AI research at Meta, says these models should be open since they will become public infrastructure. He and many others are <a href="https://www.businesstoday.in/technology/news/story/completely-ridiculous-metas-chief-ai-scientist-yann-lecun-dismisses-elon-musks-civilisation-destruction-fear-383371-2023-05-30">unconvinced by the AGI doom</a> narrative.</p>
<center>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
A NYT article on the debate around whether LLM base models should be closed or open.<br><br>Meta argues for openness, starting with the release of LLaMA (for non-commercial use), while OpenAI and Google want to keep things closed and proprietary.<br><br>They argue that openness can be…
</p>
— Yann LeCun (<span class="citation" data-cites="ylecun">@ylecun</span>) <a href="https://twitter.com/ylecun/status/1659172655663030272?ref_src=twsrc%5Etfw">May 18, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
<p>Notably, <a href="https://fortune.com/2023/05/05/meta-mark-zuckerberg-not-invited-ai-meeting-white-house/">Meta wasn’t invited</a> when US President Joe Biden recently met with the leadership of Google DeepMind and OpenAI. That’s despite the fact that Meta is almost certainly a leader in AI research; it produced PyTorch, the machine-learning framework OpenAI used to make GPT-3.</p>
<p>At the White House meetings, OpenAI chief executive Sam Altman suggested the US government should issue licences to those who are trusted to responsibly train AI models. Licences, as Stability AI chief executive Emad Mostaque <a href="https://twitter.com/EMostaque/status/1658653142429450242?s=20">puts it</a>, “are a kinda moat”.</p>
<p>Companies such as Google, OpenAI and Microsoft have everything to lose by allowing small, independent competitors to flourish. Bringing in licensing and regulation would help cement their position as market leaders and hamstring competition before it can emerge.</p>
<p>While regulation is appropriate in some circumstances, regulations that are rushed through will favour incumbents and suffocate small, <a href="https://www.forbes.com/sites/hessiejones/2023/04/19/amid-growing-call-to-pause-ai-research-laion-petitions-governments-to-keep-agi-research-open-active-and-responsible/?sh=1b21161a62e3">free and open-source competition</a>.</p>
<center>
<blockquote class="twitter-tweet blockquote">
<p lang="en" dir="ltr">
Think Google or Microsoft are encouraging legislation for your safety? But of course! These are honorable companies.<br><br>You might think they'd like less competition too though. Maybe a monopoly? Maybe legal red tape preventing free and open source alternatives? Perhaps other… <a href="https://t.co/Z7vSpMyuHg">https://t.co/Z7vSpMyuHg</a>
</p>
— Michael Timothy Bennett (<span class="citation" data-cites="MiTiBennett">@MiTiBennett</span>) <a href="https://twitter.com/MiTiBennett/status/1654357631514079233?ref_src=twsrc%5Etfw">May 5, 2023</a>
</blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</center>
<!-- Below is The Conversation's page counter tag. Please DO NOT REMOVE. -->
<p><img src="https://realworlddatascience.net/viewpoints/posts/2023/06/05/https:/counter.theconversation.com/content/206614/count.gif?distributor=republish-lightbox-basic" alt="The Conversation" width="1" height="1" style="border: none !important; box-shadow: none !important; margin: 0 !important; max-height: 1px !important; max-width: 1px !important; min-height: 1px !important; min-width: 1px !important; opacity: 0 !important; outline: none !important; padding: 0 !important" referrerpolicy="no-referrer-when-downgrade"></p>
<!-- End of code. If you don't see any code above, please get new code from the Advanced tab after you click the republish button. The page counter does not collect any personal data. More info: https://theconversation.com/republishing-guidelines -->
<div class="article-btn">
<p><a href="../../../../../viewpoints/index.html">Discover more Viewpoints</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<a href="https://theconversation.com/profiles/michael-timothy-bennett-1283108">Michael Timothy Bennett</a> is a PhD student in the School of Computing, <a href="https://theconversation.com/institutions/australian-national-university-877">Australian National University</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-12">
<dl>
<dt>Copyright and licence</dt>
<dd>
This article is republished from <a href="https://theconversation.com">The Conversation</a> under a Creative Commons license. Read the <a href="https://theconversation.com/no-ai-probably-wont-kill-us-all-and-theres-more-to-this-fear-campaign-than-meets-the-eye-206614">original article</a>.
</dd>
<dd>
<p>Thumbnail image by <a href="https://alanwarburton.co.uk/">Alan Warburton</a> / © BBC / <a href="https://www.betterimagesofai.org">Better Images of AI</a> / Social Media / <a href="https://creativecommons.org/licenses/by/4.0/">Licenced by CC-BY 4.0</a>.</p>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Regulation</category>
  <guid>https://realworlddatascience.net/viewpoints/posts/2023/06/05/no-AI-probably-wont-kill-us.html</guid>
  <pubDate>Mon, 05 Jun 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/posts/2023/06/05/images/AlanWarburton-SocialMedia.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>What’s the future of data science and AI in an LLM world?</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/future.html</link>
  <description><![CDATA[ 




<p>The impact ChatGPT and large language models (LLMs) are having on the practice and profession of data science is something <a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">we discussed recently with data scientists from Unilever, BT, Deliveroo, and others</a>. So, it was interesting to hear a perspective this week from Osama Rahman, director of the <a href="https://datasciencecampus.ons.gov.uk/">Data Science Campus</a> at the UK Office for National Statistics.</p>
<p>Speaking Tuesday at <a href="https://rss.org.uk/training-events/events/events-2023/local-groups/what-is-the-future-of-data-science-and-ai-online/">an online event</a>, Rahman mused on how LLMs brought both potential benefits and risks. For example, those who can already code can code more efficiently now with the help of LLM-powered tools. However, those same tools also allow non-coders to code – and inexpert use of tools and code presents risks. How do we guard against this, he was asked. “I don’t know,” came the response, “other than you have to observe and clampdown on it.”</p>
<p>Such problems are by no means new or unique to the post-ChatGPT era, of course. As someone with a background in economics, Rahman said he has, over the years, observed “inexpert uses of economics.” His advice was to “make sure experts are plugged in” – to teams, conversations, decision-making processes, etc. – “and are seen as the experts in the use of these tools.”</p>
<p>The discussion was wide-ranging, and also took in questions on whether data scientists have the right skills at this moment – “Skills evolve, it’s just a natural process… We need to keep a culture of curiosity…” – and whether enough is being done to address ethical issues – “My key issue is that ethical frameworks need a lot more discussion and debate than it takes to put out a new tool… I don’t have much to add, other than that there is a problem.”</p>
<p>However, two questions – and answers – jumped out at me as particularly interesting. Rahman was asked: Have we delivered on the promise of data science from 5 years ago? “No, but that’s because expectations were wrong,” he said. “Data science wasn’t going to completely and utterly transform government. But where it has delivered is in an evolving set of tools, people, and skills coming in and allowing us to do impactful stuff. It hasn’t delivered on the false promise that it would change the world, but it has delivered a lot.”</p>
<p>He was also asked: How will data science and AI have changed the world in 5–10 years? “I’m not sure it will,” he said. “It will do certain things. It will allow us to address certain analytical problems more efficiently.” Rahman then offered a salutary reminder. Email once made life more efficient; now, we’re all at risk of “death by email.”</p>
<p>We’ll be sure to update this post with a link to a video or other recording of the event, if/when it becomes available. For now, be sure to check out our two-part discussion on LLMs and data science:</p>
<ul>
<li><a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">How is ChatGPT changing data science?</a></li>
<li><a href="https://realworlddatascience.net/careers/posts/2023/05/18/chatgpt-data-science-pt2.html">Large language models: Do we need to understand the maths, or simply recognise the limitations?</a></li>
</ul>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “What’s the future of data science and AI in an LLM world?” Real World Data Science, May 26, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/future.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Large language models</category>
  <category>Skills</category>
  <category>Tools</category>
  <category>Ethics</category>
  <category>People</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/future.html</guid>
  <pubDate>Fri, 26 May 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/05/26/images/binoculars.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘I’m way more into prevention than cure’: Stephanie Hare on why we need a culture of technology ethics</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/04/28/stephanie-hare.html</link>
  <description><![CDATA[ 




<p>We’re about a year late coming to <a href="https://www.harebrain.co/">Stephanie Hare</a>’s book, <a href="https://londonpublishingpartnership.co.uk/technology-is-not-neutral/"><em>Technology is Not Neutral: A Short Guide to Technology Ethics</em></a>. But, as discussed in our interview below, time has only made the text more relevant. The book was written pre-ChatGPT, but Hare’s explorations of ethical questions in the context of facial recognition technology and Covid-19 exposure tracking apps feel both pointed and urgent at this moment, when researchers, regulators, and regular people are weighing the opportunities and potential harms of large language models and generative AI tools.</p>
<p>“We’re having some sort of moment with technology ethics – AI ethics being just a branch of that,” says Hare. Reflecting on her career, spanning 25 years, she says: “The stuff that we’re talking about today that dominates the headlines – that is dominating the discussion in the tech sector – was not discussed at all at the turn of the century, other than by maybe people in the science and technology studies domain or academics. But it wasn’t filtering into boardrooms. It wasn’t on the front pages of newspapers, and it wasn’t being covered in the national news. So, it’s amazing. A whole field has sprung up.”</p>
<p>However, as Hare makes clear in our interview, we still have a long way to go to build a culture of technology ethics throughout society. Check out the full conversation below or on YouTube.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/INKwSTNFSVY" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="timestamps" class="level2">
<h2 class="anchored" data-anchor-id="timestamps">Timestamps</h2>
<ul>
<li>ChatGPT: just another “flavour of the month” in the tech industry? (<a href="https://youtu.be/INKwSTNFSVY?t=78">1:18</a>)</li>
<li>Has concern about large language models helped put technology ethics on the map? (<a href="https://youtu.be/INKwSTNFSVY?t=197">3:17</a>)</li>
<li>What will it take to build a culture of technology ethics – in society, in academia, in industry? (<a href="https://youtu.be/INKwSTNFSVY?t=556">9:16</a>)</li>
<li>Drawing lessons from history (<a href="https://youtu.be/INKwSTNFSVY?t=735">12:15</a>)</li>
<li>Why technology ethics is a “wicked problem” (<a href="https://youtu.be/INKwSTNFSVY?t=1497">24:57</a>)</li>
<li>Checklists and changing mindsets (<a href="https://youtu.be/INKwSTNFSVY?t=1789">29:49</a>)</li>
</ul>
</section>
<section id="quotes" class="level2">
<h2 class="anchored" data-anchor-id="quotes">Quotes</h2>
<p>“The European Union has the AI Act coming down the pike. It doesn’t cover stuff like ChatGPT specifically, but then I don’t know if you want good regulation to cover the technology itself, or how technology is used. I talked about this in my book: do you want to regulate forks – a tool – or do you want to regulate use cases for forks? We’ve regulated the use case, if you will, of murder, or of injury with a fork – or, frankly, any other tool. So it’s the use case we focus on. We don’t really regulate forks. [But] we do regulate some technologies, like biomedical technologies, human genetic stuff, anything nuclear. So we just need to think about where does AI fit with that?” (<a href="https://youtu.be/INKwSTNFSVY?t=342">5:42</a>)</p>
<p>“Move fast and break things was the mantra for this culture [in the technology industry] for a really long time, at least out of the US. And it made a lot of people a lot of money, and they got worshipped by the media. And, you know, they have a whole audience of ‘bros’ who are fans of them. And they’ve never really, any of them, been held to account for what they’ve built.” (<a href="https://youtu.be/INKwSTNFSVY?t=716">11:56</a>)</p>
<p>“Another generation or two, when we’re older, might look at some of what technology we’ve built or our behaviour on climate change, our track record – did we do what we could have done to slow global warming, to improve biodiversity? – and they might hold us to account, saying, ‘You could have stopped this and you didn’t, right? It’s not just what you did. It’s what you did not do.’ So we have to be super careful when we think about ethics, because ethics change, values change over time. And what seems okay today may not be okay in 10, 20, 30 years time. That is on my mind all the time. It’s not very relaxing.” (<a href="https://youtu.be/INKwSTNFSVY?t=1110">18:30</a>)</p>
<p>“[Laws and regulations] are important, they’re necessary, but they’re insufficient. You can act a lot faster if you can get people preventing stuff from being built in the first place, and that means you need to have a culture of people working in technology, both within the organisations – whether that’s research labs, government, companies, universities, whatever – and on the outside – journalists, academics, thinkers, etc., or just the public, an informed public – who can see something and sound the alarm and go, ‘Wait a minute, hang on. That’s not okay.’” (<a href="https://youtu.be/INKwSTNFSVY?t=1982">33:02</a>)</p>
</section>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to another Real World Data Science interview. I’m Brian Tarran. And today I’m joined by Stephanie Hare, a researcher and broadcaster and author of the book Technology is Not Neutral: A Short Guide to Technology Ethics, which is the focus of our conversation today. Welcome, Stephanie.</p>
<p><strong>Stephanie Hare</strong><br>
Thank you so much for having me here.</p>
<p><strong>Brian Tarran</strong><br>
I feel I’m a bit late to the party with the book. The Financial Times picked it up as one of the best books of summer 2022. But I’ve only just got around to reading it.</p>
<p><strong>Stephanie Hare</strong><br>
I mean, I only just got around to reading War and Peace last year. So there’s no rush with these things.</p>
<p><strong>Brian Tarran</strong><br>
Okay. Well, I mean, I can definitely say it’s one of the best books I’ve read in spring 2023, if that helps, and the only other one I read was Lord of the Rings. So–</p>
<p><strong>Stephanie Hare</strong><br>
Wow. I mean that’s some pretty august company, you couldn’t thrill me more.</p>
<p><strong>Brian Tarran</strong><br>
Excellent, excellent. Well, I actually thought coming late to the book might actually have been of benefit to me as a reader because, you know, you’re talking about technology ethics quite broadly. But then you focus in on a couple of use cases, specifically around facial recognition, technology, Covid-19 exposure tracking apps and things like that. But, you know, obviously, since the book was published, the whole discussion around technology ethics has kind of been dominated maybe or taken on a new dimension following the launch and adoption of ChatGPT. I wonder, you know, when the technology was launched, people started using it, adoption rates, you know, went through, went through the roof, what was your kind of initial reaction to all that and what have you made of the kinds of conversations and criticisms that have followed?</p>
<p><strong>Stephanie Hare<br>
</strong>Well, I mean, like everybody I was curious and fascinated and wanted to play around with it a bit. I don’t think I’m of the school of thought that seems to be circulating that this will either you know, destroy mankind as we know it or take everybody’s jobs or potentially upend civilization. There’s been some quite extreme, some quite extreme views put across in the media in the past few months since this was widely released to the public. I don’t know, for some reason, I didn’t drink the Kool-Aid, when I started working in technology. So I always take these things with a grain of salt. And I guess my, my cautionary note to anybody listening to this is you know, at this time last year, all of my clients were wanting presentations and analysis about web3 and NFTs and cryptocurrency and before that, it was blockchain. There’s like always a sort of flavour of the month. AI, for people who’ve worked in this field, is known to have winters, summers, springs, autumns, you know, these seasons of when it’s like coming on and really exciting or not? I’m more excited by DeepMind’s use of artificial intelligence, I think they’re actually working on interesting problems, right, around like protein discovery, like real science, as opposed to like, oh, look, I can have a new sci fi avatar or do a deep fake, you know, people can do deep fakes already. We’re just doing them now in even more disturbing ways. So I guess, I guess it’s that. I’m intrigued by it. But I don’t I don’t feel the need to sort of freak out. Either way, positively or negatively, I have a much more sort of detached satellite-level view, I think probably just because I’m older, seeing these trends come and go. And it’s like, let’s just let’s just wait this out and see how it goes.</p>
<p><strong>Brian Tarran</strong><br>
From your perspective as someone who’s interested in and researching in the area of technology ethics, right, do you see a kind of almost a benefit that the conversation around this has put technology ethics, the conversation around that, on the map? Or do you worry that we’re kind of obsessing over this one technology and this one application? We’re not looking at the field more broadly?</p>
<p><strong>Stephanie Hare</strong><br>
Well, there’s a few things to say on this. So like, first of all, a couple of weeks ago, a bunch of people working in AI, about 1000-plus people – including some fictitious people, by the way – sign this this letter calling for a moratorium on AI research for six months, which was unenforceable, clearly not going to happen, was signed by Elon Musk, who then very quickly announced he was developing his own rival to OpenAI, the company that invented ChatGPT. So you take all of that with a grain of salt. But again, if you’re, if you’re an historian, or if you just have a long memory, you’ll remember that there have been several letters like this. There’s always somebody, you know, very big-wig people. It’s not that we want to dismiss it. But Stephen Hawking and Elon Musk were warning, you know, over around 10 years ago that AI was going to kill humanity if we didn’t put guardrails on it. Professor Stuart Russell talked about this in his Reith Lectures a couple of years ago, which are still online and you can listen to them. And you know, he’s not an alarmist. He’s a serious person and a serious thinker. So we want to listen to him. But I guess what I’m just saying is, you know, every time some sort of new technology or new use case for technology comes up, there’s a group of people who come out and freak out and they get lots of op-eds.&nbsp;It’s usually men, I must say. There’s a lot of women doing some really interesting scholarship in this area that don’t get the op-eds and quite the publicity. So there’s that. Then it is interesting because it makes people think about technology ethics, usually, again, from a place of either fear, right – Are they going to kill us? Are they going to take our jobs? Are they going to remove human agency? – or money – How are people going to make a huge amount of money? Who’s going to make the money? And by displacing whom, right? So, we have two levers: incredible doom or incredible opportunity. And that leaves the rest of us, I think, probably somewhere in the middle, scratching our heads and going like, is this going to actually change my life? And if so, how, and do I really care, given that I’ve got like, you know, a cost of living crisis, recovering from the Covid pandemic for the past few years? Like, if you’re not in this world, it can seem like a lot of shouting. There’s also the question of, do we need new laws? So we know that the European Union has the AI Act coming down the pike. That’s supposed to be passed this year, and there’ll be a two year implementation grace period. So that’s interesting. It doesn’t cover stuff really, like ChatGPT specifically, but then I don’t know if you want good regulation to cover the technology itself, or how technology is used. And I talked about this in my book, like, do you want to regulate forks – a tool – or do you want to regulate use cases for forks? So if I’m, if I stab you, or kill you with a fork, which is totally possible, that is something that we’ve regulated; we’ve regulated the use case, if you will, of murder, or of injury with a fork or frankly, any other tool. So it’s the use case we focus on. We don’t really regulate forks. We do regulate some technologies like bioethics technologies, or biomedical technologies, excuse me, sort of human genetic stuff, anything nuclear. Those technologies we do specifically regulate. So we just need to think about where does AI fit with that? And also, do we need new regulations for everything, or can we use existing ones? And that’s what’s becoming really interesting is that in the US, where I’m from, the main regulator, the FTC, seems to think that it can use a lot of existing laws already. So they’ve been like, if your AI is claiming to do stuff that it can’t, we’re gonna come after you under, like, kind of sort of false advertising, if you will, misrepresenting yourself. They might come after some of the big AI companies based on anti-competition law, right? So no new laws needed for that. And then with the music industry, they’ve been going after all the people who are like, oh, let’s like remix a Drake song, and saying, well, actually, you can’t do that, because you’re violating copyright law, take it down. Right. So again, I don’t want to be like too, too calm about it. Like, we do need to look at some of the use cases that are really problematic and hurting people. But we might actually have a lot more in our arsenal to combat this than we’re currently using. And I think what’s going to happen is, unfortunately, the pace of crafting legislation, and then regulators never fully enforce regulations– Look at the GDPR: no company’s ever been given the full fine. And here in the UK, the ICO is famous for letting companies off the hook, giving them less than half of the original fine. It’s ridiculous. So if you’re going to pin your hopes on regulation, I’m not sure that’s great. I’m weirdly more optimistic about landmark legal cases. So we’re seeing an Australian mayor who was totally defamed by ChatGPT, in Australia, he’s going to be taking or is taking OpenAI to court. And then we might see some of these copyright issues, that could be taken to court, right. And like, that’s where people I think will get more action and, frankly, more respect, because these companies are really happy to pay a lot of money to lobby our lawmakers, and water stuff down. And they always say, Oh, my God, it’s going to constrain innovation. And if they really get desperate, they’ll be like, China! If we don’t, if we’re not allowed to do everything we want, China will win! That is like a– that is just a game that takes everybody nowhere, whereas in the lawsuit angle, that’s interesting, because you’re demonstrating responsibility, you’re discussing liability, you’re having to demonstrate harm. And in the process of discovery, right, you might be able to actually get some of these companies to open up their datasets, how their algorithms work, like, I’m much more intrigued to see where that’s gonna go.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, but I think I mean, having read your book, I would, I would have thought you might perceive all of this sort of stuff as kind of sticking plasters to put over the the injuries that might be caused by these technologies, right? Your argument seems to be that we have an issue whereby we don’t have a culture of technology ethics. So when we’re thinking about building these tools, or when we’re starting off down the path of creating something like this, we’re not already thinking about, you know, the use cases, the harms that might arise from that and things like that. What does it take to build a culture of technology ethics, do you think, in our society, in our academic institutions in our companies?</p>
<p><strong>Stephanie Hare</strong><br>
Honestly, I think, I think this whole accountability piece is going to be what it takes. Because you see, like Alphabet CEO Sundar Pichai gave an interview recently to CBS 60 Minutes in the US where he was like, yeah, there’s a risk that this technology could get out of control, like dot dot dot, this would be terrible for mankind. And you see him kind of be like, hope somebody does something about that. And it’s like, I know somebody that might do something about that, Mr Pichai – you! But clearly he feels, and you can see his point, he feels that right now, if it’s not illegal, then it’s permissible. And he has to win market share. If he doesn’t do it, he’s going to lose. And companies have this all the time. If they wait too long, they lose their first-mover advantage, and they get destroyed. We can go through like countless examples of that in business, particularly in technology. So I get it. But what he isn’t understanding is that if his company is the one that puts out the technology that leads to terrible harm – you know, physically killing people, harming them, destroying the national security infrastructure, something like that – right now, I don’t think he’s thinking about how that’s going to affect him. And that’s because we don’t really penalise executives very often. The worst that might happen is they might leave with a huge golden parachute, and go off and sort of retire in Hawaii with their millions, right? Like nothing really happens to them. So how do you have a culture of technology ethics, where the people who are creating technology and have the power to stop, right, to maybe like back off on stuff, they aren’t really thinking about how will I personally be held responsible if this goes south? So like, Sam Altman and OpenAI, same thing, he was like, he gave an interview where he’s like, I’m really scared about this technology I’m building. It’s like, okay, you could slow down or back off, you could make your datasets open, you could make your algorithms open. You’re called Open AI, that was supposed to be your whole mission, why you were created was to benefit humanity, like, what are you doing? So it’s weird. And I think it comes from the fact that, you know, move fast and break things was the mantra for this culture for a really long time, at least out of the US. And it made a lot of people a lot of money, and they got worshipped by the media. And you know, they have a whole audience of bros who are fans of them. And they’ve never really, any of them, been held to account for what they’ve built.</p>
<p><strong>Brian Tarran</strong><br>
So your interest in technology ethics clearly predates you know, that all the noise at the moment around large language models and generative AI and things like that. What was it that got you interested in this subject? Was it a particular application, something that caused some concern? Or– How did it come about?</p>
<p><strong>Stephanie Hare</strong><br>
This is gonna sound completely weird, but it didn’t come from my experience in tech, really, at all. I have had two paths in my adult life, one has been working in these technology companies with a brief but happy foray in political risk, which is now sort of part of the skill set for tech. But I trained as an historian, and I interviewed someone who was a French civil servant, who at the end of his life was put on trial for crimes against humanity for his actions as a young civil servant during the Second World War. So he collaborated, as so many French civil servants did. And in the course of that collaboration, over a period of many years, went from just, you know, just signing documents and kind of doing what he was told to do, to deporting people and sending them to Auschwitz. So I was very young when I interviewed him, and that marked me, as I would hope it would mark anybody. I talked with him on and off for about three years, until he died. And that was the subject of my PhD. And then I did a fellowship at St.&nbsp;Anthony’s College, Oxford, and spent years looking at it further. And that’s actually going to be my next book. I needed a long time to sit with that material and to read around it, but I had to get the interview while he was still alive. He was so old, he was 93 when I started talking to him, and so it was important to get that down for posterity’s sake first, and then circle back and do some analysis later when I was a bit older. When you talk to somebody who in his case was, you know, not antisemitic, not of the far right politically, was actually like centre-left, had lots of Jewish friends, etc. Was like top of his class, you know, came from a milieu and a background and a formation that I think many of us would read and be like, Okay, that seems pretty reasonable. You ask yourself, how on earth did that person in his, like, young period of his late 20s, early 30s end up being involved and actively participating in what ends up being mass murder. It’s probably the most extreme case study of ethics, or one of the most extreme case studies of ethics that I could have stumbled upon. And it stayed with me and to be honest, it shapes a lot of my work and how I think about human rights and civil liberties and the freedoms that we so often take for granted because I’ve studied, as an historian looking at France and Germany, how quickly those things can be taken away – very quickly, terrifyingly so, in fact. So that lens is always with me. And when I was then working in technology, and seeing some of the things that could be done with these tools and watching this lack of accountability, down to the point of gross negligence in some cases. And also, as a young technologist, not being given any training – we were given no training at all in ethics, in, like, discussing data protection – it was basically: this is the law, just obey the law, like, that’s the, that’s the box that you have to play in. Other than that, like, go for it. And when I look back on that now it’s like, Oh, my God, that’s the equivalent of putting your family in the car, and everybody goes off without wearing their seatbelts on and, you know, all this sort of safety design that we take for granted in cars now, it’s just mad when you think about it, or the way we used to fly. We’re in this phase, it’s really interesting, just over the course of my career – 25 years – where the stuff that we’re talking about today that dominates the headlines, right, that is dominating the discussion in the tech sector, was not discussed at all at the turn of the century, other than by maybe people in the science and technology studies domain or academics. But it wasn’t filtering into boardrooms. It wasn’t on the front pages of newspapers, and it wasn’t being covered in the national news, whereas like now that is all I’m doing. So it’s amazing. A whole field has sprung up.</p>
<p><strong>Brian Tarran</strong><br>
I think that that kind of origin story, if you like, explains some of your, perhaps, belief in the importance of exploring this accountability question when it comes to technology, ethics?</p>
<p><strong>Stephanie Hare</strong><br>
Yeah, because I watched it, and I think what was so fascinating– So as I say, I was in my early 20s. In fact, I was 20, when this man was put on trial, and I had just moved to France. It was the longest trial in French legal history – it was a big deal, you could not not watch it. So I was reading this and seeing it in the press every day, and I watched the French people discussing it around me, you know, really being divisive, this stuff does not go away. And his view was: I was just following orders, I was doing what I was told to do. Which you know, you hear that a lot from engineers or people who are like, this is the design spec I’ve been given, or this is what my boss has told me to do, or this is what our investors want, etc. Or people feel they don’t have the power to stand up because, you know what, they’ve got a mortgage, they’ve got kids, and employers know that, like, they know that and they use it as leverage against people to silence them. Or they’ve signed an NDA, because we get made to sign these NDAs when we work in tech, and then we get made to sign another NDA when we leave, right, so we can’t disparage our employer, and maybe we’re given some money so we don’t talk about the things we’ve seen. You know, it’s, it’s gross – it’s a gross little world, and like you have to be very, very solid and take good care of yourself to work in it, I reckon. To try and keep your ethical and moral compass. It’s hard. So I think because I saw that. And I saw that someone who – whether we believe him or not, this is what he claimed – in his 30s, he was just doing kind of what everybody around him was doing under a situation of crisis. He was let off the hook. I mean, he wasn’t just not persecuted in 1945, he was actually promoted. And then he became France’s top civil servant, and then he became an MP, and then he became budget minister. I mean, this guy’s career was not hurt in any way by what he did. On the contrary, right, he advanced. And yet, by the end of his life, French values had changed, so a new generation wanted to hold him to account. And I think about that a lot for all of us, right, who are sort of walking around in our 30s or 40s. Another generation or two, when we’re older, might look at some of what technology we’ve built or our behaviour on climate change, our track record – did we do what we could have done to slow global warming, to improve biodiversity? – and they might, they might hold us to account saying, you could have stopped this and you didn’t, right? It’s not just what you did. It’s what you did not do. Right. So we have to be super careful when we think about ethics, because ethics change, values change over time. And what seems okay today may not be okay in 10, 20, 30 years time, and we might be the 80- or 90-year-olds who are put on trial. That is on my mind all the time, right. It’s not very relaxing.</p>
<p><strong>Brian Tarran</strong><br>
No, and I guess it makes me think. Well, I mean, this is getting into the hypotheticals right. But is it– if we can’t necessarily predict or plan out how values might evolve over time, is it enough to be able to, to just say or to document that we asked the right questions at the time, rather than just doing things blindly. Is that where we need to kind of almost formalise our process of writing down, setting out, you know, we want to do this, we’ve considered these potential harms, we’ve considered these potential benefits, and we kind of document that so at least, you know, future generations can say well, “They thought about it. They might have not thought about it in the right way, but they tried”?</p>
<p><strong>Stephanie Hare</strong><br>
Absolutely, I think, you know, show your work and be like, these were our, you know, these were our sort of first principles of where we were starting from, this is the context in which we were making this decision. Because again, I don’t, I don’t necessarily fear the judgement of history in terms of if I get something wrong. People get stuff wrong all the time. That’s just being human. It’s, did I not care? You know, was I like, well, sorry, little little boys and girls who are babies now, like, I need to do my stuff, and like, I don’t care about you, right? That attitude is tough. Or I decided I just really, you know, I really needed to buy a flat. So I decided to work for some dodgy company, or dodgy, dodgy company that’s owned by a foreign government, but I knew it was going to be fine, and they’re offering me a tonne of money, and now I can go on nicer holidays. I’ve had these conversations with people about this literally this past week, like, these are live issues for people. There’s a cost of living crisis, ethics can feel like a luxury for some people rather than a necessity. And human beings are very bad, all of us, at thinking about, you know, future selves, right? Like we kind of, we optimise for how we’re feeling now, and we’ll deal with 20 years from now later if we even get there. So I think there’s that. There’s also– this really inspired the writing of the book, Technology is Not Neutral. I knew, I had this weird sense – I had just gone independent, so I had left working for these companies, I was not under any NDAs anymore, which right there gives you a clue; I could say what I wanted – but I also knew there was a chance that I was going to have to go back either into industry, or maybe work for a government, I don’t know what I’m going to need to do in the future or who I’m going to want to work with or what reasons I might even have for that. But I knew I had this window of being an independent researcher and broadcaster, that I could say whatever I wanted, and I had that thing of like, okay, if you’ve had a window of, say, five years, for example, what would you say if you were not afraid? If you were not scared? If you were like, you know, screw the money, screw the corporate pressure, screw the government, whatever, what do you want to talk to the public about? And my views were, I really wanted to talk to them about facial recognition, because I feel people just fundamentally do not understand how dangerous that technology is and how it can be used. I wanted to talk about the pandemic technologies, because we were, you know, I was writing it during the pandemic, and I thought, well, if a pandemic ever happens again, let’s have a nice little tidy case study for potentially future historians or future medical personnel, public health officials to pull out, because when the pandemic hit, we all had to go back and look at stuff from the Spanish flu. You know, there’s a lot of discussion of like, why has this come as such a surprise? Are we going to use these technologies again or not? Right. Like, you know, is it worth it? Is the return on investment worth it in all senses – ethically, as well as medically, all of those things? So I thought I would lay down a couple of markers that I hoped would stand the test of time. But the big thing I wanted to do, because I was always thinking I might have to go and sign another NDA and go work because I too must earn my living, was I wanted to write something so that anyone who cares about technology, is working in it, is investing in it, right – it’s not just people who code, it’s people who fund the people who code. Buying technology – procurement is massive, you’re a really powerful person if you’re in charge of procurement. But also just consumers, and citizens and parents, and teachers and kids. If I could write up everything that I had learned in my 25 years, and succinctly as possible, right – as short as possible, because people are tired, they’re busy – I could pass that baton on, so that if I ever have to stop going on television and radio, and I’m no longer allowed to write in newspapers and warn people about the stuff I’m seeing and the abuses of power, and showing them examples of history of how this can go so terribly wrong, maybe it will have, like, lit somebody else. And I’m delighted to report – I mean, we’ll see; time will tell, it’s only been out a year – the amount of people who have brought me in to train their staff, to talk to their board. I’ve talked to children. I’ve talked to university students, I’ve taught classes all over the world, because we can now do online teaching. I’ve taken a lot of it on television and radio and in the newspapers. People wanted this, and I’m not the only person working on it, of course – there’s been a whole flowering of people, scholars, etc., working in putting out amazing books and documentaries. It’s really, we’re having some sort of moment with technology ethics – AI ethics being just a branch of that. So that’s really encouraging. So I sort of feel like, you know, again, if I, if I’m gonna have to account for myself at the age of 93, I would like to be able to point to that and go, I tried. I tried. And I have no idea if it will succeed or not, but I stood up to the plate and I swung the bat and, you know, I aimed for the bleachers.</p>
<p><strong>Brian Tarran</strong><br>
One of the things I thought was really interesting about the book, it comes towards the end when you’re kind of talking about, you’re summing up, and you talk about how your thinking about almost like the the approach or solution to the technology ethics issue has changed over the course of the writing of the book. You had, like, a list of potential, like, proposals, proposed actions that you wanted to analyse, but then you realised that actually technology ethics is a “wicked problem”. I wonder if you could explain what that term means for people who might not be familiar with it and and why you think of it that way?</p>
<p><strong>Stephanie Hare</strong><br>
Yeah, I’m so grateful to have learned about the term “wicked problem”. My friend Jason Crabtree, who wrote an amazing book about electricity grids, like smart electricity grids, for Cambridge University Press, had asked me to read his manuscript maybe 10 years ago, and I read it, and one thing I took away that just absolutely blew my mind was this concept. So I shall gift it to you for those of you have not heard it. Because then suddenly, you’re like, God, it makes so much sense. There are certain problems, I would say, like, the climate crisis, and biodiversity loss would be a good example of this. There’s certain problems that have many causes, many causes, so there isn’t going to be one solution to fix them. So people constantly ask me, oh, is this the magic bullet? No, they’re like, there are certain problems that there is no magic bullet – the pandemic is probably another, actually. Then, if you do try to solve these wicked problems, the mere act of solving them can introduce a whole new set of problems to them. So like, it becomes even more of a head– You know, I’m trying not to swear, but a messing with your head moment. And it’s exhausting, you know, and it gives you your forehead wrinkles and makes you just sort of want to bang your forehead onto the nearest wall. And yet, you also can’t opt out and be like, well, it’s just too hard. It’s a wicked problem. There’s no solution, there’s nothing to be done, you know, throw up your hands, because you’re like, Yeah, but the problem is, is if we don’t do anything, like literally people are dying; literally, climates are becoming uninhabitable, we’re going to have massive climate migration, that’s going to cause all sorts of problems, water scarcity, we can have wars over this, like, we have to do something. So like, you have to still act on a wicked problem, all while knowing that it’s not going to be solved in a binary sense of like zero, one, black and white, I can point to it and measure it. And for people who like metrics, that’s a real pain, because they’re like, I want to know what good looks like and I want to know how we’ll know when we get there, you know, what’s the percentage, what’s the number? And you kind of have to be like, Well, with a wicked problem, you might never solve it, or you won’t solve it once. Because again, with something like climate change, or pandemics, these are things you’re probably gonna have to solve again, and again, and again, because it’s dynamic. And it’s constant, you know, we’re always going to be managing our relationship with the climate, with the environment. So, you know, we can pick a certain temperature, or a certain percentage of landmass that, you know, has trees or whatever, and like, come up with a little metric for our metric-oriented friends. But that’s still not very meaningful. So it’s more that when you think of a wicked problem, like facial recognition technologies, like, we need to be able to identify people in certain situations, and like, we want that, right. Like, we want to be able to catch criminals, and we want to be able to catch terrorists when they’ve managed to pull off a terrible act of, of harm to people. But at the same time, do you want to turn your society into a sort of permanent dragnet? Do we not care about privacy? If so, like, when do we care about privacy? And when are we okay with maybe sacrificing that for the greater good and who decides that? It’s really problematic if you live in London as I do, and your police force, which is using this technology, has admitted, they’ve admitted themselves to being misogynist, institutionally misogynist, homophobic, racist, right? And then we’re gonna give them a technology that doesn’t work very well on people with certain skin. It doesn’t identify people of a certain age as well. It’s got all sorts of problems. So you’re kind of like, hmm? Facial recognition is covered a bit under the EU AI Act. But even then there’s like so many loopholes. And the thing is, if you cite national security, it usually gets waved through because no one wants to be the person who said, I said we couldn’t use this technology, and then something bad happened. Right? So you err on the side of, like, the precautionary principle. The default is, let them use it. We must trust them. Except what do you do if your police force has given you quite ample evidence not to trust them? Or companies. You know, this is not to bash on the police, by the way – companies are some of the worst offenders in this area. So that’s what I mean about it being a wicked problem is, it’s out there. It’s installed. It’s all over the UK, it’s definitely all over the US as well. And we don’t really have a good framework for it.</p>
<p><strong>Brian Tarran</strong><br>
But then this is where we loop back around to the kind of culture, right, creating a culture of technology ethics? You know, we can’t just put a checklist in place once, do it, tick it off, yeah, we’ve done that for facial recognition technology, we’re good to go. Because there are always new potential use cases for it, new applications, new integrations with different systems that we always need to be thinking, every time, is this the right thing to do? Or–</p>
<p><strong>Stephanie Hare</strong><br>
I mean, I’m still a big fan of checklists. So it’s not that I’m anti-checklist. And I’m not saying that you said that, by the way, I’m more thinking aloud. Checklists can still be useful, right? Like, whenever I’m in a really bad mood, I’m like, Okay, hang on, have I slept? Do I just need a glass of water? Am I hungry? You know, what I think is angry may just be that I skipped lunch. You can kind of go through those things, and anybody who’s had to like troubleshoot why a baby or a small child is unhappy will also have a checklist and what’s on the thing – ah, they missed naptime, where’s their bear? That sort of thing. Companies need checklists, because you’re trying to get loads of people singing from the same hymn sheet, I get that. But what I wanted to get away from was this idea that, like, one person or one team gets this checklist and maybe does that once a year, once a quarter, pick your cadence – and everybody else gets a pass. Ethics doesn’t work that way, because again, ethics is kind of I think in the wicked problem scenario of, like, how do we decide what our values are and how to live them? And how do we know, where do we draw the line? And then how do you, how do you decide if you’ve gone over the line or not? And all of that, who decides who decides? Those are really complex questions that mean that really you can’t abdicate. This is, in a company’s case, it’s the CEO, it’s the board, all the way on down – it has to be baked in to every single employee, and also investors, mindset. And I was thinking about it in terms of cybersecurity, I once had a colleague who gave me an analogy that I think is helpful, so I’ll share it for what it’s worth: When you go on to, say, an oil rig, in the North Sea – a highly dangerous environment – you might be the most junior person there, and you’re there for your very first day of work. But if you spot something on that rig that is a health and safety risk, you have to speak up. You’re not going to go, like, Oh, my boss might say something, whatever, because, like, everybody’s life on that rig is depending on everyone having that culture of careful, that’s not okay. And that really put me in mind where it was like, Oh, wow, we’re going to have to like inculcate an entire new mindset. And we think about technology ethics a lot because of technology being the word, and we think it must mean like hardware or software, it’s always about coding, and it’s often guys in hoodies coding. But my preferred method of hacking is culture. Right. So like, again, if we tried to just solve everything through regulation and laws, that takes, you know – if you look at the average time it takes to pass a law and then for regulators to enforce it – ages, we’re talking years, like it’s too late. These technologies will have moved on. Ditto, calls for international treaties. Do it, by all means. Have a look at how long it takes most international treaties to get passed and then ratified – and then, P.S. What happens when people break them? Really, right. So like, they’re important, they’re necessary, but they’re insufficient. You can act a lot faster if you can get people preventing stuff from being built in the first place, and that means you need to have a culture of people working in technology, both within the organisations – whether that’s research labs, government, companies, universities, whatever – and on the outside – journalists, academics, thinkers, etc, just the public, an informed public – who can see something and do what I just described on the oil rig, like, sound the alarm and go, Wait a minute, hang on. That’s not okay. That is, that to me feels faster. And I’m way more into prevention than cure, for all sorts of reasons. So I think like, yes, to laws and regulations, yes, to treaties; this will be faster. And I think it will be more resilient.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, I agree. And I have to say, wrapping up, that I think Technology is Not Neutral is a great place to start to inculcate that mind shift, that mindset change. So, Stephanie, thank you very much for joining us today.</p>
<p><strong>Stephanie Hare</strong><br>
Thank you for having me.</p>
<p><strong>Brian Tarran</strong><br>
You said you’re working on a new book. Have you got a timeline for that? Or a title?</p>
<p><strong>Stephanie Hare</strong><br>
No.&nbsp;I am the slowest thinker and writer, I’m like the opposite of move fast and break things, I’m like move slowly and like think it over maybe several times. So I’m just getting started out. I’ll sort of go five years. It’s gonna be, it’s a history book. Alright. So this is, this is different, I’m having to take my classes in French and German right now to get kind of match fit in those languages again, and then you know, I’ll be off and writing. But, yeah, I hope to have another book out, you know, in five years.</p>
<p><strong>Brian Tarran</strong><br>
Well, if the year it took me to read Technology is Not Neutral is any indication, in three, four or five years time it will still be relevant today. So–</p>
<p><strong>Stephanie Hare</strong><br>
That’s the thing with history, it always stands the test of time.</p>
<p><strong>Brian Tarran</strong><br>
Well, thank you, thank you again for joining us on Real World Data Science. It’s been a pleasure talking to you.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
<p>© 2023 Royal Statistical Society</p>
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/04/28/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/04/28/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photo of Stephanie Hare is not covered by this licence. Photo is by Mitzi de Margary, supplied by Stephanie Hare and used with permission.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
<p>Tarran, Brian. 2023. “‘I’m way more into prevention than cure’: Stephanie Hare on why we need a culture of technology ethics.” Real World Data Science, April 28, 2023. <a href="https://realworlddatascience.net/viewpoints/interviews/posts/04/28/stephanie-hare.html">URL</a></p>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Technology ethics</category>
  <category>AI ethics</category>
  <category>Culture</category>
  <category>Regulation</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/04/28/stephanie-hare.html</guid>
  <pubDate>Fri, 28 Apr 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/04/28/images/stephanie-hare-bw.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Data science as ‘a rainbow’, and other definitions</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/defining-DS.html</link>
  <description><![CDATA[ 




<p>What does “data science” mean to you? That’s a question we’ve been asking a lot in recent weeks as part of our <a href="https://realworlddatascience.net/careers/career-profiles/">career profiles</a> series of interviews – the first of which, featuring <a href="https://realworlddatascience.net/careers/career-profiles/posts/03/28/tamanna-haque.html">Jaguar Land Rover’s Tamanna Haque</a>, was published yesterday.</p>
<p>It’s also a question that was asked recently of Sylvia Richardson, emeritus director of the Medical Research Council Biostatistics Unit at the University of Cambridge and immediate past president of the Royal Statistical Society (RSS).</p>
<p>Richardson was interviewed by Francesca Dominici, interim co-editor-in-chief of the Harvard Data Science Review. In response to the question “What’s data science for you?”, Richardson said:</p>
<blockquote class="blockquote">
<p>It’s hard to be original, but I was racking my brain for a good metaphor, and came up with the metaphor of a rainbow of interconnected disciplines, sharing the common aim of making the best use of data-rich environments we live in to solve problems in society. So, like in a rainbow, data scientists have to work together to draw out information from data. And the colors must match, [though] they are different. Similarly, there are different but intersecting data science tasks, taking different shapes and forms. As data scientists, we recognize and enjoy diversity, we’re not doing all the same tasks. Nevertheless, there is a backbone, a shape to the rainbow. And for us, this backbone is probability theory, study design, and quantifying uncertainty using statistical thinking. We also know that rainbows change all the time. They don’t last, but they keep reappearing. Data science is also evolving constantly because new questions and new types of data keep arising. In a similar way to the rainbow which is strongly influenced by the atmosphere, one key aspect of data science is that we have a strong link to practice. So, we work together to solve problems from different perspectives, we evolve, we try to be relevant to science and society, and make the best use of the data. [<a href="https://hdsr.mitpress.mit.edu/pub/v27yux58/release/2?from=2089&amp;to=3374">Source</a>]</p>
</blockquote>
<p>Richardson’s view on the meaning and importance of data science has special resonance to me, as editor of Real World Data Science. While president of RSS, Richardson set up the <a href="https://rss.org.uk/policy-campaigns/policy-groups/data-science-task-force/">Data Science Task Force</a> out of which this website emerged. As she explains to Dominici:</p>
<blockquote class="blockquote">
<p>… while I was president, I felt a sense of urgency to encourage the RSS to revisit its engagement with data science, and I created a data science task force right at the beginning of my presidency. It didn’t get going earlier because there was COVID to keep us busy! Nevertheless, the Data Science Task Force got underway in 2021 and came up with two major recommendations. One was to give more resources to the practitioners’ community, which led the RSS to create a Real World Data Science online platform. A second direction was to brainstorm on what is still needed for the discipline to thrive. [<a href="https://hdsr.mitpress.mit.edu/pub/v27yux58/release/2?from=17202&amp;to=17799">Source</a>]</p>
</blockquote>
<p>You can read (or listen) to Richardson and Dominici’s conversation in full on the <a href="https://hdsr.mitpress.mit.edu/pub/v27yux58/release/2">Harvard Data Science Review website</a>.</p>
<p>And we’ll have more <a href="https://realworlddatascience.net/careers/career-profiles/">career profiles</a> – and more personal definitions of data science – to share soon. In the meantime, why not tell us what “data science” means to you?</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Data science as ‘a rainbow’, and other definitions.” Real World Data Science, March 29, 2023. <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/defining-DS.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Updates</category>
  <category>Themes</category>
  <category>People</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/defining-DS.html</guid>
  <pubDate>Wed, 29 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/29/images/rainbow.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>OpenAI’s text classifier won’t calm fears about AI-written homework</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/AI-screening.html</link>
  <description><![CDATA[ 




<p>When ChatGPT launched in December 2022, it wasn’t long before users highlighted <a href="https://news.sky.com/story/the-ultimate-homework-cheat-how-teachers-are-facing-up-to-chatgpt-12780601">the tool’s potential as a homework aid</a>. Pop an essay question into ChatGPT’s prompt box or feed your creative writing task to the AI instead, <em>et voila</em> – your work is done!</p>
<p>In reality, of course, things aren’t quite so simple. ChatGPT, like other large language models, has an unfortunate <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/01/27/talking-chatgpt.html">habit of making stuff up</a> – fine for creative writing, perhaps; not so good for a history essay. Outputs need to be checked and verified if you want to guarantee a good mark on your assignments. But while ChatGPT can’t – and shouldn’t – be trusted completely, many have found that it can help lighten the homework load.</p>
<p>With <a href="https://www.theguardian.com/technology/2023/feb/02/chatgpt-100-million-users-open-ai-fastest-growing-app">ChatGPT’s user count crossing the 100 million mark</a> last month, it’s understandable that worries about an explosion of AI-written text have proliferated in many professions, including education. <a href="https://www.washingtonpost.com/education/2023/01/05/nyc-schools-ban-chatgpt/">Some education systems</a> have decided to <a href="https://www.smh.com.au/national/nsw/can-you-tell-between-a-year-6-student-and-ai-teachers-say-they-can-20230120-p5ce5s.html">ban the use of ChatGPT</a>. Other educators have adopted a more relaxed approach. Writing in <em>Scientific American</em>, <a href="https://www.scientificamerican.com/article/how-chatgpt-can-improve-education-not-threaten-it/">law professor John Villasenor argued</a>:</p>
<blockquote class="blockquote">
<p>“The time when a person had to be a good writer to produce good writing ended in late 2022, and we need to adapt. Rather than banning students from using labor-saving and time-saving AI writing tools, we should teach students to use them ethically and productively… They need to learn to compose well-organized, coherent essays involving a mix of AI-generated text and traditional writing.”</p>
</blockquote>
<p>Villasenor makes a valid point. But experience tells us that not every student is going to use these tools ethically. Some will pursue the path of least resistance and will attempt to present ChatGPT’s outputs as their own. So, the question becomes: Is it possible to tell the difference between human-generated text and AI-generated text?</p>
<section id="spot-the-difference" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="spot-the-difference">Spot the difference</h2>
<p>One answer to that question comes from OpenAI, makers of ChatGPT. On January 31, they launched a classifier “to distinguish between text written by a human and text written by AIs from a variety of providers”.</p>
<p>OpenAI <a href="https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text">introduces the classifier</a> by saying that reliably detecting <em>all</em> AI-written text is “impossible”. But it goes on to say:</p>
<blockquote class="blockquote">
<p>“… we believe good classifiers can inform mitigations for false claims that AI-generated text was written by a human: for example, running automated misinformation campaigns, using AI tools for academic dishonesty, and positioning an AI chatbot as a human.”</p>
</blockquote>
<p>OpenAI stresses that the current version of the classifier “should not be used as a primary decision-making tool”, and users should take that statement to heart – especially if they are planning to vet student homework with it. In evaluations, OpenAI reports that its classifier correctly identifies AI-written text as “likely AI-written” only 26% of the time, while human written text is incorrectly labelled as AI-written 9% of the time.</p>
<p>These two reported numbers are important. They are, respectively, the classifier’s <strong>true positive rate</strong> and the <strong>false positive rate</strong>. The former is the conditional probability of a positive result given that a piece of text <em>is</em> AI generated; the latter is the conditional probability of a positive result given that a piece of text <em>is not</em> AI generated. However, neither piece of information directly addresses the question that will be of most interest to teachers: “If a piece of homework is flagged as ‘likely AI-written’ by the OpenAI classifier, what is the probability that it actually <em>is</em> AI-written?”</p>
<p>To answer this question, we need to flip the conditional probabilities – from “the probability of positive test given text is AI generated” to “the probability text is AI generated given positive test”. Bayes’ theorem provides a formula for doing just that, as described in <a href="https://www.significancemagazine.com/science/547-a-visual-guide-to-screening-test-results">this 2017 article by Tim Brock, published by Significance magazine</a>.</p>
<p>As Brock’s article demonstrates, versions of this problem are familiar to medical statisticians, who often find themselves having to explain screening test outcomes – specifically, the probability that a person has disease X given that they have tested positive for said disease. This probability depends on the <strong>prevalence</strong> of a disease and the <strong>sensitivity</strong> and <strong>specificity</strong> of the test, and Brock defines these terms as follows:</p>
<ul>
<li><dl>
<dt>Prevalence</dt>
<dd>
The proportion of the population being tested that are affected by a given condition.
</dd>
</dl></li>
<li><dl>
<dt>Sensitivity</dt>
<dd>
The proportion of patients with the condition being screened for that are correctly identified as having the condition.
</dd>
</dl></li>
<li><dl>
<dt>Specificity</dt>
<dd>
The proportion of patients without the condition being screened for that are correctly identified as not having the condition.
</dd>
</dl></li>
</ul>
<p>Sensitivity and specificity are also referred to as, respectively, the true positive rate (mentioned earlier) and the true negative rate.</p>
<p>We know from OpenAI’s own evaluations that out of 100 pieces of AI-written text, only around 26 would be correctly classified as “likely AI-written”, so the classifier’s sensitivity is 26%. And out of 100 pieces of human-written text, around 9 would be incorrectly classified as AI written, meaning 91 would be correctly classified as not AI written, so specificity is 91%. But the big piece of information we don’t have is prevalence: What proportion of homework assignments are written by AI?</p>
<p>This prevalence figure is likely to vary based on where students live, what age they are, their level of interest in AI tools and technologies, and many other factors. <a href="https://stanforddaily.com/2023/01/22/scores-of-stanford-students-used-chatgpt-on-final-exams-survey-suggests/">A poll of Stanford University students by The Stanford Daily</a>, for example, found that 17% of respondents used ChatGPT for final assignments or exams in the fall quarter – though it reports that “only about 5% reported having submitted written material directly from ChatGPT with little to no edits”.</p>
<p>So, let’s assume for the moment that 5% of homework assignments are AI-generated. If you were screening 1,000 pieces of homework with the OpenAI classifier, you’d see something close to the following results:</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 21%">
<col style="width: 22%">
<col style="width: 21%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">True positives</th>
<th style="text-align: right;">False positives</th>
<th style="text-align: right;">True negatives</th>
<th style="text-align: right;">False negatives</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Results</td>
<td style="text-align: right;">13</td>
<td style="text-align: right;">86</td>
<td style="text-align: right;">864</td>
<td style="text-align: right;">37</td>
</tr>
</tbody>
</table>
<p>The figures below show the results graphically as proportions of (a) all tests and (b) all positive tests. (All plots are produced using Python and the <code>matplotlib</code> package; code and functions are available from <a href="https://github.com/brtarran/screening-tests">this GitHub repository</a>.)</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig1a.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all tests, assuming 5% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 1a:</strong> Classifier test results as a percentage of all tests, assuming 5% prevalence of AI-written homework.</p>
</div></div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig1b.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all positive tests, assuming 5% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 1b:</strong> Classifier test results as a percentage of all positive tests, assuming 5% prevalence of AI-written homework.</p>
</div></div><p>From Figure 1b, we see that if the classifier delivers a “likely AI-written” result, the chance that the text is AI-written is only about 13%. This is the classifier’s <a href="https://uk.cochrane.org/news/sensitivity-and-specificity-explained-cochrane-uk-trainees-blog">positive predictive value</a> at the assumed 5% prevalence.</p>
<p>If we reproduce our figures using a prevalence rate of 17%, also from the Stanford survey, the chance that a positive result is a true positive is now about 37%.</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 21%">
<col style="width: 22%">
<col style="width: 21%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">True positives</th>
<th style="text-align: right;">False positives</th>
<th style="text-align: right;">True negatives</th>
<th style="text-align: right;">False negatives</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Results</td>
<td style="text-align: right;">44</td>
<td style="text-align: right;">75</td>
<td style="text-align: right;">755</td>
<td style="text-align: right;">126</td>
</tr>
</tbody>
</table>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig2a.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all tests, assuming 17% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 2a:</strong> Classifier test results as a percentage of all tests, assuming 17% prevalence of AI-written homework.</p>
</div></div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig2b.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all positive tests,  assuming 17% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 2b:</strong> Classifier test results as a percentage of all positive tests, assuming 17% prevalence of AI-written homework.</p>
</div></div><p>Yet another survey, <a href="https://www.prweb.com/releases/intelligent_com_survey_finds_30_percent_of_college_students_use_artificial_intelligence_chatbot_chatgpt_for_written_homework/prweb19141759.htm">this one from Intelligent.com</a>, claims that 30% of college students have used ChatGPT for written homework. Plugging this number into our calculations, the chance that a positive test result is a true positive is now slightly better than 50/50.</p>
<table class="table">
<colgroup>
<col style="width: 12%">
<col style="width: 21%">
<col style="width: 22%">
<col style="width: 21%">
<col style="width: 22%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th style="text-align: right;">True positives</th>
<th style="text-align: right;">False positives</th>
<th style="text-align: right;">True negatives</th>
<th style="text-align: right;">False negatives</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Results</td>
<td style="text-align: right;">78</td>
<td style="text-align: right;">63</td>
<td style="text-align: right;">637</td>
<td style="text-align: right;">222</td>
</tr>
</tbody>
</table>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig3a.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all tests, assuming 30% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 3a:</strong> Classifier test results as a percentage of all tests, assuming 30% prevalence of AI-written homework.</p>
</div></div><div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/fig3b.png" class="img-fluid figure-img" alt="Horizontal stacked bar chart showing test results as a percentage of all positive tests,  assuming 30% prevalence of AI-written homework"></p>
</figure>
</div>

<div class="no-row-height column-margin column-container"><div class="">
<p><strong>Figure 3b:</strong> Classifier test results as a percentage of all positive tests, assuming 30% prevalence of AI-written homework.</p>
</div></div></section>
<section id="determining-guilt" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="determining-guilt">Determining ‘guilt’</h2>
<p>If a test has a positive predictive value of just over 50% (at an assumed prevalence rate of 30%), does that provide a reasonable basis on which to accuse someone of getting ChatGPT to do their homework? That depends on who you ask. If we look to the legal system for guidance, in civil cases like personal injury claims or contract disputes judges typically make decisions on the so-called “balance of probabilities”. This is generally assumed to mean if we are more than 50% sure of someone’s “guilt” in this context, that might be sufficient to find against them. However, in criminal law, a higher standard applies: “beyond reasonable doubt”. Legal scholars have long wrestled with how to quantify this in probabilistic terms, and surveys of judges put “beyond reasonable doubt” somewhere in the range of being 80% to 99% certain of guilt – see, for example <span class="citation" data-cites="mccauliff1982burdens">McCauliff (1982)</span> and <span class="citation" data-cites="solan1999refocusing">Solan (1999)</span>.</p>
<div class="no-row-height column-margin column-container"><div id="ref-mccauliff1982burdens" class="csl-entry">
McCauliff, Catherine MA. 1982. <span>“Burdens of Proof: Degrees of Belief, Quanta of Evidence, or Constitutional Guarantees.”</span> <em>Vand. L. Rev.</em> 35: 1293.
</div><div id="ref-solan1999refocusing" class="csl-entry">
Solan, Lawrence M. 1999. <span>“Refocusing the Burden of Proof in Criminal Cases: Some Doubt about Resaonable Doubt.”</span> <em>Tex. L. Rev.</em> 78: 105.
</div></div><p>It is at this standard of evidence that OpenAI’s classifier shows its limitations. For example, if we flip Bayes’ theorem around, we find that to achieve a positive predictive value of at least 80%, the prevalence rate needs to be at least 58%. For a positive predictive value of 90%, prevalence needs to be 76%. (Verify these figures for yourself: Python code and functions are available from this <a href="https://github.com/brtarran/screening-tests">GitHub repository</a>).</p>
<p>Thus far in our calculations, we’ve set prevalence according to estimates of the percentage of students who use ChatGPT for their homework. But, according to statistician and science writer Robert Matthews, individual students could justifiably complain about having their guilt decided on this basis. “It’s like deciding someone is guilty of a crime just because they happen to live in an area notorious for criminal gangs,” he says. Instead, the guilt of individual students should be decided using an estimate of the chances that <em>they</em> would use ChatGPT for <em>that particular</em> homework assignment.</p>
<p>Looked at in this way, Matthews says, “You already have to be pretty convinced of a person’s ‘guilt’ even before applying the classifier if you want to put the evidence ‘beyond reasonable doubt’. Bayes’ theorem highlights the need to be really clear about what you mean by the ‘accuracy’ of a test, and about what question you want the test to answer.”</p>
<p>So, here’s a question that teachers will be asking if they are worried about ChatGPT-generated homework: “Has the piece of text I’m marking been written by AI?” If those same teachers use the OpenAI classifier to try to answer that question, they will no doubt expect that something classified as “likely AI-written” is more likely to be AI-written than not. However, as it stands now – and as our examples above have shown – users can’t be confident that’s the case. In education terms, this particular ‘test’ is a long way from scoring top marks.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “OpenAI’s text classifier won’t calm fears about AI-written homework.” Real World Data Science, March 15, 2023. <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/03/15/AI-screening.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



</section>

 ]]></description>
  <category>AI</category>
  <category>Large language models</category>
  <category>Classifiers</category>
  <category>Screening tests</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/AI-screening.html</guid>
  <pubDate>Wed, 15 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/03/15/images/teacher-marking-homework.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>US legislators get their data science act together</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/interviews/posts/2023/03/06/data-science-act.html</link>
  <description><![CDATA[ 




<p>On February 14, 2023, a bipartisan group of US legislators introduced the <a href="https://stevens.house.gov/media/press-releases/rep-stevens-leads-bipartisan-legislation-increase-access-data-science-and">Data Science and Literacy Act</a> with the goal of boosting access to data science education and building “America’s 21st century STEM workforce”. We sat down with guests Zarek Drozda, Anna Bargagliotti, Christine Franklin and Steve Pierson to discuss the news and to hear why data science education is “the new apple pie”.</p>
<ul>
<li>Zarek Drozda is director of the <a href="https://www.datascience4everyone.org/about">Data Science 4 Everyone</a> coalition.</li>
<li><a href="https://cse.lmu.edu/faculty/?expert=anna.bargagliotti">Anna Bargagliotti</a> is graduate program director and professor of mathematics at the Seaver College of Science and Engineering, Loyola Marymount University.</li>
<li>Christine Franklin is the American Statistical Association’s <a href="https://www.amstat.org/education/asa-k-12-statistical-ambassador">K-12 statistical ambassador</a>.</li>
<li>Steve Pierson is the <a href="https://twitter.com/asa_scipol?lang=en">ASA’s director of science policy</a>.</li>
</ul>
<p>Check out our full conversation below or on YouTube.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/OaRFFgKb1S0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="timestamps" class="level2">
<h2 class="anchored" data-anchor-id="timestamps">Timestamps</h2>
<ul>
<li>The state of data science education in the United States (<a href="https://youtu.be/OaRFFgKb1S0?t=211">3:31</a>)</li>
<li>What will be the main impacts of the Data Science and Literacy Act? (<a href="https://youtu.be/OaRFFgKb1S0?t=554">9:14</a>)</li>
<li>Professional development support for teachers and teacher-educators (<a href="https://youtu.be/OaRFFgKb1S0?t=786">13:06</a>)</li>
<li>How much money is needed to deliver data science education? (<a href="https://youtu.be/OaRFFgKb1S0?t=1133">18:53</a>)</li>
<li>Developing a data science curriculum (<a href="https://youtu.be/OaRFFgKb1S0?t=1629">27:09</a>)</li>
<li>Building confidence in data, statistics, and technology (<a href="https://youtu.be/OaRFFgKb1S0?t=1914">31:54</a>)</li>
<li>Learning from, and making connections with, international colleagues (<a href="https://youtu.be/OaRFFgKb1S0?t=2223">37:03</a>)</li>
</ul>
</section>
<section id="quotes" class="level2">
<h2 class="anchored" data-anchor-id="quotes">Quotes</h2>
<p>“Most of our teachers in US schools, math teachers, have not had any formal training in statistics. Or if they have, it’s been maybe one course. They’re very uncomfortable with trying to implement these standards [for data science and statistics education]. And it’s just going to require a tremendous amount of professional development. Sounds easy in theory to deliver professional development, but very difficult in practice.” (<a href="https://youtu.be/OaRFFgKb1S0?t=618">10:18</a>)</p>
<p>“We know that in aggregate, between federal, state, private and local funding, we’re going to have to create the necessary resources to make sure that our K-12 public education system can prepare students for a world that’s changing super fast, and the K-12 system moves super slow in how it adapts to new content. And so really it’s both about what can we do to upskill data science, data literacy skills [and] it’s also about how do we help the system adapt faster as new technology comes out and leverage the importance of data in that.” (<a href="https://youtu.be/OaRFFgKb1S0?t=1176">19:36</a>)</p>
<p>“I think we’ve spoken to some 50 or 60 offices, both on the Senate side and the House side. And this [has been] received really well. We don’t get any pushback on that there is a need for greater data literacy. Here stateside, I’ve been saying it’s kind of like advocating for apple pie. People get it and they resonate.” (<a href="https://youtu.be/OaRFFgKb1S0?t=1280">21:20</a>)</p>
<p>“As we introduce this bill, I think we should be messaging [that] there’s a economic competition aspect to this; that it’ll be really important for the US to make investments in this area to, frankly, catch up to where I think other international peers are.” (<a href="https://youtu.be/OaRFFgKb1S0?t=2434">40:34</a>)</p>
<p>“Data tell our stories, and they reflect what’s happening in our world today – much like art around us in some ways. And a way to think about data science education is to think about what we need our data understanding to be at each point in time in our educational career, or in our lives. And it’s not static, it’s an evolving thing. So you have to move with the data that are being collected.” (<a href="https://youtu.be/OaRFFgKb1S0?t=2574">42:54</a>)</p>
</section>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove repetitions.</p>
</div>
</div>
</div>
<p><strong>Brian Tarran</strong><br>
Hello, and welcome to the Real World Data Science news q&amp;a. I’m Brian Tarran. And I’m joined today by a panel of guests to discuss some promising developments in the United States around data science education. On the show today we have Zarek Drozda, director of the Data Science 4 Everyone coalition, Anna Bargagliotti, Graduate Programme Director and Professor of Mathematics at the Seaver College of Science and Engineering, Loyola Marymount University, Christine Franklin, the American Statistical Association’s K-12 statistical ambassador, and Steve Pearson, who is the ASA’s Director of Science Policy. Welcome all. Thank you for joining us. Steve, I’d like to come to you first, because it was one of your ASA science policy tweets that that first drew my attention to this story. And that specifically was the tweet about the introduction of a new Data Science and Literacy Act in the US House of Representatives. Can you give our viewers an overview of the act and its significance to the data science education landscape, please.</p>
<p><strong>Steve Pierson</strong><br>
Happy to Brian and I also want to credit my colleague, Ed Wu, an ASA science policy fellow who worked a lot on this and championed it. So I see kind of two overarching points here for the bill. One is just to help out those budding efforts around the United States to bring more data science education to students, right, the demand in the jobs is out there. Students should know about these jobs, we want to connect them to the 21st century jobs. So this is a Department of Education programme that helps out those schools, communities that need the help that want the help. We’re not trying to require anything of schools, which already have enough curriculum requirements. So this is a voluntary programme, that I mean, I think it’s developing curriculum, it’s providing professional development. But I think there’s another aspect of this, Brian, which is just kind of the attention that this can bring to these jobs, to the schools to the members of Congress that, you know, data intensive jobs are a great job opportunity in the 21st century, right? You can look at so many places to know that, right? The Bureau of Labor Statistics has both statistician and data scientist as the top 10 jobs in terms of projected growth for the next decade. There’s Glassdoor, there’s many others, so we know that. We want to make sure that today’s students know about those opportunities and are connected to them. But we also want to just kind of diversify the STEM workforce. So there’s components of that in the bill as well. And so we want, we think that, you know, a bill introduced into the US Congress will help bring attention to that, including the members of Congress and others.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. I’ll take a step back briefly to look at the data science education landscape as it is today and Zarek, you helped facilitate a National Academies workshop last September, and one of the aims was indeed to survey that landscape for data science education for the K-12 grades – and for international audiences, correct me if I’m wrong, that’s students aged about five up to 17. Is that correct?</p>
<p><strong>Zarek Drozda</strong><br>
Right, for five to 18 range.</p>
<p><strong>Brian Tarran</strong><br>
So yeah, so how would you summarise that kind of state of data science education in the US right now?</p>
<p><strong>Zarek Drozda</strong><br>
Yeah, well, first focus on the workshop that was facilitated by the National Academies. And that was not the first but definitely the largest to date, in terms of a national convening of the United States for data science and data literacy education. We had 100 plus researchers, programme developers, and higher ed faculty in the room. There were 500 online, it was a big, you know, kind of early stage milestone for billing data science education in the United States. And we had a number of topics ranging from you know, what does this look like a practice? What is the professional development for, for K-12 teachers look like? What are examples both standalone data science courses, and also integration into different existing K-12 subject areas. And it was really a showcase of you know, a lot of the curriculum work that’s been developed over the past 10, 15 years for building your full length data science high school courses, or for building lesson plans or for building, you know, education, classroom specific software for data analysis that students can really get their their head around. And so I think it was a milestone to then this legislation then built off right that Steve was mentioning. I’m glad that you know news of both the National Academies workshop and then the legislation and kind of the growing momentum here in the US generally has made it across the pond. I think, partially our social media game was strong enough, which is exciting to hear. But I think it’s just a testament to you know, the energy for this space is really growing, right? Because it’s, it’s career connected. I think it’s so relevant to so many other emerging technologies, whether it’s artificial intelligence or ChatGPT or cyber. And I think, students, what came through really clearly in the workshop is that students really find this content relevant because of the technology applications. And it seems so, you know, of the moment.</p>
<p><strong>Brian Tarran</strong><br>
Yep. Well, certainly, you talked about jumping across the pond. So two weeks ago now, but it might have been three, I attended a meeting, a discussion around what they refer to as the digital skills gap in the UK. And I left that meeting feeling very much like what they were talking about, defining as digital skills were data science skills. And so when I saw that there was this Data Science and Literacy Act, I thought, well, you know, here’s, here’s something that hopefully, other other places like the UK can learn from. So Anna, you participated didn’t you in the workshop? So do you mind sort of giving us an overview of the data science landscape as it is, as it is now?</p>
<p><strong>Anna Bargagliotti</strong><br>
Absolutely, um, so I think, in the United States, at the moment, I think we’re at a spot where the different states are sort of moving. And in the United States, each state has their own department of education. So they, we are not, they’re not federal standards, they are state standards. And each in a lot of states, those standards are being revised and to include data science standards, and those discussions are moving pretty quickly, with some states already approving, other states implementing this coming fall, for example. And other states that are still in the process of sort of starting that. But it’s, but it’s exciting. The other thing that’s really been happening is trying to understand what the curriculum should what curriculum should look like in K-12, in particular. And the GAISE report, like you mentioned before, has a, lays out a, you know, a nice sort of example of what that should look like at the elementary, middle school and high school levels, and can be used sort of as an anchor point for states looking at what they should be doing. I would say at the university level, at the what we call the 12-16 level in the US, we are pretty good. There are many data science programmes and majors and minors across the United States. And they are quite strong, there’s more and more that pop up. And overall, those majors and minors look pretty similar from university to university, and those students are coming out with very, you know, a good skill set, and they are all finding jobs. As Steve mentioned, the job growth is there. And students are feeling quite prepared when they go to into the job growth. So I think where the university level is, could have been well articulated and well defined at the moment, the K-12 level is still sort of in flux of trying to figure out what should be there. And part of that has to do also with teacher preparation, it’s trying to understand what teachers should have and know in order to teach whatever these data science ideas are that are important for the K-12 level. The GAISE report makes some very, I think, concrete recommendations about what that should be, particularly being anchored in the statistical investigative process or problem solving process and understanding how you can use questioning in that and that being really a skill set that we are trying to promote in K-12 education, that then they use also at the university level if they continue on that way. And then just understanding that there’s different large conceptions of data now. Data are not just numbers, data could be sounds, could be text and whatnot. And these ideas are sort of these data science ideas that we are trying to promote in K-12, as well as at the university level. So I think overall, the landscape is quite good. I mean, we’re moving in these great directions. And I think slowly, we’re getting to some consensus about what that looks like. And we’re seeing that in the states moving forward with different standards.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. And so you mentioned the GAISE report there and that’s the Guidelines for Assessment and Instruction in Statistics Education, and of course that’s something you co-authored with, with Chris Franklin, Chris. Yeah, of course. Yeah. I’d like to bring you into the conversation. Now, Chris. You know, you and I have spoken a number of times over the years about GAISE about statistics, education and statistical literacy and, and the challenges of delivering high quality education in data and statistics at all levels of the curriculum. I wanted to get your impression of what you think the big contributions are that this act will hopefully make towards improvement of the data science education landscape.</p>
<p><strong>Christine Franklin</strong><br>
Well, I was very excited to see this act. And I think one of the big impacts that I see is how it can help our state departments of education actually try to implement standards that we’re seeing put in place right now, in terms of statistics and data science. Teachers, right now, most of our teachers in the US schools, math teachers have not had any formal training in statistics. Or if they have, it’s been maybe one course, they’re very uncomfortable with trying to implement these standards. And it’s just going to require a tremendous amount of professional development. Sounds easy in theory to deliver professional development, but very difficult in practice. And a big part of the difficulty of delivering professional development is funding to, to pay for this. Unfortunately, what I’ve seen is state departments of education will often implement these very nice standards in their curriculum, but then they’ve run out of money, or they don’t have sources of funding to where they can then think about the professional development of the teachers. So it’s not only the professional development of the teachers, but also the curriculum that’s going to support the standards that are put in place. Now, fortunately, ASA, for example, has just a wealth of open source resources that teachers can use. But then how did the teachers know where to get it? How do they know how to implement it in the classroom. So state departments are charged with trying to develop a framework of materials for their teachers. This takes money, this takes expertise. So not only that, but I think this bill can help with funding to allow state departments to do that. But professional development typically has been like week long workshops, day workshops, maybe they go online and do workshops, but really, for professional development to be successful. Teachers need day to day support, which requires funding once again, to provide the resource within schools and school systems to provide more of the day to day support that these teachers need. And I think lastly, one thing that we don’t think a lot about, but I’m hoping this bill will help, is the assessment that goes along with the curriculum that we’re implementing for statistics and data science. Once again, that takes funding that takes manpower support. And I’m really hoping that this bill can be a source that that our state DoE’s can turn to make their standards more successful with implementation.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, Chris, when you were speaking there about providing professional development support for the teachers, it reminded me of when I was a primary school governor here in the UK a few months back, a few years back, sorry. And we would always talk about math education, trying to improve math education, and that I think, the teacher confidence to deliver the math curriculum is always the issue that we run up against. So having support, having resources, having people that can go in and help, that changes the dynamic, I think, for teachers and certainly equips them to, to deliver on, you know, on that vision of, of data science education and statistical literacy for all, which is something that we spoke about before, right?</p>
<p><strong>Christine Franklin</strong><br>
That’s exactly right.</p>
<p><strong>Brian Tarran</strong><br>
That’s, that’s your vision for where we get to as a society?</p>
<p><strong>Christine Franklin</strong><br>
Well, I think one thing, one other thing we need to remember, it’s not just the teachers that need our support. It’s also the teacher educators that are preparing our school level teachers. And we, we need to keep that at the top of the list of priorities because most of our teacher educators recognise that our school level teachers need this support, but they are in a similar situation to where they don’t know exactly what they need to do. And so we’ve got kind of two big spots here that we need to work on for professional development, and it’s gonna take a lot of time and effort.</p>
<p><strong>Brian Tarran</strong><br>
Yeah, well, we’ll come back to that later, if you don’t mind. Zarek, did you want to come in? It looked like you was about to chime in.</p>
<p><strong>Zarek Drozda</strong><br>
Yeah, I was just, I wanted to agree with Chris and second it and expand it because I think it’s professional development for teacher educators and every layer above that, right. It’s every layer above the teachers: teacher educators, it’s the district staff who are implementing and creating these programmes, it’s the state staff we’re creating the standards, it’s state policy makers, it’s federal policymakers – like, you could think about professional development for all those stakeholders. And we know we need to build, you know, better education, right, for every one of those groups that are above the individual educator in a classroom, knowing that the national infrastructure is just supporting the teacher in the individual classroom to do this best at the end of the day. So yeah, we think about that in terms of a, there’s a whole system that needs to move here.</p>
<p><strong>Brian Tarran</strong><br>
I think that’s an important point to note, I think, because I go back to that digital skills workshop I was at and one of the questions that came up from from the chair was, you know, what one thing can I take back to the Secretary of State to say we need to add this to the curriculum, but it’s not one thing is it? It’s, it’s it’s a whole system, as you say, Zarek. I did want to ask you a bit about the organisation that you’re a part of, you have a coalition called Data Science 4 Everyone. To what extent was you involved in the kind of shaping of this, of this bill? And, you know, you obviously, you’ve obviously welcomed it, and you’re excited about the potential, and how much work do you see as being left to do to, to kind of get it over the line and get it into application?</p>
<p><strong>Zarek Drozda</strong><br>
Sure, well, just a very quick background on DS4E. We’re a national initiative and a coalition as you said, based at the University of Chicago here in the States. We’ve been putting together a community of education researchers and K-12, system leaders to advance policy and advance awareness and advance the case making right for why data science and data literacy and statistical acumen is so important in this day and age. And we’re really working across the K-12 system, which is very decentralised in the US, to try to forward those goals. Yeah, as I think about next steps and what’s needed, again, just re-double what Chris said, we need more funding. We did some, to give you an example. So when computer science was being built out as a new school subject in the States, they spent somewhere in the range of three to $4 billion over 15 years to build an entirely new school subject. We’re not necessarily doing that here, right? We’re not necessarily building out a whole new school subject, I think we’re really, at least our group has been much more focused on how can we integrate and upskill teachers in K-12 math, or K-12 science or K-12 social studies, right, and integrate these concepts into the existing K-12 ecosystem, working with the different subject societies. But, you know, this bill is a first really great milestone, but we know now we’re going to have to call on state legislators to pass appropriations at the state level to fund teacher support locally, we’re going to have to, you know, call on schools and districts, right, to help give teachers time to be able to implement these classroom experiences. And we’re going to need more research. Right. So this bill calls for grant programmes to state and local partners to create. But I think we also need more funding for NSF and IES, the two kind of education research bodies in the US at the national level, to fund things like student assessments, or to fund accommodations for students with disabilities to be able access to technology for data science software. There’s a lot more R&amp;D work that also has to happen to bring down the adoption costs over time for doing this type of work and making sure that every student regardless of their background, can benefit from the skill areas, and you know, upskilling in this space. And I think the last thing I would say is that we know we also need to work on teacher confidence, right? I think it’s both teacher confidence with statistics, right, and probabilistic thinking. And it’s also the the confidence of the technology, which is brand new, right? Most classrooms in the US have not been using spreadsheets, even though most workplaces do, let alone, you know, R, Python, SQL, any of the more kind of modern computational tools that are used in modern day statistics. And so we have a lot of work on that front to do as well.</p>
<p><strong>Brian Tarran</strong><br>
Okay. And so, if I’ve understood it correctly, there’s about $50 million over five years that is being asked for in this bill. But that’s, from what you’re saying, am I correct in thinking that’s just a kind of a small part of what’s needed to completely deliver on your goals?</p>
<p><strong>Zarek Drozda</strong><br>
It is a first step. An important one, but a first step.</p>
<p><strong>Brian Tarran</strong><br>
So, longer term, is it– Do you head towards the billions territory, like in the computer science space? Or is it a little less demanding of finances and resources and that, do you think? I know it’s hard to say, to pin these things down, but–</p>
<p><strong>Zarek Drozda</strong><br>
At least from my angle, I’d love the group to jump in here, it’s probably a little bit less demanding. But we know that in aggregate between federal, state, private and local funding, we’re going to have to create the necessary resources to make sure that our K-12 public education system can prepare students for a world that’s changing super fast, and the K-12 system moves super slow, right, in how it adapts to new content. And so really it’s both about, you know, what can we do to upskill data science, data literacy skills. It’s also about how do we help the system just adapt faster as new technology comes out and, you know, leverage the importance of data in that.</p>
<p><strong>Steve Pierson</strong><br>
And Brian, I can jump in a little bit on the price tag, which, when we were shopping around this bill, we didn’t actually include like a cost per year for this, because we know that that can be a very sensitive topic, and we were, we really wanted to have bipartisan introduction. So, and we were fortunate to get it right. But it was the offices who have agreed to kind of consider us that came up with the $10 million. And I’m, you know, I know for a fact that, you know, a few of the offices, at least one of the offices did want significantly more, but this was how we were gonna get bipartisan introduction.</p>
<p><strong>Brian Tarran</strong><br>
Yeah. Okay. And on that point, that bipartisan nature of the bill’s introduction, does that give you as a group hope that it will eventually make it through Congress and become a law, and that there’ll be these resources made available?</p>
<p><strong>Steve Pierson</strong><br>
Yeah, absolutely. And I’ll also just say, Brian, that I think we’ve spoken to some 50 or 60 offices, both on the Senate side and the House side. And this is, it’s received really well, we don’t get any pushback on that, you know, yes, there is a need for greater data literacy. Here stateside, I’ve been saying it’s kind of like advocating for apple pie. Right. This is, people get it and they resonate. And to that point, we only brought this to Representative Stevens, I think it was maybe late October. But they really wanted to move on this, they wanted to wait for the new Congress for bandwidth issues. But, significantly, we’re told that the representative wanted this to be her first bill introduced of the new Congress, and she had many to choose from. So I think that’s really positive. The other thing is, I’ve heard from email, we haven’t had a chance to debrief with the staff yet, because they’re swamped with all kinds of things, but they’re getting a lot of positive feedback from people about this bill. So it really seems to be kind of tapping a nerve. A recognition.</p>
<p><strong>Zarek Drozda</strong><br>
I was just going to add to Steve that when we went– So in advance of that legislation being introduced, we had 15 of the largest math and science and technology education associations supporting the legislation, which was a huge win. It showed, I think, that this data science, data literacy, education is really a collaborative multi-subject effort in the States, which does not happen often, it’s usually very siloed. And I think the other thing I’d say is, in the first 24 hours since the bill was introduced, we had 150-160 additional education leaders and organisations sign on to the letter of support that we were helping circulate between Data Science 4 Everyone and the American Statistical Association. And just to re-emphasise that we saw a lot of energy around this, and bipartisan, right. We’re building support on both sides of the aisle, because it’s, you know, this is apple pie, it’s so evident that every student’s going to need this for the next decade.</p>
<p><strong>Brian Tarran</strong> I like this. So data was once the new oil, but now data science education is the new apple pie. I think this is this is great. Anna, you know, assuming that the Data Science and Literacy Act goes through, funds are made available, this work starts in earnest, what sort of timescales are we looking at, do you think, before we start to see the real world impact, you know, in terms of teacher training, student outcomes, and then eventually, obviously, building this workforce, that is so needed, that is equipped with data literacy and data science skills?</p>
<p><strong>Anna Bargagliotti</strong><br>
Yeah, I think I kind of want to say two things to this point. I think post K-12, the college level, we are seeing those outcomes, and they are great. And I think we are really, that is, it feels very good. It feels like we’ve targeted the right things. It feels that students report back that they’re excelling in their jobs and doing great things. So I think that part is sort of, is taken care of. I think at the K-12 level, what’s harder is we’re less nimble. Like Zarek mentioned, K-12 is just a beast to move. It’s very difficult. And we’re in a situation where the target of data science changes every day, truly every day, for two real reasons. One is because the conceptualization of data changes every day. We can imagine today we think of data as text, but in probably a month, there’s some other type of data that we haven’t thought of that will emerge. And so now all of a sudden, you’ve got, you’re trying to teach pillars or concepts in K-12 that are actually a moving target. And then the other big thing that changes pretty much every day is our capabilities for wrangling, visualising access to data, all that stuff is changing. And so at the university level, you’re much more nimble because you’re in these courseworks, and your students are very advanced, and you can kind of move within those, those spaces, and you can change a course at a time. At the K-12 level we’re much more prescribed and harder to move. So I think in terms of timeframe, I think if we focus on the sort of large concepts and the baseline skill sets that we want to graduate students from K-12, I think we can move much quicker than getting into sort of the nitty gritty of a student needs to be able to programme per se, or something like that, like I think more that statistical investigative process, and those questioning, those types of ideas are really the crux of what K-12 looks like that then allows the university level to be more nimble. So for me, the timeframe is I think we have to, we have to think about it differently as we’re never going to arrive. It’s not going to be like, Oh, in five years, this is completed. It’s a, are we reacting in the right way? Or are we sort of ahead of the game. And I think we can get ahead of the game if we go to the concepts and that idea instead of thinking of topics that we’re teaching. And I hope that with this, I have great hope for this bill. I think it’s like everybody said that this is just such a great first drop in the bucket with the apple pie that I think hopefully in the next few years, the states are going to have been moved and then everybody will be doing some type of data science at the state level. And then it’s like Chris mentioned, before moving the professional development, which is a big challenge.</p>
<p><strong>Brian Tarran</strong><br>
When you were speaking, just there, Anna, and you were you were talking about the difference between you what you’re achieving at the college level versus the younger level, it made me think that, you know, this isn’t just about providing a next generation of data science workers, right, it’s about equipping everyone with the skills to be able to exist in a data science world. And this goes to the point that I think Chris and I have spoke about before, right, about being able to be, when you’re confronted with data, being able to ask the right questions about that data. And so I think obviously, that’s, to me, that’s where I think maybe the Guidelines for Assessment and Instruction in Statistics Education seems a promising first step in the development of a data science, data literacy, statistics curricula, do you see that that needing to be – obviously these things are always needing to be revised, right – but do you see that, Chris, as a kind of foundation on which the states can start to build and to move towards this vision that’s laid down in the act?</p>
<p><strong>Christine Franklin</strong><br>
Well, most definitely. And we’ve been real fortunate in the US here that our states right now that are trying to implement more statistics and data science standards, are going to the GAISE II document to use as a guiding document. And ASA has been very fortunate also to where these states, many of them have reached out to us to actually help advise them as they go through the process. I wanted to come in on a follow up with something Anna said in terms of the timeline. As she was speaking, I thought about how when we were sending out our document for review with the GAISE II, the updates, and we sent it out to probably about 20 to 25 different reviewers, we received more feedback than we knew what to do with. But many of the reviewers, very well respected people in the field, came back to us and said, we were being way too ambitious with the GAISE II document that, in fact, so many states here in the US we’re still back trying to implement the recommendations we made in the 2005 GAISE document. And our response was, we can’t be writing for today. What our goal is, is to try to write a document to where 5, 10 years from now, this is where we hope that our K through 12 system will be. And I’ve noticed this in working with other national documents, that I think the tendency oftentimes is to try to write a document for where we are now. And I think that we always need to, in terms of a timeline, think about 10 years down the road when we wrote the document. And it’s hard to be visionary. But as Anna was saying, things are changing so quickly. I mean, the GAISE II document, I think the writers are all saying, oh, we should have included this, we should have included that. Because since its publication in 2020, we’re already seeing needed changes. So I think we’re always going to be catching up to some degree. But as Anna said, I think the goal of these documents needs to be conceptual understanding, it needs to be that role of questioning. I like to say, I just want people to be healthy sceptics to where when they see statistical information, they see data, they immediately start asking questions. They may not know the answers, or know what the answers aresupposed to be, but at least they’re questioning.</p>
<p><strong>Anna Bargagliotti</strong><br>
And I’ll just add one really quick thing, Brian, if that’s okay. Chris and I are about to embark on another ASA initiative, which is the revision of the SET report, which is the Statistics Education for Teachers report that the last publication was, oh my gosh, Chris, I can’t remember even the date–</p>
<p><strong>Christine Franklin</strong><br>
2015.</p>
<p><strong>Anna Bargagliotti</strong><br>
2015. And the the idea of the new report that we will be starting to write this year, along with some wonderful colleagues, is going to be to talk about the teacher preparation aspect of that in light of everything that’s happened with statistics and data science in particular, what should that look like? And how, how could that be? So I just wanted to add that.</p>
<p><strong>Brian Tarran</strong><br>
Excellent. I also wanted to ask, again, maybe this is a question for Zarek. If we’re talking about data science for everyone, what about people like me, who have already already finished their education? I mean, I know you can always learn; every day is an opportunity to learn new things. But, you know, from your coalition’s perspectives, Zarek, what do you want to see happen so that, you know, that we’re not leaving behind big chunks of the population, you know, the older chunks of the population who haven’t had the benefit of going through this education system as it is now, let alone what it might be in five years time, right?</p>
<p><strong>Zarek Drozda</strong><br>
Yeah, Brian, it’s a great question. And I, I just came off a year of serving as a fellow in the US Department of Education. And I had a lot of conversations with the programme officer who is responsible for research, education research and adult education, about that subject. Right. And I think one of the themes that I learned from that work and from that, from those conversations was this idea around fear of technology, as it accelerates. It’s really hard for people to deal with, you know, ChatGPT, DALL-E, AI, neural networks, you know, the list goes like on and on, and it changes every month, as as we’ve discussed here. And I think a big goal from our side is both to build confidence when people are dealing with a deluge of data and a increasing amount of information, right, which we talked about, and it’s also the confidence in the technology tools that are constantly changing. So I think as we think about, you know, a student K-12, we want to get them on a tool, so they can be confident and switch to the next one when it comes out. Because we know that technology integration is just is really critical. And the same thing is true for the adult learners, right, or for the for the folks that are older, there is a wealth of online digital learning, online courses, asynchronous experiences, to learn any coding languages, any programming language, any just software – doesn’t even have to be computation or coding intensive, right, it can just be spreadsheets or, or Tableau or some of the not-too-syntax heavy tools, and there’s so much digital and elearning opportunities for that. If we can build formal exposure into the classroom pathway, and build student confidence to then jump on to those later on. That is really critical. Because if you don’t get an exposure, it’s so hard to take the first step to jump in to the digital training or to you know, go to your employer and say, I want this, you know, this professional development programme, because it’s hard to know where to start. And we also worked on a data literacy training programme for Department of Ed employees while I was there and helping design that experience. You know, for professional or mid career, folks, I think the most important thing was you build confidence and create bitesize first steps to try to like tone down the fear, so people can approach the new world with confidence rather than just responding to it.</p>
<p><strong>Brian Tarran</strong><br>
So I just want to wrap up now, last question for you all, really, maybe if we start with Steve. From a policy perspective, Steve, you know, are there other initiatives on the horizon and things in the pipeline that, you know, people should be watching for in terms of trying to improve data science education across the board in the US, and maybe specifically for the ASA are their areas you’re going to be focusing your efforts and support on.</p>
<p><strong>Steve Pierson</strong><br>
We certainly do want to expand this effort. And we’re trying– In a way, this bill is serving as a way for us to gather that information, because people then know that we’re doing this and they might well hopefully suggest items to, to us. We’ve gotten some I know that, you know, Zarek has a file, I have my own file of what we might want to, how we might want to extend it just with this bill. But yes, we certainly do want to do that. And so for listeners out there that have ideas, please please send them to us. I won’t offer specifics at this point. And I’d love to hear what my colleagues have to say, as well.</p>
<p><strong>Brian Tarran</strong><br>
Does anybody want to jump in on that? Zarek, what’s on your list?</p>
<p><strong>Zarek Drozda</strong><br>
Very short term is just building a Senate version of the legislation, I think, right? We’re going to be working with with the ASA on that, to find champions in that chamber. But then I think I would go back to my call for you know, state legislators need to be thinking about this as well, right, because we know that every state is going to look a little different. We’re in a context right now where locally driven education solutions are going to be really important. And so we’re going to have to build different slightly different flavours of this all around the country. And we’re going to need a lot of work from, I think, state and local champions to fund and help support and build these experiences that are so critical for students across the country.</p>
<p><strong>Brian Tarran</strong><br>
And are there, you know, on the point you mentioned earlier, Zarek, about this news,crossing the pond and reaching me over here in the UK, do you look elsewhere, you know, outside the US and the UK for other good examples of where education systems are starting to integrate data science into the teaching at, you know, the earlier parts of the school curriculum and the school levels.</p>
<p><strong>Anna Bargagliotti</strong><br>
I think Chris can probably jump in even more than me on this one. But definitely in New Zealand. Our colleagues in New Zealand are fantastic. And they’ve been doing K-12 data science and statistics very well for many, many years. And Chris has some very close collaborators. So I’ll hand it over to her to on that. But I thought I’d mention it.</p>
<p><strong>Christine Franklin</strong><br>
Yes, I I think that that’s when you know, when Steve says how can we reach out, I think even beyond policy, a collaboration with international colleagues that have advanced their work in K through 12. I mean, I had the good fortune of having a Fulbright to New Zealand back in 2015. And just the inspiration, the wealth of knowledge that I obtained from there, to bring back to the US with our work here was phenomenal. Plus, we built up collaborations that we are continuing today. We have collaborations with people in the UK, for example, in other countries. I think the other thing I wanted to say besides reaching out internationally is that we as statisticians in the US need to be doing more to help K through 12. And I think about my, you know, my colleagues at the university in the statistics department which I was part of, my colleagues, some of them actually worked with me to reach out to the math educators so that they could try to help with what needed to be done with the preparation of teachers. So I think statisticians need to become more involved, both practising statisticians and academic statisticians, with helping educators at K through 12. And that includes trying to become involved with state departments of education as well, because that’s really where things filter down to the local level in our school districts. So I would like to see somehow a structure put in place to make that happen more. And I’m hoping things such as this bill will bring that awareness to practising statisticians, that this is really important, and you need to become more aware of what’s happening at K through 12, and become involved.</p>
<p><strong>Zarek Drozda</strong><br>
To just add to what Chris is saying, I think it is so important for investment in the K-12. space. And, Brian, I’ll give you a sneak preview of a report that we were collating on international examples of data science and statistics education in K-12, and really serious investments that we’ve seen, I think, and Chris already mentioned, some really great ones that have been long running champions at this internationally. Our recent scan: Israel, their ministry of education is doing a tonne of work for data science, data literacy education. I’ve had so many conversations with them over Zoom. China added a standard semester for big data statistics coding and modelling. And it’s now also in their college entrance exam. There’s examples in Germany, New Zealand, South Korea, Scotland, we’ve we’re continuing to build the list. Frankly, in the UK, right, with core maths, you’re seeing more integration of data and computational thinking into the curricula pathways there. I think in many ways the US is behind, and as we introduce this bill, I think we should be messaging, there’s a economic competition aspect to this, right; that it’ll be really important for the US to make investments in this area to, frankly, catch up to where I think other international peers are.</p>
<p><strong>Brian Tarran</strong><br>
Steve, you wanted to come in on that?</p>
<p><strong>Steve Pierson</strong><br>
I mean, you mentioned like someone coming in mid career, right. And I think that that is really important. But we’ve also kind of been talking about the other ways you can access this, right, in any part of your career, but you can also access data jobs, rural and urban. So we’ve been kind of selling that dimension. But also, you know, just access in terms of diversifying the STEM workforce, we think that’s really important. But it’s also about degree level, right? We did a search for one member of Congress that had a major, I think it was a pharmaceutical in their district. And if you put in data, right, and thousands of jobs pop up for that company. And it’s not just the PhDs, right, it’s more entry level, the people who are what Zarek mentioned in terms of just accreditation, that you can enter a lot of points. But I also want to just make a– point out one part of the bill, which really singles out two-year colleges, which can help the mid career people, the early career people or others, and they face a lot of the same challenges as K through 12. Right, making sure that the instructors are upskilled, that they have a curriculum, but they also need the time to coordinate with their other disciplines that are involved here. They need time to go to that local workforce, what do you need in terms of data science? And for those students that want to go on to a four-year degree, they need to make sure that there’s a smooth pathway for those students. So there are provisions in the bill also for for two year colleges. And those would be my closing comments, Brian.</p>
<p><strong>Brian Tarran</strong><br>
Okay. Anybody else for some closing words? Or should we wrap up on reminding everyone that data science education is the new apple pie?</p>
<p><strong>Anna Bargagliotti</strong><br>
I can close this with something more philosophical, maybe. To me, I think a nice way to think about it or sort of a romantic way to think about it is it’s just data tell our stories, and they reflect what’s happening in our world today, much like art around us in some ways. And a way to think about just data science education is just to think about what we need, what we need our data understanding to be at each point in time in our educational career, or in our lives. And it’s not static, it’s an evolving thing. So you have to move sort of with the data that are being collected.</p>
<p><strong>Brian Tarran</strong><br>
Very good point. Thank you very much, Anna, Steve, Zarek, and Chris, for joining us to talk about the Data Science and Literacy Act. I’m sure there’ll be much more to to follow and update on as this act or bill winds its way through through Congress. So we’ll look forward to hearing more about that in due course. So thank you for joining us today. Thank you to those of you who are watching for joining us. Stay tuned at realworlddatascience.net for more news Q&amp;As.</p>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/interviews/index.html">Find more Interviews</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/03/06/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/interviews/posts/2023/03/06/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “US legislators get their data science act together.” Real World Data Science, March 6, 2023. <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/03/06/data-science-act.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Data science education</category>
  <category>Data literacy</category>
  <category>Policy</category>
  <guid>https://realworlddatascience.net/viewpoints/interviews/posts/2023/03/06/data-science-act.html</guid>
  <pubDate>Mon, 06 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/interviews/posts/2023/03/06/images/andy-feliciotti-isg8AL7-6uk-unsplash.png" medium="image" type="image/png" height="93" width="144"/>
</item>
<item>
  <title>Data science can help close the ‘digital skills’ gap, or so it seems</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/digital-skills.html</link>
  <description><![CDATA[ 




<p>Digital skills. We all need them. Employers say they want them, but there aren’t enough to go around. Supply can’t meet demand, so we’re left with a gap – a digital skills gap. But what are <em>digital skills</em> exactly?</p>
<p>This is a question that was asked repeatedly, in various different constructions, by <a href="https://members.parliament.uk/member/4092/career">Stephen Metcalfe MP</a>, chairing a meeting of the <a href="https://www.scienceinparliament.org.uk/information/about/">Parliamentary and Scientific Committee</a> on Tuesday, February 7. I went along to the meeting as an observer, hoping to hear an answer to that very question.</p>
<p>What I got was several different answers – no single solid definition, but a reasonable sense that boosting data science skills would go a long way towards closing the digital skills gap.</p>
<section id="survey-says" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="survey-says">Survey says…</h2>
<p>The committee meeting was sponsored by the Institution of Engineering and Technology (IET), and the main focus of discussion was the results of IET’s <a href="https://www.theiet.org/impact-society/factfiles/innovation-and-skills-factfiles/iet-skills-survey/skills-for-a-digital-future-survey/">skills for a digital future survey</a>, based on a YouGov poll of 1,235 respondents drawn from engineering employers (defined as “employers who employ at least one engineering and technology employee in the UK”).</p>

<div class="no-row-height column-margin column-container"><div class="">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/images/billetto-editorial-YvLd3xbo0ac-unsplash.jpg" class="img-fluid figure-img" alt="Woman painting while wearing virtual reality headset. Photo by Billetto Editorial on Unsplash." width="500"></p>
<figcaption class="figure-caption">Digital skills, including AI skills, are not only required of engineers, says the IET’s Graham Herries. Generative AI tools like Stable Diffusion threaten to shake-up the creative industries. (Photo by <a href="https://unsplash.com/@billetto?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Billetto Editorial</a> on <a href="https://unsplash.com/photos/YvLd3xbo0ac?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>)</figcaption>
</figure>
</div>
</div></div><p>Kicking off the discussion was Graham Herries, an engineering director and chair of the IET’s Innovation and Skills Panel, who drew attention to the harms that the digital skills gap is reportedly having. Of those respondents who identified skills gaps in their own organisations, 49% pointed to a reduction in productivity, while 35% said skills shortages were restricting company growth.</p>
<p>As the hot topic of the day, <a href="../../../../../../news-and-views/editors-blog/posts/2023/01/27/talking-chatgpt.html">ChatGPT inevitably came up during the discussion</a>. Herries sees it as a disruptive force, and 36% of all respondents believe artificial intelligence (AI) skills will be important for their engineers to have within five years (24% say they are important <em>now</em>). But AI skills are important for non-engineers too, argued Herries, as he pointed to stirrings in the creative industries caused by generative art tools such as <a href="https://stability.ai/blog/stable-diffusion-public-release">Stable Diffusion</a>.</p>
<p>Herries therefore puts AI skills under the broad umbrella of “digital skills”. But, to him, it’s not enough to simply be able to use AI technology; rather, users should know enough to be able to ask the right questions about the provenance of the data used to train the AI, its quality and biases, etc. This was a point developed further by Yvonne Baker, an engineer and the CEO of STEM Learning. Baker talked about digital skills as being both the ability to use digital technology and also to understand its limitations. Yet another perspective was offered by Rab Scott, director of industrial digitalisation at the University of Sheffield’s Advanced Manufacturing Research Centre. Scott defined digital skills in the context of <a href="https://rss.onlinelibrary.wiley.com/doi/10.1111/1740-9713.01523">quality control systems in industry 4.0</a>: it’s about knowing how and where to place a sensor to collect data about the manufacturing process, to feed that data into a data collection system, analyse the data for insights, and use those insights to inform decision-making.</p>
</section>
<section id="closing-the-gap" class="level2">
<h2 class="anchored" data-anchor-id="closing-the-gap">Closing the gap</h2>
<p>Further definitions of “digital skills” are to be found in the <a href="https://www.theiet.org/impact-society/factfiles/innovation-and-skills-factfiles/iet-skills-survey/skills-for-a-digital-future-survey/">IET’s published report</a>. Survey respondents were encouraged to describe the term in their own words, so we see things like:</p>
<ul>
<li><p>“the ability to understand, process and analyse data.”</p></li>
<li><p>“Coding, programming, software design, use of social media for marketing and communicating with stakeholders, data visualisation, work that relies solely on the use [of] online systems.”</p></li>
</ul>
<p>When respondents were asked what skills were lacking in both the external labour market and their internal workforce, around a fifth cited “more complex numerical/statistical skills and understanding”. And when looking to the future and to the skills anticipated to be important areas for growth in the next five years, 39% of respondents picked “data analytics” while 31% said “artificial intelligence and machine learning”.</p>
<p>So, perhaps you now understand why I left the meeting with the feeling that more data science skills, more data science training, could help address the shortfall in “digital skills”.</p>
<p>But how exactly can we equip more people with the right skills? At one point during the discussion, Metcalfe told the meeting that he was still looking for a key takeaway, something he could take to the Secretary of State and say, ‘This is what we need to embed in the curriculum’. What was offered instead was a range of possible solutions.</p>
<p>The IET survey found broad backing for government support for reskilling: 40% of respondents favoured grants or loans for training (and retraining) programmes, 39% would like more funding for apprenticeships, while 33% think there should be better carers advice and guidance in schools and colleges.</p>
<p>Baker also made the case for digital skills to be taught in schools as part of every subject, not just in computer science lessons, and that teachers would need to be supported to deliver this.</p>
<p>But how would <em>you</em> close the “digital skills” gap, if given the chance?</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Have you got news for us?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Is there a recent data science story you’d like our team to discuss? Do you have your own thoughts to share on a hot topic, or a burning question to put to the community? If so, either comment below or <a href="../../../../../../contact.html">contact us</a>.</p>
</div>
</div>
<div class="article-btn">
<p><a href="../../../../../../viewpoints/editors-blog/index.html">Back to Editors’ blog</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Data science can help close the ‘digital skills’ gap, or so it seems.” Real World Data Science, February 14, 2023. <a href="https://realworlddatascience.net/news-and-views/editors-blog/posts/2023/02/14/digital-skills.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>

 ]]></description>
  <category>Skills</category>
  <category>Training</category>
  <category>AI</category>
  <category>Machine learning</category>
  <category>Data analytics</category>
  <guid>https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/digital-skills.html</guid>
  <pubDate>Tue, 14 Feb 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/viewpoints/editors-blog/posts/2023/02/14/images/billetto-editorial-YvLd3xbo0ac-unsplash.jpg" medium="image" type="image/jpeg"/>
</item>
</channel>
</rss>
