<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/careers/index.html</link>
<atom:link href="https://realworlddatascience.net/careers/index.xml" rel="self" type="application/rss+xml"/>
<description></description>
<image>
<url>https://realworlddatascience.net/images/rwds-logo-150px.png</url>
<title>Real World Data Science</title>
<link>https://realworlddatascience.net/careers/index.html</link>
<height>83</height>
<width>144</width>
</image>
<generator>quarto-1.3.361</generator>
<lastBuildDate>Wed, 24 May 2023 00:00:00 GMT</lastBuildDate>
<item>
  <title>‘For me, data science is about bridging the gap between business requirements and the data that businesses have’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/jasmine-holdsworth.html</link>
  <description><![CDATA[ 




<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/Plga2ldbcTE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="transcript" class="level2">
<h2 class="anchored" data-anchor-id="transcript">Transcript</h2>
<div class="callout callout-style-simple callout-warning" style="margin-top: 0.75rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>This transcript has been produced using <a href="https://otter.ai/">speech-to-text transcription software</a>. It has been only lightly edited to correct mistranscriptions and remove some repetitions.</p>
</div>
</div>
</div>
<section id="what-does-your-job-at-expedia-involve" class="level3">
<h3 class="anchored" data-anchor-id="what-does-your-job-at-expedia-involve">What does your job at Expedia involve?</h3>
<p>I would probably call myself more on the analyst side. So, while my day-to-day job doesn’t necessarily involve AI, ML and productionalising models, it’s more taking business goals or requirements and taking the data and essentially bridging the gap between the two. I am on the incrementality analytics team. So, what that means is I measure the short-term returns from our marketing efforts that we have. And I do that via geotesting. So, I’m essentially working in the geotesting part of the company if you like. And before that I worked in the customer data section. So, essentially looking at customer data and working with that.</p>
</section>
<section id="how-long-have-you-been-working-in-data-science" class="level3">
<h3 class="anchored" data-anchor-id="how-long-have-you-been-working-in-data-science">How long have you been working in data science?</h3>
<p>More in an analyst role, but probably about seven years now, I began in Stack Overflow just as a data analyst, and then worked at DAZN – which is like a Netflix for sports – as a data analyst, and then joined here as a senior analyst, and then moved into data science in the last couple of years. I would, I would credit Stack Overflow as the place where my career kind of was birthed, if you like. I started there as an account manager, so with hardly any technical background at all required, and then moved into a role that was essentially looking after, or reporting the metrics of advertising campaigns for companies that would advertise on Stack Overflow. So that required a little technical knowledge, not much – a few pivot tables and things like that. But then the longer I stayed there, the further my career developed, and they had, at the time – probably still do – some fantastically smart people that work there, as you can imagine. I was sponsored to do a General Assembly data analytics course, which was focused around Excel, dashboarding, and SQL and essentially fell in love with data analysis. It was the most technical subject matter that I had experienced to that point, and I found a real natural affinity to it, particularly SQL. And then [I] moved into more of a data analyst role within Stack Overflow, so – as you can probably imagine – an absolute sea of proprietary data that needed analysing, and started learning R, or rather being taught R within Stack Overflow, and loved it. I think I was there for three-and-a-half years, and then moved into a data analyst role at DAZN. At this point, I did a data science General Assembly bootcamp course, and fell in love with that. And then I decided that I really loved General Assembly as a concept; I actually started a second job teaching there, so the courses that I had previously taken I was now teaching, first as a teaching assistant, and then as a lead instructor, which was one of the most, yeah, one of the most amazing experiences I’ve had actually, I learned a lot from that. And then I got a job as a senior analyst within Expedia Group, which is where I am now, and then moved into a data science role, which is what I’m doing currently. So, I actually left school at 16, and had to go into a full-time employment. And the General Assembly education that I took a part in was my first of that type. So, when I realised that data science was absolutely something that I really wanted to dedicate the rest of my life to, I decided to take on a part-time data science bachelor’s degree, which I am now about a year away from finishing. Because I’m doing it part time it takes a bit longer. But yeah, so I will have my data science bachelor’s completed, hopefully, by 2024.</p>
</section>
<section id="who-or-what-inspired-you-to-work-in-data-science" class="level3">
<h3 class="anchored" data-anchor-id="who-or-what-inspired-you-to-work-in-data-science">Who or what inspired you to work in data science?</h3>
<p>There were two big inspirations into getting into data sciences. So, they were actually the data scientists that I worked with at Stack Overflow. They were the first two data scientists, I believe, that Stack Overflow had ever hired. I worked very closely with them as an analyst and one of them was, had previously worked – I don’t know if it was officially an astrophysicist – but had studied black holes, and I remember thinking that was just amazing. And the other was, was very famous within the field. And they spent a lot of time giving me one-on-one training on R and SQL and basic analysis, and I was so inspired by these two individuals that I, it was also a career path that I didn’t really know existed.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/images/jh-photo.png" class="img-fluid figure-img" alt="Portrait photo of Jasmine Holdsworth"></p>
<figcaption class="figure-caption">Jasmine Holdsworth</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>What was impressed upon me in that first year [in data science] was the importance of statistics and interpreting statistics in a way that’s honest.</p>
</div>
</div>
</div>
</section>
<section id="what-does-data-science-mean-to-you" class="level3">
<h3 class="anchored" data-anchor-id="what-does-data-science-mean-to-you">What does data science mean to you?</h3>
<p>For me, it is bridging the gap between the business requirements and the data that businesses have. So, you’ll have business goals, requirements that kind of come down the line and there’s a lot of data that’s being collected, and, essentially, you have to try and be the bridge between the two. So, not just doing very complicated analyses, with very sophisticated models – at least not in my role – it’s about being able to create analysis that’s interpretable, that you can present to non-technical stakeholders that they’re going to understand to a degree. So, I do know that in different roles in different companies, it will be slightly different. But yeah, for me, it’s about making data, yeah, interpretable, to the non-technical stakeholders to enable them to do their job better.</p>
</section>
<section id="what-is-your-most-important-skill-as-a-data-scientist" class="level3">
<h3 class="anchored" data-anchor-id="what-is-your-most-important-skill-as-a-data-scientist">What is your most important skill as a data scientist?</h3>
<p>I like to think that there is one responsibility around how statistics are interpreted. So, just making sure that when you’re giving someone a statistic, that they understand what it can be used for, what it can’t be used for, and that it doesn’t kind of get halfway around the company before, you know, without any danger of it being misinterpreted. And I do think that the other is just being a translator. So, as well as teaching with General Assembly, I teach people within my company, things like SQL, R, and some basic data analysis. And I feel like it’s taking what is quite a technical, complicated subject and almost translating it into, if you like, English, so that people can kind of get some sense of what something may mean, without necessarily having to have the degree to back it up.</p>
</section>
<section id="what-hurdles-did-you-face-in-becoming-a-data-scientist" class="level3">
<h3 class="anchored" data-anchor-id="what-hurdles-did-you-face-in-becoming-a-data-scientist">What hurdles did you face in becoming a data scientist?</h3>
<p>Towards the beginning of my career to say – 5, 6 years ago – it was quite hard to get interviews. It was never hard to get interviews with technical people within companies, because you can– a technical person can see whether or not you know what you’re talking about. But recruiters don’t, and if someone is a recruiter for a technical role, their proxy for whether or not you can do the role is what’s your level of education, which is completely understandable and that’s what education is for. But it did mean that sometimes I applied for roles that were well below my, my level, and if I did so through a recruiter, then I wouldn’t hear anything back. But if I spoke to a technical person within that company, then it would be fine.</p>
</section>
<section id="how-did-you-overcome-those-hurdles" class="level3">
<h3 class="anchored" data-anchor-id="how-did-you-overcome-those-hurdles">How did you overcome those hurdles?</h3>
<p>Actually, I guess the story of how I joined Expedia is quite relevant in that way. So, I presented some, just some fun analysis that I did at an R-Ladies meetup, and I was already talking to a recruiter within Expedia Group and I said to them, oh, well, I happen to be visiting your offices to present at this meetup, so maybe I can meet you there. And they actually sent the manager of the team that they wanted me to join. So, this manager attended the meetup, watched me present, and then they ended up hiring me, which is really great. But I do really think that that was a result of being able to see me on stage, talking about stuff that I had done, showing code that I had written, and it kind of bypassed a few steps. So yeah, I would definitely say meetups and connections are very helpful to overcome that.</p>
</section>
<section id="the-most-important-lesson-from-your-first-year-in-data-science" class="level3">
<h3 class="anchored" data-anchor-id="the-most-important-lesson-from-your-first-year-in-data-science">The most important lesson from your first year in data science?</h3>
<p>I think that what was impressed upon me in that first year – and what really drove me to do the bootcamp courses and then, ultimately, the degree – above everything, actually, was the importance of statistics and interpreting statistics in a way that’s honest. So, I feel like– I feel like with coding, that comes quite naturally to me, and writing SQL queries, R, that was all kind of fine. That didn’t require a lot. But I really, I had an amazing manager who taught me a lot about, essentially, if you’re going to go and speak to this company about the campaign that they’ve run on our website, then you need to impress that X doesn’t necessarily mean Y, it just gives evidence to, or alludes to, and essentially just making sure that how you’re communicating things is as accurate as possible.</p>
</section>
<section id="any-mistakes-or-regrets-in-your-career-so-far" class="level3">
<h3 class="anchored" data-anchor-id="any-mistakes-or-regrets-in-your-career-so-far">Any mistakes or regrets in your career so far?</h3>
<p>When I look back on my career, I think the things that have really stayed with me that I’ve really learned from, mistakes wise, are around small little mistakes around how you interpret data. Maybe it was a, like, years ago, summing the wrong cell in Excel but not checking two or three or four times before that goes out. I’m now quite– I over-check everything. I think that the most important part of our job, as well as being the translation, is being the correct translation. You need to be reliable. People need to know that if you put out analysis that they can trust you. So, I would say I regret every small, tiny little data error that I ever made, which I can’t even recall right now, but I know have kind of cumulated enough that it has made me a very fastidious checker, I suppose.</p>
</section>
<section id="how-do-you-see-your-role-in-data-science-evolving" class="level3">
<h3 class="anchored" data-anchor-id="how-do-you-see-your-role-in-data-science-evolving">How do you see your role in data science evolving?</h3>
<p>I definitely see myself being an individual contributor in a consumer-facing company, just because that is basically what I’ve been doing up to this point. I don’t really have any desire to get into people management. I very much love being stuck in a room with my laptop, solving problems. Above all else, it still makes me happy. However, I do also love knowledge sharing – I love teaching, whether it’s with General Assembly, or whether it’s within the company that I work now. And I would like to kind of balance those two goals moving forward. So, keeping my role within my company as like an individual contributor and actually being like the front face for the, for the analysis that’s happening rather than kind of managing it. But also making sure that I carve out time to upskill others, because data science as a field, I mean, as you all know, is growing so much and people are coming in from different backgrounds. And I’m lucky enough to be able to kind of speak to a few people like that and do some very casual mentorship. And it makes me happy to see, so I hope that as my career develops, I will see more people maybe with backgrounds a little bit more like mine, come through and bring some diversity to the sector.</p>
</section>
<section id="new-developments-or-ideas-you-are-most-excited-about" class="level3">
<h3 class="anchored" data-anchor-id="new-developments-or-ideas-you-are-most-excited-about">New developments or ideas you are most excited about?</h3>
<p>It would be remiss of me to not mention like ChatGPT or generative AI, etc. But honestly, I am more interested in – or vaguely interested, I should say – in wearable technology. So, I’ve read a few very, very interesting papers and articles that talk about the development of wearable technology, not just your kind of watches, but potentially clothing, etc., that can be used for people with specific health problems to really help pinpoint, like, inflection points in time when something might happen. For example, a heart attack is about to happen, or is imminent, or is happening. So I actually feel like at the moment, this is perhaps going slightly under the radar, compared with more, you know, sexy developments like chatbots and things. But I’m very interested to see in the next one to two decades how ubiquitous wearables will be, and how closely entwined that will become with healthcare. So that’s something that I’m keeping half an eye on.</p>
</section>
<section id="any-words-of-advice-for-budding-data-scientists" class="level3">
<h3 class="anchored" data-anchor-id="any-words-of-advice-for-budding-data-scientists">Any words of advice for budding data scientists?</h3>
<p>You will never stop learning at all because, frankly, the field is moving very, very quickly. So, even if you were to kind of consider yourself an absolute expert today, tomorrow that may not be the case. You will constantly be learning. And I have found that learning the same thing several times through different mediums and having things explained to you different ways is so valuable. Because you may think that you understand something from, say, your bootcamp, but then when you read about it as part of your degree – this is obviously personal to me – you read about it in a different way. And you think, Oh, I’ve never thought of it like that. And then you watch a YouTube video and someone visualises it and you think, okay, I understand this all a little bit deeper now. So, constantly revising what you do know and learning anything that’s new as it comes up, I think everyone at every stage of career can kind of, can do that.</p>
<div class="article-btn">
<p><a href="../../../../../../careers/career-profiles/index.html">Discover more Career profiles</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘For me, data science is about bridging the gap between business requirements and the data that businesses have.’” Real World Data Science, May 24, 2023. <a href="https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/jasmine-holdsworth.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>
</section>

 ]]></description>
  <category>Data analysis</category>
  <category>SQL</category>
  <category>R</category>
  <category>Bootcamps</category>
  <category>Education</category>
  <guid>https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/jasmine-holdsworth.html</guid>
  <pubDate>Wed, 24 May 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/career-profiles/posts/2023/05/24/images/jh-photo.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>Large language models: Do we need to understand the maths, or simply recognise the limitations?</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/posts/2023/05/18/chatgpt-data-science-pt2.html</link>
  <description><![CDATA[ 




<p><a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">Part 1 of our conversation with the Royal Statistical Society’s Data Science and AI (DS&amp;AI) Section</a> ended on a discussion around the need to verify that large language models (LLMs), when embedded in workflows and operational processes, are working as intended. But there was also acknowledgement that this could be difficult to achieve, not least of all because, as Giles Pavey said, “nobody knows exactly how these things work – not even the people who build them.” And then, of course, there is the speed at which developments are taking place: Trevor Duguid Farrant made the point that an expert may not even have a chance to finish reviewing the latest version of an LLM before a new iteration is rolled out.</p>
<p>These issues – of verification, explainability and interpretability – are of particular interest to data scientists like Anjali Mazumder, whose work focuses on the impact AI technologies could have, and are having, on society and individuals.</p>
<p>In part 2 of our Q&amp;A about ChatGPT and other LLM-powered advances, and what all of this might mean for data science, Mazumder kicks off the conversation by setting out her perspective.</p>
<p>Our full list of interviewees, in order of appearance, are:</p>
<ul>
<li><p><strong>Anjali Mazumder</strong>, AI and Justice &amp; Human Rights Theme Lead at the Alan Turing Institute, and DS&amp;AI committee member.</p></li>
<li><p><strong>Detlef Nauck</strong>, head of AI and data science research at BT, and editorial board member, Real World Data Science.</p></li>
<li><p><strong>Martin Goodson</strong>, CEO and chief scientist at Evolution AI, and DS&amp;AI committee member.</p></li>
<li><p><strong>Louisa Nolan</strong>, head of public health data science, Public Health Wales, and DS&amp;AI secretary.</p></li>
<li><p><strong>Piers Stobbs</strong>, VP science at Deliveroo, and DS&amp;AI committee member.</p></li>
<li><p><strong>Trevor Duguid Farrant</strong>, senior principal statistician at Mondelez International, and DS&amp;AI committee member.</p></li>
<li><p><strong>Giles Pavey</strong>, global director for data science at Unilever, and DS&amp;AI vice-chair.</p></li>
<li><p><strong>Adam Davison</strong>, head of data science at the Advertising Standards Authority, and DS&amp;AI committee member.</p></li>
</ul>
<div class="keyline">
<hr>
</div>
<p><strong>Anjali Mazumder:</strong> I work in research, but I also sit in the crux of government, industry, and civil society, looking at how they’re using these technologies. For me, it’s about knowing what the opportunities are but also understanding the limitations, the risks and the harms, and how we balance those and put in place oversight mechanisms that act as safeguards to ensure that these technologies don’t cause harm. We’re taking a very socio-technical approach that requires an interdisciplinary team to understand these issues and what should be done. Part of this is about not only the outcomes and the impact but also the upstream side of it – recognising that these models have been built on the work of people who have done the labelling, and that this also has implications – to say nothing of the associated environmental issues or energy issues!</p>
<p><strong>Detlef Nauck:</strong> I think the regulators really have to look at this. It has come completely out of left field for them. All the regulators that we are monitoring, they regulate the space as it was three years ago – they are mainly concerned about predictive models and bias. But if you look at, say, what Microsoft wants to do – putting GPT into Office 365 and into Bing – that will completely change how people interact with and consume information. I think the large tech companies really have a responsibility here, when they make this public, to make sure that people understand what this technology actually is, and how it can be used and has to be used.</p>
<p>Also, they need to open up about how these things have been built. There are a lot of stories around <a href="https://time.com/6247678/openai-chatgpt-kenya-workers/">how OpenAI used cheap labour in order to do the labelling and reinforcement learning for ChatGPT</a>, and these things have to become public knowledge; they need to become part of some kind of Kitemark for these models: “Ethically built, properly checked, hallucinate only a little bit. Whatever you do, don’t take it for granted. Check it!” That’s the kind of disclaimer they need to put on these models.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-12 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>If you look at what Microsoft wants to do – putting GPT into Office 365 and into Bing – that will completely change how people interact with and consume information. Large tech companies really have a responsibility here, when they make this public, to make sure that people understand what this technology actually is.</p>
</div>
</div>
</div>
<p><strong>Regulatory principles always seem to stress that AI systems should be understandable, and we should be able to explain how we get particular outputs. But a lot of our conversation has focused on how we don’t really know how these models work. So, is that, in itself, a problem, and is it something that the data science community can help with – to dig into how these things work and try and get that across – to help meet these principles of explainability and interpretability?</strong></p>
<p><strong>DN:</strong> That’s a very specialist job, I would say – specialist research into how these mathematical structures work. It’s not something I could do, and I’ve not seen any significant work there. One thing that we are interested in is whether we can do knowledge embedding, so that you can “teach” concepts that these models can then use to communicate, and that would lead to smaller systems where you have some understanding of what’s inside. But all of this kind of work, I think, is very much just beginning.</p>
<p><strong>Martin Goodson:</strong> Do we actually need this? There’s sort of a big assumption there that you need to understand how LLMs work in order to build in the kinds of things that we care about as a society. But we don’t understand how humans think. Of course, we can ask a human, “Why did you make that decision?” You can’t understand the cause of that decision – that’s a complex neuroscience question. But you can ask what the reason is for making a decision, and you can ask an LLM what its reasoning is as well. I think a lot of these questions about explainability are stuck in the past, when you’re trying to explain how a linear model works. It’s really not the same thing when you’ve got an LLM where you can just say, “Why did you make that decision?”</p>
<p><strong>Louisa Nolan:</strong> I was going to say something very similar. Most people don’t know how most things work…</p>
<p><strong>DN:</strong> My point was, these things are largely still like the Improbability Drive in the <em>Hitchhiker’s Guide to the Galaxy</em>. You press a button, and you don’t really know what comes out, and that’s the problem we need to get our heads around.</p>
<p><strong>LN:</strong> But people don’t know what percentages are, and yet we still use them for decision making. I don’t think people need to understand the maths behind LLMs, and I think it would be a hopeless job to expect everybody to do that. What we do need to understand is what LLMs can and can’t do. What’s the body of work that they are drawing from? What isn’t in there? What are the things that you need to check? So, for some things, it’ll be brilliant: if you’ve written something and you want it rewritten for a nine-year-old; if you want to summarise a paper; if you want to write code, as long as you already know how to code – these could be real labour-saving tasks. If you’re using ChatGPT to write a thesis about something that you haven’t looked at, that’s where the danger is. It’s this kind of simple understanding that people need to get in their heads – and the maths, except for the people who care about it, is beside the point, and probably detrimental, because it means that people won’t engage with it.</p>
<p><strong>DN:</strong> I agree, but I wasn’t talking about the general public. I meant, the people who build these things – they should know what they’re doing.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-12 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>There’s a big assumption that you need to understand how LLMs work in order to build in the kinds of things that we care about as a society. But we don’t understand how humans think. You can ask a human what their reason is for making a decision, and you can ask an LLM what its reasoning is as well.</p>
</div>
</div>
</div>
<p><strong>We talked there about communication. There was a webinar recently by the <a href="https://rss.org.uk/membership/rss-groups-and-committees/groups/glasgow/">Royal Statistical Society’s Glasgow Local Group</a>, and the presenter, <a href="https://www.hannahrosekirk.com/">Hannah Rose Kirk</a>, showed how you can take tabular data and statistical results and ask ChatGPT to produce a nice paragraph or two that explains the numbers. Is this the sort of thing that any of you have experimented with? Have you had any successes at using ChatGPT to translate data into readable English that decision makers can act on?</strong></p>
<p><strong>Piers Stobbs:</strong> I have an interesting use case. We had a basic survey: 200-odd responses, multiple languages, and we just said, “Please summarise the results of this survey contained in this CSV file.” And it came up with five or six relevant bullet points. What was amazing was that we could then interrogate it. For example, “Please compare the results that were in English versus in French, and describe the differences.” Again, it did it, but then you have the issue of, was it all correct? Well, the bulk of it was. Now I am intrigued by whether you can ask it to do correlations and some actual statistical things on a dataset, and does it get that right? I don’t know. We’ve not really got to that. But, to go back to one of the earlier discussion points around productivity, that initial survey work could have easily taken a week of someone’s time if we didn’t run it through ChatGPT.</p>
<p><strong>Trevor Duguid Farrant:</strong> Piers, in this case you’re interested in checking and seeing if it’s right. If you’d asked a group of people to do that survey for you and get the results, you’d have just accepted whatever they gave you back. You wouldn’t have questioned it.</p>
<p><strong>PS:</strong> That’s true. And the results were plausible, certainly.</p>
<p><strong>AM:</strong> I think one of the challenges is that the results could seem like they’re plausible, right – whether that’s a statistical output or a text output. This was not a proper experiment, but I asked ChatGPT about colleagues and friends who are quite prominent researchers, asking, “Who is so-and-so?”, and it produced biographies that were quite plausibly them, but it wasn’t them. It might have listed the correct PhD, say, but the date was off by a year, or the date was correct but it was from the wrong institution. So, depending on what the issue is, these seemingly plausible results could have more serious implications.</p>
<p><strong>LN:</strong> So, just to join those two things together: for me, the question is not, “Do we understand how ChatGPT works?” As Martin says, we don’t understand how humans work, and surely we’re trying to develop something that enhances human thinking in some way. The more important question for me is, “How do we know that what is produced is useful?”</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-12 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>For me, the question is not, ‘Do we understand how ChatGPT works?’ We don’t understand how humans work, and surely we’re trying to develop something that enhances human thinking in some way. The more important question is, ‘How do we know that what is produced is useful?’</p>
</div>
</div>
</div>
<p><strong>Giles, <a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">you mentioned previously that you’re doing some work at Unilever around how to minimise hallucination</a>. I don’t know how much you can say on what direction that’s going in, and how successful you expect that to be, but that’s obviously going to be a really important part of refining these models to be more widely usable.</strong></p>
<p><strong>Giles Pavey:</strong> I’m by no means an expert, but there’s quite a lot you can do with both the architecture of it and also the pre-prompts that you put in – more or less saying, “Quote what the source is, and if you’re not sure, then tell me you’re not sure.” I think what’s interesting is the question of whether we’ll have to rely on OpenAI or Microsoft to do that work, and it will be just another thing that we have to trust them for. Or, will it be something that people within an organisation can put in themselves?</p>
<p><strong>MG:</strong> I think it’s absolutely critical that open-source models are developed that can compete with these tech companies, otherwise there’s going to be a huge transfer of power to these companies.</p>
<p><strong>GP:</strong> Arguably, the single biggest issue is, who elected Sam Altman (no-one) and are we as society happy with him having so much power over our future?</p>
<p><strong>To close us out, I’d like to return to <a href="http://localhost:5404/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">a question Trevor posed earlier</a>, which is: How might organisations like the Royal Statistical Society help companies to embrace LLMs and start using them, so that everyone can benefit from the technology?</strong></p>
<p><strong>Adam Davison:</strong> My instinct is that there’s some great parallel here with the stuff that the Data Science and AI Section have been doing in general, where we’ve said, “OK, there’s lots of good advice out there on how to do things in data science, but how do you make it practical? How do you make it real? How do you apply those ethical principles? How do you make sure you have people with the right technical understanding in charge of projects to get value?” If, five years ago, the hype around data science was leading organisations to hire 100 data scientists in the hope that something innovative would happen, well then, we don’t want those same organisations now thinking that they need to hire 100 prompt engineers and keep their fingers crossed for something special. Our focus has been on “<a href="https://realworlddatascience.net/viewpoints/newsletter/">industrial strength data science</a>”, so I think we can extend that to show what “industrial strength LLM usage” looks like in practice.</p>
<div class="callout callout-style-simple callout-note" style="margin-top: 2.25rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Want to hear more from the RSS Data Science and AI Section? Sign up for its newsletter at <a href="https://rssdsaisection.substack.com/">rssdsaisection.substack.com</a>.</p>
</div>
</div>
</div>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../careers/posts/2023/05/11/chatgpt-data-science-pt1.html">← Read part one</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../careers/index.html">Back to Careers</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/careers/posts/2023/05/18/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/careers/posts/2023/05/18/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Images are not covered by this licence. Thumbnail image by <a href="https://unsplash.com/@deepmind?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Google DeepMind</a> on <a href="https://unsplash.com/photos/52afknBiUk4?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-12">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “Large language models: Do we need to understand the maths, or simply recognise the limitations?” Real World Data Science, May 18, 2023. <a href="https://realworlddatascience.net/careers/posts/2023/05/18/chatgpt-data-science-pt2.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Large language models</category>
  <category>AI</category>
  <category>Communication</category>
  <category>Regulation</category>
  <guid>https://realworlddatascience.net/careers/posts/2023/05/18/chatgpt-data-science-pt2.html</guid>
  <pubDate>Thu, 18 May 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/posts/2023/05/18/images/google-deepmind-52afknBiUk4-unsplash.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>How is ChatGPT changing data science?</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html</link>
  <description><![CDATA[ 




<p>For many people, it starts with a question. Something simple, something they already know the answer to. A test, in other words, to see what these AI-powered chatbots are all about. But spend any amount of time with ChatGPT and other such tools and you’ll quickly start to wonder what else they might do, and how useful they might be in your day-to-day working life.</p>
<p>Data scientists certainly have been thinking along these lines, and to find out more about current use cases, proofs of concepts and potential applications, Real World Data Science got together with members of the <a href="https://rss.org.uk/membership/rss-groups-and-committees/sections/data-science-section/">Royal Statistical Society’s Data Science and AI Section</a> (DS&amp;AI) for a group discussion.</p>
<p>Our interviewees, in order of appearance, are:</p>
<ul>
<li><strong>Piers Stobbs</strong>, VP science at Deliveroo, and DS&amp;AI committee member.</li>
<li><strong>Detlef Nauck</strong>, head of AI and data science research at BT, and editorial board member, Real World Data Science.</li>
<li><strong>Adam Davison</strong>, head of data science at the Advertising Standards Authority, and DS&amp;AI committee member.</li>
<li><strong>Trevor Duguid Farrant</strong>, senior principal statistician at Mondelez International, and DS&amp;AI committee member.</li>
<li><strong>Giles Pavey</strong>, global director for data science at Unilever, and DS&amp;AI vice-chair.</li>
<li><strong>Martin Goodson</strong>, CEO and chief scientist at Evolution AI, and DS&amp;AI committee member.</li>
</ul>
<p>The first part of our discussion focuses on how large language models are becoming part of the data science toolkit, and what this new development means for data science teams and skillsets. Stay tuned for part two, which we’ll be publishing soon!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/05/11/images/chatgpt-homescreen.png" class="img-fluid figure-img" alt="Photo of ChatGPT homescreen, by Levart_Photographer on Unsplash." width="500"></p>
</figure>
</div>
<p><strong>As data scientists, how has ChatGPT – and other tools built on large language models (LLMs) – changed your working lives?</strong></p>
<p><strong>Piers Stobbs:</strong> Up to about a year ago, although I was really impressed with the developments in deep learning and the improvements in computer vision and natural language models, it felt in line with general improvements in machine learning. And then, probably about six months ago, with things like DALL·E and ChatGPT, it felt like something changed – properly ground-breaking capabilities. And I still can’t quite get my head around the fact that you can basically have a model that tries to predict the next token, and it comes up with outputs that really feel quite sensible and human-like – if prone to <a href="https://realworlddatascience.net/viewpoints/editors-blog/posts/2022/11/23/LLM-content-warning.html">hallucination</a>.</p>
<p>The way I think about it is, this feels like a brand-new capability that we’ve just not really had before. It’s almost like an interface with unstructured information. Historically, you sort of have to turn text into something, and then turn something back into text, if you want to have this interface with humans. Now, we’ve got this really quite elegant way of plugging the gaps, which feels full of opportunities.</p>
<p>I’m having great fun playing around with the code co-pilots – GitHub’s Copilot is amazing and, productivity wise, is helping me a lot. I am now a much faster coder because there’s all those Stack Exchange lookups that I don’t have to do anymore. Again, from a personal productivity perspective, I’m using [ChatGPT] for initial drafts of documents and other things. And then I use it almost for validating things. For instance, I had a random discussion the other night with ChatGPT about logistic algorithms. It’s not going to solve problems for you, but I asked it to give some pointers of things I could be thinking about – some of which I had, some of which I hadn’t. So, it’s almost like a brainstorming helper, somehow.</p>
<p>But probably the thing I’m most excited about is the knowledge sharing side of it – plugging it into, or on top of, private information, and surfacing all that knowledge that is locked away in documents and intranet pages.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/05/11/images/piers-stobbs.png" class="img-fluid figure-img" alt="Portrait photo of Piers Stobbs"></p>
<figcaption class="figure-caption">Piers Stobbs</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>This feels like a brand-new capability – an interface with unstructured information. Historically, you have to turn text into something, and then turn something back into text, if you want to have this interface with humans. Now, we’ve got this elegant way of plugging the gaps.</p>
</div>
</div>
</div>
<p><strong>Detlef Nauck:</strong> We’re looking into running proof of concepts to see whether LLMs do bring value. Software engineering is the most obvious one, and easiest to set up and run. And then we want to look at making use of internal documents – so, either summarization or creation of internal documents in appropriate language. The latter use cases are trickier to evaluate. We want to know whether the outputs produced are any good. With software engineering you can track GitHub statistics, for example. But if you give ChatGPT to somebody to write marketing material, or to get information out of a document, how do you know that the results are good? We need to get our head around metrics for evaluation.</p>
<p><strong>Adam Davison:</strong> I’ve been using it for basically anything where I don’t remember the API very well or it’s a bit confusing. <a href="https://pandas.pydata.org/">Pandas</a> is the key, right? We all use pandas, but you don’t really remember how to do some complicated thing with <code>apply()</code>, say, so you just ask GPT-4 to give you the answer, and it saves you that hassle. Also, I read some insightful tweet that said these chat systems are really good for things where generating the solution is hard, but verifying it is easy. And I think that’s true for some of these things. You know, you get a short piece of Python code, you can basically look at that and you can tell if it’s right.</p>
<p>In data science, you’re a bit of a jack-of-all-trades. You need to do little bits of everything, but you’re not a specialist in anything. And so, I think for software development, it’s been really helpful. For example, right now, I’m doing a bit of frontend development in a project to visualise something. I’m never going to be a professional frontend developer, but GPT-4 can help deal with the oddities of JavaScript much more easily than it would be for me to trawl through Stack Overflow posts.</p>
<p>But the thing that we’re using it for, practically, is natural language processing (NLP) and classification. We have this particular problem at the Advertising Standards Authority (ASA) where we are running lots of different models that are completely unconnected to each other because every project is a different topic. So, one week we’re looking at, “Do these gambling ads appeal to young people?” and then the week after it’s, “Are these cryptocurrency ads being clear about the risks involved?” It’s very disparate, we don’t have a lot of time to iterate on models, and we don’t have huge amounts of training data. Ten years ago, when you were doing sentiment classification, you were on Mechanical Turk getting 10,000 examples, and even then it didn’t work very well after these really complicated models. Now, you’ve got a couple of hundred examples and with the embeddings [from LLMs] you can get to a pretty decent classifier quite quickly. We’re also starting to experiment with using OpenAI’s fine-tuning tools, and the performance that we’ve seen from that is very impressive, to the extent that it’s making us rethink whether we bother doing anything else in some of our classifiers.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/05/11/images/adam-davison.png" class="img-fluid figure-img" alt="Portrait photo of Adam Davison"></p>
<figcaption class="figure-caption">Adam Davison</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>Five years ago, if you had a sophisticated problem involving text or images, you’d need a big research team with a big budget to tackle it. But increasingly we find, like many other people, that you can take models off the shelf and repurpose them for quite diverse tasks.</p>
</div>
</div>
</div>
<p><strong>Trevor Duguid Farrant:</strong> My organisation is not as far forward as the rest of you. I’ve introduced it to the leadership team, and the digital services team – what was IT – are looking to make a decision on whether we can use it or not. I think there’ll be so much pressure they’ll have to use it, but there’s still a feeling of discomfort with it, whereas I think it’s really good and have started using it. Everyone else on the call seems to have started using it. So, can organisations like the Royal Statistical Society help companies to embrace this and start using it, and then everyone can benefit from it?</p>
<p><strong>Giles Pavey:</strong> I wish I could be with Piers and Adam – actually using it – but my life has been taken over as the guy who goes and explains it to the business. Unilever is a massive business, and we are concerned about privacy, confidentiality and trustworthiness. We’ve now built an initial GPT instance on Azure and fed it with some of our own documents, and a lot of my time has been working with legal to convince ourselves that that’s okay. Now we are really trying to work out just how we manage the amazing demand for proofs of concepts and use cases – and what we’re just about to uncover, I think, is the unknown but potentially massive expense of running it.</p>
<p>In pure proofs of concepts, departments that have large knowledge banks are using it: research and development, and marketing, for example. And one of the big technical things that we’re working on – and, because of the size that we are, we’re doing a lot of work with OpenAI and Microsoft on this – is how to stop the models from hallucinating.</p>
<p><strong>Have your experiences with ChatGPT and other tools changed your thinking about the skillsets required of data scientists and data science teams?</strong></p>
<p><strong>AD:</strong> A little bit. As someone at a small organisation, I think it’s quite exciting because, five years ago, maybe you were in a world where if you had a sophisticated problem involving text or images, you’d need a big research team with a big budget to tackle it. But increasingly we find, like many other people, that you can take models off the shelf and repurpose them for quite diverse tasks. So, I think it’s becoming increasingly viable to have a small team of people who are implementers, who aren’t necessarily backed up by a big research organisation, doing increasingly sophisticated stuff.</p>
<p>I don’t think it does away with the sort of things that we always bang on about in the Data Science and AI Section, like the need for an understanding of statistics and how the underlying systems really work, because I think you still need to understand what you’re doing with LLMs, as with any other machine learning technique. But, if I had to guess, what we’re going to be seeing now is that for a lot of problems, you’re going to have more of a division – so, you’re either in one of a small number of very large labs doing research on very cutting-edge big models, or you can be an implementer who is taking things off the shelf and applying them. And maybe that space in between is going to get a little bit squeezed – that would be my guess, but obviously it’s very unpredictable.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/05/11/images/giles-pavey.png" class="img-fluid figure-img" alt="Portrait photo of Giles Pavey"></p>
<figcaption class="figure-caption">Giles Pavey</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>We’ve built an initial GPT instance on Azure. Now we are really trying to work out just how we manage the amazing demand for proofs of concepts and use cases – and what we’re just about to uncover, I think, is the unknown but potentially massive expense of running it.</p>
</div>
</div>
</div>
<p><strong>PS:</strong> That’s exactly my view. When I first started hiring data scientists, a long time ago, you basically had to write stuff from scratch, and you needed PhDs – people who really understood, at a deep level, how the maths all works. But I think there’s been a steady progression towards valuing software engineering skills, and I think, in some ways, this is another step along that path. If I think now about implementing a chatbot over your own knowledge base, it’s basically like plugging APIs together with some Python. Adam’s point is still hugely important, though, because I think we still need the background knowledge about what’s actually going on – OK, I’m creating embeddings here, and that’s allowing this search to work so I can surface the right docs – that whole process, which an average software engineer is maybe not going to know. But I think it’s definitely blurring the lines.</p>
<p><strong>Martin Goodson:</strong> It’s just as important now to understand how to evaluate performance. The difference is, it used to be that you were trying to figure out whether it’s 80% accurate, or 85%. Now, it’s like 99.9%. But you still need to figure it out. You still need to understand what the failure modes are, what caused it; how is it actually working, and is it doing what you need it to do for the product? Is it actually satisfying our needs as users or as customers of the products.</p>
<p><strong>DN:</strong> I think in the future, the skills we will need are people who can run and build these models. Giles made the point about how expensive it is to run these things. Right now, you have two options: subscribe to an API, and then you are limited in how you can modify these models; or build your own – take an open-source LLM and modify it. But then you need people who know how to build a high-performance computing environment and operate this efficiently. You need to know how to actually train the models, how to curate the data, how to set the model parameters. And I always think there’s too much alchemy still going on in this field, right? It’s not proper science. People build these things and then are surprised at what they can do; they didn’t know such things would be possible. A lot of these capabilities only emerge when you make the models really, really big and, essentially, you also have no control over them – you can’t stop them hallucinating. So, these are the kinds of issues we need to get under control if we want to get any value out of them.</p>
<p>Prompt engineering is another one – you really need to understand how these models work and how to prompt them. If you want to give them to, say, a marketer to generate copywriting, they may not have the right ideas of how to prompt the machine. So, I could see roles developing out of data science that understand how to influence these models and make them do what we want them to do.</p>
<p><strong>MG:</strong> The other angle to this is junior engineers. Now, the bar for being a useful junior engineer is that you’re better than GitHub Copilot. Why do you need a really junior person if you can just use a large language model to be the junior developer?</p>
<p><strong>DN:</strong> I’m not thinking about the data science person who needs to write some code for a project here, but if you have a large software team in an organisation that produces production code, they will become more efficient by using these tools. But still, with all this overhead of testing and putting it all together, there will be a lot of manual work that needs to be done. But the teams will get more efficient and junior people will get up to speed quicker. That’s probably another advantage.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/05/11/images/trevor-duguid-farrant.png" class="img-fluid figure-img" alt="Portrait photo of Trevor Duguid Farrant"></p>
<figcaption class="figure-caption">Trevor Duguid Farrant</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>Can the Royal Statistical Society help non-tech companies embrace large language models, extolling their virtues and dispelling the myths?</p>
</div>
</div>
</div>
<p><strong>PS:</strong> I think Detlef’s point about understanding is an interesting one. It definitely feels like there’s been this sort of continuum from, you know, “OK, it’s a linear regression, we know what’s going on” to complex models to ensemble models where, again, you’re combining these things you can individually understand. Even with big ImageNet architectures, billions of parameters, at least conceptually you can understand how these work and build out tools where you can understand the layers. To me, what’s different now is you’ve got this reinforcement learning layer on top, or diffusion layer, or some other additional approach – this combination of really complicated things. I honestly don’t know where to start with trying to understand why a specific output is generated, and I think that is a proper concern. That’s definitely an area of research, because I think we need to understand this.</p>
<p><strong>GP:</strong> I think there’s also a question in large companies of just who owns these things. Up until this point, everybody’s been happy that AI is the realm of data science. And, suddenly, generative AI looks like it might be the realm of the IT team – that it’s a service that you get off the shelf. It’s going to be interesting to see how that plays out. I really liked the point that Martin was making about being able to tell what the systems are actually doing, what they are supposed to do and how to check them, because if you don’t have a background in that area, you might just assume they work. Now, nobody knows exactly how these things work – not even the people who build them. But having a background in how you test things, for potential causes for things not working, is actually going to be incredibly powerful or useful.</p>
<p><strong>TDF:</strong> Will experts like us actually be able to check it because of the speed that new versions are coming out and the developments that are happening? Is it going to take us six months to check that GPT-3.5 works? Well, too late, a month later GPT-4’s out! I just think that pace is going to keep accelerating.</p>
<div class="callout callout-style-simple callout-note" style="margin-top: 2.25rem;">
<div class="callout-body d-flex">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-body-container">
<p>Want to hear more from the RSS Data Science and AI Section? Sign up for its newsletter at <a href="https://rssdsaisection.substack.com/">rssdsaisection.substack.com</a>.</p>
</div>
</div>
</div>
<div class="nav-btn-container">
<div class="grid">
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../careers/index.html">Back to Careers</a></p>
</div>
</div>
<div class="g-col-12 g-col-sm-6">
<div class="nav-btn">
<p><a href="../../../../../careers/posts/2023/05/18/chatgpt-data-science-pt2.html">Read part two →</a></p>
</div>
</div>
</div>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img src="https://realworlddatascience.net/careers/posts/2023/05/11/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1" style="height:22px!important;vertical-align:text-bottom;"><img src="https://realworlddatascience.net/careers/posts/2023/05/11/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1" style="height:22px!important;margin-left:3px;vertical-align:text-bottom;"></a> This interview is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photos are not covered by this licence. Portrait photos are supplied by interviewees and used with permission. ChatGPT homescreen photo by <a href="https://unsplash.com/@siva_photography?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Levart_Photographer</a> on <a href="https://unsplash.com/photos/drwpcjkvxuU?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</p>
</div>
<div class="g-col-12 g-col-md-12">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “How is ChatGPT changing data science?” Real World Data Science, May 11, 2023. <a href="https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Large language models</category>
  <category>AI</category>
  <category>Skills</category>
  <category>People</category>
  <guid>https://realworlddatascience.net/careers/posts/2023/05/11/chatgpt-data-science-pt1.html</guid>
  <pubDate>Thu, 11 May 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/posts/2023/05/11/images/chatgpt-homescreen.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘I always thought someone like me couldn’t work in data, let alone data science’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/career-profiles/posts/2023/04/24/sami-rahman.html</link>
  <description><![CDATA[ 




<p><strong>Hi, Sami. Thank you for sharing your career story with Real World Data Science. Please tell us a little about yourself and your role in data science.</strong><br>
Hello! I’m Sami Rahman, a passionate head of data engineering and data platform at Penguin Random House, the book publisher that has enriched lives through literature. I started my career in data science five years ago and I’ve evolved into a data generalist with expertise in machine learning, data infrastructure, and data strategy.</p>
<p><strong>What does your job involve?</strong><br>
My role is about harnessing the power of data to drive extraordinary outcomes. Leading a skilled team, we empower our company to leverage data and cutting-edge technologies for informed decisions and automation. I help shape our organisation’s capabilities in data science, analytics, machine learning, data management, and strategy.</p>
<p><strong>What does “data science” mean to you?</strong><br>
Data science, to me, is a captivating fusion of modern data technologies and computational statistics that tackles business challenges, crafts intelligent automation, and generates insightful revelations.</p>
<p><strong>What do you think is your most important skill as a data scientist?</strong><br>
Active listening is key. A data scientist must be surgical and precise in developing models, analysis, and tools that reinforce the company’s bottom line and operations. Data science exists to create value using data.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/career-profiles/posts/2023/04/24/images/sami-rahman.png" class="img-fluid figure-img" alt="Portrait photo of Sami Rahman"></p>
<figcaption class="figure-caption">Photo supplied by Sami Rahman, used with permission.</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>As I’ve transitioned into management, maintaining my coding prowess is an ongoing challenge. I stay sharp by doing data science and infrastructure development for fun, leveraging tools like ChatGPT and AirOps where I’m rusty.</p>
</div>
</div>
</div>
<p><strong>How did you get into data science?</strong><br>
I began with a psychology degree, which led to working as business psychologist where I discovered psychometric data analysis. After a master’s in countering organised crime and terrorism and a few short jobs in counter terrorism/intelligence, I decided that it wasn’t for me. I embraced my love for statistics and research, I dove into data science, learning Python through online platforms, and secured my first data scientist role at a WPP agency called Essence.</p>
<p><strong>What, or who, first inspired you to become a data scientist?</strong><br>
I always thought someone like me couldn’t work in data, let alone data science. <a href="https://www.wbs.ac.uk/about/person/suzy-moat/">Dr Suzy Moat’s</a> fascinating talk on machine learning’s application to human behaviour and psychology showed me that a psychologist could make a significant impact in this field, inspiring my aspiration to try to have a data science career.</p>
<p><strong>What were the hurdles or challenges that you needed to overcome on your route into the profession?</strong><br>
Breaking into data science without a typical background in maths/computer science/physics was daunting. Building a Kaggle portfolio and coding models for fun prepared me for interviews. Another challenge was learning to harmonise my “data brain” and “business brain” to solve problems efficiently. Understanding how data solutions impact business problems will always propel you forward. </p>
<p><strong>And what are the challenges that you face now, as a working data scientist?</strong><br>
As I’ve transitioned into management, maintaining my coding prowess is an ongoing challenge. I stay sharp by doing data science and infrastructure development for fun, leveraging tools like ChatGPT and AirOps where I’m rusty. I’m currently building my own cloud data platform and running a lot of image neural networks on it.</p>
<p><strong>What was your first job in data science, and how does it compare to your current role?</strong><br>
As an analytics executive at WPP agency Essence, I tackled data science, cloud engineering, and analytics problems for clients. They were a lot more singular and tactical in nature. Now, as head of data engineering and data platform at Penguin Random House, I focus on shaping data and technology strategy to align with the company’s broader vision.</p>
<p><strong>What was the most important thing you learned in your first year on the job?</strong><br>
To always consider the bigger picture: how your work integrates with the organisation/client’s objectives, delivers value, and aligns with the aspirations of other stakeholders. Actionable insights and value is the most important thing.</p>
<p><strong>What have been your career highlights so far?</strong><br>
Two shining moments include being the first of three of HSBC UK fraud data science leaders, where each of our departments tackled a different type of crime and protected our customers, and developing data strategies and capabilities for analytics, science, and business intelligence at Penguin Random House.</p>
<p><strong>Have there been any mistakes or regrets along the way?</strong><br>
I regret not delving deeper into natural language processing (NLP) or spatial data science, which are now more accessible and growing fields within data science. I reckon the NLP methodologies would’ve been extremely useful seeing as I’m at a publishing company now!</p>
<p><strong>How do you think your role will evolve over the rest of your career?</strong><br>
As data technologies become more accessible, I anticipate data roles will transform. I envision a future where data professionals focus on general AI, quantum machine learning, and multi-dimensional data analytics as traditional specialisms become democratised.</p>
<p><strong>If you were starting out in data science now, what three things would you put at the top of your reading/study list?</strong><br>
I’d recommend <em>Skin in the Game</em> by Nassim Nicholas Taleb, <em>Calling Bullshit: The Art of Scepticism in a Data-Driven World</em> by Jevin West and Carl Bergstrom,  and <em>Artificial Intelligence: How Machine Learning Will Shape the Next Decade</em> by Matthew Burgess.</p>
<p><strong>What personal or professional advice would you give for anyone wanting to be a data scientist now?</strong><br>
Success in data science hinges on understanding how it can transform organisations and engaging with business stakeholders. My advice: never stop listening to the business – the stakeholders are your biggest allies. I would also try to find your niche that sets you apart from everyone else. Mine when I first started in the field was my expertise on computational psychology and behavioural machine learning. </p>
<p><strong>What new ideas or developments in the field of data science are you personally most excited about or intrigued by?</strong><br>
Transfer learning excites me most, as numerous large technology companies now offer pre-trained models based on billions/trillions of parameters. This will revolutionise industries worldwide, as it will be easier to build more performant models even if a company has less data.</p>
<p><strong>What do you think will be the main challenges facing data science as a field in the next few years?</strong><br>
The challenge lies in staying relevant amidst the democratisation of data science. Through large language models, low-code, and transfer learning, advanced data science methods will become easier for non-specialists to do and use. Innovation and keeping up with modern data technologies will be crucial.</p>
<div class="article-btn">
<p><a href="../../../../../../careers/career-profiles/index.html">Discover more Career profiles</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/04/24/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/04/24/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>. Photo of Sami Rahman is not covered by this licence.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘I always thought someone like me couldn’t work in data, let alone data science.’” Real World Data Science, April 24, 2023. <a href="https://realworlddatascience.net/careers/career-profiles/posts/04/24/sami-rahman.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Publishing</category>
  <category>Data engineering</category>
  <category>Data strategy</category>
  <category>Machine learning</category>
  <guid>https://realworlddatascience.net/careers/career-profiles/posts/2023/04/24/sami-rahman.html</guid>
  <pubDate>Mon, 24 Apr 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/career-profiles/posts/2023/04/24/images/sami-rahman-bw.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>The politics of performance measurement</title>
  <dc:creator>Noah Wright</dc:creator>
  <link>https://realworlddatascience.net/careers/posts/2023/04/18/politics-of-performance-measurement.html</link>
  <description><![CDATA[ 




<p>At the beginning of 2016, the Criminal Justice Division (CJD) of the Texas Governor’s Office received news all government agencies dread: budgets were to be cut. CJD oversaw a grant program that funded specialty courts throughout the state, however it was now being told that the program’s budget of $10.6m would be reduced 20% to $8.5m by 2018.</p>
<p>How should these cuts be distributed among grant holders? CJD had no meaningful performance data on which to base its decisions, and I would know: I was hired by the agency just a few months before to analyze grant performance. Still, decisions needed to be made. We had to come up with a plan of action, and the clock was ticking…</p>
<p>This is a story of making opportunity out of crisis, of the interaction between not just theory of change and technical implementation, but the “political” process of negotiating these changes with stakeholders in a manner that led to better decisions. Through careful outreach and continuous communication, we developed a data collection and performance assessment process that enabled us to allocate budget cuts in a manner widely accepted.</p>
<p>The story ends on a bittersweet note. But, along the way, there are lessons to be learned about how to find common ground, manage expectations, forge productive working partnerships, and sustain a data science project longer term.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/04/18/images/crowd-of-voices.png" class="img-fluid figure-img" alt="A crowd of people talking, with speech bubbles representing the different voices, digital art. Image created by Real World Data Science using Microsoft Bing Image Creator" width="500"></p>
</figure>
</div>
<section id="step-1-consider-your-options" class="level2">
<h2 class="anchored" data-anchor-id="step-1-consider-your-options">Step 1: Consider your options</h2>
<p>Texas had over 150 specialty courts in 2016, providing a program of specialized services – usually drug treatment – to offenders as an alternative to incarceration. About half of the state’s specialty courts received CJD grant funds (and about half of grantees received 100% of their program budget from our grants). Funding cuts of the size we needed to make would not go over well with them. Any changes to the program would have to run a gauntlet of decision-makers including advisory boards, interest groups, and professional associations, most with contacts in the legislature.</p>
<p>Complicating this situation further, CJD didn’t even make the final funding decisions. We administered the grants, but the merit review process fell to the Specialty Courts Advisory Council, an appointed group of specialty courts staff and related experts who annually scored the grant applications we received. We needed to get them onboard.</p>
<p>The way our Executive Director saw it, we had three options to implement the cut in a way that could get us buy-in from stakeholders and the Advisory Council:</p>
<ol type="1">
<li><strong>Cut across the board.</strong> The Advisory Council would employ the same scoring method as the previous year but reduce each grant amount by 20%.</li>
</ol>
<p>This option would leave long-running grantees scrambling to make up for this shortfall by reducing services, laying off staff, or spending more of their limited local funds. Worse, it would punish all grantees equally – our most successful programs would be arbitrarily defunded.</p>
<ol start="2" type="1">
<li><strong>Fewer grants.</strong> Grants were scored based on the quality of their application and all grants that passed a certain threshold got funded. The Advisory Council would employ the same scoring method as the previous year but instead of funding the top $10.6m worth of grants, they would fund the top $8.5m worth.</li>
</ol>
<p>This seemed a less bad option than cutting across the board, but we would still run into the problem of arbitrarily defunding successful programs. Grants near the bottom of the Advisory Council’s cutoff that got funded the previous year would be denied renewal only because the goalposts had moved.</p>
<ol start="3" type="1">
<li><strong>Targeted funding.</strong> The Advisory Council would incorporate performance data and statewide strategic plan alignment into their scoring method and make cuts accordingly.</li>
</ol>
<p>At the time, the Advisory Council did not take performance into consideration when scoring grant applications. They agreed in theory that a grant requesting its tenth annual renewal should perhaps at some point be assessed on its outcomes, but they had never seen CJD commit to a rigorous performance assessment process before. We administered the grants, not them, so without our commitment to develop a performance assessment process, and their trust in that commitment, this would not be a viable option.</p>
<p>After due consideration, option 3 emerged as the favorite of our Executive Director. On the face of it, this seemed the most “objective” approach to take. We would let the data decide who gets funded and who doesn’t, rather than cutting arbitrarily. But that would be a fallacious argument. Data does not decide. It might inform our decisions, but it would be up to us to choose the structure of the performance measurement process: what aspects to focus on, what data to collect, what benchmarks to set – all of which would later help determine funding decisions. And in any funding decision, politics inevitably plays a role.</p>
<p>Politics is, in its broadest sense, the negotiated decision-making between groups with opposing interests. And in developing our performance measurement process we would encounter a variety of interests – from the Advisory Council down to the grantees themselves. Success would require us to acknowledge stakeholder perspectives and address or manage them appropriately. Planning decisions made in the early phases of a project as a result of political processes directly influence the type and scope of analysis a data scientist will eventually be able to perform, so it behooves the data scientist to participate in these processes!</p>
</section>
<section id="step-2-engage-stakeholders-and-define-performance" class="level2">
<h2 class="anchored" data-anchor-id="step-2-engage-stakeholders-and-define-performance">Step 2: Engage stakeholders and define performance</h2>
<p>Having settled on our preferred option, our Executive Director convened a strategy session with the Advisory Council to discuss how to proceed as part of a broader strategic plan. The session began by achieving consensus on high-level goals such as “fund strategically”, “focus on success”, “build capacity”, etc. The session also helped the Advisory Council and CJD alike to clarify our conception of how we ought to fit into the specialty courts field going forward. CJD would develop its performance assessment system to help the Advisory Council target funding, but that would come as part of a larger plan that included capacity building, training and technical assistance, helping courts obtain non-CJD sources of funding, and steering grantees toward established best practice.</p>
<p>We left the meeting with a very basic plan that looked good on paper. Our Executive Director set to work persuading our external stakeholders of the wisdom of this new strategic direction. Meanwhile, I had to build a performance assessment process that people could trust.</p>
<p>CJD had no formally designated standards to measure performance data against. However, drug courts have been around for decades and there existed a large body of research supporting the program model.<sup>1</sup> Offering supervised drug treatment instead of incarceration had been repeatedly shown to cost less money and lower recidivism rates. I performed a literature review and spoke with numerous subject matter experts to get started on defining program-specific performance metrics.</p>
<p>I was conscious that imposing metrics without any feedback or input from affected parties would all but guarantee bad-faith engagement, especially if these metrics are tied to funding. A problem inherent to any performance measurement is that once something gets measured as a performance outcome, it warps the very processes it is intended to measure. This phenomenon happens so frequently that the phrase “Campbell’s Law” was coined to describe it in 1979.<sup>2</sup> Think of standardized testing at schools: once the government ties test performance to school funding it creates powerful incentives for schools to improve test scores at any cost. Even in the absence of outright cheating, struggling schools feel massive pressure to adjust their curriculum, to the point where they teach test score optimization strategies more than math, language, history, and science.</p>
<p>I consistently heard from specialty court scholars and practitioners alike that arrest recidivism would be the ideal outcome measure. On paper, recidivism was a direct expression of long-term program success and could also be used as an outcome variable for classification modeling. And, in practice, a court could do little to affect recidivism by way of manipulation. Courts do not make arrests – police make arrests. Once a specialty court participant finished a program, the court itself no longer intervened in their lives. If a participant got arrested within 1-3 years of completion, the program had no say in the matter.</p>
<p>This, however, presented an implementation problem: one-year recidivism data would, by definition, take a year past the point of implementation to collect, i.e., not soon enough to inform our cuts. And while recidivism was the best measure of success, it could not be the only measure. Recidivism was, after all, a stochastic process not within the court’s control – a crime wave or other systemic factors could move recidivism up and make it look like a successful court had actually failed. We would have to use something else as well.</p>
<p>The National Association of Drug Court Professionals (NADCP) publishes a book of best practice standards, and our stakeholders identified a court’s adherence to these standards as another strong performance assessment standard. These criteria, unlike recidivism, were directly under the program’s control. Does your program have the recommended staff? Does your program drug test participants frequently enough to guarantee sobriety? Does your program meet with participants regularly enough? Do you offer a continuum of services instead of a “one-size-fits-all” approach?</p>
<p>In addition to being much easier to measure than recidivism, best practice adherence also resists Campbell’s Law by avoiding outcome measurement. In our school metaphor, this would be like measuring school performance based on student-to-teacher ratio, variety of course offerings, attendance rates, and teacher qualifications. Far from perfect, but measuring a variety of elements that predict success and taking them as a whole represents a vast improvement over a single, easily-gamed outcome measure.</p>
<p>But to operationalize these standards, we would have to have good data.</p>
</section>
<section id="step-3-update-processes-and-collect-data" class="level2">
<h2 class="anchored" data-anchor-id="step-3-update-processes-and-collect-data">Step 3: Update processes and collect data</h2>
<p>We inherited a longstanding process in which grantees had to fill out a form every six months asking them to report performance data. This is a screenshot of what that form looked like:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/posts/2023/04/18/images/screenshot.png" class="img-fluid figure-img" alt="A screenshot of a data table containing example data collected from grantees in the Texas speciality courts funding program, prior to the development of a new performance measurement process."></p>
</figure>
</div>
<p>No additional definitions or instructions were provided, leaving grantees with many questions: Does the request for “annual data” mean as of fiscal year or calendar year? What counts as a person being “assessed for eligibility”? And so on. Grantees did not know the answers, and neither did we. And these were the more straightforward measures. The form went on for 10 pages, most of which asked grantees to report extensively on information they had already provided as part their application.</p>
<p>This disaster of an assessment process did have a silver lining. When we announced we were throwing out these forms entirely we faced almost no pushback from grantees.</p>
<p>We knew from the start that our new assessment process would need to collect individual-level participant data instead of aggregated measures. Even with clear definitions, 75 grants would mean 75 different aggregations at work. Asking the grantees to report their individual-level participant data in a consistent format and doing the aggregations ourselves meant a single aggregation at work.</p>
<p>But we needed to establish trust with grantees before making this request. Strictly speaking, we could mandate the reporting of this data. However, if that angered enough of our grantees, they or their contacts might take it up with our bosses at the Governor’s Office, and our bosses could cancel any plan we came up with if they thought it was not worth the fuss. So, from day one we communicated clearly to all grantees that we would maintain total transparency when it came to definitions and calculations. Before we used any calculated metric to assess performance we would send it to the grantees themselves to review for accuracy.</p>
<p>To avoid the vagueness and inscrutability that characterized the old reporting process, every piece of data we asked for in the new process had a clear written definition and specific reason for being asked. These reasons usually amounted to some combination of best practices, Advisory Council recommendations, and grantee suggestions.</p>
<p>Implementing the new process was far from easy, however. We faced numerous administrative and technical barriers. Texas courts at this time did not share a common case management system, so we couldn’t just get a data export from everybody. Meanwhile, the Governor’s Office banned all of its divisions from all usage of the cloud. This forced us to build a more labor-intensive reporting process, in which courts would obtain blank Excel templates with required data fields. Courts had either to fill out these templates by hand or export their case management data and reconfigure it to template specifications. Then, courts submitted their data for review and we sent back any bad formatting.</p>
<p>We collected preliminary data at the six-month mark and made another adjustment based on these results, which we would not count toward performance measurement. A majority of courts had some kind of data error in this first case. Specific definitions of data fields had to be written and rewritten using grantee feedback over the course of the year, leading to significant changes between the six-month reports and the year-end reports.</p>
<p>Importantly, we had developed reporting requirements iteratively with participation from grantees and the Advisory Council from the start. By mid-2017 we had so successfully achieved buy-in that only one grantee court’s judge refused to give us data (the court’s grant manager later sent it to us).</p>
</section>
<section id="step-4-analyze-and-report-findings" class="level2">
<h2 class="anchored" data-anchor-id="step-4-analyze-and-report-findings">Step 4: Analyze and report findings</h2>
<p>In the course of this process, we established the benchmarks in Table 1 based on best practices and justification for funding. Because this was our initial rollout, we set the specific values low to function more as minimum standards than targets.</p>
<div class="figure-caption">
<p><strong>Table 1:</strong> Specialty court best practices translated into quantitative measures.</p>
</div>
<table class="table">
<colgroup>
<col style="width: 34%">
<col style="width: 19%">
<col style="width: 46%">
</colgroup>
<thead>
<tr class="header">
<th>Benchmark</th>
<th style="text-align: center;">Best practice</th>
<th>Rationale</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1. Number of participants</td>
<td style="text-align: center;">10+</td>
<td>CJD decision: programs should be of sufficient size to justify a grant</td>
</tr>
<tr class="even">
<td>2. Number of graduates</td>
<td style="text-align: center;">5+</td>
<td>CJD decision: programs should be of sufficient size to justify a grant</td>
</tr>
<tr class="odd">
<td>3. Graduation rate</td>
<td style="text-align: center;">20%-90%</td>
<td>CJD decision: 0% and 100% success rates are both red flags</td>
</tr>
<tr class="even">
<td>4. Average amount of time graduates spent in program (in months)</td>
<td style="text-align: center;">12-24</td>
<td>NADCP best practice recommended program lengths of 1-2 years</td>
</tr>
<tr class="odd">
<td>5. Percent of graduates employed, seeking education, or supported through family, partner, SSI, etc.</td>
<td style="text-align: center;">100%</td>
<td>NADCP best practice recommended against releasing participants without financial support, which all but guarantees relapse or rearrest.</td>
</tr>
<tr class="even">
<td>6. Percent of participants with “low-risk” assessment score</td>
<td style="text-align: center;">0%</td>
<td>NADCP best practice recommended moderate- or high-risk participants. Research had shown that low-risk participants get little benefit.</td>
</tr>
<tr class="odd">
<td>7. Average sessions per participant per month</td>
<td style="text-align: center;">1+</td>
<td>NADCP best practice recommended sessions be held at least monthly.</td>
</tr>
</tbody>
</table>
<p>Grantee performance data for each benchmark would be generated from the individual level data that courts sent us. Crucially, we sent our aggregations back to grantees for confirmation prior to using them in any kind of evaluation, alongside the program-wide average and the best practice values for comparison (example in the table below). If something didn’t look right, they had the chance to let us know before we took their numbers as final.</p>
<div class="figure-caption">
<p><strong>Table 2:</strong> Specialty court best practices compared with program-wide averages and grantee reported values.</p>
</div>
<table class="table">
<colgroup>
<col style="width: 47%">
<col style="width: 17%">
<col style="width: 17%">
<col style="width: 17%">
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Benchmark</strong></td>
<td style="text-align: center;"><strong>Best practice</strong></td>
<td style="text-align: center;"><strong>Program-wide average</strong></td>
<td style="text-align: center;"><strong>Grantee reported values</strong></td>
</tr>
<tr class="even">
<td>1. Number of participants</td>
<td style="text-align: center;">10+</td>
<td style="text-align: center;">89</td>
<td style="text-align: center;">96</td>
</tr>
<tr class="odd">
<td>2. Number of graduates</td>
<td style="text-align: center;">5+</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">27</td>
</tr>
<tr class="even">
<td>3. Graduation rate</td>
<td style="text-align: center;">20%-90%</td>
<td style="text-align: center;">71%</td>
<td style="text-align: center;">56%</td>
</tr>
<tr class="odd">
<td>4. Average amount of time graduates spent in program (in months)</td>
<td style="text-align: center;">12-24</td>
<td style="text-align: center;">17</td>
<td style="text-align: center;">14</td>
</tr>
<tr class="even">
<td>5. Percent of graduates employed, seeking education, or supported through family, partner, SSI, etc.</td>
<td style="text-align: center;">100%</td>
<td style="text-align: center;">95%</td>
<td style="text-align: center;">100%</td>
</tr>
<tr class="odd">
<td>6. Percent of participants with “low-risk” assessment score</td>
<td style="text-align: center;">0%</td>
<td style="text-align: center;">18%</td>
<td style="text-align: center;">2%</td>
</tr>
<tr class="even">
<td>7. Average sessions per participant per month</td>
<td style="text-align: center;">1+</td>
<td style="text-align: center;">2</td>
<td style="text-align: center;">3.7</td>
</tr>
</tbody>
</table>
<p>In the end, we found seven grants that we could unequivocally recommend be cut. Two of the seven had effectively never gotten off the ground, and served almost no participants the entire year. The other five served mostly low-risk participants, the type of people that research had shown do not benefit from specialty court programs. Some of these grantees were inevitably disappointed at the decision, but we had so actively worked within the field to develop and justify our processes that they understood why the decision had been made.</p>
</section>
<section id="factors-for-success" class="level2">
<h2 class="anchored" data-anchor-id="factors-for-success">Factors for success</h2>
<p>In the span of one year, CJD went from collecting a large volume of useless data to a specific, targeted collection of data informed by best practices. The new collection process had high grantee compliance and stakeholder buy-in.</p>
<p>The following factors proved essential to getting to a place where we had useful, reliable data upon which to base future data science efforts:</p>
<ol type="1">
<li><dl>
<dt>Discontent with status quo</dt>
<dd>
<p>The Advisory Council wanted CJD to play a more active support role in the field. Meanwhile, everyone disliked the existing performance assessment process. As a result, most of the challenges we faced along the way related to implementation rather than defending the status quo on its merits.</p>
</dd>
</dl></li>
<li><dl>
<dt>A catalyst for change</dt>
<dd>
<p>Despite existing discontent, it took a funding shortfall to kickstart the process of change. It would have been unlikely for us to be able to create this system <em>a priori</em>.</p>
</dd>
</dl></li>
<li><dl>
<dt>Continuous, high-quality communication</dt>
<dd>
<p>We could impose rules and requirements all day long, but without good faith engagement from the grantees we could never collect the quality of data we needed. Note that “continuous communication” does not mean “tell them everything you do at every point”. People become overwhelmed by torrents of information.</p>
</dd>
</dl></li>
<li><dl>
<dt>Humility and flexibility</dt>
<dd>
<p>Had we begun this process assuming we had all of the answers, we would have been dead in the water. Continuous outreach and willingness to take criticism and suggestions shaped the process as it progressed, ultimately producing a better end-product than we could have devised on our own.</p>
</dd>
</dl></li>
<li><dl>
<dt>An established program model</dt>
<dd>
<p>Drug courts have been around for decades, with a vast body of supporting research and a community of practitioners and scholars we could speak to. That meant we could focus on implementation and execution instead of determining if the model worked or not.</p>
</dd>
</dl></li>
<li><dl>
<dt>Strong leadership support</dt>
<dd>
<p>From the very beginning, we could not have accomplished what we did without the full support and advocacy of our Executive Director.</p>
</dd>
</dl></li>
</ol>
</section>
<section id="coda-why-knowledge-transfer-is-vital" class="level2">
<h2 class="anchored" data-anchor-id="coda-why-knowledge-transfer-is-vital">Coda: Why knowledge transfer is vital</h2>
<p>I wish I could write a follow-up article about how we started using classification modeling to identify the most successful programs and to promote better approaches and practices; about how we iterated the process through multiple funding cycles, tuning and perfecting it to better meet stakeholder needs. But I cannot.</p>
<p>The performance assessment system we built had some major weaknesses from the outset. It was labor intensive, not required by law, produced no immediate benefit to the agency itself, and was so new it had yet to be entrenched in agency practice. In other words, no institutional incentives worked in its favor. Only the continual push of our Executive Director and myself kept this new performance assessment system going, and once we left the agency, it foundered.</p>
<p>Still, the experience taught me much. I learned first and foremost that programs do not sustain themselves. Most of our attention had been focused on building up the best process we could. Only a minimal effort had been spent on institutionalizing and sustaining it. We had written documentation but no fundamental changes in policy or rule. We had undertaken groundbreaking efforts and built relationships, but had not planned for any meaningful knowledge transfer to other staff. While we had intended to eventually do these things, fate took us away before we could get them in place.</p>
<p>For any kind of change to last, sustainability must be built in from the start. In the moment, these actions can seem low-priority. Policy and rule changes can be arduous and time-consuming. Knowledge transfer from one stably employed staff to another feels redundant and wasteful. But without embedding sustainability, no success will outlast the individual people pushing for it.</p>
<div class="article-btn">
<p><a href="../../../../../careers/index.html">Back to Careers</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-12">
<dl>
<dt>About the author</dt>
<dd>
<strong>Noah Wright</strong> is a data scientist with the Texas Juvenile Justice Department. He is interested in the applications of data science to public policy in the context of real-world constraints, and the ethics thereof (ethics being highly relevant in his line of work). He can be reached on <a href="https://www.linkedin.com/in/noahdwright/">LinkedIn</a>.
</dd>
</dl>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Noah Wright
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/posts/2023/04/18/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/posts/2023/04/18/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This article is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Wright, Noah. 2023. “The politics of performance measurement.” Real World Data Science, April 18, 2023. <a href="https://realworlddatascience.net/careers/posts/2023/04/18/politics-of-performance-measurement.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>


</section>


<div id="quarto-appendix" class="default"><section id="footnotes" class="footnotes footnotes-end-of-document"><h2 class="anchored quarto-appendix-heading">Footnotes</h2>

<ol>
<li id="fn1"><p>Some newer types of courts (Commercial Sexual Exploitation, Mental Health, Veterans) had a much more limited body of research and had to be accommodated separately. For the sake of keeping this narrative coherent I’m focusing on drug courts, which were the majority of our programs.↩︎</p></li>
<li id="fn2"><p>Rodamar, Jeffery. 2018. “There ought to be a law! Campbell versus Goodhart.” <em>Significance</em> 15 (6): 9. <a href="https://doi.org/10.1111/j.1740-9713.2018.01205.x" class="uri">https://doi.org/10.1111/j.1740-9713.2018.01205.x</a>↩︎</p></li>
</ol>
</section></div> ]]></description>
  <category>Problem definition</category>
  <category>Stakeholder communication</category>
  <category>Relationship management</category>
  <guid>https://realworlddatascience.net/careers/posts/2023/04/18/politics-of-performance-measurement.html</guid>
  <pubDate>Tue, 18 Apr 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/posts/2023/04/18/images/crowd-of-voices.png" medium="image" type="image/png" height="105" width="144"/>
</item>
<item>
  <title>‘Data science challenges you to keep learning – there’ll always be new advances in the field’</title>
  <dc:creator>Brian Tarran</dc:creator>
  <link>https://realworlddatascience.net/careers/career-profiles/posts/2023/03/28/tamanna-haque.html</link>
  <description><![CDATA[ 




<p><strong>Hi, Tamanna. Thank you for sharing your career story with Real World Data Science. Please tell us a little about yourself and your role in data science.</strong><br>
I’m Tamanna Haque. I’ve been working at Jaguar Land Rover for nearly four years, recently promoted to lead data scientist working within product engineering. It’s coming up to eight years that I’ve been working in the field, and my areas of interest are the use of machine learning to provide the best products and experiences for my customers and stakeholders.</p>
<p><strong>What does your job involve?</strong><br>
My role involves using the connected car and AI to make our products and customer experiences better, whilst leading within our wide data science team too. The data science team in Manchester, UK, originated with myself and one of my teammates – it’s since grown to nearly 40 (cross-sites and countries) and developed into a high-performing, advanced data science team.</p>
<p>What makes us stand out is the nature of our work – we mostly use vehicle data (of participating customers), which is different to a lot of other commercial businesses or teams who’ll focus more on transactional or web data. The data we use lends itself to some pretty interesting projects, and a general futuristic feel here.</p>
<p>I’m particularly interested and active in enabling a more electric and modern luxury future from the use of vehicle data.</p>
<p><strong>What does “data science” mean to you?</strong><br>
The realisation of value! Whether that is added revenue, saved costs or improved growth, I’m led by what data science can do for the business and its customers. The use of data science can open up many exciting, value-adding opportunities.</p>
<div class="pullquote-container">
<div class="grid">
<div class="g-col-12 g-col-lg-4">
<div class="quarto-figure quarto-figure-left">
<figure class="figure">
<p><img src="https://realworlddatascience.net/careers/career-profiles/posts/2023/03/28/images/tamanna-haque.png" class="img-fluid figure-img" alt="Black and white portrait photo of Tamanna Haque"></p>
<figcaption class="figure-caption">Photo supplied by Tamanna Haque, courtesy of Jaguar Land Rover. Used with permission.</figcaption>
</figure>
</div>
</div>
<div class="g-col-12 g-col-lg-8 pullquote-grid pullquote">
<p><img src="https://realworlddatascience.net/images/pullquote-purple.png" class="img-fluid" width="50"></p>
<p>There are more routes to getting into data science nowadays, but it’s important to not lose sight of fundamentals such as statistics and mathematics. A lot of people can code-up models but it’s fair to say that only a portion of them appreciate how to do this responsibly.</p>
</div>
</div>
</div>
<p><strong>What do you think is your most important skill as a data scientist?</strong><br>
I’ve always presented myself as a technically astute data scientist, even when entering leadership. But my niche is my ever-growing commercial awareness and passion about our products, customers and business. These aren’t new qualities, but they now align with my professional interests, as well as personal (I’ve been a fan of the Jaguar brand since childhood)!</p>
<p><strong>How did you get into data science?</strong><br>
I did a maths degree at the University of Manchester, where I specialised in statistics. I didn’t do any post-graduate education and this was fine for me.</p>
<p>After graduating, I joined a digital fashion retailer (with a financial services proposition) as an analyst initially. I learned a lot about real-life data and analytics itself, whilst developing a rounded understanding about the business and how to deal with stakeholders cross-functionally. I must have served a few hundred at least(!) and left most of the ‘fancy’ stuff I learned at university aside, whilst getting to grips with so many aspects of commercial analytics. A great way for me to set solid foundations for what followed, and I personally feel this gives me a lens that others who dive straight into data science don’t have.</p>
<p>I was soon attracted to data science because it tapped into what I learned at university and challenges you to keep learning; there’ll always be things to learn, and new advances in the field.</p>
<p><strong>What, or who, first inspired you to become a data scientist?</strong><br>
I have a twin sister, we’ve always been together throughout education. Even before we graduated together, she secured her first role as an analyst. This opened my eyes to data, and data science followed for us both!</p>
<p><strong>What were the hurdles or challenges that you needed to overcome on your route into the profession?</strong><br>
I had a few people tell me I couldn’t do data science, possibly because I didn’t fit the typical data scientist stereotype in several ways. I think attitudes in the field have changed over time though and on a personal level, it’s motivated me to give it everything, and I can’t regret that.</p>
<p><strong>And what are the challenges that you face now, as a working data scientist?</strong><br>
I need to manage my diary well to ensure effectiveness and work-life balance. I’m overseeing people, other projects, doing public speaking and trying to remain hands on. I sometimes block out chunks of time in my diary – I need some meeting-free time to produce quality technical work. I try to finish on time and enjoy a very busy social life with my family and friends. A flexible attitude to how we work helps to keep me happy and energised whilst I’m delivering from various angles.</p>
<p><strong>Thinking back to your earlier roles in data science, how do they compare to your current role?</strong><br>
My current role is very different to my previous roles. I’m continually learning and adapting how I can be a good leader, providing support to a breadth of colleagues (in and outside the team) whilst delivering myself. I’m actively involved in setting and refining our team’s strategy and I’m enjoying leading projects which either deliver high financial impact or help set the path in terms of new tech and/or machine learning capability. There is much more responsibility but it’s easy to stay energised when working on cars and for a business I’ve long admired.</p>
<p><strong>What was the most important thing you learned in your first year on the job?</strong><br>
I should have had more confidence in myself, but this grew – as I adjusted to the new environment I became much more assertive. My domain knowledge and data science expertise combined help to build my self-confidence, credibility and reputation.</p>
<p><strong>What have been your career highlights so far?</strong><br>
I’m most proud of my recent promotion from senior to lead data scientist. Also it was exciting for my family and I when I gained an offer to join Jaguar Land Rover.</p>
<p><strong>Have there been any mistakes or regrets along the way?</strong><br>
No, what’s meant to be will be!</p>
<p><strong>How do you think your role will evolve over the rest of your career?</strong><br>
My progression has been relatively rapid, and I hope I’ve got many, many years ahead of me in my career. It’s hard to say how my role will evolve, I have a blend of responsibilities in my role which combined provide great fulfilment for me at the moment.</p>
<p><strong>If you were starting out in data science now, what would you put at the top of your reading/study list?</strong><br>
A good understanding of analytics and the domain you’re in are my recommended prerequisites to doing data science.</p>
<p>Analytics is an important part of the data science lifecycle, being able to get the data yourself and communicate results with influence, for example, are just a few aspects of analytics which underpin successful data science projects.</p>
<p>Also, without awareness of the business and industry you’re working in, you can become very dependent on others. Data science itself can be quite challenging, so it’s great to have a solid foundation before starting out.</p>
<p><strong>What personal or professional advice would you give for anyone wanting to be a data scientist now?</strong><br>
With the level of continuous learning required to just simply keep up, it can be more of a lifestyle and not a job, so this is something to consider!</p>
<p><strong>What do you think will be the main challenges facing data science as a field in the next few years?</strong><br>
I still expect to see a skills gap in the field. There are more routes to getting into data science nowadays, but it’s important to not lose sight of fundamentals such as statistics and mathematics. A lot of people can code-up models but it’s fair to say that only a portion of them appreciate how to do this responsibly, understanding samples versus populations, statistical testing, which type of regularisation to use in a neural network, et cetera.</p>
<p>I also think there’s a challenge of questionable data science products reaching high levels of popularity and usage amongst the public… Some recent developments in this space have been extremely intelligent but raise ethical concerns. Just because something can be done with AI doesn’t mean it should, and my preferences are towards AI being ethical and (ideally) explainable.</p>
<div class="article-btn">
<p><a href="../../../../../../careers/career-profiles/index.html">Discover more Career profiles</a></p>
</div>
<div class="further-info">
<div class="grid">
<div class="g-col-12 g-col-md-6">
<dl>
<dt>Copyright and licence</dt>
<dd>
© 2023 Royal Statistical Society
</dd>
</dl>
<p><a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> <img style="height:22px!important;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/03/28/https:/mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://realworlddatascience.net/careers/career-profiles/posts/2023/03/28/https:/mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a> This work is licensed under a Creative Commons Attribution 4.0 (CC BY 4.0) <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;"> International licence</a>, except where otherwise noted.</p>
</div>
<div class="g-col-12 g-col-md-6">
<dl>
<dt>How to cite</dt>
<dd>
Tarran, Brian. 2023. “‘Data science challenges you to keep learning – there’ll always be new advances in the field.’” Real World Data Science, March 28, 2023. <a href="https://realworlddatascience.net/careers/career-profiles/posts/03/28/tamanna-haque.html">URL</a>
</dd>
</dl>
</div>
</div>
</div>



 ]]></description>
  <category>Automotive</category>
  <category>Analytics</category>
  <category>Leadership</category>
  <category>Machine learning</category>
  <guid>https://realworlddatascience.net/careers/career-profiles/posts/2023/03/28/tamanna-haque.html</guid>
  <pubDate>Tue, 28 Mar 2023 00:00:00 GMT</pubDate>
  <media:content url="https://realworlddatascience.net/careers/career-profiles/posts/2023/03/28/images/tamanna-haque-crop.png" medium="image" type="image/png" height="105" width="144"/>
</item>
</channel>
</rss>
